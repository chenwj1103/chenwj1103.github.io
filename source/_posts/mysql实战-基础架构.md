---
title: mysql实战-基础架构
copyright: true
date: 2020-08-11 10:53:58
tags: mysql
categories: mysql
---

####  mysql的架构逻辑

![mysql的逻辑架构图](/images/mysql2/mysql的逻辑架构图.png)

< !-- more -->

> - 连接器：负责跟客户端建立连接、获取权限、维持和管理连接；建议使用长连接，定期断开长连接，或者定期进行重置连接；
>
> - 分析器：包括词法分析：多个字符串和和空格组成的sql语句，需要识别出里面的字符串分别代表什么，表字段是否存在，是否正确，是否有歧义；之后要做语法分析，就是判断一些语法规则，比如select需要符合什么规则；
>
> - 优化器：优化器选择使用什么索引，使用连接的顺序等都是需要进行优化的；
>
> - #### 执行器：先判断是否有权限，然后进行遍历每一个满足条件的行并且执行操作；

#### mysql的日志系统

> - redo log 日志，是innodb存储引擎特有的日志 [wal机制](https://www.cnblogs.com/hzmark/p/wal.html)
>
> 如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高
>
>  `redo日志`：当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB。
>
> 有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为**crash-safe**。
>
> - binlog日志
>
>   binlog是MySQL的Server层实现的，所有引擎都可以使用，他记录的是原始语句；
>
> - 两种日志的不同点
>
>   > 1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
>   > 2. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。
>   > 3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
>
> - 执行update语句的执行流程
>
>   >  update T set c=c+1 where ID=2;
>   >
>   > 1. 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
>   > 2. 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
>   > 3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。
>   > 4. 执行器生成这个操作的binlog，并把binlog写入磁盘。
>   > 5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。
>   
> - redo日志两阶段提交
>
>   > 流程是：redolog的prepare状态，写入binlog，然后commit；这样来保证两个日志存储的数据一致；
>   >
>   > 主要是为了让redo日志和binlog日志之间的逻辑一致；两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案。
>   >
>   > 如果不是两阶段提交，使用任意一个日志恢复出来的数据都有可能和原来的库里的数据不一致。
>
> - 参数设置
>
>   >  innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失
>   >
>   > ```
>   > 如果把innodb_flush_log_at_trx_commit设置成1，那么redo log在prepare阶段就要持久化一次，因为有一个崩溃恢复逻辑是要 依赖于prepare 的redo log，再加上binlog来恢复的
>   > ```
>   >
>   > sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。
>
> - 数据持久化的过程
>
>   >  在记账的例子中，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。
>   >
>   > 掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是flush。在这个flush操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。
>   >
>   > **当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”**。
>   >
>   >  
>   >
>   > MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。
>   >
>   >   **刷脏页的情况：**
>   >
>   > - `InnoDB的redo log写满了`。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写
>   > - `对应的就是系统内存不足`。 当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
>   > - 对应的就是MySQL认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”
>   > - MySQL正常关闭的情况。
>
> - redo log和change buffer的区别
>
>   >  **redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。**
>
> - 如果某次写入使用了change buffer机制，之后主机异常重启，是否会丢失change buffer和数据。
>
>   >  虽然是只更新内存，但是在事务提交的时候，我们把change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。
>
> - mysql是如何保证数据不丢失的
>
>   > 结论： 
>   >
>   > 只要redo log和binlog保证持久化到磁盘，就能确保MySQL异常重启后，数据可以恢复。
>
>   
>
> - binlog的写入流程
>
>   > `binlog的写入机制`：事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。
>   >
>   > 
>   >
>   > 一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了binlog cache的保存问题 
>   >
>   >  
>   >
>   > 系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大 小。如果超过了这个参数规定的大小，就要暂存到磁盘。
>   >
>   > 
>   >
>   > 事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache.
>   >
>   >  
>   >
>   > ![binlog写盘状态](/images/mysql2/binlog写盘状态.png)
>   >
>   > 可以看到，每个线程有自己binlog cache，但是共用同一份binlog文件。  
>   >
>   > - 图中的write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。 
>   >
>   > - 图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的IOPS。
>   >
>   > write 和fsync的时机，是由参数sync_binlog控制的:
>   >
>   > 1.  sync_binlog=0的时候，表示每次提交事务都只write，不fsync;
>   > 2.  sync_binlog=1的时候，表示每次提交事务都会执行fsync;
>   > 3.  sync_binlog=N(N>1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。
>   >
>   > 
>   >
>   > 出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日 志量的可控性，一般不建议将这个参数设成0，比较常⻅的是将其设置为100~1000中的某个数值
>
>   
>
> - redo log的写入流程
>
>   >  事务在执行过程中，生成的redo log是要先写到redo log buffer的。
>   >
>   > 
>   >
>   > redo log buffer里面的内容，是不是每次生成后都要直接持久化到磁盘呢?  不需要
>   >
>   > 
>   >
>   >  事务还没提交的时候，redo log buffer中的部分日志有没有可能被持久化到磁盘呢? 有可能
>   >
>   > 
>   >
>   > ![redoLogCunchuzhuangtai](/images/mysql2/redoLogCunchuzhuangtai.png)
>   >
>   > - 存在redo log buffer中，物理上是在MySQL进程内存中，就是图中的红色部分;
>   > - 写到磁盘(write)，但是没有持久化(fsync)，物理上是在文件系统的page cache里面，也就是图中的⻩色部分; 
>   > - 持久化到磁盘，对应的是hard disk，也就是图中的绿色部分。
>   >
>   >  
>   >
>   > 为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，它有三种可能取值:
>   >
>   > - 设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中; 
>   > - 设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘;
>   > - 设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。
>   >
>   >  
>   >
>   > InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的page cache，然后调用fsync持久化到磁盘。
>   >
>   > 
>   >
>   > 两种场景会让一个没有提交的事务的redo log写入到磁盘中:
>   >
>   > 
>   >
>   > - 一种是，**redo log buffer**占用的空间即将达到 **innodb_log_buffer_size**一半的时候，后台线程会主动写盘。注意，由于 这个事务并没有提交，所以这个写盘动作只是write，而没有调用fsync，也就是只留在了文件系统的page cache。
>   >
>   > - 另一种是，并行的事务提交的时候，顺带将这个事务的**redo log buffer**持久化到磁盘。
>   >
>   > 
>
> - 组提交
>
>   > 日志逻辑序列号(log sequence number，LSN)。LSN是单调递增的，用来对应redo log的一个个写入点。每次写入⻓度为length的redo log， LSN的值就会加上length。
>   >
>   >  
>   >
>   > 过程
>   >
>   > -  trx1是第一个到达的，会被选为这组的 leader;
>   > - 等trx1要开始写盘的时候，这个组里面已经有了三个事务，这时候LSN也变成了160;
>   > - trx1去写盘的时候，带的就是LSN=160，因此等trx1返回时，所有LSN小于等于160的redo log，都已经被持久化到磁盘; 4. 这时候trx2和trx3就可以直接返回了。
>   >
>   > binlog也有相同的机制
>
> - WAL机制主要得益于两个方面
>
>   > - redo log 和 binlog都是顺序写，磁盘的顺序写比随机写速度要快;
>   > - 组提交机制，可以大幅度降低磁盘的IOPS消耗。
>
> - **MySQL**现在出现了性能瓶颈，而且瓶颈在**IO**上，可以通过哪些方法来提升性 能呢?
>
>   > 1. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。
>   >
>   >    这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的⻛险。
>   >
>   > 2. 将sync_binlog 设置为大于1的值(比较常⻅是100~1000)。这样做的⻛险是，主机掉电时会丢binlog日志。
>   >
>   > 3. 将innodb_flush_log_at_trx_commit设置为2。这样做的⻛险是，主机掉电的时候会丢数据。
>
> - 常见日志问题
>
>   > 1. 执行一个update语句以后，我再去执行hexdump命令直接查看ibd文件内容，为什么没有看到数据有改变呢? 
>   >
>   >    **回答: ** 这可能是因为WAL机制的原因。update语句执行完成后，InnoDB只保证写完了redo log、内存，可能还没来得及将数据写到磁盘。
>   >
>   > 2. 为什么binlog cache是每个线程自己维护的，而redo log buffer是全局共用的?
>   >
>   >    **回答:** MySQL这么设计的主要原因是，binlog是不能“被打断的”。一个事务的binlog必须连续写，因此要整个事务完成后，再 一起写到文件里。而redo log并没有这个要求，中间有生成的日志可以写到redo log buffer中。redo log buffer中的内容还能“搭便⻋”，其他事务 提交的时候可以被一起写到磁盘中。
>   >
>   > 3. 事务执行期间，还没到提交阶段，如果发生crash的话，redo log肯定丢了，这会不会导致主备不一致呢?
>   >
>   >     **回答:**不会。因为这时候binlog 也还在binlog cache里，没发给备库。crash以后redo log和binlog都没有了，从业务⻆度看这个事务也没有提交，所以数据是一致的。
>   >
>   > 4. 如果binlog写完盘以后发生crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是bug?
>   >
>   >    **回答:**不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit完成了，备库也收到binlog并执行了。但是主库和客 户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不 能认为是bug。
>
> - 数据库的crash-safe保证的是:
>
>   > - 如果客户端收到事务成功的消息，事务就一定持久化了;
>   > - 如果客户端收到事务失败(比如主键冲突、回滚等)的消息，事务就一定失败了;
>   > -  如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部 (数据和日志之间，主库和备库之间)一致就可以了。
>
> - 什么情况下需要设置生产库设置为双非1
>
>   > 1.  业务高峰期。一般如果有预知的高峰期，DBA会有预案，把主库设置成“非双1”。
>   > 2.  备库延迟，为了让备库尽快赶上主库。
>   > 3. 用备份恢复主库的副本，应用binlog的过程，这个跟上一种场景类似。
>   > 4. 批量导入数据的时候。
>

#### 主从同步

> - binlog可以用来归档，也可以用来做主备同步
>
> - 建议你把备库设置成只读模式；
>
> - **主从同步流程**
>
>   > 1. 在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位 置包含文件名和日志偏移量。
>   > 2. 在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与 主库建立连接。
>   > 3. 主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。
>   > 4. 备库B拿到binlog后，写到本地文件，称为中转日志(relay log)。
>   > 5. sql_thread读取中转日志，解析出日志里的命令，并执行。
>
>   MySQL5.6以前的版本复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。 MySQL5.6版本参数slave-parallel-workers=1 表示启用多线程功能
>
> - 三种格式对比
>
>   > - statement 
>   >
>   >   > 查看日志文件 ：show binlog events in 'master.000001'; 
>   >   >
>   >   > 记录的是原始的修改数据库的数据的sql；
>   >   >
>   >   > `占用较小的空间，比如删除所有表的数据，但是存在问题，delete from t limit 1 使用不同索引不同，导致删除数据不同，有可能导致主从不一致 `
>   >   >
>   >   > 
>   >
>   > - row
>   >
>   >   > 查看日志文件 ：
>   >   >
>   >   > ```
>   >   > show binlog events in 'master.000001';
>   >   > mysqlbinlog -vv data/master.000001 --start-position=8900
>   >   > ```
>   >   >
>   >   > 记录的是真实的对应的删除的主键id、或者具体的插入的数据；
>   >   >
>   >   > `可以准确记录操作的数据，但是由于记录需要删除很多数据，所以很耗费空间`
>   >
>   >   
>   >
>   > - mixed
>   >
>   >   >  Mixed 方法利用了两种格式的优点。
>   >   >
>   >   > 设置为mixed后，就会记录为row格式;而如果执行的语句去掉limit 1，就会记录为statement格式。
>   >   >
>   >   > mixed格式可以利用statment格式的优点，同时又避免了数据不一致的⻛险。
>   >   >
>   >   > 
>
> - 双M结构的数据库
>
>   > 节点A和B之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。
>   >
>   > 
>   >
>   > 业务逻辑在节点A上更新了一条语句，然后再把生成的binlog 发给节点B，节点B执行完这条更新语句后也会生成binlog。
>   >
>   >  
>   >
>   > 如果节点A同时是节点B的备库，相当于又把节点B新生成的binlog拿过来执行了一次，然后节点A和B间，会不断地循 环执行这个更新语句，也就是循环复制了。这个要怎么解决呢?
>   >
>   >  
>   >
>   > **解决方案**
>   >
>   > - 规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系;
>   > - 一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog;
>   >
>   > - 每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这个日志是自己生成的，就直接 丢弃这个日志。
>   >
>   >  
>   >
>   > 按照这个逻辑，如果我们设置了双M结构，日志的执行流就会变成这样:
>   >
>   > - 从节点A更新的事务，binlog里面记的都是A的server id;
>   > - 传到节点B执行一次以后，节点B生成的binlog  的server id也是A的server id;
>   > - 再传回给节点A，A判断到这个server id与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。



#### 事务

>  查询数据的时候，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。
>
> - 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。
> - 在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。
> - “读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；
> - “串行化”隔离级别下直接用加锁的方式来避免并行访问。
>
> 视图是通过undolog日志来实现的，就是当系统里没有比这个回滚日志更早的read-view的时候，这些日志会被清除。
>
> ***为什么建议你尽量不要使用长事务？***
>
> > 1. 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
> >
> > 2. 导致死锁的产生；
>
> - 查询大事务
>
>   >  select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
>   >
>   > 
>
> - 如何避免大事务
>
>   > - 尽可能的减小事务范围，少用长事务，如果无法避免，保证逻辑日志空间足够用（innodb_undo_tablespaces），并且支持动态日志空间增长。
>   >
>   > - 监控Innodb_trx表，发现长事务报警。
>
> - 事务中一个数据的可见性分析：读
>
>   >  对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能：
>   >
>   > 1. 如果低于低水位，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
>   > 2. 如果高于高水位，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
>   > 3. 如果在高低水位之间，那就包括两种情况
>   >      a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见；
>   >      b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。
>
> - 事务中一个数据的可见性分析：写
>
>   > 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。
>   >
>   > 当前读是要加锁的；
>
> - **事务的可重复读的能力是怎么实现的？**
>
>   > 可重复读的核心就是一致性读（consistent read）；
>   >
>   > 而事务更新数据的时候，只能用当前读（当前读是要加锁）。
>   >
>   > 如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

#### 索引

> - 重建索引
>
>   正常重建二级索引，使用删除、新增的方式是合理的；但是重建主键索引这种方式是不合理的，因为删除主键索引需要删除所有的数据
>
> - 为什么不适用hash、数组、平衡二叉树存储索引？
>
>   索引的维护：索引需要维护可能出现页分裂，页合并的问题；
>
> - 索引下推
>
> 在5.6之前，在联合索引中使用部分索引的情况需要找到对应的主键后立即回表查询；MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少`回表次数`。
>
> - 注意事项
>
>   > - 在不影响排序结果的情况下，在取出主键后，回表之前，会在对所有获取到的主键排序
>   >
>   > - 默认按照“查询使用的索引”排序
>
> - 普通索引和唯一索引
>
>   > 第一种情况是，**这个记录要更新的目标页在内存中**。这时，InnoDB的处理流程如下：
>   >
>   > - 对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；
>   > - 对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。
>   >
>   > 这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。
>   >
>   > 第二种情况是，**这个记录要更新的目标页不在内存中**。这时，InnoDB的处理流程如下：
>   >
>   > - 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
>   > - 对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。
>
>   这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。
>
> - mysql选择错误的索引
>
>   > MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。
>   >
>   > 
>   >
>   >  ```
>   > 这个统计信息就是索引的“区分度”，这个基数越大，索引的区分度越好
>   > 
>   > show index from table；
>   > 
>   > 统计数据是使用采样统计，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。
>   > 
>   > 而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过1/M的时候，会自动触发重新做一次索引统计。 innodb_stats_persistent
>   >  ```
>   >
>   > **analyze table t 命令，可以用来重新统计索引信息**
>   >
>   > 
>   >
>   > 其次还可以使用explain查看rows扫描的行。由于有可能回表，所以有可能不使用索引，直接全表扫描。
>   >
>   >  
>   >
>   > **一种方法是，采用force index强行选择一个索引**
>   >
>   > **第二种方法就是，我们可以考虑修改语句，引导MySQL使用我们期望的索引**
>   >
>   > **第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。**
>
> - 前缀索引
>
>   > - 如果使用前缀索引，损失是可能会增加额外的记录扫描次数。由于区分度比较低，需要拿到主键后回表比较；
>   > - **使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。**
>   >
>   > - 方法：判断不同前缀的区分度
>   >
>   >   ```
>   >   select count(distinct email) as L from SUser;
>   >   
>   >    select 
>   >     count(distinct left(email,4)）as L4,
>   >     count(distinct left(email,5)）as L5,
>   >     count(distinct left(email,6)）as L6,
>   >     count(distinct left(email,7)）as L7,
>   >   from SUser;
>   >   ```
>   >
>   > - 问题：使用前缀索引 有可能没办法用到覆盖索引；
>   >
>   > - 总结
>   >
>   >   > 1. 直接创建完整索引，这样可能比较占用空间；
>   >   > 2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
>   >   > 3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
>   >   > 4. 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。
>   >
>   >   



#### 锁

> - 锁分为表锁、行锁。
> - 表锁主要用于大批量导入数据，或者修改表结构的时候；
> - 行锁是存储引擎自己实现的，innodb支持行锁，MyLSAM就不支持行锁；
>
> **如何给小表加字段**
>
> >  首先我们要解决长事务，事务不提交，就会一直占着表锁。在MySQL的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务；
>
> **如何给小表热点表加字段**
>
> >  这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程
> >
> > ```
> > ALTER TABLE tbl_name NOWAIT add column ...
> > ALTER TABLE tbl_name WAIT N add column ...
> > ```
>
> **两阶段锁协议**
>
> 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。
>
> 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
>
> **如何避免死锁**
>
> - 使用表锁；
> - 按照相同的顺序获取锁资源；
> - 一次获取所有的锁资源；
>
> **如何处理死锁**
>
> 1. 进入等待直到超时，这种可以设置innodb_lock_wait_timeout参数，默认是50s；
>
>    `存在问题` ：设置时间不好处理，50s太久了，1s假如是普通的锁等待，由会出现很多误伤；
>
> 2. 另一种策略是发起死锁检测，发现死锁后，主动回滚另一个事务，让其他事务继续执行；innodb_deadlock_detect将该参数设置为on；
>
>    （show engine innodb status 可以查看最近检测到的死锁）
>
>    `存在问题`：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。消耗cpu资源。
>
> 3. 最终思路是减少访问相同资源的并发事务量；
>
>    

#### 如何释放表空间

> - 删除整个表
>
> > Innodb_file_per_table 为on的话表示每个InnoDB表数据存储在一个以 .ibd为后缀的文件中，独立表空间；使用drop table的话可以把.ibd文件删除，释放表空间；
>
> - 删除行的表空间
>
>   > 正常的删除行记录，只是在b+树中将记录逻辑删除，后续插入数据的时候替换原有的数据；但是这个是有范围限制的；分为b+树的行复用和页复用；
>   >
>   >  
>   >
>   > delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的；
>
> - 重建表释放表空间，同时释放碎片空间
>
>   > 你可以新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。
>   >
>   > - 5.5版本之前 alter table A engine=InnoDB命令来重建表；
>   >
>   > - 5.5之后需要使用online DDL：因为将数据插入到新表中的时候是online的会花很长时间，导致请求不可用； 
>   >
>   >   > 流程如下：
>   >   >
>   >   > 1. 建立一个临时文件，扫描表A主键的所有数据页；
>   >   > 2. 用数据页中表A的记录生成B+树，存储到临时文件中；
>   >   > 3. 生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；
>   >   > 4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；
>   >   > 5. 用临时文件替换表A的数据文件。
>
> - 使用命令重建表
>
>   > - 从MySQL 5.6版本开始，alter table t engine = InnoDB（也就是recreate）默认的就是上面图4的流程了；
>   > - analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；
>   > - optimize table t 等于recreate+analyze。
>   > - Truncate 可以理解为drop+create

#### order by 工作原理

> 
>
> ![order by 是如何工作的](/images/mysql2/order by 是如何工作的.png)
>
> - 流程如下：
>
>   1. 初始化sort_buffer，确定放入name、city、age这三个字段；
>   2. 从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；
>   3. 到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中；
>   4. 从索引city取下一个记录的主键id；
>   5. 重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；
>   6. 对sort_buffer中的数据按照字段name做快速排序；
>   7. 按照排序结果取前1000行返回给客户端。
>
> - 原因
>
>   > 1. 可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。排序的数据量小于sort_buffer_size，排序就在内存（sort_buffer）中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序（使用多个文件归并排序）。
>   > 2. 除了上边的全字段排序算法还有这种rowId排序算法。 max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。
>
>   如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了（全字段排序），不用再回到原表去取数据（rowId排序）。
>
>   **如果内存够，就要多利用内存，尽量减少磁盘访问。**
>
> - 优化
>
>   > 1. 我们可以在这个市民表上创建一个city和name的联合索引。使用这个联合索引的查询出来的数据是按照name排序的，这样就不用使用临时文件进行排序。
>   > 2. 我们可以创建一个city、name和age的联合索引，使用覆盖索引，不用回表查询；
>
> - 升级
>
>   > ```
>   > select * from t where city in ('杭州',"苏州") order by name limit 100; //已经有了city_name(city, name)这个联合索引
>   > ```
>   >
>   >  还是会file_sort  因为联合索引中只用到city索引，且使用到的事rowId排序算法。
>
> - 排序算法总结
>
>   > **全字段排序**
>   >
>   > 1. 通过索引将所需的字段全部读取到sort_buffer中
>   > 2. 按照排序字段进行排序
>   > 3. 将结果集返回给客户端
>   >
>   > 
>   >
>   > - 缺点：
>   >
>   > 1. 造成sort_buffer中存放不下很多数据，因为除了排序字段还存放其他字段，对sort_buffer的利用效率不高
>   > 2. 当所需排序数据量很大时，会有很多的临时文件，排序性能也会很差
>   >
>   > - 优点：MySQL认为内存足够大时会优先选择全字段排序，因为这种方式比rowid 排序避免了一次回表操作
>   >
>   >
>   > **rowid排序**
>   >
>   > 1. 通过控制排序的行数据的长度来让sort_buffer中尽可能多的存放数据，max_length_for_sort_data
>   > 2. 只将需要排序的字段和主键读取到sort_buffer中，并按照排序字段进行排序
>   > 3. 按照排序后的顺序，取id进行回表取出想要获取的数据
>   > 4. 将结果集返回给客户端
>   >
>   > - 优点：更好的利用内存的sort_buffer进行排序操作，尽量减少对磁盘的访问
>   >
>   > - 缺点：回表的操作是随机IO，会造成大量的随机读，不一定就比全字段排序减少对磁盘的访问
>   >
>   > 
>   >
>   > **按照排序的结果返回客户所取行数**

#### 索引失效的情况

> 1. 查询条件中在索引列上使用函数
> 2. like "%_" 百分号在前. 
> 3. or关键字使用
> 4. not in ,not exist 不等于等反向操作； 
> 5. 单独引用复合索引里非第一位置的索引列. 
> 6. 字符型字段为数字时在where条件里不添加引号（隐式转换）. 
> 7. 对小表查询；

#### 幻读详解

> 幻读指的是一个事务在前后两次`查询同一个范围`的时候，后一次查询看到了前一次查询没有看到的行。
>
> 幻读是当前读才出现的，且幻读特指看到了新插入的行。
>
> 间隙锁：**跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作**。仅仅是插入，查询的话没问题；
>
> 间隙锁记为开区间，把next-key lock记为前开后闭区间

#### 间隙锁

>  **我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。**
>
> 1. 原则1：加锁的基本单位是next-key lock。next-key lock是前开后闭区间。
> 2. 原则2：查找过程中访问到的对象才会加锁。
> 3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
> 4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
> 5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。
>
> 读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。
>
> ![加gap锁的问题](/images/mysql2/加gap锁的问题.png)
>
> 

#### 饮鸩止渴的提高性能的方法

> - 数据库连接不够用，干掉占用连接，但不工作的线程
>
>   > 1. show processlist 查看线程；
>   > 2. 取出sleep状态且要查看具体事务状态，information_schema库的innodb_trx表
>   > 3. 服务端断开连接使用的是kill connection + id
>
> - 慢查询导致的原因
>
>   > 1. 索引没有设计好
>   >
>   >    > 比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库A、备库B，这个方案的大致流程是这样的: 
>   >    >
>   >    > - 在备库B上执行 set sql_log_bin=off，也就是不写binlog，然后执行alter table 语句加上索引;
>   >    > -  执行主备切换;
>   >    > -  这时候主库是B，备库是A。在A上执行 set sql_log_bin=off，然后执行alter table 语句加上索引
>   >    >
>   >    > 这是一个“古老”的DDL方案
>   >
>   > 2. sql语句没有写好
>   >
>   >    > ```
>   >    > 可以通过改写SQL语句来处理。MySQL 5.7提供了query_rewrite功能
>   >    > 
>   >    > mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from call query_rewrite.flush_rewrite_rules();
>   >    > ```
>   >
>   > 3. mysql选错了索引
>   >
>   >    >  使用force index
>   >
>   >    
>
> - **QPS**突增问题
>
>   > 由上线新功能或者程序bug导致的某个语句的QPS突然暴涨；
>   >
>   > - 如果新功能是单独的用户，可以使用管理员把用户删除；
>   > - 可以使用query-rewrite功能重写sql  改为  select 1;

#### mysql的高可用

>  在从库上执行  show slave status，返回的 seconds_behind_master表示备库延迟了多少。
>
>  **主备延迟的原因**
>
>  1. 备库所在机器的性能要比主库所在的机器性能差。
>
>  2. 备库的压力大；
>
>    > 使用一主多从；
>    >
>    > 使用binlog或者消息队列同步到外部系统进行查询；
>
>  3. 大事务，大事务10分钟；
>
>    > 不要使用一条sql删除大量的数据；
>    >
>    > 大表的ddl；
>
>  4. 备库的并行复制能力
>
>  **主备切换-可靠性优先策略**（这个是使用HA工具操作的，不是手动操作的）
>
>  > 1. 判断备库B现在的seconds_behind_master，如果小于某个值(5秒)继续下一步，否则持续重试这一步
>  > 2. 把主库A改成只读状态，即把readonly设置为true;（`主库A和备库B都处于readonly状态，也就是说这时系统处 于不可写状态`）短时间
>  > 3. 判断备库B的seconds_behind_master的值，直到这个值变成0为止;
>  > 4. 把备库B改成可读写状态，也就是把readonly 设置为false;
>  > 5. 把业务请求切到备库B。
>
>  **主备切换-可用性优先策略**
>
>  > 如果我强行把步骤4、5调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那 么系统几乎就没有不可用时间了。
>  >
>  > 可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。
>
>  **基于位点的主备切换**
>
>  >  节点B设置成节点A’的从库的时候，需要执行一条change master命令
>  >
>  > ```
>  > CHANGE MASTER TO 
>  > MASTER_HOST=$host_name 
>  > MASTER_PORT=$port 
>  > MASTER_USER=$user_name 
>  > MASTER_PASSWORD=$password 
>  > master_auto_position=1 //就表示这个主备关系使用的是GTID协议
>  > ```
>  >
>  > 

#### 读写分离的方案和坑

>  **客户端直连和带proxy的读写分离架构区别**
>
> - 客户端直连方案，因为少了一层proxy转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便
> - 带proxy的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作
>
> **读写分离会导致主从延迟读取不到数据的问题**
>
> > - 强制走主库方案
> >
> >   > 对于部分的需要强一致性的请求，可以使用强制走主库的方案；
> >
> > - sleep方案;
> >
> >   >  用户发起请求前，先执行一次sleep操作；
> >   >
> >   >  或者由前端执行ajax异步请求；
> >
> > - 判断主备无延迟方案;
> >
> >   > 每次执行查询前执行 select slave master命令，查看seconds_behind_master查看主从延迟时间；
> >   >
> >   > 对比位点
> >   >
> >   > 对比GTID
> >
> > - 配合semi-sync方案
> >
> >   >  也就是半同步机制。存在问题是存在过度等待的问题；
> >   >
> >   > 1. 事务提交的时候，把主库的binlog发送给从库；
> >   > 2. 从库收到后返回主库一个ack，表示收到了；
> >   > 3. 从库收到ack后，才返回给客户端事务完成的确认；
> >
> > - 等主库位点方案;
> >
> >   > 1. trx1事务更新完成后，⻢上执行show master status得到当前主库执行到的File和Position;
> >   >
> >   > 2. 选定一个从库执行查询语句;
> >   >
> >   > 3. 在从库上执行select master_pos_wait(File, Position, 1);  
> >   >
> >   >    参数file和pos指的是主库上的文件名和位置; 
> >   >
> >   >     timeout可选，设置为正整数N表示这个函数最多等待N秒。
> >   >
> >   > 4. 如果返回值是M>=0的正整数，则在这个从库执行查询语句;
> >   >
> >   > 5. 否则，到主库执行查询语句。
> >
> > - 等GTID方案。

#### 误删除数据库

> 恢复数据，建议在临时库上做处理，然后恢复到主库。因为这期间这些数据有可能被别的事务修改；
>
> - 使用delete语句误删数据行;
>
>   > 可以用Flashback工具通过闪回把数据恢复回来。 Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row 和binlog_row_image=FULL。
>   >
>   > `建议`： 把sql_safe_updates参数设置为on。这样一来，如果我们忘记在delete或者update语句中写where条件，或者where条件里面没有包含索引字段的话，这条语句的执行就会报错
>
> - 使用drop table或者truncate table语句误删数据表;
>
>   >  使用truncate /drop table和drop database命令删除的数据，无法使用日志恢复。只能使用全量备份进行恢复；
>   >
>   >  在临时库上做恢复后，拿到除了误删库的语句的日志进行恢复；
>   >
>   > 
>
> - 使用drop database语句误删数据库;
>
>   >  使用5.6版本后的 延迟复制备库的方式 。延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。
>
> - 使用rm命令误删整个MySQL实例。
>
> **建议**
>
> > - 建议做成自动化工具，经常演练。这样不至于手忙脚乱的处理突发状况；
> > - 账号分离。这样做的目的是，避免写错命令。DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。
> > - 制定操作规范。这样做的目的，是避免写错要删除的表名。在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表

#### kill操作没有立即完成的状态

> kill ( connection )+线程id  ,并不是立即断开连接，告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。防止这个线程加了MDL锁，被强制kill掉后没办法释放锁。
>
> 这些“kill不掉”的情况，其实是因为发送kill命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。而被kill的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的。
>
> 
>
> 1. **线程没有执行到判断线程状态的逻辑**，需要等待；
> 2. **终止逻辑耗时较长**，

#### join的执行原理和使用

>  **流程**
>
> ```
> select * from t1 straight_join t2 on (t1.a=t2.a);
> ```
>
> 1. 从表t1中读入一行数据 R；
>
> 2. 从数据行R中，取出a字段到表t2里去查找；
>
> 3. 取出表t2中满足条件的行，跟R组成一行，作为结果集的一部分；
>
> 4. 重复执行步骤1到3，直到表t1的末尾循环结束。
>
>    
>
> 在这个join语句执行过程中，`驱动表是走全表扫描`，而被驱动表是走树搜索。
>
> **注意**
>
> 1. 在使用join的时候，应该让小表做驱动表
> 2. 如果可以使用被驱动表的索引，join语句还是有其优势的；
> 3. 不能使用被驱动表的索引，只能使用Block Nested-Loop Join算法（可能会因为join_buffer不够大，需要对被驱动表做多次全表扫描），这样的语句就尽量不要使用。
> 4. 大量查询导致Buffer Pool的热数据被淘汰，影响内存命中率
>
> **优化**
>
> 回表查询的主键id如果是不连续的，则查询会变为随机IO；
>
> `MRR优化的设计思路`：
>
> > 1. 根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;
> > 2. 将read_rnd_buffer中的id进行递增排序；
> > 3. 排序后的id数组，依次到主键id索引中查记录，并作为结果返回。
> >
> > read_rnd_buffer的大小是由read_rnd_buffer_size参数控制的。如果步骤1中，read_rnd_buffer放满了，就会先执行完步骤2和3，然后清空read_rnd_buffer。之后继续找索引a的下个记录，并继续循环

#### innoDB的LRU算法

> innoDB按照5:3的比例把整个LRU链表分成了young区域和old区域。LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域 
>
> InnoDB对Bufffer Pool的LRU算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在old区域。如果1秒之后这个数据页不再被访问了，就不会被移动到LRU链表头部，这样对Buffer Pool的命中率影响就不大。young区的数据，是正常的LRU，会被移动到头部。
>
> 
>
> 





























