---
title: 高并发设计思想
copyright: true
date: 2020-06-02 14:25:13
tags: 高并发
categories: 高并发
---

#### 高并发系统的通用设计方案

> - 横向扩展：分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量；还有一种是直接升级机器提高单个服务器处理请求的能力；
> - 缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击；
> - 异步：在某些场景下，未处理完成之前，我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求；
>
> **高并发系统的演进应该是循序渐进，以解决系统中存在的问题为目的和驱动力的。**

#####  磁盘的结构以及慢的原因

> 1. 我们知道数据是放在持久化存储中的，一般的持久化存储都是使用磁盘作为存储介质的，而普通磁盘数据由机械手臂、磁头、转轴、盘片组成，盘片又分为磁道、柱面和扇区。
>
> 2. 盘片是存储介质，每个盘片被划分为多个同心圆，信息都被存储在同心圆之中，这些同心圆就是磁道。在磁盘工作时盘片是在高速旋转的，机械手臂驱动磁头沿着径向移动，在磁道上读取所需要的数据。我们把磁头寻找信息花费的时间叫做寻道时间。
>
> 3. 普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 ns（纳秒）级别，从千兆网卡上读取数据的时间是在μs（微秒）级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。

##### 异步处理的例子

> - 我们熟知的 12306 网站。当我们订票时，页面会显示系统正在排队，这个提示就代表着系统在异步处理我们的订票请求。
>
> - 采用异步的方式，后端处理时会把请求丢到消息队列中，同时快速响应用户，告诉用户我们正在排队处理，然后释放出资源来处理更多的请求。订票请求处理完之后，再通知用户订票成功或者失败。
>
> - 处理逻辑后移到异步处理程序中，Web 服务的压力小了，资源占用的少了，自然就能接收更多的用户订票请求，系统承受高并发的能力也就提升了。

##### 系统的演进过程

> - 最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。
> - 随着流量的增加和业务的变化，修正架构中存在问题的点，如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。
> - 当对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题。

#### 高并发的分层架构

> 表现层、业务逻辑层、数据访问层；

##### 分层的好处

> - **分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。**
> - **再有，分层之后可以做到很高的复用。**
> - **分层架构可以让我们更容易做横向扩展。**

![阿里系统的分层规约](/images/concurrentServer/阿里系统的分层规约.png)

##### 高并发系统设计的三大目标：高并发、高性能、高可用、可扩展

> - 健康系统的 99 分位值的响应时间通常需要控制在 200ms 之内，而不超过 1s 的请求占比要在 99.99% 以上。
>
> - 系统的吞吐量：你现在有一个系统，这个系统中处理核心只有一个，执行的任务的响应时间都在 10ms，它的吞吐量是在每秒 100 次
>
> - 成本考虑，在业务平稳期，我们会预留 30%～50% 的冗余以应对运营活动或者推广可能带来的峰值流量，但是当有一个突发事件发生时，流量可能瞬间提升到 2～3 倍甚至更高

#### 如何减少频繁创建数据库连接的性能损耗？

> 池化技术的使用技巧
>
> - 池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。
> - 池子中的对象需要在使用之前预先初始化完成，这叫做池子的预热，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。
> - 池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。
>
>  [ 数据库连接池监控的使用](https://blog.csdn.net/zguoshuaiiii/article/details/78402883)
>
> - `线上建议数据库连接池是min=10 max =20-30`
> - jdk的ThreadPoolExecutor可以调用executor.getQueue().size()监控队列的使用情况

#### 数据库技术-查询请求增加时，如何做主从分离？

> - 数据库的主从复制
>
>   - MySQL 的主从复制是依赖于 binlog 的，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上二进制日志文件。主从复制就是将 binlog 中的数据从主库传输到从库上，`一般这个过程是异步`的，即主库上的操作不会等待 binlog 同步的完成。因为如果等待从库同步完返回，则写入性能会受影响，一般会优先考虑数据库性能而不是数据的强一致性；其实就是cap，保证的是a和p；
>   - 首先从库在连接到主节点时会创建一个 IO 线程，用以请求主库更新的 binlog，并且把接收到的 binlog 信息写入一个叫做 relay log 的日志文件中，而主库也会创建一个 log dump 线程来发送 binlog 给从库；同时，从库还会创建一个 SQL 线程读取 relay log 中的内容，并且在从库中做回放，最终实现主从的一致性。这是一种比较常见的主从复制方式。
>
>   ![mysql主从复制的过程](/images/concurrentServer/mysql主从复制的过程.png)
>
>   - 主库不是可以无限的挂载从库，因为每增加一个从库会消耗主库的dunp线程，同时受限于带宽的影响，所以需要一般挂载3-5个；
>
> - 主从复制实现读写分离是一种数据库横向扩展的方法；
>
> - 主从同步延迟的问题解决
>
>   - 使用消息中间件同步数据的时候，冗余发送全部数据而不是只发送id；
>
>   - **使用缓存**
>   - **查询主库**
>
> - 一般我们会把从库落后的时间作为一个重点的数据库指标做监控和报警，正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。 
>
> - 实现主从分离的方案：
>
>   - 第一种使用TDDL这种的jar包来处理，管理多个数据源；
>   - 第二种是单独部署代理层的方案，比如mycat、DBProxy(美团)，对外暴露的是一个数据库，其实内部管理多个数据源；

####  数据库优化方案（二）：写入数据量增加时，如何实现分库分表？

> - 单数据库存在的问题：
>   - 单表的数据量达到了千万甚至上亿，读写性能在下降；
>   - 数据量的增加占据了磁盘空间，数据库的备份和恢复时间太长；
>   - 不同模块的数据。比如用户数据和用户关系数据，全都存储在一个主库中，一旦主库发生故障，所有的模块儿都会受到影响
>
> - 分库分表在解决了数据`存储瓶颈`的同时也能有效的提升`数据查询的性能`，同时可以提高并发写数据的能力；
> - `垂直拆分`是按照业务类型拆分，将业务耦合度搞的表拆分到单独的表中；
> - `水平拆分`可以按照字段取模、按照时间字段的范围拆分；
> - 分库分表存在的问题
>   - `引入了分库分表键，也叫分区键`。就是对数据分库分表依据的字段；所以每次查询都要带上这个分区键。如果没有的话需要建立查询字段到数据库分区键的映射字段；
>   - `对于一些数据库的特性在实现的时候会很困难`，比如join的场景，好在这种场景不太高，如果需要的话可以查询出来在业务层处理。比如`count的情况` 我们可以单独的记录在一张表中或者记录在redis里。

#### 如何保证分库分表后ID的全局唯一性？

> - 变种的Snowflake 算法来生成业务需要的 ID 
>
>   - 时间戳（41位的时间错）、机器 ID（10位的机器id）、序列号（12位的序列号）、IDC（2位）；
>   - 每个节点每ms可以生成4096个id；
>   - 内置到代码中或者使用单独的服务来部署发号器（单实例单cpu 2万个/s）
>- UUID（UUID无法实现有序）：需要排序、且有序的可以提高mysql的查询性能、32个16进制的数字耗费空间；
> - 使用数据库的分片自增+步长的方式；

#### 在高并发场景下，数据库和NoSQL如何做到互补？

> - nosql可以提高数据库的的读写能力，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写；例如mysql在存储数据的时候使用b+树，要找到指定的位置就要进行磁盘寻址，是一种随机IO。而Nosql（Hbase、Cassandra、LevelDB ）一般使用LSM数存储，他是将数据写到一种内存中的MemTable树中，然后写到磁盘上，；
>
> - 在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持，使用ES的倒排索引来实现全文搜索；
>
> - 提高数据库的扩展能力；NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。
>
>   > 比如mongoDB的扩展性：
>   >
>   > - 一是 Replica，也叫做副本集，你可以理解为主从分离，也就是通过将数据拷贝成多份来保证当主挂掉后数据不会丢失。同时呢，Replica 还可以分担读请求。Replica 中有主节点来承担写请求，并且把对数据变动记录到 oplog 里（类似于 binlog）；从节点接收到 oplog 后就会修改自身的数据以保持和主节点的一致。一旦主节点挂掉，MongoDB 会从从节点中选取一个节点成为主节点，可以继续提供写数据服务。
>   > - 二是 Shard，也叫做分片，你可以理解为分库分表，即将数据按照某种规则拆分成多份，存储在不同的机器上。MongoDB 的 Sharding 特性一般需要三个角色来支持，一个是 Shard Server，它是实际存储数据的节点，是一个独立的 Mongod 进程；二是 Config Server，也是一组 Mongod 进程，主要存储一些元信息，比如说哪些分片存储了哪些数据等；最后是 Route Server，它不实际存储数据，仅仅作为路由使用，它从 Config Server 中获取元信息后，将请求路由到正确的 Shard Server 中。
>   > - 三是负载均衡，就是当 MongoDB 发现 Shard 之间数据分布不均匀，会启动 Balancer 进程对数据做重新的分配，最终让不同 Shard Server 的数据可以尽量的均衡。当我们的 Shard Server 存储空间不足需要扩容时，数据会自动被移动到新的 Shard Server 上，减少了数据迁移和验证的成本。
>

#### 数据库成为瓶颈后，动态数据的查询要如何加速？

> - 数据库磁盘IO成为系统的瓶颈后可以考虑使用缓存；内存的`寻址`100ns，磁盘的`查找`需要10ms
>
> - `缓存` 不等于内存，凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存。
>
>   ![缓存的速度](/images/concurrentServer/缓存的速度.png)
>
> - `缓冲区`：**缓冲区则是一块临时存储数据的区域，这些数据后面会被传输到其他设备上。**缓冲区更像“消息队列篇”中即将提到的消息队列，用以弥补高速设备和低速设备通信时的速度差。比如，我们将数据写入磁盘时并不是直接刷盘，而是写到一块缓冲区里面，内核会标识这个缓冲区为脏。当经过一定时间或者脏缓冲区比例到达一定阈值时，由单独的线程把脏块刷新到硬盘上。这样避免了每次写数据都要刷盘带来的性能问题。
>
> - 缓存的分类
>
>   > - 静态缓存：静态数据，比如文档内容在生成的时候会渲染一个静态页面放在nginx服务器上
>   > - 分布式缓存
>   > - 热点数据本地缓存：热点数据的缓存放到进程中的hashMap中，多个进程中可能存在不同，但用户是可以接受的。如果没有从数据库中或分布式缓存中拉取，Guava 的 Loading Cache。这种通常缓存时间比较短，秒级别的或者分钟级别的，避免脏数据。
>
> - 缓存的不足
>
>   > - **缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性**
>   > - **缓存会给整体系统带来复杂度，并且会有数据不一致的风险**
>   > - **之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的**，所以需要做下数据存储量级的评估；

#### 如何选择缓存的读写策略？

> - 缓存的读取策略
>
>   - 从缓存中读取数据；
>   - 如果缓存命中，则直接返回数据；
>   - 如果缓存不命中，则从数据库中查询数据；
>   - 查询到数据后，将数据写入到缓存中，并且返回给用户。
>
> - 缓存的修改策略 
>
>   - 先更新数据库，
>   - 更新成功后删除缓存
>
> - `直接修改缓存也是不可以的，会造成库和缓存不一致的问题`
>
>   这个过程中也会有并发的问题，比如说原有金额是 20，A 请求从缓存中读到数据，并且把金额加 1，变更成 21，在未写入缓存之前又有请求 B 也读到缓存的数据后把金额也加 1，也变更成 21，两个请求同时把金额写回缓存，这时缓存里面的金额是 21，但是我们实际上预期是金额数加 2，这也是一个比较大的问题。
>
> - `更新缓存的时候 先删除缓存，后修改数据库`
>
>   假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21，这就造成了缓存和数据库的不一致。

#### 缓存如何做到高可用？

> - **客户端方案**：就是在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。有点是性能没有损耗，缺点是客户端逻辑复杂；多语言环境不能复用；
>
>   > 单一的缓存节点受到机器内存、网卡带宽和单节点请求量的限制，不能承担比较高的并发，因此我们考虑将数据分片，依照分片算法将数据打散到多个不同的节点上，每个节点上存储部分数据；
>   >
>   > 考虑一致性hash算法，当某个节点不可用的时候就沿着环往下寻找第一个遇到的可用节点。增加和删除节点只会影响一个节点上的数据，不会影响所有数据；虚拟节点的问题；
>
> - **中间代理层方案**：是在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。
>
>   业界也有很多中间代理层方案，比如 Facebook 的[Mcrouter](https://github.com/facebook/mcrouter)，Twitter 的[Twemproxy](https://github.com/twitter/twemproxy)，豌豆荚的[Codis](https://github.com/CodisLabs/codis)。
>
>   中间代理层是只是实现了高可用的路由功能；性能上有损耗
>
> - **服务端方案**：是 Redis 2.4 版本后提出的 Redis Sentinel 方案。
>
>   Redis Sentinel 也是集群部署的，这样可以避免 Sentinel 节点挂掉造成无法自动故障恢复的问题，每一个 Sentinel 节点都是无状态的。在 Sentinel 中会配置 Master 的地址，Sentinel 会时刻监控 Master 的状态，当发现 Master 在配置的时间间隔内无响应，就认为 Master 已经挂了，Sentinel 会从从节点中选取一个提升为主节点，并且把所有其他的从节点作为新主的从节点。Sentinel 集群内部在仲裁的时候，会根据配置的值来决定当有几个 Sentinel 节点认为主挂掉可以做主从切换的操作，也就是集群内部需要对缓存节点的状态达成一致才行。

#### 缓存穿透了怎么办？

> 在低缓存命中率的系统中，大量查询商品信息的请求会穿透缓存到数据库，因为数据库对于并发的承受能力是比较脆弱的。一旦数据库承受不了用户大量刷新商品页面、定向搜索衣服信息，就会导致查询变慢，导致大量的请求阻塞在数据库查询上，造成应用服务器的连接和线程资源被占满，最终导致你的电商系统崩溃。
>
> `解决方案`：
>
>  - 回种空值，但是要注意 全是当内存不够用的时候会存在全是空值的情况；
>
>  - 使用布隆过滤器：二进制数组和一个 Hash 算法组成
>
>    ```
>    加入要判断用户是否存在缓存中
>    1. 初始化一个20亿的数组； 20亿/8/1024/2014 = 238M
>    2. 把所有的数据库的用户id进行取hash然后对20亿取余，计算出在布隆过滤器的位置，设置为1；新增的数据插入数据库中，同事布隆过滤对应的位置也设置为1；
>    3. 然后获取数据前，先从布隆过滤器中判断是否存在；
>    
>    存在hash碰撞，所以会误判。不存在的却被布隆过滤器判断为存在；可以使用多个hash值解决
>    不支持删除。不止使用0和1 也是用2，但会浪费空间
>    ```

####  CDN：静态资源如何加速？(content deliver network)

> 静态资源（js文件、css文件、html、图片、视频、流媒体信息）都放到nginx等web服务器上，他们的读请求量极大，对访问速度要求极高，占据和很高的带宽；
>
> 使用CDN技术在业务服务器的上一层，增加一层特殊的缓存，用来承担绝大多数的静态资源的访问，这一层遍布在全国各地，这用用户选择就近的节点访问。
>
> `CDN是如何实现加速用户对静态资源的请求的`
>
> - DNS解决域名映射问题：一种是返回域名对应的ip，叫A记录；一种是返回CName记录就是返回域名对应的另一个域名；
>
> ![DNS域名解析过程](/images/concurrentServer/DNS域名解析过程.png)
>
> - 使用GSLB（全局负载均衡）对于部署在各地的服务器之间做负载均衡，另一方面保证流量流经的服务器与流量源头在地缘上是比较近的；

#### 消息队列：秒杀时如何处理每秒上万次的下单请求？

> - 消息队列是暂时存储数据的容器，它是一个平衡低俗系统和告诉系统处理任务时间差的工具。
>
> - 将用户请求放入到消息队列中，返回秒杀进行中；然后处理后续的下单、业务处理；之后处理结果返回给用户。
>
> - 通过异步处理简化业务流程；重要的业务线处理，次要的业务异步处理；
>
>   `异步处理、削峰填谷、解耦合`
>
> - 主要作用：提高写性能，实现系统的解耦合，提高高并发的写流量；

#### 消息投递：如何保证消息仅仅被消费一次？

> - 生产消息中丢失消息
>
>   > - 发送失败或者超时，则进行消息重传；
>
> - 消息队列中消息的丢失
>
>   > - 为了减少存储消息对磁盘的随机IO，会将消息先写入到操作系统的page Cache中，再找合适的时机输入到磁盘上。可以配置cache达到一定消息数量或者间隔一段时间后再刷盘，也就是异步刷盘；
>   > - 部署集群的方法，集群部署中leader中的数据会同步给ISR中的follower，有个ACK机制，配置成所有的ISR同步完毕才代表发送成功；kafka集群还有集群的leader选举机制；
>
> - 消费过程中消息的丢失
>
>   > - 消费消息的三步：接收消息、处理消息、更新消费进度
>   >
>   > - 服务端和消费端进行幂等处理：多次和一次执行的结果一样；
>   > - `生产端，消息服务器队列会存储生产者id和最后一条消息的映射，消息服务端会将消息id和最后一条消息的id进行比对`；
>   > - 生产的时候生成一个全局唯一id，消费后进行保存到缓存，消费的时候判断消息是否存在；而且你得用事务处理，消息处理和写入缓存必须保证原子性；
>   > - 或者处理的时候增加一个版本号使用乐观锁的机制；

#### 消息队列：如何降低消息队列系统中消息的延迟？

> - 增加消费者组的消费者的数量，一个partition只能被一个消费者组中的一个消费者消费，所以需要新建topic并且创建多个消费者来处理；
>
> - 增加线程池异步处理；
>
> - 拉取不到消息则sleep一段时间；
>
>   `数据从磁盘写入到缓冲区的过程`：
>
>   ![数据从磁盘写入到网络的过程](/images/concurrentServer/数据从磁盘写入到网络的过程.png)



#### 系统架构：每秒1万次请求的系统要做服务化拆分吗？

> `一体化项目的优点`
>
> - 开发简单直接，项目和代码集中式管理；
> - 节省了运维系统的成本；
> - 排查问题简单；
>
> `一体化项目缺点`
>
> - 系统的资源出现扩展性问题：数据库连接数成为系统的瓶颈。数据库最大连接数是8000，各个客户端的连接数是30，还有别的消息队列的服务需要连接数据库；
> - 大家共同维护一套代码：增加了研发的成本，抑制了研发的效率。业务变大的时候需要拆分成各个小团队，各个小组维护一套代码在配合时会出现问题；一个小问题影响这个服务；
> - 一体化架构对运维也有很大影响，代码比较多，比较复杂，任何小的修改都需要上线；
>
> `微服务的拆分`
>
> - 按照业务拆分：拆成内容服务、用户服务、互动服务，各个服务有各自的数据库；各个服务职能直接调用自己的库，调用其它库只能通过别的服务去调用，减少了数据库连接数；
> - 按照公共逻辑拆分：减少重复代码；
>
> ` 系统演进的感悟`
>
> - 前期考虑的是性能、可用性、可扩展性；
> - 后期考虑成功：研发团队、开发成本、沟通成本、运维成本；要做一些小工具提高工程师的效率；

#### 微服务架构：微服务化后，系统架构要如何改造？

> 服务拆分的原则：
>
> - 单一服务内部功能高内聚、低耦合。每个服务只完成自己的职责的任务，对于不是自己职责的功能要交给其他模块完成；比如判断用户是否为认证用户的逻辑要放在用户服务中而不能放到内容服务中；
> - 服务拆分的粒度，先粗略拆分、再逐渐细化；比如黑名单相关的服务要先拆到用户服务中，后期可以再细拆；
> - 拆分的过程尽量避免日常功能的迭代
>   - 优先剥离比较独立的边界服务，从非核心服务出发，减少对现有服务的影响。也给团队一个试错的机会；
>   - 两个服务有依赖关系的时候，需要先拆分被依赖的服务；
> - 服务接口的定义要具备可扩展性；比如一个微服务的接口有三个参数，一次需求开发中，组内的同学调整为4个参数，调用方没有修改，所以会报错；
>
> 微服务化带来的问题和解决思路
>
> - `引入服务注册中心`：服务接口的调用是跨进程的网络调用，同时接口调用方需要知道服务部署在哪个机器上，哪个端口上；于是需要引入服务注册中心；
> - `多个服务之间有复杂的依赖关系，需要服务治理体系`：单个服务会影响别的依赖该服务的其它服务，这时候需要熔断、限流、降级、超时控制；
> - 需要快速定位调用链路的问题，这时候需要引入`分布式追踪工具`，以及服务端监控报表；

#### RPC框架：10万QPS下如何实现毫秒级的服务调用

> 微服务拆分后存在问题
>
> - 跨网络通讯的问题；
> - 服务治理问题；
>
> RPC框架的性能要求
>
> - 选择合适的网络模型，针对性的调整网络参数，优化网络传输性能；
> - 选择合适的序列化方式，以提升封包和解包的性能；
>
> ![RPC框架的设计注意事项](/images/concurrentServer/RPC框架的设计注意事项.png)

#### 注册中心：分布式系统如何寻址？

> 注册中心组件：老派的zookeeper、k8s使用的etcd、springcloud使用的eureka，阿里使用nacos；
>
> 主要功能：
>
> 1. 提供了服务地址的存储，本地会做缓存；
>
> 2. 当存储内容发生变化的时候，可以经变更的内容推送给客户端；（紧急扩容和服务节点故障需要变更节点）
>
> 探测存活一般使用两种机制：
>
> 1. 主动请求探活机制：子服务提供一个端口，每隔一段时间注册中心向子服务探测是否可用。存在问题：①：端口固定，多了有可能被占用；②：服务多了注册中心的压力比较大；
> 2. 使用心跳机制：子服务每次向注册中心提供心跳，注册中心接受到心跳包后会在注册中心更新服务的续约时间。然后注册中心会定期检测当前时间和节点，如果阈值超过一定时间，那么节点被标记为不可用；
>
> 注意事项：
>
> - 注册中心存在过度摘除的问题，可以使用保护策略。如果存活节点少于40%，则停止摘除服务，同时服务报警；

#### 分布式Trace（链路追踪）：横跨几十个分布式组件的慢请求要如何排查？

> 主要作用
>
> - 跨进程的调用链展示，服务依赖分析，在性能优化和问题排查方面提供数据上的支持；
> - 常用组件zipkin、jaeger
>
> 一体化服务的问题排查过程：
>
> - 简单的可以添加每个方法的调用时间日志，逐步排查；
> - 使用切面对每个方法添加打印调用时间的操作；
>
> 动态代理和静态代理
>
> - 静态代理是在编译器插入代码，增加了编译的时间，运行期对性能没有影响；
> - 动态代理不会修改class文件，在运行期生成一个代理对象，这个代理对象会对源对象做字节码增强，来完成切面需要做的工作。由于需要在运行期间生成代理对象，则动态代理性能要不静态代理的查；
>
> 打印日志的小技巧：
>
> - 尽量使用ASPECTJ 做静态代理，减少了对代码的侵入性；
> - 对性能要低损耗；
> - 使用requstId标记调用流程；
> - 对请求id做取模 requestId%10==0 采样打印，以减少日志量；
> - 分布式存储，不能打印日志到服务器上，使用放入到mq中，发送日志到es中；
>
> 微服务的服务问题排查过程
>
> - 使用traceId(requestId)记录服务内的调用，使用spanId记录每一次RPC调用；
>
>   ![分布式traceId追踪问题](/images/concurrentServer/分布式traceId追踪问题.png)

#### 负载均衡：怎样提升系统的横向扩展能力？

>  负载均衡服务分类：
>
> - 代理类负载均衡服务；
>
>   >  LVS：它在osi的第四层（传输层）；
>   >
>   > nginx：它在地七层（应用层）；
>   >
>   > 一般使用lvs-->多个nginx。单节点的nginx可以承担10万以下的QPS，lvs可以承担更大的流量。
>   >
>   > 
>
> - 客户端负载均衡服务
>
>   rpc服务一般使用的rpc协议，而不是http协议，不能使用nginx这种，所以需要使用客户端负载均衡，也就是负载均衡服务内嵌在rpc客户端内。它提供多种节点选取的策略。这种一般是配合注册中心来使用，注册中心负责提供服务节点列表，客户端负责选取后进行服务调用
>
> - 常见的负载均衡策略
>
>   > - 静态策略：在选择节点时不会根据后端的服务实际运行状态来选择；
>   >
>   >   轮训的策略、权重的策略、ipHash、url_hash
>   >
>   > - 动态策略：在选择节点时会根据后端服务的状态来进行选择；
>   >
>   >   根据服务的存活情况，服务的连接数，服务的响应时间来动态的分配权重；
>   >
>   >   nginx的探活模块可以指定服务的接口探测是否可用
>   >
>   >   ![nginx的探活模块](/images/concurrentServer/nginx的探活模块.png)

#### API网关，系统的门面设计

> - 概念
>
>     api网关是一个架构模式，他可以将服务共有的功能整合在一起，独立部署为单独的一层，来解决一些服务治理问题。对出入系统的流量做统一的管控。分为入口和出口网关；
>
> - 作用：入口网关通常部署在负载均衡服务器和应用服务器之间
>
>   1. 给客户端提供一个统一的接入地址，它可以根据用户的请求路由到不同的业务服务上。你部署的微服务对外暴露的协议可能不同，api网关可以屏蔽这些细节；
>   2. 做服务治理，比如熔断、降级、流量控制和分流；
>   3. 客户端的授权和认证；
>   4. 针对设备id、用户id、用户ip维度做一些黑白名单策略；
>   5. 做日志记录；
>
> - 实现的注意事项
>
>   1. 网关注重的是性能和扩展性，你可以采用多路IO复用模型和线程池并发处理，来提升网关性能；使用责任链模式来提升网关的扩展性；
>   2. API网关的线程池可以针对不同的接口或者服务做隔离保护，提升网关的可用性；
>   3. API网关可以代替原本系统中的web层，将web层中的协议转换，认证、限流等功能放入api网关中；
>
> - API网关的开源实现
>
>   1. kong是在nginx中运行的lua程序，得益于nginx的优势，kong对于api网关来说性能是最好的；
>   2. zuul是spring cloud全家桶中的一员，他是java开发的，zuul1使用的是同步阻塞模型，所以性能不是很高，zuul2使用异步nio的线程模型，但成熟度不高；
>   3. Tyk是go语言实现的轻量级API网关；

#### 全链路压力测试

>  普通的压测存在的问题
>
> - 首先压测时需要使用线上数据和线上环境；
> - 其次，压力测试不能模拟请求，而是要使用线上的流量，你可以使用拷贝流量的方式把线上的流量拷贝到压测测试环境；比如线上的缓存数据，不可能让你使用一条数据，你命中缓存后都走缓存；
> - 不能从一台服务器发起，这样很容易达到这台服务器性能瓶颈，从而导致压力测试服务器的QPS上不去；
>
> `全链路压测`和`性能监控平台`
>
>    不能针对某个模块来做压测，需要对后端服务、数据库、缓存、消息队列、中间件等所有的服务做压测。
>
> 全链路压测平台的关键点
>
> - 流量隔离
>
>   > 要区分压力测试流量和正式流量；
>
> - 风险的控制
>
>   > 需要避免压力测试对正常用户的影响；
>
>  全链路压测要包括以下模块
>
> - 流量构造和生产模块；
>
>   > 1. 一般将http请求入口流量拷贝一份，然后经过清洗后放入到nosql存储数据库中；一般可以使用nginx日志，然后将日志进行解析（增加开发成本）；
>   > 2. 另一种是使用开源的流量拷贝工具GoReplay，它可以劫持本机某一个端口的流量，将他们记录在文件中，在压测时进行流量回放；
>
> - 压测数据隔离模块，流量染色；
>
>   > 1. 一般，我们针对读取数据（下行流量）的请求，会针对不能压测的服务或者组件做mock处理，比如浏览数据的行为不能做统计；比如展示过的数据，被请求过就不在展示了，这种要做特殊处理；这些数据要搭建mock服务，最好部署在真实的机房；
>   > 2. 对于写入的数据，我们会把数据写入到影子库中，和线上的数据完全隔离；对于mysql中的麽易新建一个mysql实例，把线上的schema和数据导入到进来，redis可以新增加一个前缀；es可以新建一个索引；
>
> - 系统健康检查和压测流量干预模块；
>
>   > 1. 先设置流量测试的压力目标比如 20万次/QPS
>   > 2. 逐渐增加压力，观察一段时间；
>   > 3. 做一些工具，来根据监控通知机制服务
>
>   ![全链路压测架构图](/images/concurrentServer/全链路压测架构图.png)
>
> 全链路压测的意义
>
> 1. 帮助我们发现系统中的性能瓶颈，方便我们做预案来应对；
> 2. 为我们做容量评估，提供数据支撑；
> 3. 在压测时候做预案演练；



#### 多机房部署：跨地域的分布式系统如何做？

>  IDC机房（互联网数据中心）部署多套服务，共享一份业务数据，共同承担来自客户的流量；
>
> 跨机房：
>
> - 北京同地双机房之间的专线延迟一般在1-3ms；
> - 国内异地双机房之间的专线延迟在50ms内；根据距离有所不同；
> - 国际化的服务延迟在100-200ms，所以需要做异步数据同步，无法做到同步调用；
>
> 同城多机房允许有跨机房的写入的发生，但是数据的读取服务的调用尽量保证在一个机房；
>
> 异地多活方案则应该避免跨机房同步数据的读取和写入，采用异步的方式，将数据从一个机房同步到另一个机房；

#### Service Mesh：如何屏蔽服务化系统的服务治理细节？

> 前面提到的服务治理方案：
>
> - 用RPC框架解决服务通信的问题；
> - 用注册中心解决服务注册，和发现的问题；
> - 使用分布式Trace中间件，排查跨服务调用慢请求；
> - 使用负载均衡服务器，解决服务扩展性的问题
> - 使用API网关植入服务熔断、降级、流控等服务治理的策略；
>
> 跨语言的细节
>
> 比如序列化的协议、各种api网关的策略
>
> 使用istio来实现service mesh来解决各个服务模块的治理的细节；

#### 给系统加上眼睛：服务端监控要怎么做？

> 主要存在的问题
>
> - 使用数据库主从延迟变长，导致业务上出现问题；
> - 接口响应时间变长；
> - 系统中出现大量错误，影响了用户的使用；
>
> 如何搭建监控服务
>
> - 指标：除了基础机器的基础指标还有以下业务指标；
>
>   > - 延迟：比如接口的响应时间、访问数据库和缓存的延迟；
>   >
>   > - 通信量：可以理解为吞吐量，也就是单位时间内请求量的大小。比如第三方服务的请求量、访问消息队列的请求量；
>   >
>   > - 错误：当前系统的错误数量，比如错误码 4** 5**，也比如虽然返回200，但是业务上是异常的；
>   >
>   > - 饱和度：服务或者资源达到上限的程度，比如cpu使用率、内存使用率、数据库连接池使用情况；
>   >
>   > ![监控指标](/images/concurrentServer/监控指标.png)
>
> - 采集指标的方法和途径：
>
>   > - 使用`代理`主要监控的是服务端的情况，比如redis调用它的state命令获取它的统计数据，kafka的队列队堆积数或者GC信息都可以通过JMX来监控使用；
>   > - 在代码中`埋点`，主要是在客户端使用的情况。使用之前说到的trace组件，监控服务的耗时，调用量，慢请求数，发送给监控服务器； 注意对数据的汇总，不要每个请求都发送数据；
>   >
>   > - `日志`也可以作为指标来源。可以使用开源的日志采集工具，flume、fluentd、filebeat
>   > - Prometheus 
>
> - 指标采集后如何处理和展示：
>
>   > 使用kafka接收消息，消费填谷；
>   >
>   > 然后使用一个消费来写入es，然后通过kibana来展示，这些主要用来做原始数据的查询；
>   >
>   > 另一种是做流式数据处理的中间件比如spark、storm来做数据处理
>   >
>   > > - 解析数据的请求量、响应时间、请求url等数据；
>   > > - 做一些聚合运算，比如tomcat的访问日志，对同一个url一段时间内的请求量、响应时间分隔位置、非200请求量的大小；
>   > > - 存入时序数据库中，比如influxDB。
>   > > - 最后使用grafana来连接时序数据库，将监控数据制作成报表，呈现出来；
>
>   ![监控系统架构图](/images/concurrentServer/监控系统架构图.png)
>
>   ![监控形成的报表](/images/concurrentServer/监控形成的报表.png)
>
>   

####  配置管理：成千上万的配置项要如何管理？

> 配置中心的开源方案：
>
> 1. 携程的apollo：支持不同环境、不同集群的配置、有完善的管理功能。支持灰度发布，热发布；
> 2. springcloud config
> 3. 阿里的nocas
>
> 配置信息的存储
>
>  一般使用mysql、etcd、redis、zookeeper都可以；
>
> 变更消息的推送
>
> - 轮训查询：应用程序向配置中心客户端注册一个监听器，配置中心的客户端定时查询配置是否有变化，如果有变化则通知触发监听器，让应用程序变更通知；为了防止查询量太大使用MD5值；
> - 长连接推送，更实时；
>
> 为了保证高可用，在配置中心的客户端添加两级缓存，一级是在内存中的缓存（降低和客户端的交互），另外一级是文件的缓存（灾备）；
>
> 动态需要调整的可以放到配置中心；

#### 降级和熔断，屏蔽非核心系统故障的影响

> - 降级和熔断主要解决的问题：
>   1. 由于依赖的资源或者服务不可用，导致整体服务宕机。比如数据库访问缓慢；
>   2. 超过系统承载能力的流量到来，系统不堪重负，出现拒绝服务的情况；
>
> - 雪崩是如何发生的？
>   1. 局部故障会导致全局故障就是雪崩。比如A服务调用B服务，b服务响应缓慢，导致A服务也运行缓慢，最终导致A服务不可用；
>   2. 所以分布式最怕的不是某个服务或者组件宕机，而是响应缓慢，响应变慢会导致雪崩拖垮整个系统。
>
> - 熔断机制
>   1. 发起服务调用，如果服务返回错误或者超时次数超过一定的阈值，则后续请求不再向远程服务发起请求而是暂时返回错误；
>   2. 状态机，关闭（调用远程服务）、半打开（尝试调用远程服务）、打开（返回错误）
>
> - 熔断机制的状态维护
>   1. 当调用失败的次数累计到一定的阈值时，熔断状态从关闭到打开状态。一般在实现时，如果成功调用一次，就会重置调用失败的次数；
>   2. 当熔断处于打开状态时，我们会启动一个超时计时器，当计时器超时时，状态切换到半打开状态，你也可以设置一个定时器，定时的探测服务是否恢复；
>   3. 在熔断处于半打开状态时，请求可以达到后端服务，如果累计一定次数后，状态切换到关闭状态；如果出现调用失败的情况则切换到打开状态；
>
> - 封装的redis客户端中实现的熔断机制：
>
>   1. 当处于熔断状态时，定期的检查redis组件是否可用
>
>      ![熔断状态检查redis组件是否可用](/images/concurrentServer/熔断状态检查redis组件是否可用.png)
>
>   2. redis客户端需要加入熔断逻辑
>
>      ![redis熔断检查逻辑](/images/concurrentServer/redis熔断检查逻辑.png)
>
> - 开关降级
>
>   开关降级是指在代码中预先设置一些开关，用来控制服务的返回值，比方说开关打开时，执行指定的降级策略，这些开关的值可以存储在配置中心中，当系统出现问题需要降级时，只需要修改配置中心中开关的值就可以了。
>
> - 具体的降级策略
>
>   1. 针对读取数据的场景，我们一般采用的策略是`直接返回降级数据`
>   2. 对一些轮训获取数据的场景，比如每隔30秒获取一次未读数的，可以`降低读取数据的频率`；
>   3. 对于写数据的场景，一般会考虑把同步写改成`异步`，这样可以牺牲一些数据的的一致性来保证系统的可用性；

#### 流量控制：高并发系统中我们如何操纵流量？

>  核心服务流量太大的时候不能熔断，需要进行流量控制
>
> ![限流策略](/images/concurrentServer/限流策略.png)
>
> 限流算法
>
> - 固定窗口
>
>   ```java
>       /**
>        * 每秒重置计数器
>        */
>       private static AtomicInteger counter = new AtomicInteger();
>   
>       public static void main(String[] args) {
>   
>           ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();
>   
>           scheduledExecutorService.scheduleAtFixedRate(new Runnable() {
>               @Override
>               public void run() {
>                   counter.set(0);
>               }
>           },0,1, TimeUnit.SECONDS);
>       }
>   ```
>
>   
>
> - 滑动窗口
>
>   > 为了解决固定窗口流量集中的问题，将一秒钟的时间段拆分成5分，每次计算都要按当前时间往后计算1秒；
>
> - 漏桶算法，消息队列
>
> - 桶令牌：消费后消费令牌，根据时间频率往令牌桶放令牌；（使用guava中的限流器；但是分布式环境的话需要在redis中存储，为了解决频繁请求的问题，则使用一次获取多个令牌的方案）





参考：极客时间 [《高并发系统设计40问》](https://time.geekbang.org/column/intro/230)













































