<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.chenwj.cn","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="学习，坚持。">
<meta property="og:type" content="website">
<meta property="og:title" content="茄子的博客">
<meta property="og:url" content="http://www.chenwj.cn/index.html">
<meta property="og:site_name" content="茄子的博客">
<meta property="og:description" content="学习，坚持。">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="陈伟杰">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://www.chenwj.cn/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>茄子的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="茄子的博客" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">茄子的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">技术博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">68</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">26</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">74</span></a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="sitemap fa-fw"></i>站点地图</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="heartbeat fa-fw"></i>公益 404</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2020-08-14/DDD-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020-08-14/DDD-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/" class="post-title-link" itemprop="url">DDD-领域驱动设计简介</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-14 17:05:52" itemprop="dateCreated datePublished" datetime="2020-08-14T17:05:52+08:00">2020-08-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 01:03:09" itemprop="dateModified" datetime="2020-08-21T01:03:09+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DDD/" itemprop="url" rel="index"><span itemprop="name">DDD</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="服务的演进"><a href="#服务的演进" class="headerlink" title="服务的演进"></a>服务的演进</h4><blockquote>
<p>单机、集中式到分布式微服务架构三个阶段</p>
<ul>
<li><p>微服务解决的问题</p>
<blockquote>
<p>可以解决应用之间的解耦、解决单体应用扩展性、小规模团队的敏捷开发；</p>
</blockquote>
</li>
<li><p>DDD的含义</p>
<blockquote>
<ul>
<li><p>DDD核心思想是通过领域驱动设计方法<code>定义领域模型</code>，从而<code>确定业务和应用边界</code>，保证业务模型与代码模型的一致性。</p>
</li>
<li><p>DDD不是架构，而是一种架构设计方法论，通过边界划分将复杂业务领域简单化，帮我们设计出清晰的领域和应用边界，可以很容易地实现架构演进。</p>
</li>
<li><p>DDD战略设计会建立领域模型，领域模型可以用于指导微服务的设计和拆分。事件风暴是建立领域模型的主要方法，它是一个从发散到收敛的过程。它通常采用用例分析、场景分析和用户旅程分析，尽可能全面不遗漏地分解业务领域，并梳理领域对象之间的关系，这是一个发散的过程。事件风暴过程会产生很多的实体、命令、事件等领域对象，我们将这些领域对象从不同的维度进行聚类，形成如聚合、限界上下文等边界，建立领域模型，这就是一个收敛的过程。</p>
</li>
<li><p>具体的过程</p>
<blockquote>
<ol>
<li><p>第一步：在事件风暴中梳理业务过程中的用户操作、事件以及外部依赖关系等，根据这些要素梳理出领域实体等领域对象。</p>
</li>
<li><p>第二步：根据领域实体之间的业务关联性，将业务紧密相关的实体进行组合形成聚合，同时确定聚合中的聚合根、值对象和实体。在这个图里，聚合之间的边界是第一层边界，它们在同一个微服务实例中运行，这个边界是逻辑边界，所以用虚线表示。</p>
</li>
<li><p>第三步：根据业务及语义边界等因素，将一个或者多个聚合划定在一个限界上下文内，形成领域模型。在这个图里，限界上下文之间的边界是第二层边界，这一层边界可能就是未来微服务的边界，不同限界上下文内的领域逻辑被隔离在不同的微服务实例中运行，物理上相互隔离，所以是物理边界，边界之间用实线来表示。</p>
</li>
</ol>
</blockquote>
</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="DDD的名字概念"><a href="#DDD的名字概念" class="headerlink" title="DDD的名字概念"></a>DDD的名字概念</h4><blockquote>
<ul>
<li><p>领域： 研究的对象或者事业的范围；</p>
</li>
<li><p>子领域：每个子域对应一个更小的问题域或更小的业务范围；（核心思想就是将问题域逐步分解，降低业务理解和系统实现的复杂度）</p>
</li>
<li><p>核心域： 关注的核心子域就是核心域；</p>
</li>
<li><p>通用域：公共的子领域；</p>
</li>
<li><p>支撑域：不是决定性的核心的域，支撑作用的领域；</p>
<p>公司在IT系统建设过程中，由于预算和资源有限，对不同类型的子域应有不同的关注度和资源投入策略</p>
</li>
<li></li>
</ul>
<p>领域的核心思想就是将问题域逐级细分，来降低业务理解和系统实现的复杂度。通过领域细分，逐步缩小微服务需要解决的问题域，构建合适的领域模型，而领域模型映射成系统就是微服务了。</p>
<p>核心域、支撑域和通用域的主要目标是：通过领域划分，区分不同子域在公司内的不同功能属性和重要性，从而公司可对不同子域采取不同的资源投入和建设策略，其关注度也会不一样</p>
<p>DDD分层架构包括用户接入层、应用层、领域层和基础层四层。</p>
</blockquote>
<h4 id="限界上下文：定义领域边界的利器"><a href="#限界上下文：定义领域边界的利器" class="headerlink" title="限界上下文：定义领域边界的利器"></a>限界上下文：定义领域边界的利器</h4><blockquote>
<ul>
<li>在事件风暴的过程中，领域专家会和设计、开发人员一起建立领域模型，在领域建模的过程中会形成通用的业务术语和用户故事。事件风暴也是一个项目团队统一语言的过程。</li>
<li>通过用户故事分析会形成一个个的领域对象，这些领域对象对应领域模型的业务对象，每一个业务对象和领域对象都有通用的名词术语，并且一一映射</li>
<li>微服务代码模型来源于领域模型，每个代码模型的代码对象跟领域对象一一对应。</li>
</ul>
<p>设计过程中我们可以用一些表格，来记录事件风暴和微服务设计过程中产生的领域对象及其属</p>
<p><img src="/images/DDD/%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%9E%8B%E5%92%8C%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt="业务模型和代码模型的关系"></p>
<p>我认为限界上下文的定义就是：用来封装通用语言和领域对象，提供上下文环境，保证在领域之内的一些术语、业务相关对象等（通用语言）有一个确切的含义，没有二义性。这个边界定义了模型的适用范围，使团队所有成员能够明确地知道什么应该在模型中实现，什么不应该在模型中实现。</p>
<p>正如电商领域的商品一样，商品在不同的阶段有不同的术语，在销售阶段是商品，而在运输阶段则变成了货物。同样的一个东西，由于业务领域的不同，赋予了这些术语不同的涵义和职责边界，这个边界就可能会成为未来微服务设计的边界。看到这，我想你应该非常清楚了，领域边界就是通过限界上下文来定义的。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2020-08-11/mysql%E5%AE%9E%E6%88%98-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020-08-11/mysql%E5%AE%9E%E6%88%98-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/" class="post-title-link" itemprop="url">mysql实战-基础架构</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-11 10:53:58" itemprop="dateCreated datePublished" datetime="2020-08-11T10:53:58+08:00">2020-08-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 15:23:05" itemprop="dateModified" datetime="2020-08-21T15:23:05+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>17k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>15 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="mysql的架构逻辑"><a href="#mysql的架构逻辑" class="headerlink" title="mysql的架构逻辑"></a>mysql的架构逻辑</h4><p><img src="/images/mysql2/mysql%E7%9A%84%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="mysql的逻辑架构图"></p>
<blockquote>
<ul>
<li><p>连接器：负责跟客户端建立连接、获取权限、维持和管理连接；建议使用长连接，定期断开长连接，或者定期进行重置连接；</p>
</li>
<li><p>分析器：包括词法分析：多个字符串和和空格组成的sql语句，需要识别出里面的字符串分别代表什么，表字段是否存在，是否正确，是否有歧义；之后要做语法分析，就是判断一些语法规则，比如select需要符合什么规则；</p>
</li>
<li><p>优化器：优化器选择使用什么索引，使用连接的顺序等都是需要进行优化的；</p>
</li>
<li><h4 id="执行器：先判断是否有权限，然后进行遍历每一个满足条件的行并且执行操作；"><a href="#执行器：先判断是否有权限，然后进行遍历每一个满足条件的行并且执行操作；" class="headerlink" title="执行器：先判断是否有权限，然后进行遍历每一个满足条件的行并且执行操作；"></a>执行器：先判断是否有权限，然后进行遍历每一个满足条件的行并且执行操作；</h4></li>
</ul>
</blockquote>
<h4 id="mysql的日志系统"><a href="#mysql的日志系统" class="headerlink" title="mysql的日志系统"></a>mysql的日志系统</h4><blockquote>
<ul>
<li>redo log 日志，是innodb存储引擎特有的日志 <a target="_blank" rel="noopener" href="https://www.cnblogs.com/hzmark/p/wal.html">wal机制</a></li>
</ul>
<p>如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高</p>
<p> <code>redo日志</code>：当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB。</p>
<p>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为<strong>crash-safe</strong>。</p>
<ul>
<li><p>binlog日志</p>
<p>binlog是MySQL的Server层实现的，所有引擎都可以使用，他记录的是原始语句；</p>
</li>
<li><p>两种日志的不同点</p>
<blockquote>
<ol>
<li>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</li>
<li>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。</li>
<li>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li>
</ol>
</blockquote>
</li>
<li><p>执行update语句的执行流程</p>
<blockquote>
<p> update T set c=c+1 where ID=2;</p>
<ol>
<li>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li>
<li>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li>
<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。</li>
<li>执行器生成这个操作的binlog，并把binlog写入磁盘。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。</li>
</ol>
</blockquote>
</li>
<li><p>redo日志两阶段提交</p>
<blockquote>
<p>流程是：redolog的prepare状态，写入binlog，然后commit；这样来保证两个日志存储的数据一致；</p>
<p>主要是为了让redo日志和binlog日志之间的逻辑一致；两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案。</p>
<p>如果不是两阶段提交，使用任意一个日志恢复出来的数据都有可能和原来的库里的数据不一致。</p>
</blockquote>
</li>
<li><p>参数设置</p>
<blockquote>
<p> innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果把innodb_flush_log_at_trx_commit设置成1，那么redo log在prepare阶段就要持久化一次，因为有一个崩溃恢复逻辑是要 依赖于prepare 的redo log，再加上binlog来恢复的</span><br></pre></td></tr></table></figure>

<p>sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。</p>
</blockquote>
</li>
<li><p>数据持久化的过程</p>
<blockquote>
<p> 在记账的例子中，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。</p>
<p>掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是flush。在这个flush操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。</p>
<p><strong>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”</strong>。</p>
<p>MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。</p>
<p>  <strong>刷脏页的情况：</strong></p>
<ul>
<li><code>InnoDB的redo log写满了</code>。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写</li>
<li><code>对应的就是系统内存不足</code>。 当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。</li>
<li>对应的就是MySQL认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”</li>
<li>MySQL正常关闭的情况。</li>
</ul>
</blockquote>
</li>
<li><p>redo log和change buffer的区别</p>
<blockquote>
<p> <strong>redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。</strong></p>
</blockquote>
</li>
<li><p>如果某次写入使用了change buffer机制，之后主机异常重启，是否会丢失change buffer和数据。</p>
<blockquote>
<p> 虽然是只更新内存，但是在事务提交的时候，我们把change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。</p>
</blockquote>
</li>
<li><p>mysql是如何保证数据不丢失的</p>
<blockquote>
<p>结论： </p>
<p>只要redo log和binlog保证持久化到磁盘，就能确保MySQL异常重启后，数据可以恢复。</p>
</blockquote>
</li>
</ul>
<ul>
<li><p>binlog的写入流程</p>
<blockquote>
<p><code>binlog的写入机制</code>：事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。</p>
<p>一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了binlog cache的保存问题 </p>
<p>系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大 小。如果超过了这个参数规定的大小，就要暂存到磁盘。</p>
<p>事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache.</p>
<p><img src="/images/mysql2/binlog%E5%86%99%E7%9B%98%E7%8A%B6%E6%80%81.png" alt="binlog写盘状态"></p>
<p>可以看到，每个线程有自己binlog cache，但是共用同一份binlog文件。  </p>
<ul>
<li><p>图中的write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。 </p>
</li>
<li><p>图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的IOPS。</p>
</li>
</ul>
<p>write 和fsync的时机，是由参数sync_binlog控制的:</p>
<ol>
<li>sync_binlog=0的时候，表示每次提交事务都只write，不fsync;</li>
<li>sync_binlog=1的时候，表示每次提交事务都会执行fsync;</li>
<li>sync_binlog=N(N&gt;1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。</li>
</ol>
<p>出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日 志量的可控性，一般不建议将这个参数设成0，比较常⻅的是将其设置为100~1000中的某个数值</p>
</blockquote>
</li>
</ul>
<ul>
<li><p>redo log的写入流程</p>
<blockquote>
<p> 事务在执行过程中，生成的redo log是要先写到redo log buffer的。</p>
<p>redo log buffer里面的内容，是不是每次生成后都要直接持久化到磁盘呢?  不需要</p>
<p> 事务还没提交的时候，redo log buffer中的部分日志有没有可能被持久化到磁盘呢? 有可能</p>
<p><img src="/images/mysql2/redoLogCunchuzhuangtai.png" alt="redoLogCunchuzhuangtai"></p>
<ul>
<li>存在redo log buffer中，物理上是在MySQL进程内存中，就是图中的红色部分;</li>
<li>写到磁盘(write)，但是没有持久化(fsync)，物理上是在文件系统的page cache里面，也就是图中的⻩色部分; </li>
<li>持久化到磁盘，对应的是hard disk，也就是图中的绿色部分。</li>
</ul>
<p>为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，它有三种可能取值:</p>
<ul>
<li>设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中; </li>
<li>设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘;</li>
<li>设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。</li>
</ul>
<p>InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的page cache，然后调用fsync持久化到磁盘。</p>
<p>两种场景会让一个没有提交的事务的redo log写入到磁盘中:</p>
<ul>
<li><p>一种是，<strong>redo log buffer</strong>占用的空间即将达到 <strong>innodb_log_buffer_size</strong>一半的时候，后台线程会主动写盘。注意，由于 这个事务并没有提交，所以这个写盘动作只是write，而没有调用fsync，也就是只留在了文件系统的page cache。</p>
</li>
<li><p>另一种是，并行的事务提交的时候，顺带将这个事务的<strong>redo log buffer</strong>持久化到磁盘。</p>
</li>
</ul>
</blockquote>
</li>
<li><p>组提交</p>
<blockquote>
<p>日志逻辑序列号(log sequence number，LSN)。LSN是单调递增的，用来对应redo log的一个个写入点。每次写入⻓度为length的redo log， LSN的值就会加上length。</p>
<p>过程</p>
<ul>
<li>trx1是第一个到达的，会被选为这组的 leader;</li>
<li>等trx1要开始写盘的时候，这个组里面已经有了三个事务，这时候LSN也变成了160;</li>
<li>trx1去写盘的时候，带的就是LSN=160，因此等trx1返回时，所有LSN小于等于160的redo log，都已经被持久化到磁盘; 4. 这时候trx2和trx3就可以直接返回了。</li>
</ul>
<p>binlog也有相同的机制</p>
</blockquote>
</li>
<li><p>WAL机制主要得益于两个方面</p>
<blockquote>
<ul>
<li>redo log 和 binlog都是顺序写，磁盘的顺序写比随机写速度要快;</li>
<li>组提交机制，可以大幅度降低磁盘的IOPS消耗。</li>
</ul>
</blockquote>
</li>
<li><p><strong>MySQL</strong>现在出现了性能瓶颈，而且瓶颈在<strong>IO</strong>上，可以通过哪些方法来提升性 能呢?</p>
<blockquote>
<ol>
<li><p>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。</p>
<p>这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的⻛险。</p>
</li>
<li><p>将sync_binlog 设置为大于1的值(比较常⻅是100~1000)。这样做的⻛险是，主机掉电时会丢binlog日志。</p>
</li>
<li><p>将innodb_flush_log_at_trx_commit设置为2。这样做的⻛险是，主机掉电的时候会丢数据。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>常见日志问题</p>
<blockquote>
<ol>
<li><p>执行一个update语句以后，我再去执行hexdump命令直接查看ibd文件内容，为什么没有看到数据有改变呢? </p>
<p>**回答: ** 这可能是因为WAL机制的原因。update语句执行完成后，InnoDB只保证写完了redo log、内存，可能还没来得及将数据写到磁盘。</p>
</li>
<li><p>为什么binlog cache是每个线程自己维护的，而redo log buffer是全局共用的?</p>
<p><strong>回答:</strong> MySQL这么设计的主要原因是，binlog是不能“被打断的”。一个事务的binlog必须连续写，因此要整个事务完成后，再 一起写到文件里。而redo log并没有这个要求，中间有生成的日志可以写到redo log buffer中。redo log buffer中的内容还能“搭便⻋”，其他事务 提交的时候可以被一起写到磁盘中。</p>
</li>
<li><p>事务执行期间，还没到提交阶段，如果发生crash的话，redo log肯定丢了，这会不会导致主备不一致呢?</p>
<p> **回答:**不会。因为这时候binlog 也还在binlog cache里，没发给备库。crash以后redo log和binlog都没有了，从业务⻆度看这个事务也没有提交，所以数据是一致的。</p>
</li>
<li><p>如果binlog写完盘以后发生crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是bug?</p>
<p>**回答:**不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit完成了，备库也收到binlog并执行了。但是主库和客 户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不 能认为是bug。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>数据库的crash-safe保证的是:</p>
<blockquote>
<ul>
<li>如果客户端收到事务成功的消息，事务就一定持久化了;</li>
<li>如果客户端收到事务失败(比如主键冲突、回滚等)的消息，事务就一定失败了;</li>
<li>如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部 (数据和日志之间，主库和备库之间)一致就可以了。</li>
</ul>
</blockquote>
</li>
<li><p>什么情况下需要设置生产库设置为双非1</p>
<blockquote>
<ol>
<li>业务高峰期。一般如果有预知的高峰期，DBA会有预案，把主库设置成“非双1”。</li>
<li>备库延迟，为了让备库尽快赶上主库。</li>
<li>用备份恢复主库的副本，应用binlog的过程，这个跟上一种场景类似。</li>
<li>批量导入数据的时候。</li>
</ol>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="主从同步"><a href="#主从同步" class="headerlink" title="主从同步"></a>主从同步</h4><blockquote>
<ul>
<li><p>binlog可以用来归档，也可以用来做主备同步</p>
</li>
<li><p>建议你把备库设置成只读模式；</p>
</li>
<li><p><strong>主从同步流程</strong></p>
<blockquote>
<ol>
<li>在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位 置包含文件名和日志偏移量。</li>
<li>在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与 主库建立连接。</li>
<li>主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。</li>
<li>备库B拿到binlog后，写到本地文件，称为中转日志(relay log)。</li>
<li>sql_thread读取中转日志，解析出日志里的命令，并执行。</li>
</ol>
</blockquote>
<p>MySQL5.6以前的版本复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。 MySQL5.6版本参数slave-parallel-workers=1 表示启用多线程功能</p>
</li>
<li><p>三种格式对比</p>
<blockquote>
<ul>
<li><p>statement </p>
<blockquote>
<p>查看日志文件 ：show binlog events in ‘master.000001’; </p>
<p>记录的是原始的修改数据库的数据的sql；</p>
<p><code>占用较小的空间，比如删除所有表的数据，但是存在问题，delete from t limit 1 使用不同索引不同，导致删除数据不同，有可能导致主从不一致 </code></p>
</blockquote>
</li>
<li><p>row</p>
<blockquote>
<p>查看日志文件 ：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">show binlog events in &#39;master.000001&#39;;</span><br><span class="line">mysqlbinlog -vv data&#x2F;master.000001 --start-position&#x3D;8900</span><br></pre></td></tr></table></figure>

<p>记录的是真实的对应的删除的主键id、或者具体的插入的数据；</p>
<p><code>可以准确记录操作的数据，但是由于记录需要删除很多数据，所以很耗费空间</code></p>
</blockquote>
</li>
</ul>
<ul>
<li><p>mixed</p>
<blockquote>
<p> Mixed 方法利用了两种格式的优点。</p>
<p>设置为mixed后，就会记录为row格式;而如果执行的语句去掉limit 1，就会记录为statement格式。</p>
<p>mixed格式可以利用statment格式的优点，同时又避免了数据不一致的⻛险。</p>
</blockquote>
</li>
</ul>
</blockquote>
</li>
<li><p>双M结构的数据库</p>
<blockquote>
<p>节点A和B之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。</p>
<p>业务逻辑在节点A上更新了一条语句，然后再把生成的binlog 发给节点B，节点B执行完这条更新语句后也会生成binlog。</p>
<p>如果节点A同时是节点B的备库，相当于又把节点B新生成的binlog拿过来执行了一次，然后节点A和B间，会不断地循 环执行这个更新语句，也就是循环复制了。这个要怎么解决呢?</p>
<p><strong>解决方案</strong></p>
<ul>
<li><p>规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系;</p>
</li>
<li><p>一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog;</p>
</li>
<li><p>每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这个日志是自己生成的，就直接 丢弃这个日志。</p>
</li>
</ul>
<p>按照这个逻辑，如果我们设置了双M结构，日志的执行流就会变成这样:</p>
<ul>
<li>从节点A更新的事务，binlog里面记的都是A的server id;</li>
<li>传到节点B执行一次以后，节点B生成的binlog  的server id也是A的server id;</li>
<li>再传回给节点A，A判断到这个server id与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><blockquote>
<p> 查询数据的时候，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>
<ul>
<li>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</li>
<li>在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。</li>
<li>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</li>
<li>“串行化”隔离级别下直接用加锁的方式来避免并行访问。</li>
</ul>
<p>视图是通过undolog日志来实现的，就是当系统里没有比这个回滚日志更早的read-view的时候，这些日志会被清除。</p>
<p><strong><em>为什么建议你尽量不要使用长事务？</em></strong></p>
<blockquote>
<ol>
<li><p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p>
</li>
<li><p>导致死锁的产生；</p>
</li>
</ol>
</blockquote>
<ul>
<li><p>查询大事务</p>
<blockquote>
<p> select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60</p>
</blockquote>
</li>
<li><p>如何避免大事务</p>
<blockquote>
<ul>
<li><p>尽可能的减小事务范围，少用长事务，如果无法避免，保证逻辑日志空间足够用（innodb_undo_tablespaces），并且支持动态日志空间增长。</p>
</li>
<li><p>监控Innodb_trx表，发现长事务报警。</p>
</li>
</ul>
</blockquote>
</li>
<li><p>事务中一个数据的可见性分析：读</p>
<blockquote>
<p> 对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能：</p>
<ol>
<li>如果低于低水位，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li>
<li>如果高于高水位，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</li>
<li>如果在高低水位之间，那就包括两种情况<br>  a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见；<br>  b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。</li>
</ol>
</blockquote>
</li>
<li><p>事务中一个数据的可见性分析：写</p>
<blockquote>
<p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。</p>
<p>当前读是要加锁的；</p>
</blockquote>
</li>
<li><p><strong>事务的可重复读的能力是怎么实现的？</strong></p>
<blockquote>
<p>可重复读的核心就是一致性读（consistent read）；</p>
<p>而事务更新数据的时候，只能用当前读（当前读是要加锁）。</p>
<p>如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><blockquote>
<ul>
<li><p>重建索引</p>
<p>正常重建二级索引，使用删除、新增的方式是合理的；但是重建主键索引这种方式是不合理的，因为删除主键索引需要删除所有的数据</p>
</li>
<li><p>为什么不适用hash、数组、平衡二叉树存储索引？</p>
<p>索引的维护：索引需要维护可能出现页分裂，页合并的问题；</p>
</li>
<li><p>索引下推</p>
</li>
</ul>
<p>在5.6之前，在联合索引中使用部分索引的情况需要找到对应的主键后立即回表查询；MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少<code>回表次数</code>。</p>
<ul>
<li><p>注意事项</p>
<blockquote>
<ul>
<li><p>在不影响排序结果的情况下，在取出主键后，回表之前，会在对所有获取到的主键排序</p>
</li>
<li><p>默认按照“查询使用的索引”排序</p>
</li>
</ul>
</blockquote>
</li>
<li><p>普通索引和唯一索引</p>
<blockquote>
<p>第一种情况是，<strong>这个记录要更新的目标页在内存中</strong>。这时，InnoDB的处理流程如下：</p>
<ul>
<li>对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；</li>
<li>对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。</li>
</ul>
<p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。</p>
<p>第二种情况是，<strong>这个记录要更新的目标页不在内存中</strong>。这时，InnoDB的处理流程如下：</p>
<ul>
<li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</li>
<li>对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。</li>
</ul>
</blockquote>
<p>这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。</p>
</li>
<li><p>mysql选择错误的索引</p>
<blockquote>
<p>MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">这个统计信息就是索引的“区分度”，这个基数越大，索引的区分度越好</span><br><span class="line"></span><br><span class="line">show index from table；</span><br><span class="line"></span><br><span class="line">统计数据是使用采样统计，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。</span><br><span class="line"></span><br><span class="line">而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过1&#x2F;M的时候，会自动触发重新做一次索引统计。 innodb_stats_persistent</span><br></pre></td></tr></table></figure>

<p><strong>analyze table t 命令，可以用来重新统计索引信息</strong></p>
<p>其次还可以使用explain查看rows扫描的行。由于有可能回表，所以有可能不使用索引，直接全表扫描。</p>
<p><strong>一种方法是，采用force index强行选择一个索引</strong></p>
<p><strong>第二种方法就是，我们可以考虑修改语句，引导MySQL使用我们期望的索引</strong></p>
<p><strong>第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</strong></p>
</blockquote>
</li>
<li><p>前缀索引</p>
<blockquote>
<ul>
<li><p>如果使用前缀索引，损失是可能会增加额外的记录扫描次数。由于区分度比较低，需要拿到主键后回表比较；</p>
</li>
<li><p><strong>使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。</strong></p>
</li>
<li><p>方法：判断不同前缀的区分度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select count(distinct email) as L from SUser;</span><br><span class="line"></span><br><span class="line"> select </span><br><span class="line">  count(distinct left(email,4)）as L4,</span><br><span class="line">  count(distinct left(email,5)）as L5,</span><br><span class="line">  count(distinct left(email,6)）as L6,</span><br><span class="line">  count(distinct left(email,7)）as L7,</span><br><span class="line">from SUser;</span><br></pre></td></tr></table></figure>
</li>
<li><p>问题：使用前缀索引 有可能没办法用到覆盖索引；</p>
</li>
<li><p>总结</p>
<blockquote>
<ol>
<li>直接创建完整索引，这样可能比较占用空间；</li>
<li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；</li>
<li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；</li>
<li>创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。</li>
</ol>
</blockquote>
</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h4><blockquote>
<ul>
<li>锁分为表锁、行锁。</li>
<li>表锁主要用于大批量导入数据，或者修改表结构的时候；</li>
<li>行锁是存储引擎自己实现的，innodb支持行锁，MyLSAM就不支持行锁；</li>
</ul>
<p><strong>如何给小表加字段</strong></p>
<blockquote>
<p> 首先我们要解决长事务，事务不提交，就会一直占着表锁。在MySQL的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务；</p>
</blockquote>
<p><strong>如何给小表热点表加字段</strong></p>
<blockquote>
<p> 这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tbl_name NOWAIT add column ...</span><br><span class="line">ALTER TABLE tbl_name WAIT N add column ...</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>两阶段锁协议</strong></p>
<p>在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。</p>
<p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>
<p><strong>如何避免死锁</strong></p>
<ul>
<li>使用表锁；</li>
<li>按照相同的顺序获取锁资源；</li>
<li>一次获取所有的锁资源；</li>
</ul>
<p><strong>如何处理死锁</strong></p>
<ol>
<li><p>进入等待直到超时，这种可以设置innodb_lock_wait_timeout参数，默认是50s；</p>
<p><code>存在问题</code> ：设置时间不好处理，50s太久了，1s假如是普通的锁等待，由会出现很多误伤；</p>
</li>
<li><p>另一种策略是发起死锁检测，发现死锁后，主动回滚另一个事务，让其他事务继续执行；innodb_deadlock_detect将该参数设置为on；</p>
<p>（show engine innodb status 可以查看最近检测到的死锁）</p>
<p><code>存在问题</code>：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。消耗cpu资源。</p>
</li>
<li><p>最终思路是减少访问相同资源的并发事务量；</p>
</li>
</ol>
</blockquote>
<h4 id="如何释放表空间"><a href="#如何释放表空间" class="headerlink" title="如何释放表空间"></a>如何释放表空间</h4><blockquote>
<ul>
<li>删除整个表</li>
</ul>
<blockquote>
<p>Innodb_file_per_table 为on的话表示每个InnoDB表数据存储在一个以 .ibd为后缀的文件中，独立表空间；使用drop table的话可以把.ibd文件删除，释放表空间；</p>
</blockquote>
<ul>
<li><p>删除行的表空间</p>
<blockquote>
<p>正常的删除行记录，只是在b+树中将记录逻辑删除，后续插入数据的时候替换原有的数据；但是这个是有范围限制的；分为b+树的行复用和页复用；</p>
<p>delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的；</p>
</blockquote>
</li>
<li><p>重建表释放表空间，同时释放碎片空间</p>
<blockquote>
<p>你可以新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。</p>
<ul>
<li><p>5.5版本之前 alter table A engine=InnoDB命令来重建表；</p>
</li>
<li><p>5.5之后需要使用online DDL：因为将数据插入到新表中的时候是online的会花很长时间，导致请求不可用； </p>
<blockquote>
<p>流程如下：</p>
<ol>
<li>建立一个临时文件，扫描表A主键的所有数据页；</li>
<li>用数据页中表A的记录生成B+树，存储到临时文件中；</li>
<li>生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；</li>
<li>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；</li>
<li>用临时文件替换表A的数据文件。</li>
</ol>
</blockquote>
</li>
</ul>
</blockquote>
</li>
<li><p>使用命令重建表</p>
<blockquote>
<ul>
<li>从MySQL 5.6版本开始，alter table t engine = InnoDB（也就是recreate）默认的就是上面图4的流程了；</li>
<li>analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；</li>
<li>optimize table t 等于recreate+analyze。</li>
<li>Truncate 可以理解为drop+create</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="order-by-工作原理"><a href="#order-by-工作原理" class="headerlink" title="order by 工作原理"></a>order by 工作原理</h4><blockquote>
<p>![order by 是如何工作的](/images/mysql2/order by 是如何工作的.png)</p>
<ul>
<li><p>流程如下：</p>
<ol>
<li>初始化sort_buffer，确定放入name、city、age这三个字段；</li>
<li>从索引city找到第一个满足city=’杭州’条件的主键id，也就是图中的ID_X；</li>
<li>到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中；</li>
<li>从索引city取下一个记录的主键id；</li>
<li>重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；</li>
<li>对sort_buffer中的数据按照字段name做快速排序；</li>
<li>按照排序结果取前1000行返回给客户端。</li>
</ol>
</li>
<li><p>原因</p>
<blockquote>
<ol>
<li>可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。排序的数据量小于sort_buffer_size，排序就在内存（sort_buffer）中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序（使用多个文件归并排序）。</li>
<li>除了上边的全字段排序算法还有这种rowId排序算法。 max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。</li>
</ol>
</blockquote>
<p>如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了（全字段排序），不用再回到原表去取数据（rowId排序）。</p>
<p><strong>如果内存够，就要多利用内存，尽量减少磁盘访问。</strong></p>
</li>
<li><p>优化</p>
<blockquote>
<ol>
<li>我们可以在这个市民表上创建一个city和name的联合索引。使用这个联合索引的查询出来的数据是按照name排序的，这样就不用使用临时文件进行排序。</li>
<li>我们可以创建一个city、name和age的联合索引，使用覆盖索引，不用回表查询；</li>
</ol>
</blockquote>
</li>
<li><p>升级</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from t where city in (&#39;杭州&#39;,&quot;苏州&quot;) order by name limit 100; &#x2F;&#x2F;已经有了city_name(city, name)这个联合索引</span><br></pre></td></tr></table></figure>

<p> 还是会file_sort  因为联合索引中只用到city索引，且使用到的事rowId排序算法。</p>
</blockquote>
</li>
<li><p>排序算法总结</p>
<blockquote>
<p><strong>全字段排序</strong></p>
<ol>
<li>通过索引将所需的字段全部读取到sort_buffer中</li>
<li>按照排序字段进行排序</li>
<li>将结果集返回给客户端</li>
</ol>
<ul>
<li>缺点：</li>
</ul>
<ol>
<li>造成sort_buffer中存放不下很多数据，因为除了排序字段还存放其他字段，对sort_buffer的利用效率不高</li>
<li>当所需排序数据量很大时，会有很多的临时文件，排序性能也会很差</li>
</ol>
<ul>
<li>优点：MySQL认为内存足够大时会优先选择全字段排序，因为这种方式比rowid 排序避免了一次回表操作</li>
</ul>
<p><strong>rowid排序</strong></p>
<ol>
<li>通过控制排序的行数据的长度来让sort_buffer中尽可能多的存放数据，max_length_for_sort_data</li>
<li>只将需要排序的字段和主键读取到sort_buffer中，并按照排序字段进行排序</li>
<li>按照排序后的顺序，取id进行回表取出想要获取的数据</li>
<li>将结果集返回给客户端</li>
</ol>
<ul>
<li><p>优点：更好的利用内存的sort_buffer进行排序操作，尽量减少对磁盘的访问</p>
</li>
<li><p>缺点：回表的操作是随机IO，会造成大量的随机读，不一定就比全字段排序减少对磁盘的访问</p>
</li>
</ul>
<p><strong>按照排序的结果返回客户所取行数</strong></p>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="索引失效的情况"><a href="#索引失效的情况" class="headerlink" title="索引失效的情况"></a>索引失效的情况</h4><blockquote>
<ol>
<li>查询条件中在索引列上使用函数</li>
<li>like “%_” 百分号在前. </li>
<li>or关键字使用</li>
<li>not in ,not exist 不等于等反向操作； </li>
<li>单独引用复合索引里非第一位置的索引列. </li>
<li>字符型字段为数字时在where条件里不添加引号（隐式转换）. </li>
<li>对小表查询；</li>
</ol>
</blockquote>
<h4 id="幻读详解"><a href="#幻读详解" class="headerlink" title="幻读详解"></a>幻读详解</h4><blockquote>
<p>幻读指的是一个事务在前后两次<code>查询同一个范围</code>的时候，后一次查询看到了前一次查询没有看到的行。</p>
<p>幻读是当前读才出现的，且幻读特指看到了新插入的行。</p>
<p>间隙锁：<strong>跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作</strong>。仅仅是插入，查询的话没问题；</p>
<p>间隙锁记为开区间，把next-key lock记为前开后闭区间</p>
</blockquote>
<h4 id="间隙锁"><a href="#间隙锁" class="headerlink" title="间隙锁"></a>间隙锁</h4><blockquote>
<p> <strong>我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。</strong></p>
<ol>
<li>原则1：加锁的基本单位是next-key lock。next-key lock是前开后闭区间。</li>
<li>原则2：查找过程中访问到的对象才会加锁。</li>
<li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。</li>
<li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。</li>
<li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>
</ol>
<p>读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。</p>
<p><img src="/images/mysql2/%E5%8A%A0gap%E9%94%81%E7%9A%84%E9%97%AE%E9%A2%98.png" alt="加gap锁的问题"></p>
</blockquote>
<h4 id="饮鸩止渴的提高性能的方法"><a href="#饮鸩止渴的提高性能的方法" class="headerlink" title="饮鸩止渴的提高性能的方法"></a>饮鸩止渴的提高性能的方法</h4><blockquote>
<ul>
<li><p>数据库连接不够用，干掉占用连接，但不工作的线程</p>
<blockquote>
<ol>
<li>show processlist 查看线程；</li>
<li>取出sleep状态且要查看具体事务状态，information_schema库的innodb_trx表</li>
<li>服务端断开连接使用的是kill connection + id</li>
</ol>
</blockquote>
</li>
<li><p>慢查询导致的原因</p>
<blockquote>
<ol>
<li><p>索引没有设计好</p>
<blockquote>
<p>比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库A、备库B，这个方案的大致流程是这样的: </p>
<ul>
<li>在备库B上执行 set sql_log_bin=off，也就是不写binlog，然后执行alter table 语句加上索引;</li>
<li>执行主备切换;</li>
<li>这时候主库是B，备库是A。在A上执行 set sql_log_bin=off，然后执行alter table 语句加上索引</li>
</ul>
<p>这是一个“古老”的DDL方案</p>
</blockquote>
</li>
<li><p>sql语句没有写好</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">可以通过改写SQL语句来处理。MySQL 5.7提供了query_rewrite功能</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (&quot;select * from call query_rewrite.flush_rewrite_rules();</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>mysql选错了索引</p>
<blockquote>
<p> 使用force index</p>
</blockquote>
</li>
</ol>
</blockquote>
</li>
<li><p><strong>QPS</strong>突增问题</p>
<blockquote>
<p>由上线新功能或者程序bug导致的某个语句的QPS突然暴涨；</p>
<ul>
<li>如果新功能是单独的用户，可以使用管理员把用户删除；</li>
<li>可以使用query-rewrite功能重写sql  改为  select 1;</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="mysql的高可用"><a href="#mysql的高可用" class="headerlink" title="mysql的高可用"></a>mysql的高可用</h4><blockquote>
<p> 在从库上执行  show slave status，返回的 seconds_behind_master表示备库延迟了多少。</p>
<p> <strong>主备延迟的原因</strong></p>
<ol>
<li><p>备库所在机器的性能要比主库所在的机器性能差。</p>
</li>
<li><p>备库的压力大；</p>
<blockquote>
<p>使用一主多从；</p>
<p>使用binlog或者消息队列同步到外部系统进行查询；</p>
</blockquote>
</li>
<li><p>大事务，大事务10分钟；</p>
<blockquote>
<p>不要使用一条sql删除大量的数据；</p>
<p>大表的ddl；</p>
</blockquote>
</li>
<li><p>备库的并行复制能力</p>
</li>
</ol>
<p> <strong>主备切换-可靠性优先策略</strong>（这个是使用HA工具操作的，不是手动操作的）</p>
<blockquote>
<ol>
<li>判断备库B现在的seconds_behind_master，如果小于某个值(5秒)继续下一步，否则持续重试这一步</li>
<li>把主库A改成只读状态，即把readonly设置为true;（<code>主库A和备库B都处于readonly状态，也就是说这时系统处 于不可写状态</code>）短时间</li>
<li>判断备库B的seconds_behind_master的值，直到这个值变成0为止;</li>
<li>把备库B改成可读写状态，也就是把readonly 设置为false;</li>
<li>把业务请求切到备库B。</li>
</ol>
</blockquote>
<p> <strong>主备切换-可用性优先策略</strong></p>
<blockquote>
<p>如果我强行把步骤4、5调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那 么系统几乎就没有不可用时间了。</p>
<p>可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。</p>
</blockquote>
<p> <strong>基于位点的主备切换</strong></p>
<blockquote>
<p> 节点B设置成节点A’的从库的时候，需要执行一条change master命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CHANGE MASTER TO </span><br><span class="line">MASTER_HOST&#x3D;$host_name </span><br><span class="line">MASTER_PORT&#x3D;$port </span><br><span class="line">MASTER_USER&#x3D;$user_name </span><br><span class="line">MASTER_PASSWORD&#x3D;$password </span><br><span class="line">master_auto_position&#x3D;1 &#x2F;&#x2F;就表示这个主备关系使用的是GTID协议</span><br></pre></td></tr></table></figure>


</blockquote>
</blockquote>
<h4 id="读写分离的方案和坑"><a href="#读写分离的方案和坑" class="headerlink" title="读写分离的方案和坑"></a>读写分离的方案和坑</h4><blockquote>
<p> <strong>客户端直连和带proxy的读写分离架构区别</strong></p>
<ul>
<li>客户端直连方案，因为少了一层proxy转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便</li>
<li>带proxy的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作</li>
</ul>
<p><strong>读写分离会导致主从延迟读取不到数据的问题</strong></p>
<blockquote>
<ul>
<li><p>强制走主库方案</p>
<blockquote>
<p>对于部分的需要强一致性的请求，可以使用强制走主库的方案；</p>
</blockquote>
</li>
<li><p>sleep方案;</p>
<blockquote>
<p> 用户发起请求前，先执行一次sleep操作；</p>
<p> 或者由前端执行ajax异步请求；</p>
</blockquote>
</li>
<li><p>判断主备无延迟方案;</p>
<blockquote>
<p>每次执行查询前执行 select slave master命令，查看seconds_behind_master查看主从延迟时间；</p>
<p>对比位点</p>
<p>对比GTID</p>
</blockquote>
</li>
<li><p>配合semi-sync方案</p>
<blockquote>
<p> 也就是半同步机制。存在问题是存在过度等待的问题；</p>
<ol>
<li>事务提交的时候，把主库的binlog发送给从库；</li>
<li>从库收到后返回主库一个ack，表示收到了；</li>
<li>从库收到ack后，才返回给客户端事务完成的确认；</li>
</ol>
</blockquote>
</li>
<li><p>等主库位点方案;</p>
<blockquote>
<ol>
<li><p>trx1事务更新完成后，⻢上执行show master status得到当前主库执行到的File和Position;</p>
</li>
<li><p>选定一个从库执行查询语句;</p>
</li>
<li><p>在从库上执行select master_pos_wait(File, Position, 1);  </p>
<p>参数file和pos指的是主库上的文件名和位置; </p>
<p> timeout可选，设置为正整数N表示这个函数最多等待N秒。</p>
</li>
<li><p>如果返回值是M&gt;=0的正整数，则在这个从库执行查询语句;</p>
</li>
<li><p>否则，到主库执行查询语句。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>等GTID方案。</p>
</li>
</ul>
</blockquote>
</blockquote>
<h4 id="误删除数据库"><a href="#误删除数据库" class="headerlink" title="误删除数据库"></a>误删除数据库</h4><blockquote>
<p>恢复数据，建议在临时库上做处理，然后恢复到主库。因为这期间这些数据有可能被别的事务修改；</p>
<ul>
<li><p>使用delete语句误删数据行;</p>
<blockquote>
<p>可以用Flashback工具通过闪回把数据恢复回来。 Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row 和binlog_row_image=FULL。</p>
<p><code>建议</code>： 把sql_safe_updates参数设置为on。这样一来，如果我们忘记在delete或者update语句中写where条件，或者where条件里面没有包含索引字段的话，这条语句的执行就会报错</p>
</blockquote>
</li>
<li><p>使用drop table或者truncate table语句误删数据表;</p>
<blockquote>
<p> 使用truncate /drop table和drop database命令删除的数据，无法使用日志恢复。只能使用全量备份进行恢复；</p>
<p> 在临时库上做恢复后，拿到除了误删库的语句的日志进行恢复；</p>
</blockquote>
</li>
<li><p>使用drop database语句误删数据库;</p>
<blockquote>
<p> 使用5.6版本后的 延迟复制备库的方式 。延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。</p>
</blockquote>
</li>
<li><p>使用rm命令误删整个MySQL实例。</p>
</li>
</ul>
<p><strong>建议</strong></p>
<blockquote>
<ul>
<li>建议做成自动化工具，经常演练。这样不至于手忙脚乱的处理突发状况；</li>
<li>账号分离。这样做的目的是，避免写错命令。DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</li>
<li>制定操作规范。这样做的目的，是避免写错要删除的表名。在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表</li>
</ul>
</blockquote>
</blockquote>
<h4 id="kill操作没有立即完成的状态"><a href="#kill操作没有立即完成的状态" class="headerlink" title="kill操作没有立即完成的状态"></a>kill操作没有立即完成的状态</h4><blockquote>
<p>kill ( connection )+线程id  ,并不是立即断开连接，告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。防止这个线程加了MDL锁，被强制kill掉后没办法释放锁。</p>
<p>这些“kill不掉”的情况，其实是因为发送kill命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。而被kill的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的。</p>
<ol>
<li><strong>线程没有执行到判断线程状态的逻辑</strong>，需要等待；</li>
<li><strong>终止逻辑耗时较长</strong>，</li>
</ol>
</blockquote>
<h4 id="join的执行原理和使用"><a href="#join的执行原理和使用" class="headerlink" title="join的执行原理和使用"></a>join的执行原理和使用</h4><blockquote>
<p> <strong>流程</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from t1 straight_join t2 on (t1.a&#x3D;t2.a);</span><br></pre></td></tr></table></figure>

<ol>
<li><p>从表t1中读入一行数据 R；</p>
</li>
<li><p>从数据行R中，取出a字段到表t2里去查找；</p>
</li>
<li><p>取出表t2中满足条件的行，跟R组成一行，作为结果集的一部分；</p>
</li>
<li><p>重复执行步骤1到3，直到表t1的末尾循环结束。</p>
</li>
</ol>
<p>在这个join语句执行过程中，<code>驱动表是走全表扫描</code>，而被驱动表是走树搜索。</p>
<p><strong>注意</strong></p>
<ol>
<li>在使用join的时候，应该让小表做驱动表</li>
<li>如果可以使用被驱动表的索引，join语句还是有其优势的；</li>
<li>不能使用被驱动表的索引，只能使用Block Nested-Loop Join算法（可能会因为join_buffer不够大，需要对被驱动表做多次全表扫描），这样的语句就尽量不要使用。</li>
<li>大量查询导致Buffer Pool的热数据被淘汰，影响内存命中率</li>
</ol>
<p><strong>优化</strong></p>
<p>回表查询的主键id如果是不连续的，则查询会变为随机IO；</p>
<p><code>MRR优化的设计思路</code>：</p>
<blockquote>
<ol>
<li>根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;</li>
<li>将read_rnd_buffer中的id进行递增排序；</li>
<li>排序后的id数组，依次到主键id索引中查记录，并作为结果返回。</li>
</ol>
<p>read_rnd_buffer的大小是由read_rnd_buffer_size参数控制的。如果步骤1中，read_rnd_buffer放满了，就会先执行完步骤2和3，然后清空read_rnd_buffer。之后继续找索引a的下个记录，并继续循环</p>
</blockquote>
</blockquote>
<h4 id="innoDB的LRU算法"><a href="#innoDB的LRU算法" class="headerlink" title="innoDB的LRU算法"></a>innoDB的LRU算法</h4><blockquote>
<p>innoDB按照5:3的比例把整个LRU链表分成了young区域和old区域。LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域 </p>
<p>InnoDB对Bufffer Pool的LRU算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在old区域。如果1秒之后这个数据页不再被访问了，就不会被移动到LRU链表头部，这样对Buffer Pool的命中率影响就不大。young区的数据，是正常的LRU，会被移动到头部。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2020-08-07/%E4%BB%8E%E6%A0%B9%E4%B8%8A%E4%BA%86%E8%A7%A3mysql-innodb%E8%AE%B0%E5%BD%95%E5%AD%98%E5%82%A8%E8%AE%B0%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020-08-07/%E4%BB%8E%E6%A0%B9%E4%B8%8A%E4%BA%86%E8%A7%A3mysql-innodb%E8%AE%B0%E5%BD%95%E5%AD%98%E5%82%A8%E8%AE%B0%E5%BD%95/" class="post-title-link" itemprop="url">从根上了解mysql-innodb记录存储记录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-07 11:50:12" itemprop="dateCreated datePublished" datetime="2020-08-07T11:50:12+08:00">2020-08-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 01:03:09" itemprop="dateModified" datetime="2020-08-21T01:03:09+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="innodb的数据结构"><a href="#innodb的数据结构" class="headerlink" title="innodb的数据结构"></a>innodb的数据结构</h2><p>InnoDB采取的方式是：将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为 16 KB</p>
<p>设计了4种不同类型的行格式，分别是Compact、Redundant、Dynamic和Compressed行格式</p>
<h3 id="Compact-格式"><a href="#Compact-格式" class="headerlink" title="Compact 格式"></a>Compact 格式</h3><p><img src="/images/mysql2/compact%E7%BB%93%E6%9E%84.png" alt="compact结构"></p>
<p>我们知道表中的某些列可能存储NULL值，如果把这些NULL值都放到记录的真实数据中存储会很占地方，所以Compact行格式把这些值为NULL的列统一管理起来，存储到NULL值列表中</p>
<p><img src="/images/mysql2/%E8%AE%B0%E5%BD%95%E5%A4%B4%E4%BF%A1%E6%81%AF.png" alt="记录头信息"></p>
<p>主要包括删除标记位、当前记录拥有的记录数、记录类型（普通记录、非叶子节点记录、最小记录、最大记录）、next_record(表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量)</p>
<p>InnoDB表对主键的生成策略：优先使用用户自定义主键作为主键，如果用户没有定义主键，则选取一个Unique键作为主键，如果表中连Unique键都没有定义的话，则InnoDB会为表默认添加一个名为row_id的隐藏列作为主键</p>
<p>一个页一般是16KB，当记录中的数据太多，当前页放不下的时候，会把多余的数据存储到其他页中，这种现象称为行溢出</p>
<h2 id="innndb是如何存储数据的"><a href="#innndb是如何存储数据的" class="headerlink" title="innndb是如何存储数据的"></a>innndb是如何存储数据的</h2><p>InnoDB其实是使用页为基本单位来管理存储空间的，默认的页大小为16KB。</p>
<p>对于InnoDB存储引擎来说，每个索引都对应着一棵B+树，该B+树的每个节点都是一个数据页，数据页之间不必要是物理连续的，因为数据页之间有双向链表来维护着这些页的顺序。</p>
<p>InnoDB的聚簇索引的叶子节点存储了完整的用户记录，也就是所谓的索引即数据，数据即索引。</p>
<p>为了更好的管理这些页，提出了一个表空间或者文件空间（，这个表空间是一个抽象的概念，它可以对应文件系统上一个或多个真实文件（不同表空间对应的文件数量可能不同）。每一个表空间可以被划分为很多很多很多个页。</p>
<h3 id="匹配左边的列"><a href="#匹配左边的列" class="headerlink" title="匹配左边的列"></a>匹配左边的列</h3><p>有个表中有联合索引 idx_name_birthday_phone_number</p>
<ul>
<li>先按照name列的值进行排序。</li>
<li>如果name列的值相同，则按照birthday列的值进行排序。</li>
<li>如果birthday列的值也相同，则按照phone_number的值进行排序。</li>
</ul>
<p>B+树的数据页和记录先是按照name列的值排序的，在name列的值相同的情况下才使用birthday列进行排序，也就是说name列的值不同的记录中birthday的值可能是无序的。而现在你跳过name列直接根据birthday的值去查找，臣妾做不到呀～ 那如果我就想在只使用birthday的值去通过B+树索引进行查找咋办呢？这好办，你再对birthday列建一个B+树索引就行了，创建索引的语法不用我唠叨了吧。</p>
<p>但是需要特别注意的一点是，如果我们想使用联合索引中尽可能多的列，搜索条件中的各个列必须是联合索引中从最左边连续的列。</p>
<h3 id="精确匹配某一列并范围匹配另外一列"><a href="#精确匹配某一列并范围匹配另外一列" class="headerlink" title="精确匹配某一列并范围匹配另外一列"></a>精确匹配某一列并范围匹配另外一列</h3><p>对于同一个联合索引来说，虽然对多个列都进行范围查找时只能用到最左边那个索引列，但是如果左边的列是精确查找，则右边的列可以进行范围查找</p>
<h3 id="使用联合索引进行排序注意事项"><a href="#使用联合索引进行排序注意事项" class="headerlink" title="使用联合索引进行排序注意事项"></a>使用联合索引进行排序注意事项</h3><p>对于联合索引有个问题需要注意，ORDER BY的子句后边的列的顺序也必须按照索引列的顺序给出，如果给出ORDER BY phone_number, birthday, name的顺序，那也是用不了B+树索引</p>
<h3 id="ASC、DESC混用"><a href="#ASC、DESC混用" class="headerlink" title="ASC、DESC混用"></a>ASC、DESC混用</h3><p>使用联合索引的各个排序列的排序顺序必须是一致的。</p>
<h3 id="排序列包含非同一个索引的列"><a href="#排序列包含非同一个索引的列" class="headerlink" title="排序列包含非同一个索引的列"></a>排序列包含非同一个索引的列</h3><p>无法使用索引进行排序</p>
<h3 id="用于分组"><a href="#用于分组" class="headerlink" title="用于分组"></a>用于分组</h3><p>使用B+树索引进行排序是一个道理，分组列的顺序也需要和索引列的顺序一致，也可以只使用索引列中左边的列进行分组</p>
<h3 id="回表"><a href="#回表" class="headerlink" title="回表"></a>回表</h3><p>会使用到两个B+树索引，一个二级索引，一个聚簇索引。 访问二级索引使用顺序I/O，访问聚簇索引使用随机I/O。需要回表的记录越多，使用二级索引的性能就越低。</p>
<h3 id="排序字段的选择"><a href="#排序字段的选择" class="headerlink" title="排序字段的选择"></a>排序字段的选择</h3><ul>
<li>只为用于搜索、排序或分组的列创建索引</li>
<li>考虑列的基数，为基数大的列建立索引；</li>
<li>索引列的类型尽量小，比如int  bigint</li>
<li>索引字符串值的前缀(B+树索引中的记录需要把该列的完整字符串存储起来，而且字符串越长，在索引中占用的存储空间越大)。只索引字符串值的前缀的策略是我们非常鼓励的，尤其是在字符串类型能存储的字符比较多的时候。</li>
<li>只有索引列在比较表达式中单独出现才可以使用索引</li>
<li>为了尽可能少的让聚簇索引发生页面分裂和记录移位的情况，建议让主键拥有AUTO_INCREMENT属性。</li>
<li>定位并删除表中的重复和冗余索引</li>
<li>尽量使用覆盖索引进行查询，避免回表带来的性能损耗。</li>
</ul>
<h2 id="使用mysql的查询"><a href="#使用mysql的查询" class="headerlink" title="使用mysql的查询"></a>使用mysql的查询</h2><h3 id="const-类型的查询"><a href="#const-类型的查询" class="headerlink" title="const 类型的查询"></a>const 类型的查询</h3><p>通过主键或者唯一二级索引列来定位一条记录的访问方法定义为：const。这种const访问方法只能在主键列或者唯一二级索引列和一个常数进行等值比较时才有效</p>
<h3 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h3><p>我们当然可以选择全表扫描来逐一对比搜索条件是否满足要求，我们也可以先使用二级索引找到对应记录的id值，然后再回表到聚簇索引中查找完整的用户记录。由于普通二级索引并不限制索引列值的唯一性，所以可能找到多条对应的记录，如果记录比较少效率还是挺高的。但如果记录多，有可能走的是随机io，所以性能会比较低。</p>
<h3 id="ref-or-null"><a href="#ref-or-null" class="headerlink" title="ref_or_null"></a>ref_or_null</h3><p>不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列的值为NULL的记录也找出来 。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &#x3D; &#39;abc&#39; OR key1 IS NULL;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="eq-ref"><a href="#eq-ref" class="headerlink" title="eq_ref"></a>eq_ref</h3><p>在连接查询中对被驱动表使用主键值或者唯一二级索引列的值进行等值查找的查询执行方式称之为：eq_ref</p>
<h3 id="index"><a href="#index" class="headerlink" title="index"></a>index</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 &#x3D; &#39;abc&#39;;</span><br><span class="line"></span><br><span class="line">由于key_part2并不是联合索引idx_key_part最左索引列，所以我们无法使用ref或者range访问方法来执行这个语句</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我们可以直接通过遍历idx_key_part索引的叶子节点的记录来比较key_part2 = ‘abc’这个条件是否成立，把匹配成功的二级索引记录的key_part1, key_part2, key_part3列的值直接加到结果集中就行了。由于二级索引记录比聚簇索记录小的多（聚簇索引记录要存储所有用户定义的列以及所谓的隐藏列，</p>
<p>而二级索引记录只需要存放索引列和主键），而且这个过程也不用进行回表操作，所以直接遍历二级索引比直接遍历聚簇索引的成本要小很多</p>
<h2 id="索引使用的特殊情况"><a href="#索引使用的特殊情况" class="headerlink" title="索引使用的特殊情况"></a>索引使用的特殊情况</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &#x3D; &#39;abc&#39; AND key2 &gt; 1000;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>根据single_table表的统计数据来判断到底使用哪个条件到对应的二级索引中查询扫描的行数会更少，选择那个扫描行数较少的条件到对应的二级索引中查询。</p>
<p>然后将从该二级索引中查询到的结果经过回表得到完整的用户记录后再根据其余的WHERE条件过滤记录。一般来说，等值查找比范围查找需要扫描的行数更少。</p>
<p>因为二级索引的节点中的记录只包含索引列和主键，所以在步骤1中使用idx_key1索引进行查询时只会用到与key1列有关的搜索条件，其余条件，比如key2 &gt; 1000这个条件在步骤1中是用不到的，只有在步骤2完成回表操作后才能继续针对完整的用户记录中继续过滤</p>
<h2 id="索引合并"><a href="#索引合并" class="headerlink" title="索引合并"></a>索引合并</h2><p>某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &#x3D; &#39;a&#39; AND key3 &#x3D; &#39;b&#39;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>第一种方案： 按照某个搜索条件读取一个二级索引，根据从该二级索引得到的主键值进行回表操作，然后再过滤其他的搜索条件。</p>
<p>第二种方案： 按照不同的搜索条件分别读取不同的二级索引，将从多个二级索引得到的主键值取交集，然后进行回表操作。</p>
<p>虽然读取多个二级索引比读取一个二级索引消耗性能，但是读取二级索引的操作是顺序I/O，而回表操作是随机I/O，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数非常少，当节省的因为回表而造成的性能损耗比访问多个二级索引带来的性能损耗更高时，读取多个二级索引后取交集比只读取一个二级索引的成本更低</p>
<ul>
<li>出现索引合并的情况 </li>
</ul>
<ol>
<li>二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况。</li>
<li>主键列可以是范围匹配 （索引合并会把从多个二级索引中查询出的主键值求交集，如果从各个二级索引中查询的到的结果集本身就是已经按照主键排好序的，那么求交集的过程就很easy）</li>
</ol>
<h2 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h2><p><code>内连接</code>中的WHERE子句和ON子句是等价的。</p>
<p>对于<code>外连接</code>的驱动表的记录来说，如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用NULL值填充。</p>
<p>对于内连接来说，驱动表和被驱动表是可以互换的，并不会影响最后的查询结果。但是对于外连接来说左外连接和右外连接的驱动表和被驱动表不能轻易互换。</p>
<h3 id="连接的原理"><a href="#连接的原理" class="headerlink" title="连接的原理"></a>连接的原理</h3><p>两表连接来说，驱动表只会被访问一遍，但被驱动表却要被访问到好多遍。</p>
<h3 id="全表扫描的代价。计算表的统计信息"><a href="#全表扫描的代价。计算表的统计信息" class="headerlink" title="全表扫描的代价。计算表的统计信息"></a>全表扫描的代价。计算表的统计信息</h3><ul>
<li>I/O成本： 将数据和索引从硬盘加载到内存中；读取一个页大小的默认成本1.0</li>
<li>CPU成本： 读取以及检测记录是否满足对应的搜索条件、对结果集进行排序；访问一条记录的成本是0.2</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">show table status like &#39;single_table&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>Rows 代表记录的行数，如果是myisam表示的是实际的记录数，innodb表示的是预估值；</li>
<li>Data_length 表示表占用的存储空间字节数。对于使用InnoDB存储引擎的表来说，该值就相当于聚簇索引占用的存储空间大小。 Data_length = 聚簇索引的页面数量 x 每个页面的大小。</li>
</ul>
<h2 id="innodb统计数据"><a href="#innodb统计数据" class="headerlink" title="innodb统计数据"></a>innodb统计数据</h2><p>SHOW TABLES FROM mysql LIKE ‘innodb%’;  // 从mysql库里查询innodb</p>
<p>SELECT * FROM mysql.innodb_index_stats  //从mysql库里查询索引统计信息</p>
<p>ANALYZE TABLE;  // ANALYZE TABLE语句会立即重新计算统计数据，也就是这个过程是同步的</p>
<h2 id="undo-log日志"><a href="#undo-log日志" class="headerlink" title="undo log日志"></a>undo log日志</h2><p>在事务对表中的记录做改动时才会为这个事务分配一个唯一的事务id</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2020-08-04/api%E7%BD%91%E5%85%B3%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020-08-04/api%E7%BD%91%E5%85%B3%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">api网关介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-04 00:20:09" itemprop="dateCreated datePublished" datetime="2020-08-04T00:20:09+08:00">2020-08-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 01:03:09" itemprop="dateModified" datetime="2020-08-21T01:03:09+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" itemprop="url" rel="index"><span itemprop="name">微服务</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>不使用网关带来的问题</p>
<ul>
<li>各个模块代码功能耦合。每个业务都会需要鉴权、限流、权限校验等逻辑，如果每个业务都各自为战，自己造轮子实现一遍，会很蛋疼，完全可以抽出来，放到一个统一的地方去做。</li>
<li>如果业务量比较简单的话，这种方式前期不会有什么问题，但随着业务越来越复杂，比如淘宝、亚马逊打开一个页面可能会涉及到数百个微服务协同工作，如果每一个微服务都分配一个域名的话，一方面客户端代码会很难维护，涉及到数百个域名，另一方面是连接数的瓶颈，想象一下你打开一个APP，通过抓包发现涉及到了数百个远程调用，这在移动端下会显得非常低效。</li>
<li>运维需要进行好多配置，域名配置、nginx配置。每上线一个新的服务，都需要运维参与，申请域名、配置Nginx等，当上线、下线服务器时，同样也需要运维参与，另外采用域名这种方式，对于环境的隔离也不太友好，调用者需要自己根据域名自己进行判断。</li>
<li>调用协议的不统一。另外还有一个问题，后端每个微服务可能是由不同语言编写的、采用了不同的协议，比如HTTP、Dubbo、GRPC等，但是你不可能要求客户端去适配这么多种协议，这是一项非常有挑战的工作，项目会变的非常复杂且很难维护。</li>
<li>后期如果需要对微服务进行重构的话，也会变的非常麻烦，需要客户端配合你一起进行改造，比如商品服务，随着业务变的越来越复杂，后期需要进行拆分成多个微服务，这个时候对外提供的服务也需要拆分成多个，同时需要客户端配合你进行改造，非常蛋疼。</li>
</ul>
<p>网关的功能</p>
<ul>
<li>流量的入口，服务的聚合；</li>
<li>针对流量进行的扩展。鉴权、限流、熔断、降级、协议转换、错误码统一、缓存、日志、监控、告警等。</li>
</ul>
<h1 id="具体的思路"><a href="#具体的思路" class="headerlink" title="具体的思路"></a>具体的思路</h1><h2 id="api的注册"><a href="#api的注册" class="headerlink" title="api的注册"></a>api的注册</h2><ul>
<li>第一种采用插件扫描业务方的API，比如Spring MVC的注解，并结合Swagger的注解，从而实现参数校验、文档&amp;&amp;SDK生成等功能，扫描完成之后，需要上报到网关的存储服务。</li>
<li>手动录入</li>
<li>配置文件的导入</li>
</ul>
<h2 id="协议转换"><a href="#协议转换" class="headerlink" title="协议转换"></a>协议转换</h2><p>内部的API可能是由很多种不同的协议实现的，比如HTTP、Dubbo、GRPC等，但对于用户来说其中很多都不是很友好，或者根本没法对外暴露，比如Dubbo服务，因此需要在网关层做一次协议转换，将用户的HTTP协议请求，在网关层转换成底层对应的协议</p>
<h2 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h2><ul>
<li>写死在代码/配置文件里，这种方式虽然比较挫，但也能使用，比如线上仍然使用的是物理机，IP变动不会很频繁，但扩缩容、包括应用上下线都会很麻烦，网关自身甚至需要实现一套健康监测机制。</li>
<li>域名。采用域名也是一种不错的方案，对于所有的语言都适用，但对于<code>内部的服务，走域名会很低效</code>，另外环境隔离也不太友好，比如预发、线上通常是同一个数据库，因此网关读取到的可能是同一个域名，这时候预发的网关调用的就是线上的服务。</li>
<li>注册中心。采用注册中心就不会有上述的这些问题，即使是在容器环境下，节点的IP变更比较频繁，但节点列表的实时维护会由注册中心搞定，对网关是透明的，另外应用的正常上下线、包括异常宕机等情况，也会由注册中心的健康检查机制检测到，并实时反馈给网关。并且采用注册中心性能也没有额外的性能损耗，采用域名的方式，额外需要走一次DNS解析、Nginx转发等，中间多了很多跳，性能会有很大的下降，但采用注册中心，网关是和业务方直接点对点的通讯，不会有额外的损耗。</li>
</ul>
<h2 id="服务调用"><a href="#服务调用" class="headerlink" title="服务调用"></a>服务调用</h2><p>网关由于对接很多种不同的协议，因此可能需要实现很多种调用方式，比如HTTP、Dubbo等，基于性能原因，最好都采用异步的方式，而Http、Dubbo都是支持异步的，比如apache就提供了基于NIO实现的异步HTTP客户端</p>
<h2 id="优雅下线"><a href="#优雅下线" class="headerlink" title="优雅下线"></a>优雅下线</h2><p>优雅下线也是网关需要关注的一个问题，网关底层会涉及到很多种协议，比如HTTP、Dubbo，而HTTP又可以继续细分，比如域名、注册中心等，有些自身就支持优雅下线</p>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><ul>
<li>网关作为所有流量的入口，性能是重中之重，早期大部分网关都是基于同步阻塞模型构建的，比如Zuul 1.x。但这种同步的模型我们都知道，每个请求/连接都会占用一个线程，而线程在JVM中是一个很重的资源，比如Tomcat默认就是200个线程，如果网关隔离没有做好的话，当发生网络延迟、FullGC、第三方服务慢等情况造成上游服务延迟时，线程池很容易会被打满，造成新的请求被拒绝，但这个时候其实线程都阻塞在IO上，系统的资源被没有得到充分的利用。另外一点，容易受网络、磁盘IO等延迟影响。需要谨慎设置超时时间，如果设置不当，且服务隔离做的不是很完善的话，网关很容易被一个慢接口拖垮</li>
<li>而异步化的方式则完全不同，通常情况下一个CPU核启动一个线程即可处理所有的请求、响应。一个请求的生命周期不再固定于一个线程，而是会分成不同的阶段交由不同的线程池处理，系统的资源能够得到更充分的利用</li>
</ul>
<h2 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h2><ul>
<li>单机。单机性能比较高，不涉及远程调用，只是本地计数，对接口RT影响最小。但需要考虑下限流数的设置，比如是针对单台网关、还是整个网关集群，如果是整个集群的话，需要考虑到网关缩容、扩容时修改对应的限流数。</li>
<li>分布式。分布式的就需要一个存储节点维护当前接口的调用数，比如redis、sentinel等，这种方式由于涉及到远程调用，会有些性能损耗，另外也需要考虑到存储挂掉的问题，比如redis如果挂掉，网关需要考虑降级方案，是降级到本地限流，还是直接将限流功能本身降级掉。另外还有不同的策略:简单计数、令牌桶等，大部分场景下其实简单计数已经够用了，但如果需要支持突发流量等场景时，可以采用令牌桶等方案</li>
</ul>
<h2 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h2><p>稳定性是网关非常重要的一环，监控、告警需要做的很完善才可以，比如接口调用量、响应时间、异常、错误码、成功率等相关的监控告警，还有线程池相关的一些，比如活跃线程数、队列积压等，还有些系统层面的，比如CPU、内存、FullGC这些基本的。网关是所有服务的入口，对于网关的稳定性的要求相对于其他服务会更高，最好能够一直稳定的运行，尽量少重启，但当新增功能、或者加日志排查问题时，不可避免的需要重新发布，因此可以参考zuul的方式，将所有的核心功能都基于不同的拦截器实现，拦截器的代码采用Groovy编写，存储到数据库中，支持动态加载、编译、运行，这样在出了问题的时候能够第一时间定位并解决，并且如果网关需要开发新功能，只需要增加新的拦截器，并动态添加到网关即可，不需要重新发布。</p>
<h2 id="熔断降级"><a href="#熔断降级" class="headerlink" title="熔断降级"></a>熔断降级</h2><p>可以基于Hystrix或者Resilience4j实现</p>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>接口的耗时、请求方式、请求IP、请求参数、响应参数(注意脱敏)等，另外由于可能涉及到很多微服务，因此需要提供一个统一的traceId方便关联所有的日志</p>
<h2 id="隔离"><a href="#隔离" class="headerlink" title="隔离"></a>隔离</h2><p>比如线程池、http连接池、redis等应用层面的隔离，另外也可以根据业务场景，将核心业务部署带单独的网关集群，与其他非核心业务隔离开。</p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>比如接口mock，文档生成、sdk代码生成、错误码统一、服务治理相关</p>
<p>参考 :<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/KnUUcl_3g3C7bZvJ1kvv1g">https://mp.weixin.qq.com/s/KnUUcl_3g3C7bZvJ1kvv1g</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2020-06-10/jvm%E8%B0%83%E4%BC%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020-06-10/jvm%E8%B0%83%E4%BC%98/" class="post-title-link" itemprop="url">jvm调优</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-10 15:56:39" itemprop="dateCreated datePublished" datetime="2020-06-10T15:56:39+08:00">2020-06-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 01:03:09" itemprop="dateModified" datetime="2020-08-21T01:03:09+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/jvm/" itemprop="url" rel="index"><span itemprop="name">jvm</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>873</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="什么情况下需要调优？"><a href="#什么情况下需要调优？" class="headerlink" title="什么情况下需要调优？"></a>什么情况下需要调优？</h4><blockquote>
<p> JVM 内存分配不合理最直接的表现就是频繁的 GC，这会导致上下文切换等性能问题，从而降低系统的吞吐量、增加系统的响应时间。</p>
<p> 因此，如果你在线上环境或性能测试时，发现频繁的 GC，且是正常的对象创建和回收，这个时候就需要考虑调整 JVM 内存分配了，从而减少 GC 所带来的性能开销。</p>
<ul>
<li><p>调整晋升到老年代的晋升年龄；-XX:PetenureSizeThreshold</p>
</li>
<li><p>年轻带和老年代 –XX:NewRatio  1：2；</p>
</li>
<li><p>Eden：survivor  -XX:SurvivorRatio：8</p>
</li>
<li><p>动态调整  -XX:+UseAdaptiveSizePolicy  </p>
</li>
<li><p>查询虚拟机默认的堆大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">MacBook-Pro:conf zhuningning$ java -XX:+PrintFlagsFinal -version | grep HeapSize</span><br><span class="line">    uintx ErgoHeapSizeLimit                         &#x3D; 0                                   &#123;product&#125;</span><br><span class="line">    uintx HeapSizePerGCThread                       &#x3D; 87241520                            &#123;product&#125;</span><br><span class="line">    uintx InitialHeapSize                          :&#x3D; 268435456                           &#123;product&#125;</span><br><span class="line">    uintx LargePageHeapSizeThreshold                &#x3D; 134217728                           &#123;product&#125;</span><br><span class="line">    uintx MaxHeapSize                              :&#x3D; 4294967296                          &#123;product&#125;</span><br><span class="line">java version &quot;1.8.0_161&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_161-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)</span><br></pre></td></tr></table></figure>

<p>使用gc日志方便查看问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- -XX:PrintGCTimeStamps：打印 GC 具体时间；</span><br><span class="line">- -XX:PrintGCDetails ：打印出 GC 详细日志；</span><br><span class="line">- -Xloggc: path：GC 日志生成路径</span><br></pre></td></tr></table></figure>


</li>
</ul>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2020-06-02/%E9%AB%98%E5%B9%B6%E5%8F%91%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020-06-02/%E9%AB%98%E5%B9%B6%E5%8F%91%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/" class="post-title-link" itemprop="url">高并发设计思想</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-02 14:25:13" itemprop="dateCreated datePublished" datetime="2020-06-02T14:25:13+08:00">2020-06-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 01:03:09" itemprop="dateModified" datetime="2020-08-21T01:03:09+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E5%B9%B6%E5%8F%91/" itemprop="url" rel="index"><span itemprop="name">高并发</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>14k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>13 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="高并发系统的通用设计方案"><a href="#高并发系统的通用设计方案" class="headerlink" title="高并发系统的通用设计方案"></a>高并发系统的通用设计方案</h4><blockquote>
<ul>
<li>横向扩展：分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量；还有一种是直接升级机器提高单个服务器处理请求的能力；</li>
<li>缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击；</li>
<li>异步：在某些场景下，未处理完成之前，我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求；</li>
</ul>
<p><strong>高并发系统的演进应该是循序渐进，以解决系统中存在的问题为目的和驱动力的。</strong></p>
</blockquote>
<h5 id="磁盘的结构以及慢的原因"><a href="#磁盘的结构以及慢的原因" class="headerlink" title="磁盘的结构以及慢的原因"></a>磁盘的结构以及慢的原因</h5><blockquote>
<ol>
<li><p>我们知道数据是放在持久化存储中的，一般的持久化存储都是使用磁盘作为存储介质的，而普通磁盘数据由机械手臂、磁头、转轴、盘片组成，盘片又分为磁道、柱面和扇区。</p>
</li>
<li><p>盘片是存储介质，每个盘片被划分为多个同心圆，信息都被存储在同心圆之中，这些同心圆就是磁道。在磁盘工作时盘片是在高速旋转的，机械手臂驱动磁头沿着径向移动，在磁道上读取所需要的数据。我们把磁头寻找信息花费的时间叫做寻道时间。</p>
</li>
<li><p>普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 ns（纳秒）级别，从千兆网卡上读取数据的时间是在μs（微秒）级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。</p>
</li>
</ol>
</blockquote>
<h5 id="异步处理的例子"><a href="#异步处理的例子" class="headerlink" title="异步处理的例子"></a>异步处理的例子</h5><blockquote>
<ul>
<li><p>我们熟知的 12306 网站。当我们订票时，页面会显示系统正在排队，这个提示就代表着系统在异步处理我们的订票请求。</p>
</li>
<li><p>采用异步的方式，后端处理时会把请求丢到消息队列中，同时快速响应用户，告诉用户我们正在排队处理，然后释放出资源来处理更多的请求。订票请求处理完之后，再通知用户订票成功或者失败。</p>
</li>
<li><p>处理逻辑后移到异步处理程序中，Web 服务的压力小了，资源占用的少了，自然就能接收更多的用户订票请求，系统承受高并发的能力也就提升了。</p>
</li>
</ul>
</blockquote>
<h5 id="系统的演进过程"><a href="#系统的演进过程" class="headerlink" title="系统的演进过程"></a>系统的演进过程</h5><blockquote>
<ul>
<li>最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。</li>
<li>随着流量的增加和业务的变化，修正架构中存在问题的点，如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。</li>
<li>当对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题。</li>
</ul>
</blockquote>
<h4 id="高并发的分层架构"><a href="#高并发的分层架构" class="headerlink" title="高并发的分层架构"></a>高并发的分层架构</h4><blockquote>
<p>表现层、业务逻辑层、数据访问层；</p>
</blockquote>
<h5 id="分层的好处"><a href="#分层的好处" class="headerlink" title="分层的好处"></a>分层的好处</h5><blockquote>
<ul>
<li><strong>分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。</strong></li>
<li><strong>再有，分层之后可以做到很高的复用。</strong></li>
<li><strong>分层架构可以让我们更容易做横向扩展。</strong></li>
</ul>
</blockquote>
<p><img src="/images/concurrentServer/%E9%98%BF%E9%87%8C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%88%86%E5%B1%82%E8%A7%84%E7%BA%A6.png" alt="阿里系统的分层规约"></p>
<h5 id="高并发系统设计的三大目标：高并发、高性能、高可用、可扩展"><a href="#高并发系统设计的三大目标：高并发、高性能、高可用、可扩展" class="headerlink" title="高并发系统设计的三大目标：高并发、高性能、高可用、可扩展"></a>高并发系统设计的三大目标：高并发、高性能、高可用、可扩展</h5><blockquote>
<ul>
<li><p>健康系统的 99 分位值的响应时间通常需要控制在 200ms 之内，而不超过 1s 的请求占比要在 99.99% 以上。</p>
</li>
<li><p>系统的吞吐量：你现在有一个系统，这个系统中处理核心只有一个，执行的任务的响应时间都在 10ms，它的吞吐量是在每秒 100 次</p>
</li>
<li><p>成本考虑，在业务平稳期，我们会预留 30%～50% 的冗余以应对运营活动或者推广可能带来的峰值流量，但是当有一个突发事件发生时，流量可能瞬间提升到 2～3 倍甚至更高</p>
</li>
</ul>
</blockquote>
<h4 id="如何减少频繁创建数据库连接的性能损耗？"><a href="#如何减少频繁创建数据库连接的性能损耗？" class="headerlink" title="如何减少频繁创建数据库连接的性能损耗？"></a>如何减少频繁创建数据库连接的性能损耗？</h4><blockquote>
<p>池化技术的使用技巧</p>
<ul>
<li><p>池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。</p>
</li>
<li><p>池子中的对象需要在使用之前预先初始化完成，这叫做池子的预热，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。</p>
</li>
<li><p>池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zguoshuaiiii/article/details/78402883"> 数据库连接池监控的使用</a></p>
</li>
<li><p><code>线上建议数据库连接池是min=10 max =20-30</code></p>
</li>
<li><p>jdk的ThreadPoolExecutor可以调用executor.getQueue().size()监控队列的使用情况</p>
</li>
</ul>
</blockquote>
<h4 id="数据库技术-查询请求增加时，如何做主从分离？"><a href="#数据库技术-查询请求增加时，如何做主从分离？" class="headerlink" title="数据库技术-查询请求增加时，如何做主从分离？"></a>数据库技术-查询请求增加时，如何做主从分离？</h4><blockquote>
<ul>
<li><p>数据库的主从复制</p>
<ul>
<li>MySQL 的主从复制是依赖于 binlog 的，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上二进制日志文件。主从复制就是将 binlog 中的数据从主库传输到从库上，<code>一般这个过程是异步</code>的，即主库上的操作不会等待 binlog 同步的完成。因为如果等待从库同步完返回，则写入性能会受影响，一般会优先考虑数据库性能而不是数据的强一致性；其实就是cap，保证的是a和p；</li>
<li>首先从库在连接到主节点时会创建一个 IO 线程，用以请求主库更新的 binlog，并且把接收到的 binlog 信息写入一个叫做 relay log 的日志文件中，而主库也会创建一个 log dump 线程来发送 binlog 给从库；同时，从库还会创建一个 SQL 线程读取 relay log 中的内容，并且在从库中做回放，最终实现主从的一致性。这是一种比较常见的主从复制方式。</li>
</ul>
<p><img src="/images/concurrentServer/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="mysql主从复制的过程"></p>
<ul>
<li>主库不是可以无限的挂载从库，因为每增加一个从库会消耗主库的dunp线程，同时受限于带宽的影响，所以需要一般挂载3-5个；</li>
</ul>
</li>
<li><p>主从复制实现读写分离是一种数据库横向扩展的方法；</p>
</li>
<li><p>主从同步延迟的问题解决</p>
<ul>
<li><p>使用消息中间件同步数据的时候，冗余发送全部数据而不是只发送id；</p>
</li>
<li><p><strong>使用缓存</strong></p>
</li>
<li><p><strong>查询主库</strong></p>
</li>
</ul>
</li>
<li><p>一般我们会把从库落后的时间作为一个重点的数据库指标做监控和报警，正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。 </p>
</li>
<li><p>实现主从分离的方案：</p>
<ul>
<li>第一种使用TDDL这种的jar包来处理，管理多个数据源；</li>
<li>第二种是单独部署代理层的方案，比如mycat、DBProxy(美团)，对外暴露的是一个数据库，其实内部管理多个数据源；</li>
</ul>
</li>
</ul>
</blockquote>
<h4 id="数据库优化方案（二）：写入数据量增加时，如何实现分库分表？"><a href="#数据库优化方案（二）：写入数据量增加时，如何实现分库分表？" class="headerlink" title="数据库优化方案（二）：写入数据量增加时，如何实现分库分表？"></a>数据库优化方案（二）：写入数据量增加时，如何实现分库分表？</h4><blockquote>
<ul>
<li><p>单数据库存在的问题：</p>
<ul>
<li>单表的数据量达到了千万甚至上亿，读写性能在下降；</li>
<li>数据量的增加占据了磁盘空间，数据库的备份和恢复时间太长；</li>
<li>不同模块的数据。比如用户数据和用户关系数据，全都存储在一个主库中，一旦主库发生故障，所有的模块儿都会受到影响</li>
</ul>
</li>
<li><p>分库分表在解决了数据<code>存储瓶颈</code>的同时也能有效的提升<code>数据查询的性能</code>，同时可以提高并发写数据的能力；</p>
</li>
<li><p><code>垂直拆分</code>是按照业务类型拆分，将业务耦合度搞的表拆分到单独的表中；</p>
</li>
<li><p><code>水平拆分</code>可以按照字段取模、按照时间字段的范围拆分；</p>
</li>
<li><p>分库分表存在的问题</p>
<ul>
<li><code>引入了分库分表键，也叫分区键</code>。就是对数据分库分表依据的字段；所以每次查询都要带上这个分区键。如果没有的话需要建立查询字段到数据库分区键的映射字段；</li>
<li><code>对于一些数据库的特性在实现的时候会很困难</code>，比如join的场景，好在这种场景不太高，如果需要的话可以查询出来在业务层处理。比如<code>count的情况</code> 我们可以单独的记录在一张表中或者记录在redis里。</li>
</ul>
</li>
</ul>
</blockquote>
<h4 id="如何保证分库分表后ID的全局唯一性？"><a href="#如何保证分库分表后ID的全局唯一性？" class="headerlink" title="如何保证分库分表后ID的全局唯一性？"></a>如何保证分库分表后ID的全局唯一性？</h4><blockquote>
<ul>
<li><p>变种的Snowflake 算法来生成业务需要的 ID </p>
<ul>
<li>时间戳（41位的时间错）、机器 ID（10位的机器id）、序列号（12位的序列号）、IDC（2位）；</li>
<li>每个节点每ms可以生成4096个id；</li>
<li>内置到代码中或者使用单独的服务来部署发号器（单实例单cpu 2万个/s）</li>
</ul>
</li>
<li><p>UUID（UUID无法实现有序）：需要排序、且有序的可以提高mysql的查询性能、32个16进制的数字耗费空间；</p>
</li>
<li><p>使用数据库的分片自增+步长的方式；</p>
</li>
</ul>
</blockquote>
<h4 id="在高并发场景下，数据库和NoSQL如何做到互补？"><a href="#在高并发场景下，数据库和NoSQL如何做到互补？" class="headerlink" title="在高并发场景下，数据库和NoSQL如何做到互补？"></a>在高并发场景下，数据库和NoSQL如何做到互补？</h4><blockquote>
<ul>
<li><p>nosql可以提高数据库的的读写能力，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写；例如mysql在存储数据的时候使用b+树，要找到指定的位置就要进行磁盘寻址，是一种随机IO。而Nosql（Hbase、Cassandra、LevelDB ）一般使用LSM数存储，他是将数据写到一种内存中的MemTable树中，然后写到磁盘上，；</p>
</li>
<li><p>在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持，使用ES的倒排索引来实现全文搜索；</p>
</li>
<li><p>提高数据库的扩展能力；NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。</p>
<blockquote>
<p>比如mongoDB的扩展性：</p>
<ul>
<li>一是 Replica，也叫做副本集，你可以理解为主从分离，也就是通过将数据拷贝成多份来保证当主挂掉后数据不会丢失。同时呢，Replica 还可以分担读请求。Replica 中有主节点来承担写请求，并且把对数据变动记录到 oplog 里（类似于 binlog）；从节点接收到 oplog 后就会修改自身的数据以保持和主节点的一致。一旦主节点挂掉，MongoDB 会从从节点中选取一个节点成为主节点，可以继续提供写数据服务。</li>
<li>二是 Shard，也叫做分片，你可以理解为分库分表，即将数据按照某种规则拆分成多份，存储在不同的机器上。MongoDB 的 Sharding 特性一般需要三个角色来支持，一个是 Shard Server，它是实际存储数据的节点，是一个独立的 Mongod 进程；二是 Config Server，也是一组 Mongod 进程，主要存储一些元信息，比如说哪些分片存储了哪些数据等；最后是 Route Server，它不实际存储数据，仅仅作为路由使用，它从 Config Server 中获取元信息后，将请求路由到正确的 Shard Server 中。</li>
<li>三是负载均衡，就是当 MongoDB 发现 Shard 之间数据分布不均匀，会启动 Balancer 进程对数据做重新的分配，最终让不同 Shard Server 的数据可以尽量的均衡。当我们的 Shard Server 存储空间不足需要扩容时，数据会自动被移动到新的 Shard Server 上，减少了数据迁移和验证的成本。</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="数据库成为瓶颈后，动态数据的查询要如何加速？"><a href="#数据库成为瓶颈后，动态数据的查询要如何加速？" class="headerlink" title="数据库成为瓶颈后，动态数据的查询要如何加速？"></a>数据库成为瓶颈后，动态数据的查询要如何加速？</h4><blockquote>
<ul>
<li><p>数据库磁盘IO成为系统的瓶颈后可以考虑使用缓存；内存的<code>寻址</code>100ns，磁盘的<code>查找</code>需要10ms</p>
</li>
<li><p><code>缓存</code> 不等于内存，凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存。</p>
<p><img src="/images/concurrentServer/%E7%BC%93%E5%AD%98%E7%9A%84%E9%80%9F%E5%BA%A6.png" alt="缓存的速度"></p>
</li>
<li><p><code>缓冲区</code>：<strong>缓冲区则是一块临时存储数据的区域，这些数据后面会被传输到其他设备上。</strong>缓冲区更像“消息队列篇”中即将提到的消息队列，用以弥补高速设备和低速设备通信时的速度差。比如，我们将数据写入磁盘时并不是直接刷盘，而是写到一块缓冲区里面，内核会标识这个缓冲区为脏。当经过一定时间或者脏缓冲区比例到达一定阈值时，由单独的线程把脏块刷新到硬盘上。这样避免了每次写数据都要刷盘带来的性能问题。</p>
</li>
<li><p>缓存的分类</p>
<blockquote>
<ul>
<li>静态缓存：静态数据，比如文档内容在生成的时候会渲染一个静态页面放在nginx服务器上</li>
<li>分布式缓存</li>
<li>热点数据本地缓存：热点数据的缓存放到进程中的hashMap中，多个进程中可能存在不同，但用户是可以接受的。如果没有从数据库中或分布式缓存中拉取，Guava 的 Loading Cache。这种通常缓存时间比较短，秒级别的或者分钟级别的，避免脏数据。</li>
</ul>
</blockquote>
</li>
<li><p>缓存的不足</p>
<blockquote>
<ul>
<li><strong>缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性</strong></li>
<li><strong>缓存会给整体系统带来复杂度，并且会有数据不一致的风险</strong></li>
<li><strong>之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的</strong>，所以需要做下数据存储量级的评估；</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="如何选择缓存的读写策略？"><a href="#如何选择缓存的读写策略？" class="headerlink" title="如何选择缓存的读写策略？"></a>如何选择缓存的读写策略？</h4><blockquote>
<ul>
<li><p>缓存的读取策略</p>
<ul>
<li>从缓存中读取数据；</li>
<li>如果缓存命中，则直接返回数据；</li>
<li>如果缓存不命中，则从数据库中查询数据；</li>
<li>查询到数据后，将数据写入到缓存中，并且返回给用户。</li>
</ul>
</li>
<li><p>缓存的修改策略 </p>
<ul>
<li>先更新数据库，</li>
<li>更新成功后删除缓存</li>
</ul>
</li>
<li><p><code>直接修改缓存也是不可以的，会造成库和缓存不一致的问题</code></p>
<p>这个过程中也会有并发的问题，比如说原有金额是 20，A 请求从缓存中读到数据，并且把金额加 1，变更成 21，在未写入缓存之前又有请求 B 也读到缓存的数据后把金额也加 1，也变更成 21，两个请求同时把金额写回缓存，这时缓存里面的金额是 21，但是我们实际上预期是金额数加 2，这也是一个比较大的问题。</p>
</li>
<li><p><code>更新缓存的时候 先删除缓存，后修改数据库</code></p>
<p>假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21，这就造成了缓存和数据库的不一致。</p>
</li>
</ul>
</blockquote>
<h4 id="缓存如何做到高可用？"><a href="#缓存如何做到高可用？" class="headerlink" title="缓存如何做到高可用？"></a>缓存如何做到高可用？</h4><blockquote>
<ul>
<li><p><strong>客户端方案</strong>：就是在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。有点是性能没有损耗，缺点是客户端逻辑复杂；多语言环境不能复用；</p>
<blockquote>
<p>单一的缓存节点受到机器内存、网卡带宽和单节点请求量的限制，不能承担比较高的并发，因此我们考虑将数据分片，依照分片算法将数据打散到多个不同的节点上，每个节点上存储部分数据；</p>
<p>考虑一致性hash算法，当某个节点不可用的时候就沿着环往下寻找第一个遇到的可用节点。增加和删除节点只会影响一个节点上的数据，不会影响所有数据；虚拟节点的问题；</p>
</blockquote>
</li>
<li><p><strong>中间代理层方案</strong>：是在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。</p>
<p>业界也有很多中间代理层方案，比如 Facebook 的<a target="_blank" rel="noopener" href="https://github.com/facebook/mcrouter">Mcrouter</a>，Twitter 的<a target="_blank" rel="noopener" href="https://github.com/twitter/twemproxy">Twemproxy</a>，豌豆荚的<a target="_blank" rel="noopener" href="https://github.com/CodisLabs/codis">Codis</a>。</p>
<p>中间代理层是只是实现了高可用的路由功能；性能上有损耗</p>
</li>
<li><p><strong>服务端方案</strong>：是 Redis 2.4 版本后提出的 Redis Sentinel 方案。</p>
<p>Redis Sentinel 也是集群部署的，这样可以避免 Sentinel 节点挂掉造成无法自动故障恢复的问题，每一个 Sentinel 节点都是无状态的。在 Sentinel 中会配置 Master 的地址，Sentinel 会时刻监控 Master 的状态，当发现 Master 在配置的时间间隔内无响应，就认为 Master 已经挂了，Sentinel 会从从节点中选取一个提升为主节点，并且把所有其他的从节点作为新主的从节点。Sentinel 集群内部在仲裁的时候，会根据配置的值来决定当有几个 Sentinel 节点认为主挂掉可以做主从切换的操作，也就是集群内部需要对缓存节点的状态达成一致才行。</p>
</li>
</ul>
</blockquote>
<h4 id="缓存穿透了怎么办？"><a href="#缓存穿透了怎么办？" class="headerlink" title="缓存穿透了怎么办？"></a>缓存穿透了怎么办？</h4><blockquote>
<p>在低缓存命中率的系统中，大量查询商品信息的请求会穿透缓存到数据库，因为数据库对于并发的承受能力是比较脆弱的。一旦数据库承受不了用户大量刷新商品页面、定向搜索衣服信息，就会导致查询变慢，导致大量的请求阻塞在数据库查询上，造成应用服务器的连接和线程资源被占满，最终导致你的电商系统崩溃。</p>
<p><code>解决方案</code>：</p>
<ul>
<li><p>回种空值，但是要注意 全是当内存不够用的时候会存在全是空值的情况；</p>
</li>
<li><p>使用布隆过滤器：二进制数组和一个 Hash 算法组成</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">加入要判断用户是否存在缓存中</span><br><span class="line">1. 初始化一个20亿的数组； 20亿&#x2F;8&#x2F;1024&#x2F;2014 &#x3D; 238M</span><br><span class="line">2. 把所有的数据库的用户id进行取hash然后对20亿取余，计算出在布隆过滤器的位置，设置为1；新增的数据插入数据库中，同事布隆过滤对应的位置也设置为1；</span><br><span class="line">3. 然后获取数据前，先从布隆过滤器中判断是否存在；</span><br><span class="line"></span><br><span class="line">存在hash碰撞，所以会误判。不存在的却被布隆过滤器判断为存在；可以使用多个hash值解决</span><br><span class="line">不支持删除。不止使用0和1 也是用2，但会浪费空间</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<h4 id="CDN：静态资源如何加速？-content-deliver-network"><a href="#CDN：静态资源如何加速？-content-deliver-network" class="headerlink" title="CDN：静态资源如何加速？(content deliver network)"></a>CDN：静态资源如何加速？(content deliver network)</h4><blockquote>
<p>静态资源（js文件、css文件、html、图片、视频、流媒体信息）都放到nginx等web服务器上，他们的读请求量极大，对访问速度要求极高，占据和很高的带宽；</p>
<p>使用CDN技术在业务服务器的上一层，增加一层特殊的缓存，用来承担绝大多数的静态资源的访问，这一层遍布在全国各地，这用用户选择就近的节点访问。</p>
<p><code>CDN是如何实现加速用户对静态资源的请求的</code></p>
<ul>
<li>DNS解决域名映射问题：一种是返回域名对应的ip，叫A记录；一种是返回CName记录就是返回域名对应的另一个域名；</li>
</ul>
<p><img src="/images/concurrentServer/DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B.png" alt="DNS域名解析过程"></p>
<ul>
<li>使用GSLB（全局负载均衡）对于部署在各地的服务器之间做负载均衡，另一方面保证流量流经的服务器与流量源头在地缘上是比较近的；</li>
</ul>
</blockquote>
<h4 id="消息队列：秒杀时如何处理每秒上万次的下单请求？"><a href="#消息队列：秒杀时如何处理每秒上万次的下单请求？" class="headerlink" title="消息队列：秒杀时如何处理每秒上万次的下单请求？"></a>消息队列：秒杀时如何处理每秒上万次的下单请求？</h4><blockquote>
<ul>
<li><p>消息队列是暂时存储数据的容器，它是一个平衡低俗系统和告诉系统处理任务时间差的工具。</p>
</li>
<li><p>将用户请求放入到消息队列中，返回秒杀进行中；然后处理后续的下单、业务处理；之后处理结果返回给用户。</p>
</li>
<li><p>通过异步处理简化业务流程；重要的业务线处理，次要的业务异步处理；</p>
<p><code>异步处理、削峰填谷、解耦合</code></p>
</li>
<li><p>主要作用：提高写性能，实现系统的解耦合，提高高并发的写流量；</p>
</li>
</ul>
</blockquote>
<h4 id="消息投递：如何保证消息仅仅被消费一次？"><a href="#消息投递：如何保证消息仅仅被消费一次？" class="headerlink" title="消息投递：如何保证消息仅仅被消费一次？"></a>消息投递：如何保证消息仅仅被消费一次？</h4><blockquote>
<ul>
<li><p>生产消息中丢失消息</p>
<blockquote>
<ul>
<li>发送失败或者超时，则进行消息重传；</li>
</ul>
</blockquote>
</li>
<li><p>消息队列中消息的丢失</p>
<blockquote>
<ul>
<li>为了减少存储消息对磁盘的随机IO，会将消息先写入到操作系统的page Cache中，再找合适的时机输入到磁盘上。可以配置cache达到一定消息数量或者间隔一段时间后再刷盘，也就是异步刷盘；</li>
<li>部署集群的方法，集群部署中leader中的数据会同步给ISR中的follower，有个ACK机制，配置成所有的ISR同步完毕才代表发送成功；kafka集群还有集群的leader选举机制；</li>
</ul>
</blockquote>
</li>
<li><p>消费过程中消息的丢失</p>
<blockquote>
<ul>
<li><p>消费消息的三步：接收消息、处理消息、更新消费进度</p>
</li>
<li><p>服务端和消费端进行幂等处理：多次和一次执行的结果一样；</p>
</li>
<li><p><code>生产端，消息服务器队列会存储生产者id和最后一条消息的映射，消息服务端会将消息id和最后一条消息的id进行比对</code>；</p>
</li>
<li><p>生产的时候生成一个全局唯一id，消费后进行保存到缓存，消费的时候判断消息是否存在；而且你得用事务处理，消息处理和写入缓存必须保证原子性；</p>
</li>
<li><p>或者处理的时候增加一个版本号使用乐观锁的机制；</p>
</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="消息队列：如何降低消息队列系统中消息的延迟？"><a href="#消息队列：如何降低消息队列系统中消息的延迟？" class="headerlink" title="消息队列：如何降低消息队列系统中消息的延迟？"></a>消息队列：如何降低消息队列系统中消息的延迟？</h4><blockquote>
<ul>
<li><p>增加消费者组的消费者的数量，一个partition只能被一个消费者组中的一个消费者消费，所以需要新建topic并且创建多个消费者来处理；</p>
</li>
<li><p>增加线程池异步处理；</p>
</li>
<li><p>拉取不到消息则sleep一段时间；</p>
<p><code>数据从磁盘写入到缓冲区的过程</code>：</p>
<p><img src="/images/concurrentServer/%E6%95%B0%E6%8D%AE%E4%BB%8E%E7%A3%81%E7%9B%98%E5%86%99%E5%85%A5%E5%88%B0%E7%BD%91%E7%BB%9C%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="数据从磁盘写入到网络的过程"></p>
</li>
</ul>
</blockquote>
<h4 id="系统架构：每秒1万次请求的系统要做服务化拆分吗？"><a href="#系统架构：每秒1万次请求的系统要做服务化拆分吗？" class="headerlink" title="系统架构：每秒1万次请求的系统要做服务化拆分吗？"></a>系统架构：每秒1万次请求的系统要做服务化拆分吗？</h4><blockquote>
<p><code>一体化项目的优点</code></p>
<ul>
<li>开发简单直接，项目和代码集中式管理；</li>
<li>节省了运维系统的成本；</li>
<li>排查问题简单；</li>
</ul>
<p><code>一体化项目缺点</code></p>
<ul>
<li>系统的资源出现扩展性问题：数据库连接数成为系统的瓶颈。数据库最大连接数是8000，各个客户端的连接数是30，还有别的消息队列的服务需要连接数据库；</li>
<li>大家共同维护一套代码：增加了研发的成本，抑制了研发的效率。业务变大的时候需要拆分成各个小团队，各个小组维护一套代码在配合时会出现问题；一个小问题影响这个服务；</li>
<li>一体化架构对运维也有很大影响，代码比较多，比较复杂，任何小的修改都需要上线；</li>
</ul>
<p><code>微服务的拆分</code></p>
<ul>
<li>按照业务拆分：拆成内容服务、用户服务、互动服务，各个服务有各自的数据库；各个服务职能直接调用自己的库，调用其它库只能通过别的服务去调用，减少了数据库连接数；</li>
<li>按照公共逻辑拆分：减少重复代码；</li>
</ul>
<p><code> 系统演进的感悟</code></p>
<ul>
<li>前期考虑的是性能、可用性、可扩展性；</li>
<li>后期考虑成功：研发团队、开发成本、沟通成本、运维成本；要做一些小工具提高工程师的效率；</li>
</ul>
</blockquote>
<h4 id="微服务架构：微服务化后，系统架构要如何改造？"><a href="#微服务架构：微服务化后，系统架构要如何改造？" class="headerlink" title="微服务架构：微服务化后，系统架构要如何改造？"></a>微服务架构：微服务化后，系统架构要如何改造？</h4><blockquote>
<p>服务拆分的原则：</p>
<ul>
<li>单一服务内部功能高内聚、低耦合。每个服务只完成自己的职责的任务，对于不是自己职责的功能要交给其他模块完成；比如判断用户是否为认证用户的逻辑要放在用户服务中而不能放到内容服务中；</li>
<li>服务拆分的粒度，先粗略拆分、再逐渐细化；比如黑名单相关的服务要先拆到用户服务中，后期可以再细拆；</li>
<li>拆分的过程尽量避免日常功能的迭代<ul>
<li>优先剥离比较独立的边界服务，从非核心服务出发，减少对现有服务的影响。也给团队一个试错的机会；</li>
<li>两个服务有依赖关系的时候，需要先拆分被依赖的服务；</li>
</ul>
</li>
<li>服务接口的定义要具备可扩展性；比如一个微服务的接口有三个参数，一次需求开发中，组内的同学调整为4个参数，调用方没有修改，所以会报错；</li>
</ul>
<p>微服务化带来的问题和解决思路</p>
<ul>
<li><code>引入服务注册中心</code>：服务接口的调用是跨进程的网络调用，同时接口调用方需要知道服务部署在哪个机器上，哪个端口上；于是需要引入服务注册中心；</li>
<li><code>多个服务之间有复杂的依赖关系，需要服务治理体系</code>：单个服务会影响别的依赖该服务的其它服务，这时候需要熔断、限流、降级、超时控制；</li>
<li>需要快速定位调用链路的问题，这时候需要引入<code>分布式追踪工具</code>，以及服务端监控报表；</li>
</ul>
</blockquote>
<h4 id="RPC框架：10万QPS下如何实现毫秒级的服务调用"><a href="#RPC框架：10万QPS下如何实现毫秒级的服务调用" class="headerlink" title="RPC框架：10万QPS下如何实现毫秒级的服务调用"></a>RPC框架：10万QPS下如何实现毫秒级的服务调用</h4><blockquote>
<p>微服务拆分后存在问题</p>
<ul>
<li>跨网络通讯的问题；</li>
<li>服务治理问题；</li>
</ul>
<p>RPC框架的性能要求</p>
<ul>
<li>选择合适的网络模型，针对性的调整网络参数，优化网络传输性能；</li>
<li>选择合适的序列化方式，以提升封包和解包的性能；</li>
</ul>
<p><img src="/images/concurrentServer/RPC%E6%A1%86%E6%9E%B6%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9.png" alt="RPC框架的设计注意事项"></p>
</blockquote>
<h4 id="注册中心：分布式系统如何寻址？"><a href="#注册中心：分布式系统如何寻址？" class="headerlink" title="注册中心：分布式系统如何寻址？"></a>注册中心：分布式系统如何寻址？</h4><blockquote>
<p>注册中心组件：老派的zookeeper、k8s使用的etcd、springcloud使用的eureka，阿里使用nacos；</p>
<p>主要功能：</p>
<ol>
<li><p>提供了服务地址的存储，本地会做缓存；</p>
</li>
<li><p>当存储内容发生变化的时候，可以经变更的内容推送给客户端；（紧急扩容和服务节点故障需要变更节点）</p>
</li>
</ol>
<p>探测存活一般使用两种机制：</p>
<ol>
<li>主动请求探活机制：子服务提供一个端口，每隔一段时间注册中心向子服务探测是否可用。存在问题：①：端口固定，多了有可能被占用；②：服务多了注册中心的压力比较大；</li>
<li>使用心跳机制：子服务每次向注册中心提供心跳，注册中心接受到心跳包后会在注册中心更新服务的续约时间。然后注册中心会定期检测当前时间和节点，如果阈值超过一定时间，那么节点被标记为不可用；</li>
</ol>
<p>注意事项：</p>
<ul>
<li>注册中心存在过度摘除的问题，可以使用保护策略。如果存活节点少于40%，则停止摘除服务，同时服务报警；</li>
</ul>
</blockquote>
<h4 id="分布式Trace（链路追踪）：横跨几十个分布式组件的慢请求要如何排查？"><a href="#分布式Trace（链路追踪）：横跨几十个分布式组件的慢请求要如何排查？" class="headerlink" title="分布式Trace（链路追踪）：横跨几十个分布式组件的慢请求要如何排查？"></a>分布式Trace（链路追踪）：横跨几十个分布式组件的慢请求要如何排查？</h4><blockquote>
<p>主要作用</p>
<ul>
<li>跨进程的调用链展示，服务依赖分析，在性能优化和问题排查方面提供数据上的支持；</li>
<li>常用组件zipkin、jaeger</li>
</ul>
<p>一体化服务的问题排查过程：</p>
<ul>
<li>简单的可以添加每个方法的调用时间日志，逐步排查；</li>
<li>使用切面对每个方法添加打印调用时间的操作；</li>
</ul>
<p>动态代理和静态代理</p>
<ul>
<li>静态代理是在编译器插入代码，增加了编译的时间，运行期对性能没有影响；</li>
<li>动态代理不会修改class文件，在运行期生成一个代理对象，这个代理对象会对源对象做字节码增强，来完成切面需要做的工作。由于需要在运行期间生成代理对象，则动态代理性能要不静态代理的查；</li>
</ul>
<p>打印日志的小技巧：</p>
<ul>
<li>尽量使用ASPECTJ 做静态代理，减少了对代码的侵入性；</li>
<li>对性能要低损耗；</li>
<li>使用requstId标记调用流程；</li>
<li>对请求id做取模 requestId%10==0 采样打印，以减少日志量；</li>
<li>分布式存储，不能打印日志到服务器上，使用放入到mq中，发送日志到es中；</li>
</ul>
<p>微服务的服务问题排查过程</p>
<ul>
<li><p>使用traceId(requestId)记录服务内的调用，使用spanId记录每一次RPC调用；</p>
<p><img src="/images/concurrentServer/%E5%88%86%E5%B8%83%E5%BC%8FtraceId%E8%BF%BD%E8%B8%AA%E9%97%AE%E9%A2%98.png" alt="分布式traceId追踪问题"></p>
</li>
</ul>
</blockquote>
<h4 id="负载均衡：怎样提升系统的横向扩展能力？"><a href="#负载均衡：怎样提升系统的横向扩展能力？" class="headerlink" title="负载均衡：怎样提升系统的横向扩展能力？"></a>负载均衡：怎样提升系统的横向扩展能力？</h4><blockquote>
<p> 负载均衡服务分类：</p>
<ul>
<li><p>代理类负载均衡服务；</p>
<blockquote>
<p> LVS：它在osi的第四层（传输层）；</p>
<p>nginx：它在地七层（应用层）；</p>
<p>一般使用lvs–&gt;多个nginx。单节点的nginx可以承担10万以下的QPS，lvs可以承担更大的流量。</p>
</blockquote>
</li>
<li><p>客户端负载均衡服务</p>
<p>rpc服务一般使用的rpc协议，而不是http协议，不能使用nginx这种，所以需要使用客户端负载均衡，也就是负载均衡服务内嵌在rpc客户端内。它提供多种节点选取的策略。这种一般是配合注册中心来使用，注册中心负责提供服务节点列表，客户端负责选取后进行服务调用</p>
</li>
<li><p>常见的负载均衡策略</p>
<blockquote>
<ul>
<li><p>静态策略：在选择节点时不会根据后端的服务实际运行状态来选择；</p>
<p>轮训的策略、权重的策略、ipHash、url_hash</p>
</li>
<li><p>动态策略：在选择节点时会根据后端服务的状态来进行选择；</p>
<p>根据服务的存活情况，服务的连接数，服务的响应时间来动态的分配权重；</p>
<p>nginx的探活模块可以指定服务的接口探测是否可用</p>
<p><img src="/images/concurrentServer/nginx%E7%9A%84%E6%8E%A2%E6%B4%BB%E6%A8%A1%E5%9D%97.png" alt="nginx的探活模块"></p>
</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="API网关，系统的门面设计"><a href="#API网关，系统的门面设计" class="headerlink" title="API网关，系统的门面设计"></a>API网关，系统的门面设计</h4><blockquote>
<ul>
<li><p>概念</p>
<p>  api网关是一个架构模式，他可以将服务共有的功能整合在一起，独立部署为单独的一层，来解决一些服务治理问题。对出入系统的流量做统一的管控。分为入口和出口网关；</p>
</li>
<li><p>作用：入口网关通常部署在负载均衡服务器和应用服务器之间</p>
<ol>
<li>给客户端提供一个统一的接入地址，它可以根据用户的请求路由到不同的业务服务上。你部署的微服务对外暴露的协议可能不同，api网关可以屏蔽这些细节；</li>
<li>做服务治理，比如熔断、降级、流量控制和分流；</li>
<li>客户端的授权和认证；</li>
<li>针对设备id、用户id、用户ip维度做一些黑白名单策略；</li>
<li>做日志记录；</li>
</ol>
</li>
<li><p>实现的注意事项</p>
<ol>
<li>网关注重的是性能和扩展性，你可以采用多路IO复用模型和线程池并发处理，来提升网关性能；使用责任链模式来提升网关的扩展性；</li>
<li>API网关的线程池可以针对不同的接口或者服务做隔离保护，提升网关的可用性；</li>
<li>API网关可以代替原本系统中的web层，将web层中的协议转换，认证、限流等功能放入api网关中；</li>
</ol>
</li>
<li><p>API网关的开源实现</p>
<ol>
<li>kong是在nginx中运行的lua程序，得益于nginx的优势，kong对于api网关来说性能是最好的；</li>
<li>zuul是spring cloud全家桶中的一员，他是java开发的，zuul1使用的是同步阻塞模型，所以性能不是很高，zuul2使用异步nio的线程模型，但成熟度不高；</li>
<li>Tyk是go语言实现的轻量级API网关；</li>
</ol>
</li>
</ul>
</blockquote>
<h4 id="全链路压力测试"><a href="#全链路压力测试" class="headerlink" title="全链路压力测试"></a>全链路压力测试</h4><blockquote>
<p> 普通的压测存在的问题</p>
<ul>
<li>首先压测时需要使用线上数据和线上环境；</li>
<li>其次，压力测试不能模拟请求，而是要使用线上的流量，你可以使用拷贝流量的方式把线上的流量拷贝到压测测试环境；比如线上的缓存数据，不可能让你使用一条数据，你命中缓存后都走缓存；</li>
<li>不能从一台服务器发起，这样很容易达到这台服务器性能瓶颈，从而导致压力测试服务器的QPS上不去；</li>
</ul>
<p><code>全链路压测</code>和<code>性能监控平台</code></p>
<p>   不能针对某个模块来做压测，需要对后端服务、数据库、缓存、消息队列、中间件等所有的服务做压测。</p>
<p>全链路压测平台的关键点</p>
<ul>
<li><p>流量隔离</p>
<blockquote>
<p>要区分压力测试流量和正式流量；</p>
</blockquote>
</li>
<li><p>风险的控制</p>
<blockquote>
<p>需要避免压力测试对正常用户的影响；</p>
</blockquote>
<p>全链路压测要包括以下模块</p>
</li>
<li><p>流量构造和生产模块；</p>
<blockquote>
<ol>
<li>一般将http请求入口流量拷贝一份，然后经过清洗后放入到nosql存储数据库中；一般可以使用nginx日志，然后将日志进行解析（增加开发成本）；</li>
<li>另一种是使用开源的流量拷贝工具GoReplay，它可以劫持本机某一个端口的流量，将他们记录在文件中，在压测时进行流量回放；</li>
</ol>
</blockquote>
</li>
<li><p>压测数据隔离模块，流量染色；</p>
<blockquote>
<ol>
<li>一般，我们针对读取数据（下行流量）的请求，会针对不能压测的服务或者组件做mock处理，比如浏览数据的行为不能做统计；比如展示过的数据，被请求过就不在展示了，这种要做特殊处理；这些数据要搭建mock服务，最好部署在真实的机房；</li>
<li>对于写入的数据，我们会把数据写入到影子库中，和线上的数据完全隔离；对于mysql中的麽易新建一个mysql实例，把线上的schema和数据导入到进来，redis可以新增加一个前缀；es可以新建一个索引；</li>
</ol>
</blockquote>
</li>
<li><p>系统健康检查和压测流量干预模块；</p>
<blockquote>
<ol>
<li>先设置流量测试的压力目标比如 20万次/QPS</li>
<li>逐渐增加压力，观察一段时间；</li>
<li>做一些工具，来根据监控通知机制服务</li>
</ol>
</blockquote>
<p><img src="/images/concurrentServer/%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="全链路压测架构图"></p>
</li>
</ul>
<p>全链路压测的意义</p>
<ol>
<li>帮助我们发现系统中的性能瓶颈，方便我们做预案来应对；</li>
<li>为我们做容量评估，提供数据支撑；</li>
<li>在压测时候做预案演练；</li>
</ol>
</blockquote>
<h4 id="多机房部署：跨地域的分布式系统如何做？"><a href="#多机房部署：跨地域的分布式系统如何做？" class="headerlink" title="多机房部署：跨地域的分布式系统如何做？"></a>多机房部署：跨地域的分布式系统如何做？</h4><blockquote>
<p> IDC机房（互联网数据中心）部署多套服务，共享一份业务数据，共同承担来自客户的流量；</p>
<p>跨机房：</p>
<ul>
<li>北京同地双机房之间的专线延迟一般在1-3ms；</li>
<li>国内异地双机房之间的专线延迟在50ms内；根据距离有所不同；</li>
<li>国际化的服务延迟在100-200ms，所以需要做异步数据同步，无法做到同步调用；</li>
</ul>
<p>同城多机房允许有跨机房的写入的发生，但是数据的读取服务的调用尽量保证在一个机房；</p>
<p>异地多活方案则应该避免跨机房同步数据的读取和写入，采用异步的方式，将数据从一个机房同步到另一个机房；</p>
</blockquote>
<h4 id="Service-Mesh：如何屏蔽服务化系统的服务治理细节？"><a href="#Service-Mesh：如何屏蔽服务化系统的服务治理细节？" class="headerlink" title="Service Mesh：如何屏蔽服务化系统的服务治理细节？"></a>Service Mesh：如何屏蔽服务化系统的服务治理细节？</h4><blockquote>
<p>前面提到的服务治理方案：</p>
<ul>
<li>用RPC框架解决服务通信的问题；</li>
<li>用注册中心解决服务注册，和发现的问题；</li>
<li>使用分布式Trace中间件，排查跨服务调用慢请求；</li>
<li>使用负载均衡服务器，解决服务扩展性的问题</li>
<li>使用API网关植入服务熔断、降级、流控等服务治理的策略；</li>
</ul>
<p>跨语言的细节</p>
<p>比如序列化的协议、各种api网关的策略</p>
<p>使用istio来实现service mesh来解决各个服务模块的治理的细节；</p>
</blockquote>
<h4 id="给系统加上眼睛：服务端监控要怎么做？"><a href="#给系统加上眼睛：服务端监控要怎么做？" class="headerlink" title="给系统加上眼睛：服务端监控要怎么做？"></a>给系统加上眼睛：服务端监控要怎么做？</h4><blockquote>
<p>主要存在的问题</p>
<ul>
<li>使用数据库主从延迟变长，导致业务上出现问题；</li>
<li>接口响应时间变长；</li>
<li>系统中出现大量错误，影响了用户的使用；</li>
</ul>
<p>如何搭建监控服务</p>
<ul>
<li><p>指标：除了基础机器的基础指标还有以下业务指标；</p>
<blockquote>
<ul>
<li><p>延迟：比如接口的响应时间、访问数据库和缓存的延迟；</p>
</li>
<li><p>通信量：可以理解为吞吐量，也就是单位时间内请求量的大小。比如第三方服务的请求量、访问消息队列的请求量；</p>
</li>
<li><p>错误：当前系统的错误数量，比如错误码 4** 5**，也比如虽然返回200，但是业务上是异常的；</p>
</li>
<li><p>饱和度：服务或者资源达到上限的程度，比如cpu使用率、内存使用率、数据库连接池使用情况；</p>
</li>
</ul>
<p><img src="/images/concurrentServer/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87.png" alt="监控指标"></p>
</blockquote>
</li>
<li><p>采集指标的方法和途径：</p>
<blockquote>
<ul>
<li><p>使用<code>代理</code>主要监控的是服务端的情况，比如redis调用它的state命令获取它的统计数据，kafka的队列队堆积数或者GC信息都可以通过JMX来监控使用；</p>
</li>
<li><p>在代码中<code>埋点</code>，主要是在客户端使用的情况。使用之前说到的trace组件，监控服务的耗时，调用量，慢请求数，发送给监控服务器； 注意对数据的汇总，不要每个请求都发送数据；</p>
</li>
<li><p><code>日志</code>也可以作为指标来源。可以使用开源的日志采集工具，flume、fluentd、filebeat</p>
</li>
<li><p>Prometheus </p>
</li>
</ul>
</blockquote>
</li>
<li><p>指标采集后如何处理和展示：</p>
<blockquote>
<p>使用kafka接收消息，消费填谷；</p>
<p>然后使用一个消费来写入es，然后通过kibana来展示，这些主要用来做原始数据的查询；</p>
<p>另一种是做流式数据处理的中间件比如spark、storm来做数据处理</p>
<blockquote>
<ul>
<li>解析数据的请求量、响应时间、请求url等数据；</li>
<li>做一些聚合运算，比如tomcat的访问日志，对同一个url一段时间内的请求量、响应时间分隔位置、非200请求量的大小；</li>
<li>存入时序数据库中，比如influxDB。</li>
<li>最后使用grafana来连接时序数据库，将监控数据制作成报表，呈现出来；</li>
</ul>
</blockquote>
</blockquote>
<p><img src="/images/concurrentServer/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="监控系统架构图"></p>
<p><img src="/images/concurrentServer/%E7%9B%91%E6%8E%A7%E5%BD%A2%E6%88%90%E7%9A%84%E6%8A%A5%E8%A1%A8.png" alt="监控形成的报表"></p>
</li>
</ul>
</blockquote>
<h4 id="配置管理：成千上万的配置项要如何管理？"><a href="#配置管理：成千上万的配置项要如何管理？" class="headerlink" title="配置管理：成千上万的配置项要如何管理？"></a>配置管理：成千上万的配置项要如何管理？</h4><blockquote>
<p>配置中心的开源方案：</p>
<ol>
<li>携程的apollo：支持不同环境、不同集群的配置、有完善的管理功能。支持灰度发布，热发布；</li>
<li>springcloud config</li>
<li>阿里的nocas</li>
</ol>
<p>配置信息的存储</p>
<p> 一般使用mysql、etcd、redis、zookeeper都可以；</p>
<p>变更消息的推送</p>
<ul>
<li>轮训查询：应用程序向配置中心客户端注册一个监听器，配置中心的客户端定时查询配置是否有变化，如果有变化则通知触发监听器，让应用程序变更通知；为了防止查询量太大使用MD5值；</li>
<li>长连接推送，更实时；</li>
</ul>
<p>为了保证高可用，在配置中心的客户端添加两级缓存，一级是在内存中的缓存（降低和客户端的交互），另外一级是文件的缓存（灾备）；</p>
<p>动态需要调整的可以放到配置中心；</p>
</blockquote>
<h4 id="降级和熔断，屏蔽非核心系统故障的影响"><a href="#降级和熔断，屏蔽非核心系统故障的影响" class="headerlink" title="降级和熔断，屏蔽非核心系统故障的影响"></a>降级和熔断，屏蔽非核心系统故障的影响</h4><blockquote>
<ul>
<li><p>降级和熔断主要解决的问题：</p>
<ol>
<li>由于依赖的资源或者服务不可用，导致整体服务宕机。比如数据库访问缓慢；</li>
<li>超过系统承载能力的流量到来，系统不堪重负，出现拒绝服务的情况；</li>
</ol>
</li>
<li><p>雪崩是如何发生的？</p>
<ol>
<li>局部故障会导致全局故障就是雪崩。比如A服务调用B服务，b服务响应缓慢，导致A服务也运行缓慢，最终导致A服务不可用；</li>
<li>所以分布式最怕的不是某个服务或者组件宕机，而是响应缓慢，响应变慢会导致雪崩拖垮整个系统。</li>
</ol>
</li>
<li><p>熔断机制</p>
<ol>
<li>发起服务调用，如果服务返回错误或者超时次数超过一定的阈值，则后续请求不再向远程服务发起请求而是暂时返回错误；</li>
<li>状态机，关闭（调用远程服务）、半打开（尝试调用远程服务）、打开（返回错误）</li>
</ol>
</li>
<li><p>熔断机制的状态维护</p>
<ol>
<li>当调用失败的次数累计到一定的阈值时，熔断状态从关闭到打开状态。一般在实现时，如果成功调用一次，就会重置调用失败的次数；</li>
<li>当熔断处于打开状态时，我们会启动一个超时计时器，当计时器超时时，状态切换到半打开状态，你也可以设置一个定时器，定时的探测服务是否恢复；</li>
<li>在熔断处于半打开状态时，请求可以达到后端服务，如果累计一定次数后，状态切换到关闭状态；如果出现调用失败的情况则切换到打开状态；</li>
</ol>
</li>
<li><p>封装的redis客户端中实现的熔断机制：</p>
<ol>
<li><p>当处于熔断状态时，定期的检查redis组件是否可用</p>
<p><img src="/images/concurrentServer/%E7%86%94%E6%96%AD%E7%8A%B6%E6%80%81%E6%A3%80%E6%9F%A5redis%E7%BB%84%E4%BB%B6%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8.png" alt="熔断状态检查redis组件是否可用"></p>
</li>
<li><p>redis客户端需要加入熔断逻辑</p>
<p><img src="/images/concurrentServer/redis%E7%86%94%E6%96%AD%E6%A3%80%E6%9F%A5%E9%80%BB%E8%BE%91.png" alt="redis熔断检查逻辑"></p>
</li>
</ol>
</li>
<li><p>开关降级</p>
<p>开关降级是指在代码中预先设置一些开关，用来控制服务的返回值，比方说开关打开时，执行指定的降级策略，这些开关的值可以存储在配置中心中，当系统出现问题需要降级时，只需要修改配置中心中开关的值就可以了。</p>
</li>
<li><p>具体的降级策略</p>
<ol>
<li>针对读取数据的场景，我们一般采用的策略是<code>直接返回降级数据</code></li>
<li>对一些轮训获取数据的场景，比如每隔30秒获取一次未读数的，可以<code>降低读取数据的频率</code>；</li>
<li>对于写数据的场景，一般会考虑把同步写改成<code>异步</code>，这样可以牺牲一些数据的的一致性来保证系统的可用性；</li>
</ol>
</li>
</ul>
</blockquote>
<h4 id="流量控制：高并发系统中我们如何操纵流量？"><a href="#流量控制：高并发系统中我们如何操纵流量？" class="headerlink" title="流量控制：高并发系统中我们如何操纵流量？"></a>流量控制：高并发系统中我们如何操纵流量？</h4><blockquote>
<p> 核心服务流量太大的时候不能熔断，需要进行流量控制</p>
<p><img src="/images/concurrentServer/%E9%99%90%E6%B5%81%E7%AD%96%E7%95%A5.png" alt="限流策略"></p>
<p>限流算法</p>
<ul>
<li><p>固定窗口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 每秒重置计数器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> AtomicInteger counter = <span class="keyword">new</span> AtomicInteger();</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">    ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();</span><br><span class="line">  </span><br><span class="line">    scheduledExecutorService.scheduleAtFixedRate(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            counter.set(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,<span class="number">0</span>,<span class="number">1</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>滑动窗口</p>
<blockquote>
<p>为了解决固定窗口流量集中的问题，将一秒钟的时间段拆分成5分，每次计算都要按当前时间往后计算1秒；</p>
</blockquote>
</li>
<li><p>漏桶算法，消息队列</p>
</li>
<li><p>桶令牌：消费后消费令牌，根据时间频率往令牌桶放令牌；（使用guava中的限流器；但是分布式环境的话需要在redis中存储，为了解决频繁请求的问题，则使用一次获取多个令牌的方案）</p>
</li>
</ul>
</blockquote>
<p>参考：极客时间 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/230">《高并发系统设计40问》</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2019-09-13/kafka%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-server%E7%AB%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019-09-13/kafka%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-server%E7%AB%AF/" class="post-title-link" itemprop="url">kafka源码剖析-server端</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-13 17:13:09" itemprop="dateCreated datePublished" datetime="2019-09-13T17:13:09+08:00">2019-09-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 01:03:09" itemprop="dateModified" datetime="2020-08-21T01:03:09+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><img src="/images/kafka/server/kafka%E7%9A%84zookeeper%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png" alt="kafka的zookeeper存储结构"></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/huazai007/articles/10990449.html">zookeeper在kafka中的作用</a></p>
<p>整理认识下kafka server端的架构图</p>
<p><img src="/images/kafka/server/server.png" alt="server"></p>
<h1 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h1><h2 id="reactor模式"><a href="#reactor模式" class="headerlink" title="reactor模式"></a>reactor模式</h2><ul>
<li>工作原理</li>
</ul>
<p>1.首先创建serverSocketChannel对象并在selector上注册op_accept事件，serverSocketChannel负责监听指定端口上的连接请求；<br>2.当客户端发起到服务端的网络连接时，服务端的selector监听到此op_accept事件，会触发selector来处理op_accept；<br>3.当acceptor接收到来自客户端的socket连接请求时会为这个连接创建响应的socketChannel，将socketChannel设计为非阻塞模式，并在selector上注册关注的IO事件，如OP_READ,OP_WRITE.此时客户端与服务端的socket连接正式完成。<br>4.当客户端通过上面建立的socket连接想服务端发送请求时，服务端的selector会监听到op_read事件，并触发执行响应的处理逻辑。当服务端向客户端写数据的时候，客户端的selector会监听到op_write事件，并处罚响应的处理逻辑。</p>
<p>注意治理的所有事件处理逻辑都是在同一个线程中完成的。</p>
<p>而kafka使用的事多线程 多个selector的设计实现的</p>
<p><img src="/images/kafka/server/Nio-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png" alt="Nio-多线程模型"></p>
<h2 id="socketServer"><a href="#socketServer" class="headerlink" title="socketServer"></a>socketServer</h2><p><img src="/images/kafka/server/socketServer.png" alt="socketServer"></p>
<p><img src="/images/kafka/server/serverSocket%E6%A0%B8%E5%BF%83%E5%AD%97%E6%AE%B5.png" alt="serverSocket核心字段"></p>
<h2 id="acceptor"><a href="#acceptor" class="headerlink" title="acceptor"></a>acceptor</h2><p>acceptor的主要功能是接收客户端建立连接的请求，创建socket连接并分配给processor处理。</p>
<p>acceptor.run方法是acceptor的核心逻辑，其中完成了对OP_ACCEPT时间的处理。</p>
<p><img src="/images/kafka/server/acceptorRun%E6%96%B9%E6%B3%95.png" alt="acceptorRun方法"></p>
<h2 id="processor"><a href="#processor" class="headerlink" title="processor"></a>processor</h2><p>processor主要用于完成读取请求和写回响应的操作，processor不处理具体业务逻辑</p>
<p><img src="/images/kafka/server/processor%E4%B8%BB%E8%A6%81%E5%8F%82%E6%95%B0.png" alt="processor主要参数"></p>
<p>processor.run()方法实现了从网络连接上读取数据的功能。</p>
<p><img src="/images/kafka/server/processorRun%E6%96%B9%E6%B3%95.png" alt="processorRun方法"></p>
<h2 id="RequestChannel"><a href="#RequestChannel" class="headerlink" title="RequestChannel"></a>RequestChannel</h2><p><img src="/images/kafka/server/RequestChannel.png" alt="RequestChannel"></p>
<p><img src="/images/kafka/server/processor%E5%A4%84%E7%90%86%E8%AF%B7%E6%B1%82.png" alt="processor处理请求"></p>
<h1 id="API层"><a href="#API层" class="headerlink" title="API层"></a>API层</h1><p>kafka的handler线程会取出processor线程，放入requestChannel的请求进行处理，并将产生的响应通过requestChanel传递给processor线程。handler线程属于kafka的api层。</p>
<h2 id="kafkaRequestHandler"><a href="#kafkaRequestHandler" class="headerlink" title="kafkaRequestHandler"></a>kafkaRequestHandler</h2><p>kafkaRequestHandler的主要职责是从RequestChannel获取请求并调用kafkaApis.handle()方法处理请求</p>
<h2 id="kafkaApis"><a href="#kafkaApis" class="headerlink" title="kafkaApis"></a>kafkaApis</h2><p>其是kafka服务器处理请求的入口类，它负责将kafkaRequestHandler传递过来的请求分发到不同的handl*处理方法中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">   * Top-level method that handles all requests and multiplexes to the right api</span><br><span class="line">   *&#x2F;</span><br><span class="line">  def handle(request: RequestChannel.Request) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      trace(&quot;Handling request:%s from connection %s;securityProtocol:%s,principal:%s&quot;.</span><br><span class="line">        format(request.requestDesc(true), request.connectionId, request.securityProtocol, request.session.principal))</span><br><span class="line">      ApiKeys.forId(request.requestId) match &#123;</span><br><span class="line">        case ApiKeys.PRODUCE &#x3D;&gt; handleProducerRequest(request)</span><br><span class="line">        case ApiKeys.FETCH &#x3D;&gt; handleFetchRequest(request)</span><br><span class="line">        case ApiKeys.LIST_OFFSETS &#x3D;&gt; handleOffsetRequest(request)</span><br><span class="line">        case ApiKeys.METADATA &#x3D;&gt; handleTopicMetadataRequest(request)</span><br><span class="line">        case ApiKeys.LEADER_AND_ISR &#x3D;&gt; handleLeaderAndIsrRequest(request)</span><br><span class="line">        case ApiKeys.STOP_REPLICA &#x3D;&gt; handleStopReplicaRequest(request)</span><br><span class="line">        case ApiKeys.UPDATE_METADATA_KEY &#x3D;&gt; handleUpdateMetadataRequest(request)</span><br><span class="line">        case ApiKeys.CONTROLLED_SHUTDOWN_KEY &#x3D;&gt; handleControlledShutdownRequest(request)</span><br><span class="line">        case ApiKeys.OFFSET_COMMIT &#x3D;&gt; handleOffsetCommitRequest(request)</span><br><span class="line">        case ApiKeys.OFFSET_FETCH &#x3D;&gt; handleOffsetFetchRequest(request)</span><br><span class="line">        case ApiKeys.GROUP_COORDINATOR &#x3D;&gt; handleGroupCoordinatorRequest(request)</span><br><span class="line">        case ApiKeys.JOIN_GROUP &#x3D;&gt; handleJoinGroupRequest(request)</span><br><span class="line">        case ApiKeys.HEARTBEAT &#x3D;&gt; handleHeartbeatRequest(request)</span><br><span class="line">        case ApiKeys.LEAVE_GROUP &#x3D;&gt; handleLeaveGroupRequest(request)</span><br><span class="line">        case ApiKeys.SYNC_GROUP &#x3D;&gt; handleSyncGroupRequest(request)</span><br><span class="line">        case ApiKeys.DESCRIBE_GROUPS &#x3D;&gt; handleDescribeGroupRequest(request)</span><br><span class="line">        case ApiKeys.LIST_GROUPS &#x3D;&gt; handleListGroupsRequest(request)</span><br><span class="line">        case ApiKeys.SASL_HANDSHAKE &#x3D;&gt; handleSaslHandshakeRequest(request)</span><br><span class="line">        case ApiKeys.API_VERSIONS &#x3D;&gt; handleApiVersionsRequest(request)</span><br><span class="line">        case ApiKeys.CREATE_TOPICS &#x3D;&gt; handleCreateTopicsRequest(request)</span><br><span class="line">        case ApiKeys.DELETE_TOPICS &#x3D;&gt; handleDeleteTopicsRequest(request)</span><br><span class="line">        case requestId &#x3D;&gt; throw new KafkaException(&quot;Unknown api code &quot; + requestId)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case e: Throwable &#x3D;&gt;</span><br><span class="line">        if (request.requestObj !&#x3D; null) &#123;</span><br><span class="line">          request.requestObj.handleError(e, requestChannel, request)</span><br><span class="line">          error(&quot;Error when handling request %s&quot;.format(request.requestObj), e)</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          val response &#x3D; request.body.getErrorResponse(e)</span><br><span class="line"></span><br><span class="line">          &#x2F;* If request doesn&#39;t have a default error response, we just close the connection.</span><br><span class="line">             For example, when produce request has acks set to 0 *&#x2F;</span><br><span class="line">          if (response &#x3D;&#x3D; null)</span><br><span class="line">            requestChannel.closeConnection(request.processor, request)</span><br><span class="line">          else</span><br><span class="line">            requestChannel.sendResponse(new Response(request, response))</span><br><span class="line"></span><br><span class="line">          error(&quot;Error when handling request %s&quot;.format(request.body), e)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; finally</span><br><span class="line">      request.apiLocalCompleteTimeMs &#x3D; time.milliseconds</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="日志处理"><a href="#日志处理" class="headerlink" title="日志处理"></a>日志处理</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>kafka使用日志文件保存生产者发送的消息，每条消息使用offset值保存它在分区中的偏移量，offset是逻辑值。同一个分区中的消息是顺序写入的。</p>
<p>分区的任一副本都会有响应的log文件；</p>
<p>为了避免日志文件太大，在对应的磁盘上建一个目录，命名规则是topicName-partitionId,log与分区之间是一一对应的；</p>
<p>kafka将log文件通过分段的方式分成多个logSegment文件，logSegment是一个逻辑上的概念，一个LogSegment文件对应磁盘上的一个日志文件和一个索引文件，其中日志文件记录消息，索引文件保存了消息的索引。日志文件大小达到一个阈值是，就会创建新的文件。命令规则是[baseOffset].log, 是第一条消息的offset。</p>
<p><img src="/images/kafka/server/Log%E7%9A%84%E7%BB%93%E6%9E%84.png" alt="Log的结构"></p>
<p>为了提高查询消息的效率，索引文件不并没有为每条消息建立索引项，而是使用稀疏索引方式为文件中的部分消息简历了索引</p>
<p><img src="/images/kafka/server/%E7%B4%A2%E5%BC%95-%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6.png" alt="索引-日志文件"></p>
<h2 id="fileMessageSet"><a href="#fileMessageSet" class="headerlink" title="fileMessageSet"></a>fileMessageSet</h2><p>fileMessageSet在磁盘上对应一个日志文件，它集成了MessageSet抽象类，它分为三部分：8个字节的offset值；4个字节的size表示messageData的大小；这两个部分组成LogOverhead,message data部分保存了消息的数据，逻辑上对应一个Message对象</p>
<p><img src="/images/kafka/server/fileMessageSet%E5%AF%B9%E8%B1%A1.png" alt="fileMessageSet对象"></p>
<p><img src="/images/kafka/server/Message%E7%B1%BB%E6%B6%88%E6%81%AF.png" alt="Message类消息"></p>
<h2 id="ByteBufferMessageSet"><a href="#ByteBufferMessageSet" class="headerlink" title="ByteBufferMessageSet"></a>ByteBufferMessageSet</h2><p>常见的算法是数据量越大压缩率越高；kafka使用的压缩方式是将多个消息一起进行压缩；服务端之间进行传输数据是压缩状态，而消费者从服务端拉取的数据也是压缩的。</p>
<h2 id="offsetIndex"><a href="#offsetIndex" class="headerlink" title="offsetIndex"></a>offsetIndex</h2><p><img src="/images/kafka/server/offsetIndex.png" alt="offsetIndex"> </p>
<h2 id="LogSegment"><a href="#LogSegment" class="headerlink" title="LogSegment"></a>LogSegment</h2><p>LogSegment中封装了一个FileMessageSet和一个offsetIndex对象，提供日志文件和索引文件的读写功能以及其他辅助功能。</p>
<p><img src="/images/kafka/server/LogSegment.png" alt="LogSegment"> </p>
<h3 id="LogSegment的read方法"><a href="#LogSegment的read方法" class="headerlink" title="LogSegment的read方法"></a>LogSegment的read方法</h3><p>四个参数：</p>
<ul>
<li>startOffset:指定读取的其实消息的offset；</li>
<li>maxOffset: 指定读取的结束的offset；</li>
<li>maxSize: 指定读取的最大字节数；</li>
<li>maxPosition: 指定读取的最大无力日志，默认是日志文件的大小；</li>
</ul>
<p>读取日志文件之前需要将startOffset和maxOffset转化为对应的无力地址才能使用；</p>
<p><img src="/images/kafka/server/LogSegmentRead%E6%96%B9%E6%B3%95.png" alt="LogSegmentRead方法"> </p>
<p><img src="/images/kafka/server/Log%E4%BD%BF%E7%94%A8%E8%B7%B3%E8%A1%A8%E7%9A%84%E6%B5%81%E7%A8%8B.png" alt="Log使用跳表的流程"> </p>
<h2 id="Log"><a href="#Log" class="headerlink" title="Log"></a>Log</h2><p>Log是对多个LogSegment对象的顺序组合，形成一个逻辑的日志，为了实现快读定位LogSegment，log使用跳表来对LogSegment进行管理；</p>
<p>jdk中有跳表的实现-concurrentSkipListMap，它是一个线程安全的实现；</p>
<p>在log中将每个LogSegment的baseOffset作为key，LogSegment对象作为value，放入segment这个跳表结构中</p>
<p><img src="/images/kafka/server/Log%E4%BD%BF%E7%94%A8%E8%B7%B3%E8%A1%A8%E7%9A%84%E6%B5%81%E7%A8%8B.png" alt="Log使用跳表的流程"> </p>
<p><img src="/images/kafka/server/logAppend%E6%96%B9%E6%B3%95%E5%A4%A7%E8%87%B4%E6%B5%81%E7%A8%8B.png" alt="logAppend方法大致流程"> </p>
<h2 id="LogManager"><a href="#LogManager" class="headerlink" title="LogManager"></a>LogManager</h2><ul>
<li>简介</li>
</ul>
<p>在一个broker上的所有log都是由LogManager进行管理的，LogManager提供了加载Log、创建Log集合、删除Log集合、查询Log集合等功能，并且启动了3个周期性的后台任务以及多个线程分别是：log-flusher（日志刷写任务）、log-retention（日志保留）任务，检查点刷新任务以及cleaner线程（日志清理）；</p>
<p><img src="/images/kafka/server/%E4%B8%89%E4%B8%AA%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%8F%8F%E8%BF%B0.png" alt="三个周期性任务的描述"></p>
<p><img src="/images/kafka/server/%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9%E5%8A%9F%E8%83%BD.png" alt="日志压缩功能"></p>
<p><img src="/images/kafka/server/%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9-cleaner%E7%BA%BF%E7%A8%8B.png" alt="日志压缩-cleaner线程"></p>
<p><img src="/images/kafka/server/LogManager%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B.png" alt="LogManager初始化流程"></p>
<h1 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h1><h2 id="副本简介"><a href="#副本简介" class="headerlink" title="副本简介"></a>副本简介</h2><p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E7%9A%84%E6%A6%82%E5%BF%B5.png" alt="副本的概念"></p>
<ul>
<li>本地和远程副本</li>
</ul>
<p><img src="/images/kafka/server/%E6%9C%AC%E5%9C%B0%E5%92%8C%E8%BF%9C%E7%A8%8B%E5%89%AF%E6%9C%AC.png" alt="本地和远程副本"></p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E7%9A%84%E6%9B%B4%E6%96%B0%E6%93%8D%E4%BD%9C.png" alt="副本的更新操作"></p>
<h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p>服务端使用partition表示分区，partition负责管理每个副本对应的replica对象，进行leader副本的切换，isr集合的管理以及调用日志存储自行他完成写入消息</p>
<p>partition的核心字段及主要方法：</p>
<p><img src="/images/kafka/server/partition%E7%9A%84%E6%A0%B8%E5%BF%83%E5%AD%97%E6%AE%B5.png" alt="partition的核心字段"></p>
<h3 id="创建副本"><a href="#创建副本" class="headerlink" title="创建副本"></a>创建副本</h3><p><img src="/images/kafka/server/%E5%88%9B%E5%BB%BA%E5%89%AF%E6%9C%AC.png" alt="创建副本"></p>
<h3 id="副本将角色切换"><a href="#副本将角色切换" class="headerlink" title="副本将角色切换"></a>副本将角色切换</h3><p>broker会根据kafkaController发送的leaderAndISRRequest请求控制副本的leader和follower副本角色切换，Partition.makeLeader()是LeaderAndISRRequest中比较重要的环节之一。</p>
<p><img src="/images/kafka/server/makerLeader%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E5%8F%82%E6%95%B0.png" alt="makerLeader中用到的参数"></p>
<p><img src="/images/kafka/server/makeLeader%E4%BB%A3%E7%A0%811.png" alt="makeLeader代码1"></p>
<p><img src="/images/kafka/server/makeLeader%E4%BB%A3%E7%A0%812.png" alt="makeLeader代码2"></p>
<ul>
<li>增加leader副本的HW</li>
</ul>
<p>当isr集合发生增减或是ISR集合中任一副本的LEO发生变化时，都会导致ISR集合中最小的LEO变大。获取ISR集合中最小的LEO作为新的HW，比较现在的HW和新的HW，取较小的作为HW；</p>
<h3 id="ISR集合管理"><a href="#ISR集合管理" class="headerlink" title="ISR集合管理"></a>ISR集合管理</h3><p>partition除了对副本的leader和follower角色进行管理，还需要管理ISR集合。随着follower副本不断与leader副本进行消息同步，follower副本的leo会逐渐后移，并最终赶上leader副本的leo，最终该follower会进入ISR集合。</p>
<p><img src="/images/kafka/server/%E6%B7%BB%E5%8A%A0ISR%E5%85%83%E7%B4%A0%E7%9A%84%E5%AE%9E%E7%8E%B0.png" alt="添加ISR元素的实现"></p>
<p><img src="/images/kafka/server/%E5%87%8F%E5%B0%91ISR%E5%85%83%E7%B4%A0%E7%9A%84%E5%AE%9E%E7%8E%B0.png" alt="减少ISR元素的实现"></p>
<p>SIR集合发生增减的时候，都会将最新的ISR集合保存在zookeeper中。</p>
<h3 id="追加消息"><a href="#追加消息" class="headerlink" title="追加消息"></a>追加消息</h3><p>在分区中，只有leader副本能够处理读写请求，partition.appendMessagesToLeader()方法提供了向leader副本对应的Log中追加消息的功能。当isr集合中副本的数量小于配置的最小的限制，且生产者对可用性有较高的可用性，则不能支架消息，会产生一个NotEnoughReplicasException异常。</p>
<p>否则追加消息到对应的leader副本，尝试增加leader的HW；</p>
<h3 id="checkEnoughReplicasReachOffset"><a href="#checkEnoughReplicasReachOffset" class="headerlink" title="checkEnoughReplicasReachOffset"></a>checkEnoughReplicasReachOffset</h3><p><img src="/images/kafka/server/checkEnoughReplicasReachOffset.png" alt="checkEnoughReplicasReachOffset"></p>
<h2 id="ReplicaManager-副本管理机制"><a href="#ReplicaManager-副本管理机制" class="headerlink" title="ReplicaManager 副本管理机制"></a>ReplicaManager 副本管理机制</h2><p><img src="/images/kafka/server/ReplicaManager1.png" alt="ReplicaManager1"></p>
<p><img src="/images/kafka/server/ReplicaManager2.png" alt="ReplicaManager2"></p>
<h3 id="副本角色切换"><a href="#副本角色切换" class="headerlink" title="副本角色切换"></a>副本角色切换</h3><p>在kafka集群中会选择一个broker称为kafkaController的leader，他负责管理整个kafka集群。controller leader根据partition的leader副本和follower副本的状态向对应的broker节点发送leaderAndIsrRequest，整个请求主要用于副本的角色切换。</p>
<p><img src="/images/kafka/server/leaderAndIsrRequestAndResponse.png" alt="leaderAndIsrRequestAndResponse"></p>
<p><img src="/images/kafka/server/becomeLeaderAndFollower.png" alt="becomeLeaderAndFollower"></p>
<p><img src="/images/kafka/server/makerFollower.png" alt="makerFollower"></p>
<p>updateFollowerLogReadResults()方法主要针对来自follower副本的fetchRequst多了异步处理。</p>
<ul>
<li>更新leader副本上维护的follower副本的各项状态，入LEO等；</li>
<li>更新follower副本不断fetch的消息，最终追上leader副本，可能对ISR集合进行可扩张，同事将ISR集合的记录保存的zookeeper；</li>
<li>检测是否需要后移leader副本的HW；</li>
</ul>
<h3 id="消息同步"><a href="#消息同步" class="headerlink" title="消息同步"></a>消息同步</h3><p>AbstractFetcherManager.addFetcherForPartitions()方法会让follower副本从指定的offset开始与leader副本进行同步。改方法的参数设计brokerAndInitialOffset类，他封装了broker的网络位置信息以及同步的其实offset。</p>
<p><img src="/images/kafka/server/addFetcherForPartitions%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC%E6%B6%88%E6%81%AF.png" alt="addFetcherForPartitions同步副本消息"></p>
<p>removeFetcherForPartitions()方法会停止指定follower副本的同步操作；如果fetcher线程不在为任何分区的follower副本提供同步，则会被shutdown掉。</p>
<p><img src="/images/kafka/server/AddPartitionsAndRemovePartitions.png" alt="AddPartitionsAndRemovePartitions"></p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E8%AF%B7%E6%B1%82%E7%9A%84offset%E8%B6%85%E8%BF%87%E4%BA%86leader%E7%9A%84%E8%8C%83%E5%9B%B4.png" alt="副本请求的offset超过了leader的范围"></p>
<h3 id="关闭副本"><a href="#关闭副本" class="headerlink" title="关闭副本"></a>关闭副本</h3><p><img src="/images/kafka/server/%E5%85%B3%E9%97%AD%E5%89%AF%E6%9C%AC.png" alt="关闭副本"></p>
<h3 id="replicaManager中的定时任务"><a href="#replicaManager中的定时任务" class="headerlink" title="replicaManager中的定时任务"></a>replicaManager中的定时任务</h3><p><img src="/images/kafka/server/replicaManager%E4%B8%AD%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.png" alt="replicaManager中的定时任务"></p>
<h3 id="metadataCache"><a href="#metadataCache" class="headerlink" title="metadataCache"></a>metadataCache</h3><p>metadataCache是broker用来缓存整个集群中全部分区状态的组件，kafkaController通过向集群中的broker发送updateMetadataRequest来更新其metadataCache组件中的缓存的数据。</p>
<p><img src="/images/kafka/server/metadataCache%E7%9A%84%E5%AD%97%E6%AE%B5.png" alt="metadataCache的字段"></p>
<ul>
<li>getPartitionMetadata方法的实现</li>
</ul>
<p><img src="/images/kafka/server/getPartitionMetadata%E6%96%B9%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B01.png" alt="getPartitionMetadata方法的实现1"></p>
<p><img src="/images/kafka/server/getPartitionMetadata%E6%96%B9%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B02.png" alt="getPartitionMetadata方法的实现2"></p>
<h1 id="groupCoordinator"><a href="#groupCoordinator" class="headerlink" title="groupCoordinator"></a>groupCoordinator</h1><p>每个broker上会实例化一个groupCoordinator对象，kafka按照consumer group名称将其分配给对应的groupCoordinator进行管理，每个groupCoordinator只负责管理consumer group的一个子集；</p>
<h2 id="groupCoordinator的功能"><a href="#groupCoordinator的功能" class="headerlink" title="groupCoordinator的功能"></a>groupCoordinator的功能</h2><ul>
<li>负责处理joinGroupRequest和syncGroupRequest完成对consumer group中分区的分配工作；</li>
<li>通过GroupMetadataManager和内部的topic维护offset信息，即使出现消费者宕机的情况，也可以找回之前提交的offset；</li>
<li>记录consumer group的相关信息，即使broker宕机导致consumer group 由新的groupCoordinator进行管理，新的groupCoordinator也可以知道consumer Group中的每个消费者负责处理那个分区等信息；</li>
<li>通过心跳检测消费者的状态；</li>
</ul>
<p><img src="/images/kafka/server/MemberMetada%E7%9A%84%E4%B8%BB%E8%A6%81%E5%AD%97%E6%AE%B5.png" alt="MemberMetadata的主要字段"></p>
<p><img src="/images/kafka/server/GroupMetadata%E5%85%83%E6%95%B0%E6%8D%AE%E4%BF%A1%E6%81%AF.png" alt="GroupMetadata元数据信息"></p>
<p>groupMetadata提供了对其字段的操作，包括对members集合的增删，对state的切换，同事需要选择group leader；</p>
<p><img src="/images/kafka/server/%E9%80%89%E6%8B%A9groupLeader.png" alt="选择groupLeader"></p>
<h2 id="groupMetadataManager"><a href="#groupMetadataManager" class="headerlink" title="groupMetadataManager"></a>groupMetadataManager</h2><p>groupMetadataManager是groupCoordinator中负责管理 consumer group元数据以及对应offset信息的组件，groupMetadataManager底层使用offsets topic，以消息的形式存储 consumer group的groupMetadata信息以及其消息的每个每个分区的信息</p>
<p><img src="/images/kafka/server/GroupMetadataManager%E5%AD%97%E6%AE%B5.png" alt="GroupMetadataManager字段"></p>
<ul>
<li>removeGroup方法的实现</li>
</ul>
<p><img src="/images/kafka/server/removeGroup%E6%96%B9%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0.png" alt="removeGroup方法的实现"></p>
<h3 id="查找groupCoordinator"><a href="#查找groupCoordinator" class="headerlink" title="查找groupCoordinator"></a>查找groupCoordinator</h3><p><img src="/images/kafka/server/%E6%9F%A5%E6%89%BEgroupCoordinator.png" alt="查找groupCoordinator"></p>
<p><img src="/images/kafka/server/GroupCoordinator-offsetPartition-ConsumerGroup.png" alt="GroupCoordinator-offsetPartition-ConsumerGroup"></p>
<h3 id="loadGroupsAndOffsets-方法"><a href="#loadGroupsAndOffsets-方法" class="headerlink" title="loadGroupsAndOffsets 方法"></a>loadGroupsAndOffsets 方法</h3><p><img src="/images/kafka/server/loadGroupsAndOffsets.png" alt="loadGroupsAndOffsets"></p>
<h3 id="SyncGroupRequest相关处理"><a href="#SyncGroupRequest相关处理" class="headerlink" title="SyncGroupRequest相关处理"></a>SyncGroupRequest相关处理</h3><p>consumer group中的leader消费者通过SyncGroupRequest将分区的分配结果发送给GroupCoordinator,GroupCoordinator会根据此分配结果形成SyncGroupResponse返回给所有的消费者。</p>
<h3 id="offsetFetchRequest和listGroupRequest处理"><a href="#offsetFetchRequest和listGroupRequest处理" class="headerlink" title="offsetFetchRequest和listGroupRequest处理"></a>offsetFetchRequest和listGroupRequest处理</h3><p><img src="/images/kafka/server/offsetFetchRequest%E5%A4%84%E7%90%86.png" alt="offsetFetchRequest处理"></p>
<h2 id="groupCoordinator分析"><a href="#groupCoordinator分析" class="headerlink" title="groupCoordinator分析"></a>groupCoordinator分析</h2><p><img src="/images/kafka/server/groupCoordinator%E5%90%84%E4%B8%AA%E5%AD%97%E6%AE%B5%E7%9A%84%E5%90%AB%E4%B9%89.png" alt="groupCoordinator各个字段的含义"></p>
<ul>
<li>groupState字段的四个状态</li>
</ul>
<p><img src="/images/kafka/server/groupState%E7%9A%84%E5%9B%9B%E4%B8%AA%E7%8A%B6%E6%80%81.png" alt="groupState的四个状态"></p>
<p><img src="/images/kafka/server/groupState%E7%9A%84%E5%9B%9B%E4%B8%AA%E7%8A%B6%E6%80%81%E8%BD%AC%E5%8C%96.png" alt="groupState的四个状态转化"></p>
<ul>
<li>joinGroup()方法</li>
</ul>
<p><img src="/images/kafka/server/JoinGroup%E6%96%B9%E6%B3%95.png" alt="JoinGroup方法"></p>
<p><img src="/images/kafka/server/dojoinGroup%E6%96%B9%E6%B3%95.png" alt="dojoinGroup方法"></p>
<p><img src="/images/kafka/server/prepareRebalance%E6%96%B9%E6%B3%95.png" alt="prepareRebalance方法"></p>
<ul>
<li>doSyncGroup()方法</li>
</ul>
<p><img src="/images/kafka/server/doSyncGroup%E6%93%8D%E4%BD%9C.png" alt="doSyncGroup操作"></p>
<ul>
<li>commitOffsetRequest()方法</li>
</ul>
<p><img src="/images/kafka/server/commitOffsetRequest.png" alt="commitOffsetRequest"></p>
<p><img src="/images/kafka/server/commitOffsetRequest2.png" alt="commitOffsetRequest2"></p>
<ul>
<li>leaveGroupRequest</li>
</ul>
<p><img src="/images/kafka/server/leaveGroupRequest.png" alt="leaveGroupRequest"></p>
<h1 id="kafkaController"><a href="#kafkaController" class="headerlink" title="kafkaController"></a>kafkaController</h1><h2 id="kafkaController简介"><a href="#kafkaController简介" class="headerlink" title="kafkaController简介"></a>kafkaController简介</h2><p><img src="/images/kafka/server/kafkaController%E7%AE%80%E4%BB%8B.png" alt="kafkaController简介"></p>
<p><img src="/images/kafka/server/broker%E5%9C%A8zookeeper%E4%B8%AD%E7%9A%84%E5%AD%98%E5%82%A8%E4%BF%A1%E6%81%AF.png" alt="broker在zookeeper中的存储信息"></p>
<p><img src="/images/kafka/server/kafkaController%E7%BB%84%E4%BB%B6.png" alt="kafkaController组件"></p>
<p>kafkaController是zookeeper与kafka集群交互的桥梁，他一方面对zookeeper进行监听，其中包括broker写入zookeeper中的数据，也包括管理员使用脚本写入的数据;另一方面根据zookeeper中数据的变化做出相应的处理，通过Request请求控制每个broker，kafkaControlle也通过zookeeper提高了高可用的机制。</p>
<h2 id="ControllerChannelManager"><a href="#ControllerChannelManager" class="headerlink" title="ControllerChannelManager"></a>ControllerChannelManager</h2><p>ControllerChannelManager主要管理broker之间的网络交互。controller只能发送leaderAndISRRequest、stopReplicaRequest、updateMetadataRequest三种请求；</p>
<p>ControllerChannelManager的核心字段是brokerStatInfo，主要用于管理集群中各个broker对应的brokerStatInfo对象。</p>
<p><img src="/images/kafka/server/ControllerChannelManager%E7%AE%A1%E7%90%86brokerStateInfo.png" alt="ControllerChannelManager管理brokerStateInfo"></p>
<h2 id="controllerContext"><a href="#controllerContext" class="headerlink" title="controllerContext"></a>controllerContext</h2><p>controllerContext中维护了controller使用到的上下文信息，从其构造函数可以猜到controllerContext与zookeeper有密切的关系，可以看做两个之间的缓存</p>
<h2 id="controllerBrokerRequestBatch"><a href="#controllerBrokerRequestBatch" class="headerlink" title="controllerBrokerRequestBatch"></a>controllerBrokerRequestBatch</h2><p>为了提高broker leader与集群中其它broker的通信效率，kafka controller使用controllerBrokerRequestBatch实现批量发送请求的功能。</p>
<p><img src="/images/kafka/server/controllerBrokerRequestBatch%E7%9A%84%E6%A0%B8%E5%BF%83%E5%AD%97%E6%AE%B5.png" alt="controllerBrokerRequestBatch的核心字段"></p>
<h2 id="partitionStateMachine"><a href="#partitionStateMachine" class="headerlink" title="partitionStateMachine"></a>partitionStateMachine</h2><p>partitionStateMachine是controller leader用于维护分区状态的状态机，分区的状态是通过partitionState接口定义的 </p>
<p><img src="/images/kafka/server/partitionState%E5%8F%8A%E8%BD%AC%E6%8D%A2.png" alt="partitionState及转换"></p>
<p><img src="/images/kafka/server/%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2%E6%97%B6%E5%AE%8C%E6%88%90%E7%9A%84%E6%93%8D%E4%BD%9C.png" alt="状态转换时完成的操作"></p>
<p>selectLeaderForPartition()方法</p>
<ul>
<li>使用指定的partitionLeaderSelector()为分区选举新的leader副本；</li>
<li>将leader副本和isr集合的信息写入zookeeper;</li>
<li>更新context.partitionLeadershipInfo集合中缓存的leader副本、isr集合等信息；</li>
<li>将上述确定的leader副本，isr集合，ar集合等信息添加到controllerBrokerRequestBatch，之后会封装成leaderAndIsrRequest发送相关的broker；</li>
</ul>
<h2 id="partitionLeaderSelector"><a href="#partitionLeaderSelector" class="headerlink" title="partitionLeaderSelector"></a>partitionLeaderSelector</h2><p>offlinePartitionLeaderSelector会根据currentLeaderAndIsr选举新的leader和isr集合；</p>
<p><img src="/images/kafka/server/offlinePartitionLeaderSelector.png" alt="offlinePartitionLeaderSelector"></p>
<ul>
<li>选举的代码实现</li>
</ul>
<p><img src="/images/kafka/server/SelectLeader1.png" alt="SelectLeader1"></p>
<p><img src="/images/kafka/server/SelectLeader2.png" alt="SelectLeader2"></p>
<h2 id="ReplicaStateMachine"><a href="#ReplicaStateMachine" class="headerlink" title="ReplicaStateMachine"></a>ReplicaStateMachine</h2><p>ReplicaStateMachine是controller leader 用于维护副本状态的状态机，副本状态由replicaState接口表示</p>
<p><img src="/images/kafka/server/replicaState%E7%8A%B6%E6%80%81.png" alt="replicaState状态"></p>
<p><img src="/images/kafka/server/replicaState%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E6%89%80%E5%81%9A%E6%93%8D%E4%BD%9C.png" alt="replicaState状态变化所做操作"></p>
<h2 id="zookeeperListener"><a href="#zookeeperListener" class="headerlink" title="zookeeperListener"></a>zookeeperListener</h2><p>I0Itec-zkClient 是zookeeper的客户端工具</p>
<h3 id="listener接口介绍"><a href="#listener接口介绍" class="headerlink" title="listener接口介绍"></a>listener接口介绍</h3><p>kafkaController 会通过zookeeper监控整个kafka集群的运行状态。具体实现是在zookeeper的指定节点添加listener，监听此节点中的数据变化或者其子节点的变化，从而触发响应的业务逻辑。</p>
<p>IZKDataListener监听指定节点的数据变化；IZKChildListener监听指定节点的子节点变化；IZKStateListener监听zookeeper连接状态的变化；</p>
<p><img src="/images/kafka/server/kafka%E5%AE%9E%E7%8E%B0%E7%9A%84zkListener%E6%8E%A5%E5%8F%A3.png" alt="kafka实现的zkListener接口"></p>
<p><img src="/images/kafka/server/topicChangeListener%E5%AE%9E%E7%8E%B0.png" alt="topicChangeListener实现"></p>
<p><img src="/images/kafka/server/deleteTopicChildChange.png" alt="deleteTopicChildChange"></p>
<p><img src="/images/kafka/server/deleteTopicChildChange2.png" alt="deleteTopicChildChange2"></p>
<p>partitionModificationListener 主要用于监听一个topic分区的变化</p>
<p><img src="/images/kafka/server/partitionModificationsListener.png" alt="partitionModificationsListener"></p>
<p>brokerChangeListener 主要负责处理broker的上线和故障下线，上线时会在“/brokers/ids”下创建临时节点，下线时会删除对应的临时节点。</p>
<p><img src="/images/kafka/server/brokerChildChange.png" alt="brokerChildChange"></p>
<p><img src="/images/kafka/server/onBrokerFailure.png" alt="onBrokerFailure"></p>
<p><img src="/images/kafka/server/onBrokerFailureDemo1.png" alt="onBrokerFailureDemo1"></p>
<p><img src="/images/kafka/server/onBrokerFailureDemo2.png" alt="onBrokerFailureDemo2"></p>
<p>副本重新分配的listener</p>
<p>partitionReassignedListener 监听zookeeper节点是 “/admin/reassign_partitions”,当管理人员通过ReassignPartitionsCommond名指定某些分区需要重新分配副本时，会将指定分区的信息写入改节点，从而触发partitionReassignedListener</p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E9%87%8D%E6%96%B0%E5%88%86%E9%85%8D%E7%9A%84%E6%AD%A5%E9%AA%A41.png" alt="副本重新分配的步骤1"></p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E9%87%8D%E6%96%B0%E5%88%86%E9%85%8D%E7%9A%84%E6%AD%A5%E9%AA%A42.png" alt="副本重新分配的步骤2"></p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E9%87%8D%E6%96%B0%E5%88%86%E9%85%8D%E7%9A%84%E6%AD%A5%E9%AA%A43.png" alt="副本重新分配的步骤3"></p>
<h2 id="kafkaController初始化与故障转移"><a href="#kafkaController初始化与故障转移" class="headerlink" title="kafkaController初始化与故障转移"></a>kafkaController初始化与故障转移</h2><p>kafkaController的启动和故障转移的过程与zookeeperLeaderElector有着密切的关系，</p>
<p>zookeeperLeaderElector中有两个比较重要的字段，leaderId以及leaderChangeListener</p>
<p><img src="/images/kafka/server/zookeeperLeaderElector.png" alt="zookeeperLeaderElector"></p>
<h3 id="触发选举"><a href="#触发选举" class="headerlink" title="触发选举"></a>触发选举</h3><ul>
<li>第一次启动的时候；</li>
<li>leaderChangeListener监听到”/controller”节点中的数据被删除；</li>
<li>zookeeper连接过期并重新连接之后；</li>
</ul>
<p><img src="/images/kafka/server/elect.png" alt="elect"></p>
<h3 id="onControllerFailover"><a href="#onControllerFailover" class="headerlink" title="onControllerFailover"></a>onControllerFailover</h3><p>elect方法中调用onBecomingLeader()方法实际上还是onControllerFailover方法。当选举成功后，会完成一系列初始化操作。</p>
<p><img src="/images/kafka/server/onControllerFailover1.png" alt="onControllerFailover1"></p>
<p><img src="/images/kafka/server/onControllerFailover2.png" alt="onControllerFailover2"></p>
<h3 id="ControllerContext-从zookeeper中获取的信息"><a href="#ControllerContext-从zookeeper中获取的信息" class="headerlink" title="ControllerContext 从zookeeper中获取的信息"></a>ControllerContext 从zookeeper中获取的信息</h3><p><img src="/images/kafka/server/ControllerContext%E4%BB%8Ezookeeper%E4%B8%AD%E8%8E%B7%E5%8F%96%E4%BF%A1%E6%81%AF.png" alt="ControllerContext从zookeeper中获取信息"></p>
<h3 id="partition-rebalance"><a href="#partition-rebalance" class="headerlink" title="partition rebalance"></a>partition rebalance</h3><p><img src="/images/kafka/server/%E4%BC%98%E5%85%88%E5%89%AF%E6%9C%AC.png" alt="优先副本"></p>
<h3 id="优先选举-checkAndTriggerPartitionRebalance"><a href="#优先选举-checkAndTriggerPartitionRebalance" class="headerlink" title="优先选举 checkAndTriggerPartitionRebalance"></a>优先选举 checkAndTriggerPartitionRebalance</h3><p><img src="/images/kafka/server/%E4%BC%98%E5%85%88%E9%80%89%E4%B8%BE1.png" alt="优先选举1"></p>
<p><img src="/images/kafka/server/%E4%BC%98%E5%85%88%E9%80%89%E4%B8%BE2.png" alt="优先选举2"></p>
<h2 id="处理controlledShutDownRequest"><a href="#处理controlledShutDownRequest" class="headerlink" title="处理controlledShutDownRequest"></a>处理controlledShutDownRequest</h2><p>更换硬件、系统升级可能需要管理broker，kafka提供了方法来管理,主动下线broker</p>
<p><img src="/images/kafka/server/controlledShutDownRequest.png" alt="controlledShutDownRequest"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2019-09-12/kafka%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-consumer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019-09-12/kafka%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-consumer/" class="post-title-link" itemprop="url">kafka源码剖析-consumer</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-12 00:59:42" itemprop="dateCreated datePublished" datetime="2019-09-12T00:59:42+08:00">2019-09-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 01:03:09" itemprop="dateModified" datetime="2020-08-21T01:03:09+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="consumer简介"><a href="#consumer简介" class="headerlink" title="consumer简介"></a>consumer简介</h1><p>kafkaConsumer提供了一套封装良好的api，开发人员可以使用api轻松实现从服务端拉取消息，开发人员不必关系与kafka服务端的交互，比如网络管理、心跳检测、请求超时重试等底层操作，也不需要关心订阅topic的分区数量、分区leader副本的网络拓扑以及rebalance等操作，<br>而且kafka还有自动commit offset的功能；</p>
<h1 id="传递保证语义"><a href="#传递保证语义" class="headerlink" title="传递保证语义"></a>传递保证语义</h1><p>旧版本消费者的进度是记录在zookeeper中，为了缓解其压力，在服务端有一个名为 _consumer_offsets 的内部topic中记录消费进度，当出现rebalance操作时，对分区重新分配，rebalance操作完成后，消费者就可以重新读取offsets topic中的记录的offset，并从此位置继续消费。</p>
<p>consumer的poll方法返回的是最后一个消息的offset，为了避免消息丢失，建议处理完之后再poll消息，当然也可以手动commit  commitSync()以及commitAsync() 方法。</p>
<h2 id="消息的传递保证有三个级别"><a href="#消息的传递保证有三个级别" class="headerlink" title="消息的传递保证有三个级别"></a>消息的传递保证有三个级别</h2><ul>
<li>至多一次  at most once:可能会丢失，绝不会重复传递；</li>
<li>至少一次  at least once ：消息绝不会丢失，可能会重复传递；</li>
<li>恰好一次 exactly once：每条消息只会被传递一次</li>
</ul>
<p>至多一次一般不会出现、如果kafka保证传递的幂等性则使用至少一次也是没有问题的、恰好一次首先要保证不会产生重复的消息，其次消费者不能重复拉取相同的消息；</p>
<h3 id="恰好一次-生产者"><a href="#恰好一次-生产者" class="headerlink" title="恰好一次-生产者"></a>恰好一次-生产者</h3><p>网络抖动可能出现至少一次的情况，所以为了实现恰好一次有以下两种方案：</p>
<ul>
<li>每个分区只有一个生产者写入消息，当出现异常或者超时的情况时，生产者要查询此分区的最后一个消息，用来决定后续操作时消息重传还是继续；</li>
<li>为每个消息添加一个全局唯一主键，生产者不做特殊处理，按照之前的方式进行重传，保证至少一次，有消费者去去重；</li>
</ul>
<h3 id="恰好一次-消费者"><a href="#恰好一次-消费者" class="headerlink" title="恰好一次-消费者"></a>恰好一次-消费者</h3><p>拉取消息消费完之后，提交offset前出现宕机，这样重启后还会处理刚才那部分消息；拉取消息后先提交offset，宕机导致处理失败，则导致已提交的部分未做处理； 为了实现恰好一次有以下方案</p>
<ul>
<li>消费者关闭自动提交offset的功能，且不再手动提交offset，这样就不适用offsets topic这个内部topic来记录其offset，而是有消费者自己保存offset在db中，用使用的原子性来实现确切一次的功能。消费者可以使用consumer.seek()方法手动设置消费位置，从此offset处开始继续消费；</li>
</ul>
<h3 id="rebalance-操作"><a href="#rebalance-操作" class="headerlink" title="rebalance 操作"></a>rebalance 操作</h3><p>我们不知道rebalance操作以及那个分区分配给了哪个消费者，我们可以通过向consumer添加consumerReBalanceListener接口来解决这个问题：</p>
<ul>
<li>onPartitionsRevoked()方法：调用时机是consumer停止拉取数据之后。rebalance之前，我们可以在此方法中实现手动提交offset，这就避免了rebalance导致的重复消费的问题；</li>
<li>onPartitionAssigned()方法：调用时机是rebalance完成之后，consumer开始拉取数据之前，我们可以在此方法中调整或者自定义offset值。</li>
</ul>
<p>通过使用consumerReBalanceListener接口和seek()方法，我们就可以从关系型数据库中获取offset并手动设置了。</p>
<h1 id="consumer-group-rebalance-设计"><a href="#consumer-group-rebalance-设计" class="headerlink" title="consumer group rebalance 设计"></a>consumer group rebalance 设计</h1><p>最开始的时候交由zookeeper管理，严重依赖zookeeper，而且会产生羊群效应，脑裂问题；</p>
<p>之后交由broker管理，造成服务端的压力过大，而且要求服务端实现分配partition的方法，如果需要重新实现分配partition的策略，则需要修改服务端代码；</p>
<p>最后优化为交给消费者管理，0.9的版本进行了重新设计；</p>
<ul>
<li>具体的策略</li>
</ul>
<p>当消费者查找到管理当前consumer group的groupCoordinator后，就会进入join group阶段，consumer首先会向groupCoordinator发送joinGroupRequest请求，其中包含消费者的相关信息；</p>
<p>服务端的groupCoordinator收到joinGroupRequest后会暂存消息，收集到全部的消费者后，会根据joinGroupRequest中的信息来确定consumer group中的可用的消费者，从中选取一个消费者成为group leader，还会选取使用的分区分配策略，最后将这些消息封装成joinGroupResponse返回给消费者；</p>
<p>虽然每个消费者都会收到joinGroupResponse,但是只有group leader收到的joinGroupResponse中封装了所有的消费者信息，当消费者确定自己是group leader后，会根据消费者的信息以及选定的分区策略来进行分区分配；</p>
<p>在synchronizing group state阶段，每个消费者会发送syncGroupRequest到groupCoordinator，但是只有group leader的syncGroupRequest请求中保函了分区的分配结果， groupCoordinator根据group leader的分区结果形成syncGroupResponse返回给所有的consumer。</p>
<h1 id="kafkaConsumer分析"><a href="#kafkaConsumer分析" class="headerlink" title="kafkaConsumer分析"></a>kafkaConsumer分析</h1><p>kafkaConsumer对外暴露了多个api，它是线程不安全的，可以使用线程池，线程池中的每个线程拥有一个kafkaProducer实例</p>
<ul>
<li>subscribe():订阅指定的topic，并为消费者自动分配分区；</li>
<li>assign():用户手动订阅指定的topic，并指定消费者的分区；</li>
<li>commit(): 提交消费者其实消费的位置；</li>
<li>seek()：指定消费者的起始位置；</li>
<li>poll(): 负责从服务端获取消息；</li>
<li>pause() /resume()方法，暂停或者继续consumer，暂定后poll()方法会返回空；</li>
</ul>
<h2 id="SubScribeState"><a href="#SubScribeState" class="headerlink" title="SubScribeState"></a>SubScribeState</h2><p><img src="/images/kafka/consumer/SubScribeState.png" alt="SubScribeState"></p>
<h1 id="rebalance操作"><a href="#rebalance操作" class="headerlink" title="rebalance操作"></a>rebalance操作</h1><h2 id="哪种情况下会出发rebalance"><a href="#哪种情况下会出发rebalance" class="headerlink" title="哪种情况下会出发rebalance"></a>哪种情况下会出发rebalance</h2><ol>
<li>有新的消费者加入consumerGroup</li>
<li>有新的消费者宕机下线</li>
<li>有消费者主动退出consumerGroup</li>
<li>consumerGroup订阅任一topic出现分区数量的变化</li>
<li>消费者取消对topic的订阅</li>
</ol>
<h3 id="第一阶段"><a href="#第一阶段" class="headerlink" title="第一阶段"></a>第一阶段</h3><ul>
<li>第一步检查是否需要重新查找groupCoordinator，主要是检查Coordinator字段是否为空以及与groupCoordinator之间的连接是正常；</li>
<li>第二步查找集群负载最低的node节点，并创建groupCoordinatorRequest,调用client.sent()方法将请求放入unsent队列中等待发送，并返回future对象，返回的对象经过compose方法适配，返回给heartbeatCompletionHandler;</li>
<li>第三步调用consumerNetClient.poll(future) 方法，groupCoordinatorRequest请求发送出去，此处使用阻塞的方式发送，知道收到groupCoordinatorResponse响应或异常完成，</li>
<li>第四步检查返回的RequestFuture<Void> 对象，如果出现retriableException异常，则调用ConsumerNetWorkClient.awaitMetadataUpdate()方法阻塞更新metadata中记录的集群元素后跳转到步骤一继续操作。如果不是RetriableException则直接报错；</li>
<li>第五步如果找到GroupCoordinator节点，但是网络连接失败，则将其unsent中对应的请求秦孔，并将coordinator字段置为空，重新查找GroupCoordinator</li>
</ul>
<h3 id="第二阶段"><a href="#第二阶段" class="headerlink" title="第二阶段"></a>第二阶段</h3><p>在成功查找到GroupCoordinator之后进入Join group阶段，在此阶段消费者会向GroupCoordinator发送joinGroupRequest请求，并处理响应</p>
<p><img src="/images/kafka/consumer/joinGroup.png" alt="joinGroupRequest"></p>
<p>在进行完joinGroupRequest之后要进行joinGroupResponse()方法，</p>
<p><img src="/images/kafka/consumer/joinGroupResponse.png" alt="joinGroupResponse"></p>
<h3 id="第三阶段"><a href="#第三阶段" class="headerlink" title="第三阶段"></a>第三阶段</h3><p>在完成分区分配后，要进入synchronizing group state阶段，主要逻辑是向groupCoordinator发送syncGroupRequest，并处理syncGroupResponse响应。</p>
<p><img src="/images/kafka/consumer/onjoinComplete.png" alt="onjoinComplete"></p>
<h1 id="offset"><a href="#offset" class="headerlink" title="offset"></a>offset</h1><p>offset commit 分为同步和异步提交以及手动提交，手动提交就是调用异步提交。</p>
<p><img src="/images/kafka/consumer/offsetCommit.png" alt="offsetCommit"></p>
<h2 id="fetch-offset"><a href="#fetch-offset" class="headerlink" title="fetch offset"></a>fetch offset</h2><p>在rebalance结束后，每个消费者都确定了其需要消费的分区，在开始消费之前，消费者需要确定拉取消息的其实位置，假设之前已经将最后的消费者提交到了groupCoordinator中，groupCoordinator将其提交到内部的offset_topic中.此时消费者需要通过offsetFetchRequest 请求上次提交的位置，从此继续消费。</p>
<h1 id="fetcher"><a href="#fetcher" class="headerlink" title="fetcher"></a>fetcher</h1><p>fetcher类的功能发送请求获取指定的消息集合，并更新消费位置。而且需要拉取最新的postion，有earlist、latest两种策略，上面两种策略都会发送offsetsRequest，请求指定的offset。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2019-04-14/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-%E5%A0%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019-04-14/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-%E5%A0%86/" class="post-title-link" itemprop="url">java数据结构和算法-堆</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-04-14 02:00:13" itemprop="dateCreated datePublished" datetime="2019-04-14T02:00:13+08:00">2019-04-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 01:03:09" itemprop="dateModified" datetime="2020-08-21T01:03:09+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">数据结构和算法</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>树包括二叉树、红黑树、2-3-4树、堆等各种不同的树</p>
<p>这里的堆是一种树，由它实现的优先级队列的插入和删除的时间复杂度都为O(logN)，这样尽管删除的时间变慢了，但是插入的时间快了很多，当速度非常重要，而且有很多插入操作时，可以选择用堆来实现优先级队列。</p>
<h1 id="堆的定义"><a href="#堆的定义" class="headerlink" title="堆的定义"></a>堆的定义</h1><p>1.它是完全二叉树，除了树的最后一层节点不需要是满的，其它的每一层从左到右都是满的。注意下面两种情况，第二种最后一层从左到右中间有断隔，那么也是不完全二叉树。</p>
<p><img src="/images/datastructure/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E5%92%8C%E9%9D%9E%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91.png" alt="完全二叉树和非完全二叉树"></p>
<p>2.它通常用数组来实现</p>
<p><img src="/images/datastructure/%E6%95%B0%E7%BB%84%E6%9D%A5%E5%AE%9E%E7%8E%B0%E4%BA%8C%E5%8F%89%E6%A0%91.png" alt="数组来实现二叉树"></p>
<p>这种用数组实现的二叉树，假设节点的索引值为index，那么：</p>
<ul>
<li><p>节点的左子节点是 2*index+1，</p>
</li>
<li><p>节点的右子节点是 2*index+2，</p>
</li>
<li><p>节点的父节点是 （index-1）/2。</p>
</li>
</ul>
<ol start="3">
<li>堆中的每一个节点的关键字都大于（或等于）这个节点的子节点的关键字。</li>
</ol>
<h2 id="二叉搜索树和堆的区别"><a href="#二叉搜索树和堆的区别" class="headerlink" title="二叉搜索树和堆的区别"></a>二叉搜索树和堆的区别</h2><p>这里要注意堆和前面说的二叉搜索树的区别，二叉搜索树中所有节点的左子节点关键字都小于右子节点关键字，在二叉搜索树中通过一个简单的算法就可以按序遍历节点。但是在堆中，按序遍历节点是很困难的，如上图所示，堆只有沿着从根节点到叶子节点的每一条路径是降序排列的，指定节点的左边节点或者右边节点，以及上层节点或者下层节点由于不在同一条路径上，他们的关键字可能比指定节点大或者小。所以相对于二叉搜索树，堆是弱序的。</p>
<h2 id="遍历和查找"><a href="#遍历和查找" class="headerlink" title="遍历和查找"></a>遍历和查找</h2><p>　前面我们说了，堆是弱序的，所以想要遍历堆是很困难的，基本上，堆是不支持遍历的。</p>
<p>对于查找，由于堆的特性，在查找的过程中，没有足够的信息来决定选择通过节点的两个子节点中的哪一个来选择走向下一层，所以也很难在堆中查找到某个关键字。</p>
<p>因此，堆这种组织似乎非常接近无序，不过，对于快速的移除最大（或最小）节点，也就是根节点，以及能快速插入新的节点，这两个操作就足够了。</p>
<h2 id="移除"><a href="#移除" class="headerlink" title="移除"></a>移除</h2><p>移除是指删除关键字最大的节点（或最小），也就是根节点。</p>
<p>　　根节点在数组中的索引总是0，即maxNode = heapArray[0];</p>
<p>　　移除根节点之后，那树就空了一个根节点，也就是数组有了一个空的数据单元，这个空单元我们必须填上。</p>
<p>　　第一种方法：将数组所有数据项都向前移动一个单元，这比较费时。</p>
<p>　　第二种方法：</p>
<p>　　　　①、移走根</p>
<p>　　　　②、把最后一个节点移动到根的位置</p>
<p>　　　　③、一直向下筛选这个节点，直到它在一个大于它的节点之下，小于它的节点之上为止。</p>
<p><img src="/images/datastructure/%E5%A0%86%E7%A7%BB%E9%99%A4%E6%9C%80%E5%A4%A7%E7%9A%84%E8%8A%82%E7%82%B9.png" alt="堆移除最大的节点"></p>
<h2 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h2><p>插入节点也很容易，插入时，选择向上筛选，节点初始时插入到数组最后第一个空着的单元，数组容量大小增一。然后进行向上筛选的算法。</p>
<p>注意：向上筛选和向下不同，向上筛选只用和一个父节点进行比较，比父节点小就停止筛选了。</p>
<p><img src="/images/datastructure/%E5%A0%86%E6%8F%92%E5%85%A5%E5%92%8C%E5%90%91%E4%B8%8A%E7%AD%9B%E9%80%89.png" alt="堆插入和向上筛选"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.chenwj.cn/2019-04-14/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-hash%E8%A1%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.ico">
      <meta itemprop="name" content="陈伟杰">
      <meta itemprop="description" content="学习，坚持。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="茄子的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019-04-14/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-hash%E8%A1%A8/" class="post-title-link" itemprop="url">java数据结构和算法-hash表</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-04-14 00:10:48" itemprop="dateCreated datePublished" datetime="2019-04-14T00:10:48+08:00">2019-04-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-21 01:03:09" itemprop="dateModified" datetime="2020-08-21T01:03:09+08:00">2020-08-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" itemprop="url" rel="index"><span itemprop="name">数据结构</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Hash表也称散列表，也有直接译作哈希表，Hash表是一种根据关键字值（key - value）而直接进行访问的数据结构。它基于数组，通过把关键字映射到数组的某个下标来加快查找速度，但是又和数组、链表、树等数据结构不同，在这些数据结构中查找某个关键字，通常要遍历整个数据结构，也就是O(N)的时间级，但是对于哈希表来说，只是O(1)的时间级。</p>
<h1 id="哈希函数的引入"><a href="#哈希函数的引入" class="headerlink" title="哈希函数的引入"></a>哈希函数的引入</h1><p>hash表时一种根据关键字值（key-value）进行访问的数据结构。通过把关键字映射到数组的某个小标来加快查找速度。</p>
<p>映射的话，将关键字hash话。</p>
<p>我们知道 ASCII 是一种编码，其中 a 表示97，b表示98，以此类推，一直到122表示z，而每个单词都是由这26个字母组成，我们可以不用 ASCII 编码那么大的数字，自己设计一套类似 ASCII的编码，比如a表示1，b表示2，依次类推，z表示26，那么表示方法我们就知道了。</p>
<p>但是这个肯定数量范围不够，那么肯定有一个位置存储了多个单词，每个数组的数据项平均要存储192个单词，如果要查找一个但是还是很慢。</p>
<ol>
<li>第一种方法：考虑每个数组包含一个子数组或者一个子链表，这种存储数据很快，但是姚村192个单词中找到一个还是很慢。</li>
<li>第二种方法：为啥要让那么多单词占据同一个数据项呢？也就是我们没有把单词分得足够开，数组表示的元素太少，我们需要扩展数组的下标，是其中每个位置都只存放一个单词。</li>
</ol>
<p>arrayIndex = largerNumber % smallRange</p>
<p>它把一个大范围的数字哈希（转化）成一个小范围的数字，这个小范围的数对应着数组的下标。使用哈希函数向数组插入数据后，这个数组就是哈希表。</p>
<h1 id="冲突"><a href="#冲突" class="headerlink" title="冲突"></a>冲突</h1><p>把巨大的数字范围压缩到较小的数字范围，那么肯定会有几个不同的单词哈希化到同一个数组下标，即产生了冲突。</p>
<h2 id="开放地址法和链地址法"><a href="#开放地址法和链地址法" class="headerlink" title="开放地址法和链地址法"></a>开放地址法和链地址法</h2><p>冲突可能会导致哈希化方案无法实施，前面我们说指定的数组范围大小是实际存储数据的两倍，因此可能有一半的空间是空着的，所以，当冲突产生时，一个方法是通过系统的方法找到数组的一个空位，并把这个单词填入，而不再用哈希函数得到数组的下标，这种方法称为开放地址法。比如加入单词 cats 哈希化的结果为5421，但是它的位置已经被单词parsnip占用了，那么我们会考虑将单词 cats 存放在parsnip后面的一个位置 5422 上。</p>
<p>另一种方法，前面我们也提到过，就是数组的每个数据项都创建一个子链表或子数组，那么数组内不直接存放单词，当产生冲突时，新的数据项直接存放到这个数组下标表示的链表中，这种方法称为链地址法。</p>
<h2 id="开放地址法"><a href="#开放地址法" class="headerlink" title="开放地址法"></a>开放地址法</h2><p>开放地址法中，若数据项不能直接存放在由哈希函数所计算出来的数组下标时，就要寻找其他的位置。分别有三种方法：线性探测、二次探测以及再哈希法。</p>
<h3 id="线性探测"><a href="#线性探测" class="headerlink" title="线性探测"></a>线性探测</h3><p>在线性探测中，它会线性的查找空白单元。比如如果 5421 是要插入数据的位置，但是它已经被占用了，那么就使用5422，如果5422也被占用了，那么使用5423，以此类推，数组下标依次递增，直到找到空白的位置。这就叫做线性探测，因为它沿着数组下标一步一步顺序的查找空白单元。</p>
<p>需要注意的是，当哈希表变得太满时，我们需要扩展数组，但是需要注意的是，数据项不能放到新数组中和老数组相同的位置，而是要根据数组大小重新计算插入位置。这是一个比较耗时的过程，所以一般我们要确定数据的范围，给定好数组的大小，而不再扩容。</p>
<h3 id="装填因子"><a href="#装填因子" class="headerlink" title="装填因子"></a>装填因子</h3><p>已填入哈希表的数据项和表长的比率叫做装填因子，比如有10000个单元的哈希表填入了6667 个数据后，其装填因子为 2/3。当装填因子不太大时，聚集分布的比较连贯，而装填因子比较大时，则聚集发生的很大了。</p>
<h3 id="二次探测"><a href="#二次探测" class="headerlink" title="二次探测"></a>二次探测</h3><p>二测探测是防止聚集产生的一种方式，思想是探测相距较远的单元，而不是和原始位置相邻的单元。</p>
<p>线性探测中，如果哈希函数计算的原始下标是x, 线性探测就是x+1, x+2, x+3, 以此类推；而在二次探测中，探测的过程是x+1, x+4, x+9, x+16，以此类推，到原始位置的距离是步数的平方。</p>
<h3 id="再哈希法"><a href="#再哈希法" class="headerlink" title="再哈希法"></a>再哈希法</h3><p>我们知道二次聚集的原因是，二测探测的算法产生的探测序列步长总是固定的：1,4，9,16以此类推。那么我们想到的是需要产生一种依赖关键字的探测序列，而不是每个关键字都一样，那么，不同的关键字即使映射到相同的数组下标，也可以使用不同的探测序列。</p>
<h2 id="链地址法"><a href="#链地址法" class="headerlink" title="链地址法"></a>链地址法</h2><p>在开放地址法中，通过再哈希法寻找一个空位解决冲突问题，另一个方法是在哈希表每个单元中设置链表（即链地址法），某个数据项的关键字值还是像通常一样映射到哈希表的单元，而数据项本身插入到这个单元的链表中。其他同样映射到这个位置的数据项只需要加到链表中，不需要在原始的数组中寻找空位。</p>
<p><img src="/images/datastructure/%E9%93%BE%E5%9C%B0%E5%9D%80%E6%B3%95.png" alt="链地址法"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>哈希表基于数组，类似于key-value的存储形式，关键字值通过哈希函数映射为数组的下标，如果一个关键字哈希化到已占用的数组单元，这种情况称为冲突。用来解决冲突的有两种方法：开放地址法和链地址法。在开发地址法中，把冲突的数据项放在数组的其它位置；在链地址法中，每个单元都包含一个链表，把所有映射到同一数组下标的数据项都插入到这个链表中。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="陈伟杰"
      src="/images/favicon.ico">
  <p class="site-author-name" itemprop="name">陈伟杰</p>
  <div class="site-description" itemprop="description">学习，坚持。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">74</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">68</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/chenwj1103" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chenwj1103" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈伟杰</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">638k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">9:40</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
