<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>DDD-领域驱动设计简介</title>
    <url>/2020-08-14/DDD-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h4 id="服务的演进"><a href="#服务的演进" class="headerlink" title="服务的演进"></a>服务的演进</h4><blockquote>
<p>单机、集中式到分布式微服务架构三个阶段</p>
<ul>
<li><p>微服务解决的问题</p>
<blockquote>
<p>可以解决应用之间的解耦、解决单体应用扩展性、小规模团队的敏捷开发；</p>
</blockquote>
</li>
<li><p>DDD的含义</p>
<blockquote>
<ul>
<li><p>DDD核心思想是通过领域驱动设计方法<code>定义领域模型</code>，从而<code>确定业务和应用边界</code>，保证业务模型与代码模型的一致性。</p>
</li>
<li><p>DDD不是架构，而是一种架构设计方法论，通过边界划分将复杂业务领域简单化，帮我们设计出清晰的领域和应用边界，可以很容易地实现架构演进。</p>
</li>
<li><p>DDD战略设计会建立领域模型，领域模型可以用于指导微服务的设计和拆分。事件风暴是建立领域模型的主要方法，它是一个从发散到收敛的过程。它通常采用用例分析、场景分析和用户旅程分析，尽可能全面不遗漏地分解业务领域，并梳理领域对象之间的关系，这是一个发散的过程。事件风暴过程会产生很多的实体、命令、事件等领域对象，我们将这些领域对象从不同的维度进行聚类，形成如聚合、限界上下文等边界，建立领域模型，这就是一个收敛的过程。</p>
</li>
<li><p>具体的过程</p>
<blockquote>
<ol>
<li><p>第一步：在事件风暴中梳理业务过程中的用户操作、事件以及外部依赖关系等，根据这些要素梳理出领域实体等领域对象。</p>
</li>
<li><p>第二步：根据领域实体之间的业务关联性，将业务紧密相关的实体进行组合形成聚合，同时确定聚合中的聚合根、值对象和实体。在这个图里，聚合之间的边界是第一层边界，它们在同一个微服务实例中运行，这个边界是逻辑边界，所以用虚线表示。</p>
</li>
<li><p>第三步：根据业务及语义边界等因素，将一个或者多个聚合划定在一个限界上下文内，形成领域模型。在这个图里，限界上下文之间的边界是第二层边界，这一层边界可能就是未来微服务的边界，不同限界上下文内的领域逻辑被隔离在不同的微服务实例中运行，物理上相互隔离，所以是物理边界，边界之间用实线来表示。</p>
</li>
</ol>
</blockquote>
</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="DDD的名字概念"><a href="#DDD的名字概念" class="headerlink" title="DDD的名字概念"></a>DDD的名字概念</h4><blockquote>
<ul>
<li><p>领域： 研究的对象或者事业的范围；</p>
</li>
<li><p>子领域：每个子域对应一个更小的问题域或更小的业务范围；（核心思想就是将问题域逐步分解，降低业务理解和系统实现的复杂度）</p>
</li>
<li><p>核心域： 关注的核心子域就是核心域；</p>
</li>
<li><p>通用域：公共的子领域；</p>
</li>
<li><p>支撑域：不是决定性的核心的域，支撑作用的领域；</p>
<p>公司在IT系统建设过程中，由于预算和资源有限，对不同类型的子域应有不同的关注度和资源投入策略</p>
</li>
<li></li>
</ul>
<p>领域的核心思想就是将问题域逐级细分，来降低业务理解和系统实现的复杂度。通过领域细分，逐步缩小微服务需要解决的问题域，构建合适的领域模型，而领域模型映射成系统就是微服务了。</p>
<p>核心域、支撑域和通用域的主要目标是：通过领域划分，区分不同子域在公司内的不同功能属性和重要性，从而公司可对不同子域采取不同的资源投入和建设策略，其关注度也会不一样</p>
<p>DDD分层架构包括用户接入层、应用层、领域层和基础层四层。</p>
</blockquote>
<h4 id="限界上下文：定义领域边界的利器"><a href="#限界上下文：定义领域边界的利器" class="headerlink" title="限界上下文：定义领域边界的利器"></a>限界上下文：定义领域边界的利器</h4><blockquote>
<ul>
<li>在事件风暴的过程中，领域专家会和设计、开发人员一起建立领域模型，在领域建模的过程中会形成通用的业务术语和用户故事。事件风暴也是一个项目团队统一语言的过程。</li>
<li>通过用户故事分析会形成一个个的领域对象，这些领域对象对应领域模型的业务对象，每一个业务对象和领域对象都有通用的名词术语，并且一一映射</li>
<li>微服务代码模型来源于领域模型，每个代码模型的代码对象跟领域对象一一对应。</li>
</ul>
<p>设计过程中我们可以用一些表格，来记录事件风暴和微服务设计过程中产生的领域对象及其属</p>
<p><img src="/images/DDD/%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%9E%8B%E5%92%8C%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt="业务模型和代码模型的关系"></p>
<p>我认为限界上下文的定义就是：用来封装通用语言和领域对象，提供上下文环境，保证在领域之内的一些术语、业务相关对象等（通用语言）有一个确切的含义，没有二义性。这个边界定义了模型的适用范围，使团队所有成员能够明确地知道什么应该在模型中实现，什么不应该在模型中实现。</p>
<p>正如电商领域的商品一样，商品在不同的阶段有不同的术语，在销售阶段是商品，而在运输阶段则变成了货物。同样的一个东西，由于业务领域的不同，赋予了这些术语不同的涵义和职责边界，这个边界就可能会成为未来微服务设计的边界。看到这，我想你应该非常清楚了，领域边界就是通过限界上下文来定义的。</p>
</blockquote>
]]></content>
      <categories>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>api网关介绍</title>
    <url>/2020-08-04/api%E7%BD%91%E5%85%B3%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<p>不使用网关带来的问题</p>
<ul>
<li>各个模块代码功能耦合。每个业务都会需要鉴权、限流、权限校验等逻辑，如果每个业务都各自为战，自己造轮子实现一遍，会很蛋疼，完全可以抽出来，放到一个统一的地方去做。</li>
<li>如果业务量比较简单的话，这种方式前期不会有什么问题，但随着业务越来越复杂，比如淘宝、亚马逊打开一个页面可能会涉及到数百个微服务协同工作，如果每一个微服务都分配一个域名的话，一方面客户端代码会很难维护，涉及到数百个域名，另一方面是连接数的瓶颈，想象一下你打开一个APP，通过抓包发现涉及到了数百个远程调用，这在移动端下会显得非常低效。</li>
<li>运维需要进行好多配置，域名配置、nginx配置。每上线一个新的服务，都需要运维参与，申请域名、配置Nginx等，当上线、下线服务器时，同样也需要运维参与，另外采用域名这种方式，对于环境的隔离也不太友好，调用者需要自己根据域名自己进行判断。</li>
<li>调用协议的不统一。另外还有一个问题，后端每个微服务可能是由不同语言编写的、采用了不同的协议，比如HTTP、Dubbo、GRPC等，但是你不可能要求客户端去适配这么多种协议，这是一项非常有挑战的工作，项目会变的非常复杂且很难维护。</li>
<li>后期如果需要对微服务进行重构的话，也会变的非常麻烦，需要客户端配合你一起进行改造，比如商品服务，随着业务变的越来越复杂，后期需要进行拆分成多个微服务，这个时候对外提供的服务也需要拆分成多个，同时需要客户端配合你进行改造，非常蛋疼。</li>
</ul>
<p>网关的功能</p>
<ul>
<li>流量的入口，服务的聚合；</li>
<li>针对流量进行的扩展。鉴权、限流、熔断、降级、协议转换、错误码统一、缓存、日志、监控、告警等。</li>
</ul>
<h1 id="具体的思路"><a href="#具体的思路" class="headerlink" title="具体的思路"></a>具体的思路</h1><h2 id="api的注册"><a href="#api的注册" class="headerlink" title="api的注册"></a>api的注册</h2><ul>
<li>第一种采用插件扫描业务方的API，比如Spring MVC的注解，并结合Swagger的注解，从而实现参数校验、文档&amp;&amp;SDK生成等功能，扫描完成之后，需要上报到网关的存储服务。</li>
<li>手动录入</li>
<li>配置文件的导入</li>
</ul>
<h2 id="协议转换"><a href="#协议转换" class="headerlink" title="协议转换"></a>协议转换</h2><p>内部的API可能是由很多种不同的协议实现的，比如HTTP、Dubbo、GRPC等，但对于用户来说其中很多都不是很友好，或者根本没法对外暴露，比如Dubbo服务，因此需要在网关层做一次协议转换，将用户的HTTP协议请求，在网关层转换成底层对应的协议</p>
<h2 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h2><ul>
<li>写死在代码/配置文件里，这种方式虽然比较挫，但也能使用，比如线上仍然使用的是物理机，IP变动不会很频繁，但扩缩容、包括应用上下线都会很麻烦，网关自身甚至需要实现一套健康监测机制。</li>
<li>域名。采用域名也是一种不错的方案，对于所有的语言都适用，但对于<code>内部的服务，走域名会很低效</code>，另外环境隔离也不太友好，比如预发、线上通常是同一个数据库，因此网关读取到的可能是同一个域名，这时候预发的网关调用的就是线上的服务。</li>
<li>注册中心。采用注册中心就不会有上述的这些问题，即使是在容器环境下，节点的IP变更比较频繁，但节点列表的实时维护会由注册中心搞定，对网关是透明的，另外应用的正常上下线、包括异常宕机等情况，也会由注册中心的健康检查机制检测到，并实时反馈给网关。并且采用注册中心性能也没有额外的性能损耗，采用域名的方式，额外需要走一次DNS解析、Nginx转发等，中间多了很多跳，性能会有很大的下降，但采用注册中心，网关是和业务方直接点对点的通讯，不会有额外的损耗。</li>
</ul>
<h2 id="服务调用"><a href="#服务调用" class="headerlink" title="服务调用"></a>服务调用</h2><p>网关由于对接很多种不同的协议，因此可能需要实现很多种调用方式，比如HTTP、Dubbo等，基于性能原因，最好都采用异步的方式，而Http、Dubbo都是支持异步的，比如apache就提供了基于NIO实现的异步HTTP客户端</p>
<h2 id="优雅下线"><a href="#优雅下线" class="headerlink" title="优雅下线"></a>优雅下线</h2><p>优雅下线也是网关需要关注的一个问题，网关底层会涉及到很多种协议，比如HTTP、Dubbo，而HTTP又可以继续细分，比如域名、注册中心等，有些自身就支持优雅下线</p>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><ul>
<li>网关作为所有流量的入口，性能是重中之重，早期大部分网关都是基于同步阻塞模型构建的，比如Zuul 1.x。但这种同步的模型我们都知道，每个请求/连接都会占用一个线程，而线程在JVM中是一个很重的资源，比如Tomcat默认就是200个线程，如果网关隔离没有做好的话，当发生网络延迟、FullGC、第三方服务慢等情况造成上游服务延迟时，线程池很容易会被打满，造成新的请求被拒绝，但这个时候其实线程都阻塞在IO上，系统的资源被没有得到充分的利用。另外一点，容易受网络、磁盘IO等延迟影响。需要谨慎设置超时时间，如果设置不当，且服务隔离做的不是很完善的话，网关很容易被一个慢接口拖垮</li>
<li>而异步化的方式则完全不同，通常情况下一个CPU核启动一个线程即可处理所有的请求、响应。一个请求的生命周期不再固定于一个线程，而是会分成不同的阶段交由不同的线程池处理，系统的资源能够得到更充分的利用</li>
</ul>
<h2 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h2><ul>
<li>单机。单机性能比较高，不涉及远程调用，只是本地计数，对接口RT影响最小。但需要考虑下限流数的设置，比如是针对单台网关、还是整个网关集群，如果是整个集群的话，需要考虑到网关缩容、扩容时修改对应的限流数。</li>
<li>分布式。分布式的就需要一个存储节点维护当前接口的调用数，比如redis、sentinel等，这种方式由于涉及到远程调用，会有些性能损耗，另外也需要考虑到存储挂掉的问题，比如redis如果挂掉，网关需要考虑降级方案，是降级到本地限流，还是直接将限流功能本身降级掉。另外还有不同的策略:简单计数、令牌桶等，大部分场景下其实简单计数已经够用了，但如果需要支持突发流量等场景时，可以采用令牌桶等方案</li>
</ul>
<h2 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h2><p>稳定性是网关非常重要的一环，监控、告警需要做的很完善才可以，比如接口调用量、响应时间、异常、错误码、成功率等相关的监控告警，还有线程池相关的一些，比如活跃线程数、队列积压等，还有些系统层面的，比如CPU、内存、FullGC这些基本的。网关是所有服务的入口，对于网关的稳定性的要求相对于其他服务会更高，最好能够一直稳定的运行，尽量少重启，但当新增功能、或者加日志排查问题时，不可避免的需要重新发布，因此可以参考zuul的方式，将所有的核心功能都基于不同的拦截器实现，拦截器的代码采用Groovy编写，存储到数据库中，支持动态加载、编译、运行，这样在出了问题的时候能够第一时间定位并解决，并且如果网关需要开发新功能，只需要增加新的拦截器，并动态添加到网关即可，不需要重新发布。</p>
<h2 id="熔断降级"><a href="#熔断降级" class="headerlink" title="熔断降级"></a>熔断降级</h2><p>可以基于Hystrix或者Resilience4j实现</p>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>接口的耗时、请求方式、请求IP、请求参数、响应参数(注意脱敏)等，另外由于可能涉及到很多微服务，因此需要提供一个统一的traceId方便关联所有的日志</p>
<h2 id="隔离"><a href="#隔离" class="headerlink" title="隔离"></a>隔离</h2><p>比如线程池、http连接池、redis等应用层面的隔离，另外也可以根据业务场景，将核心业务部署带单独的网关集群，与其他非核心业务隔离开。</p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>比如接口mock，文档生成、sdk代码生成、错误码统一、服务治理相关</p>
<p>参考 :<a href="https://mp.weixin.qq.com/s/KnUUcl_3g3C7bZvJ1kvv1g">https://mp.weixin.qq.com/s/KnUUcl_3g3C7bZvJ1kvv1g</a></p>
]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>网关</tag>
      </tags>
  </entry>
  <entry>
    <title>canal-阿里开源的增量数据订阅与消费框架</title>
    <url>/2017-12-18/canal-%E9%98%BF%E9%87%8C%E5%BC%80%E6%BA%90%E7%9A%84%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E8%AE%A2%E9%98%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<p>  最近拿到一个需求，需要根据数据的变化，实时通知业务方更新redis缓存。所以研究了canal开源框架。</p>
<p>  具体业务是，监控库中订单表的某条订单状态发生变化，则将该条数据的id通过kafka的生产者写入topic，业务方从topic中读取订单的id，然后从库里获取订单的数据更新redis。</p>
<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p> <a href="https://github.com/alibaba/canal">canal源码</a>中包含canal的文档，server端 client端的 例子 源码包等等。</p>
<h1 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h1><p> canal是应阿里巴巴存在杭州和美国的双机房部署，存在跨机房同步的业务需求而提出的。目前内部使用的同步，已经支持mysql5.x和oracle部分版本的日志解析</p>
<h1 id="支持的业务（数据库同步，增量订阅-amp-消费。）"><a href="#支持的业务（数据库同步，增量订阅-amp-消费。）" class="headerlink" title="支持的业务（数据库同步，增量订阅&amp;消费。）"></a>支持的业务（数据库同步，增量订阅&amp;消费。）</h1><p>数据库镜像、数据库实时备份、多级索引（卖家和买家各自分库索引）、<strong>业务cache刷新</strong>、价格变化等重要业务消息、</p>
<h1 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h1><h2 id="mysql主备复制实现"><a href="#mysql主备复制实现" class="headerlink" title="mysql主备复制实现"></a>mysql主备复制实现</h2><p>如下图所示：</p>
<p> <img src="/images/canal/mysql%E4%B8%BB%E5%A4%87%E5%A4%8D%E5%88%B6%E5%AE%9E%E7%8E%B0.jpg" alt="mysql主备复制实现"></p>
<p>从上图看主要分为三个步骤：</p>
<p>1.master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events，可以通过show binlog events进行查看）；</p>
<p> <img src="/images/canal/%E6%9F%A5%E7%9C%8Bbinlog%E6%97%A5%E5%BF%97.png" alt="查看binlog日志"></p>
<p>2.slave将master的binary log events拷贝到它的中继日志(relay log)；</p>
<p>3.slave重做中继日志中的事件，将改变反映它自己的数据。</p>
<h2 id="canal的工作原理"><a href="#canal的工作原理" class="headerlink" title="canal的工作原理"></a>canal的工作原理</h2><p> <img src="/images/canal/canal%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.jpg" alt="canal的工作原理"></p>
<p>原理如下：</p>
<p>1.canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议</p>
<p>2.mysql master收到dump请求，开始推送binary log给slave(也就是canal)</p>
<p>3.canal解析binary log对象(原始为byte流)</p>
<h1 id="部署（实例）"><a href="#部署（实例）" class="headerlink" title="部署（实例）"></a>部署（实例）</h1><h2 id="部署canal-server端"><a href="#部署canal-server端" class="headerlink" title="部署canal-server端"></a>部署canal-server端</h2><ol>
<li>开启mysql的binlog功能，并配置binlog模式为row。在mysql的my.cnf下加入：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[mysqld]  </span><br><span class="line">log-bin&#x3D;mysql-bin #添加这一行就ok  </span><br><span class="line">binlog-format&#x3D;ROW #选择row模式  </span><br><span class="line">server_id&#x3D;1 #配置mysql replaction需要定义，不能和canal的slaveId重复  </span><br></pre></td></tr></table></figure>

<ol start="2">
<li>canal的原理是模拟自己为mysql的slave，所以这里需要作为mysql slave的权限,而正对已有账户则可以直接grand操作。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE USER canal IDENTIFIED BY &#39;canal&#39;;  </span><br><span class="line">GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#39;canal&#39;@&#39;%&#39;;</span><br><span class="line">-- GRANT ALL PRIVILEGES ON *.* TO &#39;canal&#39;@&#39;%&#39; ;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>下载<a href="https://github.com/alibaba/canal/releases">canal</a>对应的版需要修改</li>
</ol>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>vim canal/conf/example/instance.properties </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#################################################</span><br><span class="line">## mysql serverId (要求不与主库的id一样)</span><br><span class="line">canal.instance.mysql.slaveId &#x3D; 1234</span><br><span class="line"></span><br><span class="line"># position info （主库的ip和port）</span><br><span class="line">canal.instance.master.address &#x3D; 127.0.0.1:3306</span><br><span class="line">canal.instance.master.journal.name &#x3D; </span><br><span class="line">canal.instance.master.position &#x3D; </span><br><span class="line">canal.instance.master.timestamp &#x3D; </span><br><span class="line"></span><br><span class="line">#canal.instance.standby.address &#x3D; </span><br><span class="line">#canal.instance.standby.journal.name &#x3D;</span><br><span class="line">#canal.instance.standby.position &#x3D; </span><br><span class="line">#canal.instance.standby.timestamp &#x3D; </span><br><span class="line"></span><br><span class="line"># username&#x2F;password（主库的账号和密码）</span><br><span class="line">canal.instance.dbUsername &#x3D; canal</span><br><span class="line">canal.instance.dbPassword &#x3D; canal</span><br><span class="line">canal.instance.defaultDatabaseName &#x3D;</span><br><span class="line">canal.instance.connectionCharset &#x3D; UTF-8</span><br><span class="line"></span><br><span class="line"># table regex </span><br><span class="line">canal.instance.filter.regex &#x3D; .*\\..*</span><br><span class="line"># table black regex</span><br><span class="line">canal.instance.filter.black.regex &#x3D;  </span><br><span class="line"></span><br><span class="line">#################################################</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>vim canal/conf/canal.properties </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#################################################</span><br><span class="line">#########         common argument        ############# </span><br><span class="line">#################################################</span><br><span class="line">canal.id&#x3D; 1</span><br><span class="line">canal.ip&#x3D;</span><br><span class="line">canal.port&#x3D; 11111</span><br><span class="line">canal.zkServers&#x3D;</span><br><span class="line"># flush data to zk</span><br><span class="line">canal.zookeeper.flush.period &#x3D; 1000</span><br><span class="line"># flush meta cursor&#x2F;parse position to file</span><br><span class="line">canal.file.data.dir &#x3D; $&#123;canal.conf.dir&#125;</span><br><span class="line">canal.file.flush.period &#x3D; 1000</span><br><span class="line">## memory store RingBuffer size, should be Math.pow(2,n)</span><br><span class="line">canal.instance.memory.buffer.size &#x3D; 16384</span><br><span class="line">## memory store RingBuffer used memory unit size , default 1kb</span><br><span class="line">canal.instance.memory.buffer.memunit &#x3D; 1024 </span><br><span class="line">## meory store gets mode used MEMSIZE or ITEMSIZE</span><br><span class="line">canal.instance.memory.batch.mode &#x3D; MEMSIZE</span><br><span class="line"></span><br><span class="line">## detecing config</span><br><span class="line">canal.instance.detecting.enable &#x3D; false</span><br><span class="line">#canal.instance.detecting.sql &#x3D; insert into retl.xdual values(1,now()) on duplicate key update x&#x3D;now()</span><br><span class="line">canal.instance.detecting.sql &#x3D; select 1</span><br><span class="line">canal.instance.detecting.interval.time &#x3D; 3</span><br><span class="line">canal.instance.detecting.retry.threshold &#x3D; 3</span><br><span class="line">canal.instance.detecting.heartbeatHaEnable &#x3D; false</span><br><span class="line"></span><br><span class="line"># support maximum transaction size, more than the size of the transaction will be cut into multiple transactions delivery</span><br><span class="line">canal.instance.transaction.size &#x3D;  1024</span><br><span class="line"># mysql fallback connected to new master should fallback times</span><br><span class="line">canal.instance.fallbackIntervalInSeconds &#x3D; 60</span><br><span class="line"></span><br><span class="line"># network config</span><br><span class="line">canal.instance.network.receiveBufferSize &#x3D; 16384</span><br><span class="line">canal.instance.network.sendBufferSize &#x3D; 16384</span><br><span class="line">canal.instance.network.soTimeout &#x3D; 30</span><br><span class="line"></span><br><span class="line"># binlog filter config</span><br><span class="line">canal.instance.filter.query.dcl &#x3D; false</span><br><span class="line">canal.instance.filter.query.dml &#x3D; false</span><br><span class="line">canal.instance.filter.query.ddl &#x3D; false</span><br><span class="line">canal.instance.filter.table.error &#x3D; false</span><br><span class="line">canal.instance.filter.rows &#x3D; false</span><br><span class="line"></span><br><span class="line"># binlog format&#x2F;image check</span><br><span class="line">canal.instance.binlog.format &#x3D; ROW,STATEMENT,MIXED </span><br><span class="line">canal.instance.binlog.image &#x3D; FULL,MINIMAL,NOBLOB</span><br><span class="line"></span><br><span class="line"># binlog ddl isolation</span><br><span class="line">canal.instance.get.ddl.isolation &#x3D; false</span><br><span class="line"></span><br><span class="line">#################################################</span><br><span class="line">#########         destinations        ############# </span><br><span class="line">#################################################</span><br><span class="line">canal.destinations&#x3D; example,instance_user_cache_provider</span><br><span class="line"># conf root dir</span><br><span class="line">canal.conf.dir &#x3D; ..&#x2F;conf</span><br><span class="line"># auto scan instance dir add&#x2F;remove and start&#x2F;stop instance</span><br><span class="line">canal.auto.scan &#x3D; false</span><br><span class="line">canal.auto.scan.interval &#x3D; 5</span><br><span class="line"></span><br><span class="line">canal.instance.global.mode &#x3D; spring </span><br><span class="line">canal.instance.global.lazy &#x3D; false</span><br><span class="line">#canal.instance.global.manager.address &#x3D; 127.0.0.1:1099</span><br><span class="line">#canal.instance.global.spring.xml &#x3D; classpath:spring&#x2F;memory-instance.xml</span><br><span class="line">canal.instance.global.spring.xml &#x3D; classpath:spring&#x2F;file-instance.xml</span><br><span class="line">#canal.instance.global.spring.xml &#x3D; classpath:spring&#x2F;default-instance.xml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>./bin/startup.sh</p>
<h3 id="停止"><a href="#停止" class="headerlink" title="停止"></a>停止</h3><p>./bin/stop.sh</p>
<p>查看log日志</p>
<p>cat canal/log/canal/canal.log  </p>
<h2 id="部署canal-client端"><a href="#部署canal-client端" class="headerlink" title="部署canal-client端"></a>部署canal-client端</h2><h3 id="创建maven工程，添加pom依赖"><a href="#创建maven工程，添加pom依赖" class="headerlink" title="创建maven工程，添加pom依赖"></a>创建maven工程，添加pom依赖</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;  </span><br><span class="line">    &lt;groupId&gt;com.alibaba.otter&lt;&#x2F;groupId&gt;  </span><br><span class="line">    &lt;artifactId&gt;canal.client&lt;&#x2F;artifactId&gt;  </span><br><span class="line">    &lt;version&gt;1.0.12&lt;&#x2F;version&gt;  </span><br><span class="line">&lt;&#x2F;dependency&gt;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;** </span><br><span class="line"> * Created by chenwj on 17-11-17. </span><br><span class="line"> *&#x2F;  </span><br><span class="line">import java.net.InetSocketAddress;  </span><br><span class="line">import java.util.List;  </span><br><span class="line">  </span><br><span class="line">import com.alibaba.otter.canal.client.CanalConnector;  </span><br><span class="line">import com.alibaba.otter.canal.common.utils.AddressUtils;  </span><br><span class="line">import com.alibaba.otter.canal.protocol.Message;  </span><br><span class="line">import com.alibaba.otter.canal.protocol.CanalEntry.Column;  </span><br><span class="line">import com.alibaba.otter.canal.protocol.CanalEntry.Entry;  </span><br><span class="line">import com.alibaba.otter.canal.protocol.CanalEntry.EntryType;  </span><br><span class="line">import com.alibaba.otter.canal.protocol.CanalEntry.EventType;  </span><br><span class="line">import com.alibaba.otter.canal.protocol.CanalEntry.RowChange;  </span><br><span class="line">import com.alibaba.otter.canal.protocol.CanalEntry.RowData;  </span><br><span class="line">import com.alibaba.otter.canal.client.*;  </span><br><span class="line">import org.jetbrains.annotations.NotNull;  </span><br><span class="line">  </span><br><span class="line">public class ClientSample &#123;  </span><br><span class="line">  </span><br><span class="line">    public static void main(String args[]) &#123;  </span><br><span class="line">        &#x2F;&#x2F; 创建链接   第一个为服务端的ip  第二个为端口 在canal.properties 配置文件中配置 第三个参数为实例的名称   第三个和第四个参数可以不配置</span><br><span class="line">        CanalConnector connector &#x3D; CanalConnectors.newSingleConnector(new InetSocketAddress(AddressUtils.getHostIp(),  </span><br><span class="line">                11111), &quot;example&quot;, &quot;&quot;, &quot;&quot;);  </span><br><span class="line">        int batchSize &#x3D; 1000;  </span><br><span class="line">        int emptyCount &#x3D; 0;  </span><br><span class="line">        try &#123;  </span><br><span class="line">            connector.connect();  </span><br><span class="line">            connector.subscribe(&quot;.*\\..*&quot;);  </span><br><span class="line">            connector.rollback();  </span><br><span class="line">            int totalEmtryCount &#x3D; 1200;  </span><br><span class="line">            while (emptyCount &lt; totalEmtryCount) &#123;  </span><br><span class="line">                Message message &#x3D; connector.getWithoutAck(batchSize); &#x2F;&#x2F; 获取指定数量的数据  </span><br><span class="line">                long batchId &#x3D; message.getId();  </span><br><span class="line">                int size &#x3D; message.getEntries().size();  </span><br><span class="line">                if (batchId &#x3D;&#x3D; -1 || size &#x3D;&#x3D; 0) &#123;  </span><br><span class="line">                    emptyCount++;  </span><br><span class="line">                    System.out.println(&quot;empty count : &quot; + emptyCount);  </span><br><span class="line">                    try &#123;  </span><br><span class="line">                        Thread.sleep(1000);  </span><br><span class="line">                    &#125; catch (InterruptedException e) &#123;  </span><br><span class="line">                        e.printStackTrace();  </span><br><span class="line">                    &#125;  </span><br><span class="line">                &#125; else &#123;  </span><br><span class="line">                    emptyCount &#x3D; 0;  </span><br><span class="line">                    &#x2F;&#x2F; System.out.printf(&quot;message[batchId&#x3D;%s,size&#x3D;%s] \n&quot;, batchId, size);  </span><br><span class="line">                    printEntry(message.getEntries());  </span><br><span class="line">                &#125;  </span><br><span class="line">  </span><br><span class="line">                connector.ack(batchId); &#x2F;&#x2F; 提交确认  </span><br><span class="line">                &#x2F;&#x2F; connector.rollback(batchId); &#x2F;&#x2F; 处理失败, 回滚数据  </span><br><span class="line">            &#125;  </span><br><span class="line">  </span><br><span class="line">            System.out.println(&quot;empty too many times, exit&quot;);  </span><br><span class="line">        &#125; finally &#123;  </span><br><span class="line">            connector.disconnect();  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    private static void printEntry(@NotNull List&lt;Entry&gt; entrys) &#123;  </span><br><span class="line">        for (Entry entry : entrys) &#123;  </span><br><span class="line">            if (entry.getEntryType() &#x3D;&#x3D; EntryType.TRANSACTIONBEGIN || entry.getEntryType() &#x3D;&#x3D; EntryType.TRANSACTIONEND) &#123;  </span><br><span class="line">                continue;  </span><br><span class="line">            &#125;  </span><br><span class="line">  </span><br><span class="line">            RowChange rowChage &#x3D; null;  </span><br><span class="line">            try &#123;  </span><br><span class="line">                rowChage &#x3D; RowChange.parseFrom(entry.getStoreValue());  </span><br><span class="line">            &#125; catch (Exception e) &#123;  </span><br><span class="line">                throw new RuntimeException(&quot;ERROR ## parser of eromanga-event has an error , data:&quot; + entry.toString(),  </span><br><span class="line">                        e);  </span><br><span class="line">            &#125;  </span><br><span class="line">  </span><br><span class="line">            EventType eventType &#x3D; rowChage.getEventType();  </span><br><span class="line">            System.out.println(String.format(&quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; binlog[%s:%s] , name[%s,%s] , eventType : %s&quot;,  </span><br><span class="line">                    entry.getHeader().getLogfileName(), entry.getHeader().getLogfileOffset(),  </span><br><span class="line">                    entry.getHeader().getSchemaName(), entry.getHeader().getTableName(),  </span><br><span class="line">                    eventType));  </span><br><span class="line">  </span><br><span class="line">            for (RowData rowData : rowChage.getRowDatasList()) &#123;  </span><br><span class="line">                if (eventType &#x3D;&#x3D; EventType.DELETE) &#123;  </span><br><span class="line">                    printColumn(rowData.getBeforeColumnsList());  </span><br><span class="line">                &#125; else if (eventType &#x3D;&#x3D; EventType.INSERT) &#123;  </span><br><span class="line">                    printColumn(rowData.getAfterColumnsList());  </span><br><span class="line">                &#125; else &#123;  </span><br><span class="line">                    System.out.println(&quot;-------&gt; before&quot;);  </span><br><span class="line">                    printColumn(rowData.getBeforeColumnsList());  </span><br><span class="line">                    System.out.println(&quot;-------&gt; after&quot;);  </span><br><span class="line">                    printColumn(rowData.getAfterColumnsList());  </span><br><span class="line">                &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    private static void printColumn(@NotNull List&lt;Column&gt; columns) &#123;  </span><br><span class="line">        for (Column column : columns) &#123;  </span><br><span class="line">            System.out.println(column.getName() + &quot; : &quot; + column.getValue() + &quot;    update&#x3D;&quot; + column.getUpdated());  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="启动客户端的main方法"><a href="#启动客户端的main方法" class="headerlink" title="启动客户端的main方法"></a>启动客户端的main方法</h3><p>启动后看到控制端信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">empty count : 1  </span><br><span class="line">empty count : 2  </span><br><span class="line">empty count : 3  </span><br><span class="line">empty count : 4  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>触发数据改变</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table test (  </span><br><span class="line">uid int (4) primary key not null auto_increment,  </span><br><span class="line">name varchar(10) not null);  </span><br><span class="line">  </span><br><span class="line">insert into test (name) values(&#39;10&#39;);  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; binlog[mysql-bin.000016:3281] , name[canal_test,test] , eventType : INSERT  </span><br><span class="line">uid : 7    update&#x3D;false  </span><br><span class="line">name : 10    update&#x3D;false  </span><br><span class="line">empty count : 1  </span><br><span class="line">empty count : 2  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>以上只是简单的单机模式的demo，集群模式和具体的配置文件中的参数详见<a href="https://github.com/alibaba/canal/wiki/AdminGuide">配置</a>。</p>
<p>其中spring的配置文件采用默认的 canal.instance.global.spring.xml = classpath:spring/file-instance.xml</p>
<p>而xxxx-instance.xml (canal组件的配置定义，可以在多个instance配置中共享) </p>
<p>如下所示为多个示例</p>
<p> <img src="/images/canal/%E5%A4%9A%E5%AE%9E%E4%BE%8B%E7%9A%84%E9%85%8D%E7%BD%AE.jpg" alt="多实例的文件"></p>
<p>数据对象格式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">Entry  </span><br><span class="line">    Header  </span><br><span class="line">        logfileName [binlog文件名]  </span><br><span class="line">        logfileOffset [binlog position]  </span><br><span class="line">        executeTime [binlog里记录变更发生的时间戳,精确到秒]  </span><br><span class="line">        schemaName   </span><br><span class="line">        tableName  </span><br><span class="line">        eventType [insert&#x2F;update&#x2F;delete类型]  </span><br><span class="line">    entryType   [事务头BEGIN&#x2F;事务尾END&#x2F;数据ROWDATA]  </span><br><span class="line">    storeValue  [byte数据,可展开，对应的类型为RowChange]  </span><br><span class="line">RowChange</span><br><span class="line"></span><br><span class="line">isDdl       [是否是ddl变更操作，比如create table&#x2F;drop table]</span><br><span class="line"></span><br><span class="line">sql         [具体的ddl sql]</span><br><span class="line"></span><br><span class="line">rowDatas    [具体insert&#x2F;update&#x2F;delete的变更数据，可为多条，1个binlog event事件可对应多条变更，比如批处理]</span><br><span class="line"></span><br><span class="line">beforeColumns [Column类型的数组，变更前的数据字段]</span><br><span class="line"></span><br><span class="line">afterColumns [Column类型的数组，变更后的数据字段]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Column</span><br><span class="line"></span><br><span class="line">index</span><br><span class="line"></span><br><span class="line">sqlType     [jdbc type]</span><br><span class="line"></span><br><span class="line">name        [column name]</span><br><span class="line"></span><br><span class="line">isKey       [是否为主键]</span><br><span class="line"></span><br><span class="line">updated     [是否发生过变更]</span><br><span class="line"></span><br><span class="line">isNull      [值是否为null]</span><br><span class="line"></span><br><span class="line">value       [具体的内容，注意为string文本]  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://github.com/alibaba/canal/wiki">更详细讲解</a></p>
<p><a href="http://blog.csdn.net/hackerwin7/article/details/37923607">参考博客</a></p>
]]></content>
      <categories>
        <category>canal</category>
      </categories>
      <tags>
        <tag>mysql,canal</tag>
      </tags>
  </entry>
  <entry>
    <title>git常用命令总结</title>
    <url>/2018-11-14/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="克隆代码"><a href="#克隆代码" class="headerlink" title="克隆代码"></a>克隆代码</h1><p>将远端的git项目拉取到本地：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone resource_url</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="正常的开发流程"><a href="#正常的开发流程" class="headerlink" title="正常的开发流程"></a>正常的开发流程</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.在master分支拉取远端分支的代码到本地，以保证新创建的分支的时候是最新的代码；</span><br><span class="line">git pull origin master </span><br><span class="line"> </span><br><span class="line">2.查看最新的tag，因为开发分支名字的后缀tag是基于最新的tag开出来的，加入最新的tag是1.1.1</span><br><span class="line">git tag</span><br><span class="line"></span><br><span class="line">3.创建新的分支 </span><br><span class="line"></span><br><span class="line">git checkout -b br_test_develop_1.1.1</span><br><span class="line"></span><br><span class="line">4.进行开发</span><br><span class="line">。。。。</span><br><span class="line"></span><br><span class="line">5.查看代码的状态</span><br><span class="line"> git status</span><br><span class="line"> </span><br><span class="line">6.&#39;.&#39;代表当前目录下的所有文件， 也是可以只是添加某一个文件到stage缓存区</span><br><span class="line">git add . 或者 git add files </span><br><span class="line"></span><br><span class="line">7.把 stage 缓存生成一次 commit，并加入 commit 历史, - m是添加注释</span><br><span class="line">git commit -m &quot;commit message&quot;</span><br><span class="line"></span><br><span class="line">8.将新的分支push到远端，将新的commit代码push到远端。</span><br><span class="line">git push origin br_test_develop_1.1.1</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="修改提交日志"><a href="#修改提交日志" class="headerlink" title="修改提交日志"></a>修改提交日志</h2><p>假如你执行 commit -m 时记录的日志描述和本次执行commit的功能不符合，又不想创建新的commit，此时可以使用一下命令。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git commit --amend  </span><br><span class="line"></span><br><span class="line">然后使用 vim编辑操作</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="上线项目需要做的操作"><a href="#上线项目需要做的操作" class="headerlink" title="上线项目需要做的操作"></a>上线项目需要做的操作</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这里假设开发分支为 br_test_develop_1.1.1 。</span><br><span class="line"></span><br><span class="line">1. 先拉取br_test_develop_1.1.1的远端代码，</span><br><span class="line">git pull origin br_test_develop_1.1.1</span><br><span class="line"></span><br><span class="line">2. 然后切换到master分支,拉取master分支的远端代码</span><br><span class="line">git checkout master</span><br><span class="line">git pull origin master</span><br><span class="line"></span><br><span class="line">3. 切换到br_test_develop_1.1.1分支，merge master的代码到br_test_develop_1.1.1,有冲突解决冲突，提交到远端。（防止开发的代码污染master分支，这一步不可以省略。）</span><br><span class="line">git checkout br_test_develop_1.1.1</span><br><span class="line">git merge master</span><br><span class="line">git push origin br_test_develop_1.1.1</span><br><span class="line"></span><br><span class="line">4. 切换到master分支，merge br_test_develop_1.1.1的代码到master分支。</span><br><span class="line">git checkout master</span><br><span class="line">git merge br_test_develop_1.1.1</span><br><span class="line">git push origin master</span><br><span class="line"></span><br><span class="line">5. 确认当前分支是master，且是最新的代码。查看tag，上线的tag在最新的基础上命名一个，或者按照版本需要创建一个tag。</span><br><span class="line">git fetch -all &#x2F;&#x2F; 这将更新git remote 中所有的远程repo 所包含分支的最新commit-id，包括tag</span><br><span class="line">git tag  &#x2F;&#x2F; 查看tag 列表</span><br><span class="line">git tag 1.1.2  &#x2F;&#x2F;创建本地tag为1.1.2</span><br><span class="line">git push --tag &#x2F;&#x2F; push tag 到远端</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="情景1：本地开发着，需要合并远端的开发分支的代码"><a href="#情景1：本地开发着，需要合并远端的开发分支的代码" class="headerlink" title="情景1：本地开发着，需要合并远端的开发分支的代码"></a>情景1：本地开发着，需要合并远端的开发分支的代码</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. stash存储本地的开发中的代码</span><br><span class="line">git add .</span><br><span class="line">git stash</span><br><span class="line"></span><br><span class="line">2. 执行rebase命令，拉取远端代码重建base</span><br><span class="line">git pull --rebase</span><br><span class="line"></span><br><span class="line">3. 取出stash的代码，pop命令会取出并删除stash的代码（最近的一次）</span><br><span class="line">git stash pop </span><br><span class="line"></span><br><span class="line">4. 手动解决冲突 并add .</span><br><span class="line">git add .</span><br><span class="line"></span><br><span class="line">5. 结束reabse模式，如果此时提示No rebase in progress?则表示已经没有冲突了；否则上面两步要重复多次或者执行 git rebase --abort</span><br><span class="line">git rebase --continue 或者 git rebase --abort</span><br><span class="line"></span><br><span class="line">6. 提交代码到远端</span><br><span class="line">git status</span><br><span class="line">git add .</span><br><span class="line">git commit -m “commit message”</span><br><span class="line">git push origin &#39;branchName&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="情景2：git-reset-回退到某次提交的代码"><a href="#情景2：git-reset-回退到某次提交的代码" class="headerlink" title="情景2：git reset 回退到某次提交的代码"></a>情景2：git reset 回退到某次提交的代码</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 查看log日志，取出要取消的某次操作的commitId</span><br><span class="line">git log</span><br><span class="line"></span><br><span class="line">2. 执行reset操作 </span><br><span class="line">git reset --hard &lt;commitId&gt; </span><br><span class="line">或者 </span><br><span class="line">git reset --hard HEAD~2 &#x2F;&#x2F;回退两个commitId</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3. 强制提交到远端 (-f 慎重使用)</span><br><span class="line">git push origin &lt;branchName&gt; -f</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>注意</code>：reset参数。<b>add 是将代码添加工作区，commit是将代码添加到缓存区</b></p>
<ul>
<li>-soft – 缓存区和工作目录都不会被改变(执行了add和commit)</li>
<li>–mixed – 默认选项。缓存区和你指定的提交同步，但工作目录不受影响（只是add 未commit） </li>
<li>–hard – 缓存区和工作目录都同步到你指定的提交(代码都没有了)（代码都没有了）</li>
</ul>
<h2 id="情景3：-git-revert-取消某次的提交-merge版本的commit无法处理"><a href="#情景3：-git-revert-取消某次的提交-merge版本的commit无法处理" class="headerlink" title="情景3： git revert 取消某次的提交(merge版本的commit无法处理)"></a>情景3： git revert 取消某次的提交(merge版本的commit无法处理)</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 查看log日志，取出要取消的某次操作的commitId</span><br><span class="line">git log</span><br><span class="line"></span><br><span class="line">2. 执行reset操作</span><br><span class="line">git revert -n &lt;commitId&gt;</span><br><span class="line"></span><br><span class="line">3. commit push</span><br><span class="line">git commit -m “commit message”</span><br><span class="line">git push origin &lt;branchName&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="情景4：本地正开发着，需要切换到别的分支，此时可以将代码stash到缓存区"><a href="#情景4：本地正开发着，需要切换到别的分支，此时可以将代码stash到缓存区" class="headerlink" title="情景4：本地正开发着，需要切换到别的分支，此时可以将代码stash到缓存区"></a>情景4：本地正开发着，需要切换到别的分支，此时可以将代码stash到缓存区</h2><p>git-stash - Stash the changes in a dirty working directory away</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git add .</span><br><span class="line"></span><br><span class="line">git stash &#x2F;&#x2F;Stash the changes in a dirty working directory away</span><br><span class="line"></span><br><span class="line">git stash list &#x2F;&#x2F;查看缓存记录</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;需要恢复缓存的代码到工作区. 其中stashId可以在git stash list 命令展示的列表中查看</span><br><span class="line">git stash pop 或者 git stash apply stashId</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 清除缓存 </span><br><span class="line">git stash clear  或者 git stash drop  stashId</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>建议</code>： stash缓存使用完请及时clear，时间久了可能容易忘记stash的内容，恢复的时候造成冲突。</p>
<h2 id="关于分支的常用操作"><a href="#关于分支的常用操作" class="headerlink" title="关于分支的常用操作"></a>关于分支的常用操作</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 拉取远端的分支代码，因为默认down代码的时候，不是获取所有远端的最新的代码</span><br><span class="line"> git fetch --all</span><br><span class="line"></span><br><span class="line">2. 查看远端、本地的分支，以及所有分支</span><br><span class="line">git branch &#x2F;&#x2F;查看本地分支</span><br><span class="line">git branch -r &#x2F;&#x2F; -r代码remote，所有的远端分支。</span><br><span class="line">git branch -a &#x2F;&#x2F;查看所有的分支</span><br><span class="line"></span><br><span class="line">3. 一般情况下，远端分支和本地分支是同名的，如果不是同名的需要查看本地分支追踪的远端分支如何查看。</span><br><span class="line">git branch -vv</span><br><span class="line"></span><br><span class="line">4. 如何设置本地追踪的远端分支</span><br><span class="line">git branch --set-upstream-to&#x3D;origin&#x2F;&lt;branch&gt; master</span><br><span class="line"></span><br><span class="line">5. 删除在本地有但在远程库中已经不存在的分支</span><br><span class="line">git remtte prune origin </span><br><span class="line"></span><br><span class="line">6. 删除本地分支</span><br><span class="line">git branch -d &lt;branchName&gt;</span><br><span class="line"></span><br><span class="line">7. 删除远端分支 (必须有权限)</span><br><span class="line">git push origin --delete &lt;branchName&gt;  </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="关于标签的操作"><a href="#关于标签的操作" class="headerlink" title="关于标签的操作"></a>关于标签的操作</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 查看标签列表 之前要执行git fetch --all 拉取远端的分支以及tag到本地</span><br><span class="line">git tag</span><br><span class="line"></span><br><span class="line">2. 查看tag的详细信息,打标签的人以及时间</span><br><span class="line">git show &lt;tagName&gt;</span><br><span class="line"></span><br><span class="line">3. 打标签</span><br><span class="line">git tag &lt;tagName&gt; &#x2F;&#x2F; 在本地的当前commitId节点处创建一个tag标签</span><br><span class="line">或者</span><br><span class="line">git tag -a &lt;tagName&gt; -m &quot;commit message&quot;</span><br><span class="line"></span><br><span class="line">4. 删除本地标签</span><br><span class="line">git tag -d &lt;tagName&gt;</span><br><span class="line"></span><br><span class="line">5. 删除远端分支</span><br><span class="line">git push origin --delete &lt;tagName&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="创建新的项目提交到gitlab上"><a href="#创建新的项目提交到gitlab上" class="headerlink" title="创建新的项目提交到gitlab上"></a>创建新的项目提交到gitlab上</h2><ol>
<li>需要在gitlab上操作创建一个项目</li>
<li>配置用户名和邮箱</li>
</ol>
<h3 id="已有项目添加到远端"><a href="#已有项目添加到远端" class="headerlink" title="已有项目添加到远端"></a>已有项目添加到远端</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 计入文件夹，初始化为git项目</span><br><span class="line">cd existing_folder</span><br><span class="line">git init</span><br><span class="line"></span><br><span class="line">2. 本地和远端进行关联</span><br><span class="line">git remote add origin http:&#x2F;&#x2F;172.16.117.224&#x2F;ent_teach&#x2F;ent-test.git</span><br><span class="line"></span><br><span class="line">3. 执行 add commit push 操作</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;Initial commit&quot;</span><br><span class="line">git push -u origin master</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="创建一个新项目"><a href="#创建一个新项目" class="headerlink" title="创建一个新项目"></a>创建一个新项目</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 克隆远端项目</span><br><span class="line">git clone http:&#x2F;&#x2F;172.16.117.224&#x2F;ent_teach&#x2F;ent-test.git</span><br><span class="line"></span><br><span class="line">2. 进入相应的目录，添加README.md文件。执行 add commit push 操作</span><br><span class="line">cd ent-test</span><br><span class="line">touch README.md</span><br><span class="line">git add README.md</span><br><span class="line">git commit -m &quot;add README&quot;</span><br><span class="line">git push -u origin master</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="解决冲突的技巧"><a href="#解决冲突的技巧" class="headerlink" title="解决冲突的技巧"></a>解决冲突的技巧</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">这一篇解释了手动解决冲突时&lt;&lt;&lt;&lt;和&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;的含义 </span><br><span class="line">一般情况下rebase都是会有冲突的，详细查看冲突可以用命令git status然后就会显示哪个文件有冲突，然后打开有冲突的哪个文件，会发现有一些“&lt;&lt;&lt;&lt;&lt;&lt;&lt;”， “&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;”， “&gt;&gt;&gt;&gt;&gt;&gt;&gt;” 这样的符号。</span><br><span class="line"></span><br><span class="line">“&lt;&lt;&lt;&lt;&lt;&lt;&lt;” 表示冲突代码开始</span><br><span class="line"></span><br><span class="line">“&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;” 表示test与master冲突代码分隔符</span><br><span class="line"></span><br><span class="line">“&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot; 表示冲突代码的结束</span><br><span class="line"></span><br><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt;  </span><br><span class="line">所以这一块区域test的代码</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;  </span><br><span class="line">这一块区域master的代码</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 查看日志</span><br><span class="line">git log  &#x2F;&#x2F;显示的是commitId以及commit Message</span><br><span class="line"></span><br><span class="line">2.查看状态</span><br><span class="line">git status</span><br><span class="line"></span><br><span class="line">3. 快速查看旧版本</span><br><span class="line">git checkout commitId</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="gitlab配置ssh-key"><a href="#gitlab配置ssh-key" class="headerlink" title="gitlab配置ssh key"></a>gitlab配置ssh key</h2><p>1.打开本地git bash,使用如下命令生成ssh公钥和私钥对</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &#39;xxx@xxx.com&#39; 然后一路回车(-C 参数是你的邮箱地址)</span><br></pre></td></tr></table></figure>
<p><img src="/images/git/ssh-key.png" alt="ssh-key"></p>
<p>2.然后打开<del>/.ssh/id_rsa.pub文件(</del>表示用户目录，比如我的windows就是C:\Users\Administrator)，复制其中的内容</p>
<p>3.打开gitlab,找到Profile Settings–&gt;SSH Keys—&gt;Add SSH Key,并把上一步中复制的内容粘贴到Key所对应的文本框，在Title对应的文本框中给这个sshkey设置一个名字，点击Add key按钮</p>
<p><img src="/images/git/gitlab-setting.png" alt="gitlab-setting"></p>
<ol start="4">
<li>到此就完成了gitlab配置ssh key的所有步骤，我们就可以愉快的使用ssh协议进行代码的拉取以及提交等操作了</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://www.cnblogs.com/ToDoToTry/p/4095626.html">git fetch 与git pull的区别</a></li>
<li><a href="https://blog.csdn.net/TTKatrina/article/details/79288238">git rebase的用法</a></li>
<li><a href="https://blog.csdn.net/yxlshk/article/details/79944535">git revert与git reset操作详解</a></li>
<li><a href="https://www.cnblogs.com/ouber23/articles/5466040.html">暂存区与工作区</a></li>
</ol>
]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git命令总结</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo统计配置</title>
    <url>/2017-10-10/hexo%E7%BB%9F%E8%AE%A1%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>后续会整理hexo搭建博客的完整流程，包括过程中踩过的坑。</p>
<h1 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h1><ol>
<li><a href="https://www.jianshu.com/p/702a7aec4d00">leancloud统计</a></li>
<li>卜算子统计 (/themes/next/_config.yml) 路径的themes的next的_config.xml文件中 enable改为true即可.</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Show PV&#x2F;UV of the website&#x2F;page with busuanzi.</span><br><span class="line"># Get more information on http:&#x2F;&#x2F;ibruce.info&#x2F;2015&#x2F;04&#x2F;04&#x2F;busuanzi&#x2F;</span><br><span class="line">busuanzi_count:</span><br><span class="line">  # count values only if the other configs are false</span><br><span class="line">  enable: true</span><br><span class="line">  # custom uv span for the whole site</span><br><span class="line">  site_uv: true</span><br><span class="line">  site_uv_header: &lt;i class&#x3D;&quot;fa fa-user&quot;&gt;&lt;&#x2F;i&gt;</span><br><span class="line">  site_uv_footer:</span><br><span class="line">  # custom pv span for the whole site</span><br><span class="line">  site_pv: true</span><br><span class="line">  site_pv_header: &lt;i class&#x3D;&quot;fa fa-eye&quot;&gt;&lt;&#x2F;i&gt;</span><br><span class="line">  site_pv_footer:</span><br><span class="line">  # custom pv span for one page only</span><br><span class="line">  page_pv: true</span><br><span class="line">  page_pv_header: &lt;i class&#x3D;&quot;fa fa-file-o&quot;&gt;&lt;&#x2F;i&gt;</span><br><span class="line">  page_pv_footer:</span><br></pre></td></tr></table></figure>
<h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><ol>
<li><a href="http://shenzekun.cn/hexo%E7%9A%84next%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B.html">next主题秘籍</a></li>
<li><a href="http://www.yuan-ji.me/Hexo-%E4%BC%98%E5%8C%96%EF%BC%9A%E6%8F%90%E4%BA%A4sitemap%E5%8F%8A%E8%A7%A3%E5%86%B3%E7%99%BE%E5%BA%A6%E7%88%AC%E8%99%AB%E6%8A%93%E5%8F%96-GitHub-Pages-%E9%97%AE%E9%A2%98/">优化百度收录博客文章</a></li>
<li><a href="https://tongji.baidu.com/web/24767668/homepage/index">百度统计</a></li>
<li><a href="http://dashboard.daovoice.io/app/7e36aff1/users?segment=all-users">daoVoice</a></li>
<li><a href="https://livere.com/insight">来必力</a></li>
<li><a href="https://github.com/the0demiurge/CharlesScripts/blob/master/charles/bin/ssr">SSR客户端</a></li>
<li><a href="https://www.djangoz.com/2017/08/16/linux_setup_ssr/">SSR客户端2</a></li>
</ol>
]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法-hash表</title>
    <url>/2019-04-14/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-hash%E8%A1%A8/</url>
    <content><![CDATA[<p>Hash表也称散列表，也有直接译作哈希表，Hash表是一种根据关键字值（key - value）而直接进行访问的数据结构。它基于数组，通过把关键字映射到数组的某个下标来加快查找速度，但是又和数组、链表、树等数据结构不同，在这些数据结构中查找某个关键字，通常要遍历整个数据结构，也就是O(N)的时间级，但是对于哈希表来说，只是O(1)的时间级。</p>
<h1 id="哈希函数的引入"><a href="#哈希函数的引入" class="headerlink" title="哈希函数的引入"></a>哈希函数的引入</h1><p>hash表时一种根据关键字值（key-value）进行访问的数据结构。通过把关键字映射到数组的某个小标来加快查找速度。</p>
<p>映射的话，将关键字hash话。</p>
<p>我们知道 ASCII 是一种编码，其中 a 表示97，b表示98，以此类推，一直到122表示z，而每个单词都是由这26个字母组成，我们可以不用 ASCII 编码那么大的数字，自己设计一套类似 ASCII的编码，比如a表示1，b表示2，依次类推，z表示26，那么表示方法我们就知道了。</p>
<p>但是这个肯定数量范围不够，那么肯定有一个位置存储了多个单词，每个数组的数据项平均要存储192个单词，如果要查找一个但是还是很慢。</p>
<ol>
<li>第一种方法：考虑每个数组包含一个子数组或者一个子链表，这种存储数据很快，但是姚村192个单词中找到一个还是很慢。</li>
<li>第二种方法：为啥要让那么多单词占据同一个数据项呢？也就是我们没有把单词分得足够开，数组表示的元素太少，我们需要扩展数组的下标，是其中每个位置都只存放一个单词。</li>
</ol>
<p>arrayIndex = largerNumber % smallRange</p>
<p>它把一个大范围的数字哈希（转化）成一个小范围的数字，这个小范围的数对应着数组的下标。使用哈希函数向数组插入数据后，这个数组就是哈希表。</p>
<h1 id="冲突"><a href="#冲突" class="headerlink" title="冲突"></a>冲突</h1><p>把巨大的数字范围压缩到较小的数字范围，那么肯定会有几个不同的单词哈希化到同一个数组下标，即产生了冲突。</p>
<h2 id="开放地址法和链地址法"><a href="#开放地址法和链地址法" class="headerlink" title="开放地址法和链地址法"></a>开放地址法和链地址法</h2><p>冲突可能会导致哈希化方案无法实施，前面我们说指定的数组范围大小是实际存储数据的两倍，因此可能有一半的空间是空着的，所以，当冲突产生时，一个方法是通过系统的方法找到数组的一个空位，并把这个单词填入，而不再用哈希函数得到数组的下标，这种方法称为开放地址法。比如加入单词 cats 哈希化的结果为5421，但是它的位置已经被单词parsnip占用了，那么我们会考虑将单词 cats 存放在parsnip后面的一个位置 5422 上。</p>
<p>另一种方法，前面我们也提到过，就是数组的每个数据项都创建一个子链表或子数组，那么数组内不直接存放单词，当产生冲突时，新的数据项直接存放到这个数组下标表示的链表中，这种方法称为链地址法。</p>
<h2 id="开放地址法"><a href="#开放地址法" class="headerlink" title="开放地址法"></a>开放地址法</h2><p>开放地址法中，若数据项不能直接存放在由哈希函数所计算出来的数组下标时，就要寻找其他的位置。分别有三种方法：线性探测、二次探测以及再哈希法。</p>
<h3 id="线性探测"><a href="#线性探测" class="headerlink" title="线性探测"></a>线性探测</h3><p>在线性探测中，它会线性的查找空白单元。比如如果 5421 是要插入数据的位置，但是它已经被占用了，那么就使用5422，如果5422也被占用了，那么使用5423，以此类推，数组下标依次递增，直到找到空白的位置。这就叫做线性探测，因为它沿着数组下标一步一步顺序的查找空白单元。</p>
<p>需要注意的是，当哈希表变得太满时，我们需要扩展数组，但是需要注意的是，数据项不能放到新数组中和老数组相同的位置，而是要根据数组大小重新计算插入位置。这是一个比较耗时的过程，所以一般我们要确定数据的范围，给定好数组的大小，而不再扩容。</p>
<h3 id="装填因子"><a href="#装填因子" class="headerlink" title="装填因子"></a>装填因子</h3><p>已填入哈希表的数据项和表长的比率叫做装填因子，比如有10000个单元的哈希表填入了6667 个数据后，其装填因子为 2/3。当装填因子不太大时，聚集分布的比较连贯，而装填因子比较大时，则聚集发生的很大了。</p>
<h3 id="二次探测"><a href="#二次探测" class="headerlink" title="二次探测"></a>二次探测</h3><p>二测探测是防止聚集产生的一种方式，思想是探测相距较远的单元，而不是和原始位置相邻的单元。</p>
<p>线性探测中，如果哈希函数计算的原始下标是x, 线性探测就是x+1, x+2, x+3, 以此类推；而在二次探测中，探测的过程是x+1, x+4, x+9, x+16，以此类推，到原始位置的距离是步数的平方。</p>
<h3 id="再哈希法"><a href="#再哈希法" class="headerlink" title="再哈希法"></a>再哈希法</h3><p>我们知道二次聚集的原因是，二测探测的算法产生的探测序列步长总是固定的：1,4，9,16以此类推。那么我们想到的是需要产生一种依赖关键字的探测序列，而不是每个关键字都一样，那么，不同的关键字即使映射到相同的数组下标，也可以使用不同的探测序列。</p>
<h2 id="链地址法"><a href="#链地址法" class="headerlink" title="链地址法"></a>链地址法</h2><p>在开放地址法中，通过再哈希法寻找一个空位解决冲突问题，另一个方法是在哈希表每个单元中设置链表（即链地址法），某个数据项的关键字值还是像通常一样映射到哈希表的单元，而数据项本身插入到这个单元的链表中。其他同样映射到这个位置的数据项只需要加到链表中，不需要在原始的数组中寻找空位。</p>
<p><img src="/images/datastructure/%E9%93%BE%E5%9C%B0%E5%9D%80%E6%B3%95.png" alt="链地址法"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>哈希表基于数组，类似于key-value的存储形式，关键字值通过哈希函数映射为数组的下标，如果一个关键字哈希化到已占用的数组单元，这种情况称为冲突。用来解决冲突的有两种方法：开放地址法和链地址法。在开发地址法中，把冲突的数据项放在数组的其它位置；在链地址法中，每个单元都包含一个链表，把所有映射到同一数组下标的数据项都插入到这个链表中。</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>hash表</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法-堆</title>
    <url>/2019-04-14/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95-%E5%A0%86/</url>
    <content><![CDATA[<p>树包括二叉树、红黑树、2-3-4树、堆等各种不同的树</p>
<p>这里的堆是一种树，由它实现的优先级队列的插入和删除的时间复杂度都为O(logN)，这样尽管删除的时间变慢了，但是插入的时间快了很多，当速度非常重要，而且有很多插入操作时，可以选择用堆来实现优先级队列。</p>
<h1 id="堆的定义"><a href="#堆的定义" class="headerlink" title="堆的定义"></a>堆的定义</h1><p>1.它是完全二叉树，除了树的最后一层节点不需要是满的，其它的每一层从左到右都是满的。注意下面两种情况，第二种最后一层从左到右中间有断隔，那么也是不完全二叉树。</p>
<p><img src="/images/datastructure/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E5%92%8C%E9%9D%9E%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91.png" alt="完全二叉树和非完全二叉树"></p>
<p>2.它通常用数组来实现</p>
<p><img src="/images/datastructure/%E6%95%B0%E7%BB%84%E6%9D%A5%E5%AE%9E%E7%8E%B0%E4%BA%8C%E5%8F%89%E6%A0%91.png" alt="数组来实现二叉树"></p>
<p>这种用数组实现的二叉树，假设节点的索引值为index，那么：</p>
<ul>
<li><p>节点的左子节点是 2*index+1，</p>
</li>
<li><p>节点的右子节点是 2*index+2，</p>
</li>
<li><p>节点的父节点是 （index-1）/2。</p>
</li>
</ul>
<ol start="3">
<li>堆中的每一个节点的关键字都大于（或等于）这个节点的子节点的关键字。</li>
</ol>
<h2 id="二叉搜索树和堆的区别"><a href="#二叉搜索树和堆的区别" class="headerlink" title="二叉搜索树和堆的区别"></a>二叉搜索树和堆的区别</h2><p>这里要注意堆和前面说的二叉搜索树的区别，二叉搜索树中所有节点的左子节点关键字都小于右子节点关键字，在二叉搜索树中通过一个简单的算法就可以按序遍历节点。但是在堆中，按序遍历节点是很困难的，如上图所示，堆只有沿着从根节点到叶子节点的每一条路径是降序排列的，指定节点的左边节点或者右边节点，以及上层节点或者下层节点由于不在同一条路径上，他们的关键字可能比指定节点大或者小。所以相对于二叉搜索树，堆是弱序的。</p>
<h2 id="遍历和查找"><a href="#遍历和查找" class="headerlink" title="遍历和查找"></a>遍历和查找</h2><p>　前面我们说了，堆是弱序的，所以想要遍历堆是很困难的，基本上，堆是不支持遍历的。</p>
<p>对于查找，由于堆的特性，在查找的过程中，没有足够的信息来决定选择通过节点的两个子节点中的哪一个来选择走向下一层，所以也很难在堆中查找到某个关键字。</p>
<p>因此，堆这种组织似乎非常接近无序，不过，对于快速的移除最大（或最小）节点，也就是根节点，以及能快速插入新的节点，这两个操作就足够了。</p>
<h2 id="移除"><a href="#移除" class="headerlink" title="移除"></a>移除</h2><p>移除是指删除关键字最大的节点（或最小），也就是根节点。</p>
<p>　　根节点在数组中的索引总是0，即maxNode = heapArray[0];</p>
<p>　　移除根节点之后，那树就空了一个根节点，也就是数组有了一个空的数据单元，这个空单元我们必须填上。</p>
<p>　　第一种方法：将数组所有数据项都向前移动一个单元，这比较费时。</p>
<p>　　第二种方法：</p>
<p>　　　　①、移走根</p>
<p>　　　　②、把最后一个节点移动到根的位置</p>
<p>　　　　③、一直向下筛选这个节点，直到它在一个大于它的节点之下，小于它的节点之上为止。</p>
<p><img src="/images/datastructure/%E5%A0%86%E7%A7%BB%E9%99%A4%E6%9C%80%E5%A4%A7%E7%9A%84%E8%8A%82%E7%82%B9.png" alt="堆移除最大的节点"></p>
<h2 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h2><p>插入节点也很容易，插入时，选择向上筛选，节点初始时插入到数组最后第一个空着的单元，数组容量大小增一。然后进行向上筛选的算法。</p>
<p>注意：向上筛选和向下不同，向上筛选只用和一个父节点进行比较，比父节点小就停止筛选了。</p>
<p><img src="/images/datastructure/%E5%A0%86%E6%8F%92%E5%85%A5%E5%92%8C%E5%90%91%E4%B8%8A%E7%AD%9B%E9%80%89.png" alt="堆插入和向上筛选"></p>
]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>堆</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法1-简介</title>
    <url>/2019-02-23/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%951-%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>将一个班级的学生名字要临时存储在内存中，你会选择什么数据结构来存储，数组还是ArrayList，或者HashSet，或者别的数据结构。如果不懂数据结构的，可能随便选择一个容器来存储，也能完成所有的功能，但是后期如果随着学生数据量的增多，随便选择的数据结构肯定会存在性能问题，而一个懂数据结构和算法的人，在实际编程中会选择适当的数据结构来解决相应的问题，会极大的提高程序的性能。</p>
<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><p>数据结构是计算机存储、组织数据的方式，指相互之间存在一种或多种特定关系的数据元素的集合。</p>
<p>精心选择的数据结构可以带来更高的运行或者存储效率。数据结构往往同高效的检索算法和索引技术有关</p>
<h2 id="数据结构的基本功能"><a href="#数据结构的基本功能" class="headerlink" title="数据结构的基本功能"></a>数据结构的基本功能</h2><p>1.如何插入一条新的数据项<br>2.如何寻找某一特定的数据项<br>3.如何删除某一特定的数据项<br>4.如何迭代的访问各个数据项，以便进行显示或其他操作</p>
<h2 id="常见的数据结构"><a href="#常见的数据结构" class="headerlink" title="常见的数据结构"></a>常见的数据结构</h2><ul>
<li>数组 array</li>
<li>链表 linkedList</li>
<li>堆 heap</li>
<li>栈 stack</li>
<li>队列 queue</li>
<li>树 tree </li>
<li>哈希表 hash</li>
<li>图 graph</li>
</ul>
<p><img src="/images/datastructure/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9.png" alt="数据结构的优缺点"></p>
<h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><p>算法简单来说就是解决问题的步骤。</p>
<p>在Java中，算法通常都是由类的方法来实现的。前面的数据结构，比如链表为啥插入、删除快，而查找慢，平衡的二叉树插入、删除、查找都快，这都是实现这些数据结构的算法所造成的。后面我们讲的各种排序实现也是算法范畴的重要领域。</p>
<h2 id="算法的五个特征"><a href="#算法的五个特征" class="headerlink" title="算法的五个特征"></a>算法的五个特征</h2><ul>
<li><p>有穷性：对于任意一组合法输入值，在执行有穷步骤之后一定能结束，即：算法中的每个步骤都能在有限时间内完成。</p>
</li>
<li><p>确定性：在每种情况下所应执行的操作，在算法中都有确切的规定，使算法的执行者或阅读者都能明确其含义及如何执行。并且在任何条件下，算法都只有一条执行路径。</p>
</li>
<li><p>可行性：算法中的所有操作都必须足够基本，都可以通过已经实现的基本操作运算有限次实现之。</p>
</li>
<li><p>有输入：作为算法加工对象的量值，通常体现在算法当中的一组变量。有些输入量需要在算法执行的过程中输入，而有的算法表面上可以没有输入，实际上已被嵌入算法之中。</p>
</li>
<li><p>有输出：它是一组与“输入”有确定关系的量值，是算法进行信息加工后得到的结果，这种确定关系即为算法功能。</p>
</li>
</ul>
<h2 id="算法的设计原则"><a href="#算法的设计原则" class="headerlink" title="算法的设计原则"></a>算法的设计原则</h2><ul>
<li><p>正确性：程序无语法错误。程序对于精心选择的、典型、苛刻切带有刁难性的几组输入数据能够得出满足要求的结果。</p>
</li>
<li><p>可读性：算法为了人的阅读与交流，其次才是计算机执行。因此算法应该易于人的理解；另一方面，晦涩难懂的程序易于隐藏较多的错误而难以调试。</p>
</li>
<li><p>健壮性：当输入的数据非法时，算法应当恰当的做出反应或进行相应处理，而不是产生莫名其妙的输出结果。并且，处理出错的方法不应是中断程序执行，而是应当返回一个表示错误或错误性质的值，以便在更高的抽象层次上进行处理。</p>
</li>
<li><p>高效率与低存储量需求：通常算法效率值得是算法执行时间；存储量是指算法执行过程中所需要的最大存储空间，两者都与问题的规模有关。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>数据结构简介</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法10-树</title>
    <url>/2019-03-26/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%9510-%E6%A0%91/</url>
    <content><![CDATA[<p>前面我们介绍数组的数据结构，我们知道对于有序数组，查找很快，并介绍可以通过二分法查找，但是想要在有序数组中插入一个数据项，就必须先找到插入数据项的位置，然后将所有插入位置后面的数据项全部向后移动一位，来给新数据腾出空间，平均来讲要移动N/2次，这是很费时的。同理，删除数据也是。</p>
<p>然后我们介绍了另外一种数据结构——链表，链表的插入和删除很快，我们只需要改变一些引用值就行了，但是查找数据却很慢了，因为不管我们查找什么数据，都需要从链表的第一个数据项开始，遍历到找到所需数据项为止，这个查找也是平均需要比较N/2次。</p>
<p>那么我们就希望一种数据结构能同时具备数组查找快的优点以及链表插入和删除快的优点，于是 树 诞生了。</p>
<h1 id="树的概念"><a href="#树的概念" class="headerlink" title="树的概念"></a>树的概念</h1><p><img src="/images/datastructure/%E6%A0%91.png" alt="树"></p>
<p>①、路径：顺着节点的边从一个节点走到另一个节点，所经过的节点的顺序排列就称为“路径”。</p>
<p>②、根：树顶端的节点称为根。一棵树只有一个根，如果要把一个节点和边的集合称为树，那么从根到其他任何一个节点都必须有且只有一条路径。A是根节点。</p>
<p>③、父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点；B是D的父节点。</p>
<p>④、子节点：一个节点含有的子树的根节点称为该节点的子节点；D是B的子节点。</p>
<p>⑤、兄弟节点：具有相同父节点的节点互称为兄弟节点；比如上图的D和E就互称为兄弟节点。</p>
<p>⑥、叶节点：没有子节点的节点称为叶节点，也叫叶子节点，比如上图的H、E、F、G都是叶子节点。</p>
<p>⑦、子树：每个节点都可以作为子树的根，它和它所有的子节点、子节点的子节点等都包含在子树中。</p>
<p>⑧、节点的层次：从根开始定义，根为第一层，根的子节点为第二层，以此类推。</p>
<p>⑨、深度：对于任意节点n,n的深度为从根到n的唯一路径长，根的深度为0；</p>
<p>⑩、高度：对于任意节点n,n的高度为从n到一片树叶的最长路径长，所有树叶的高度为0；</p>
<h1 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h1><p>二叉树：树的每个节点最多只能有两个子节点。</p>
<p>二叉搜索树(binary search tree)：若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树。</p>
<p>树的效率：查找节点的时间取决于这个节点所在的层数，每一层最多有2n-1个节点，总共N层共有2n-1个节点，那么时间复杂度为O(logn),底数为2。</p>
<h2 id="查找节点"><a href="#查找节点" class="headerlink" title="查找节点"></a>查找节点</h2><p>查找某个节点，我们必须从根节点开始遍历。</p>
<p>①、查找值比当前节点值大，则搜索右子树；</p>
<p>②、查找值等于当前节点值，停止搜索（终止条件）；</p>
<p>③、查找值小于当前节点值，则搜索左子树；</p>
<h2 id="插入节点"><a href="#插入节点" class="headerlink" title="插入节点"></a>插入节点</h2><p> 要插入节点，必须先找到插入的位置。与查找操作相似，由于二叉搜索树的特殊性，待插入的节点也需要从根节点开始进行比较，小于根节点则与根节点左子树比较，反之则与右子树比较，直到左子树为空或右子树为空，则插入到相应为空的位置，在比较的过程中要注意保存父节点的信息<br> 及 待插入的位置是父节点的左子树还是右子树，才能插入到正确的位置。</p>
<h2 id="遍历树"><a href="#遍历树" class="headerlink" title="遍历树"></a>遍历树</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">①、中序遍历:左子树——》根节点——》右子树 （根节点在中间）</span><br><span class="line">②、前序遍历:根节点——》左子树——》右子树 （根节点在前边）</span><br><span class="line">③、后序遍历:左子树——》右子树——》根节点 （根节点在后边）</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/images/datastructure/%E9%81%8D%E5%8E%86%E6%A0%91.png" alt="遍历树"></p>
<h2 id="用数组表示树"><a href="#用数组表示树" class="headerlink" title="用数组表示树"></a>用数组表示树</h2><p>用数组表示树，那么节点是存在数组中的，节点在数组中的位置对应于它在树中的位置。下标为 0 的节点是根，下标为 1 的节点是根的左子节点，以此类推，按照从左到右的顺序存储树的每一层。</p>
<p><img src="/images/datastructure/%E7%94%A8%E6%95%B0%E7%BB%84%E8%A1%A8%E7%A4%BA%E6%A0%91.png" alt="用数组表示树"></p>
<p>在大多数情况下，使用数组表示树效率是很低的，不满的节点和删除掉的节点都会在数组中留下洞，浪费存储空间。更坏的是，删除节点如果要移动子树的话，子树中的每个节点都要移到数组中新的位置，这是很费时的。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>树是由边和节点构成，根节点是树最顶端的节点，它没有父节点；二叉树中，最多有两个子节点；某个节点的左子树每个节点都比该节点的关键字值小，右子树的每个节点都比该节点的关键字值大，那么这种树称为二叉搜索树，其查找、插入、删除的时间复杂度都为logN；可以通过前序遍历、中序遍历、后序遍历来遍历树，前序是根节点-左子树-右子树，中序是左子树-根节点-右子树，后序是左子树-右子树-根节点；删除一个节点只需要断开指向它的引用即可；哈夫曼树是二叉树，用于数据压缩算法，最经常出现的字符编码位数最少，很少出现的字符编码位数多一些。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.algorithm.tree;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 二叉树搜索树</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-04-08 11:22 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class BinaryTree implements Tree &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private Node root;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Node find(int key) &#123;</span><br><span class="line"></span><br><span class="line">        Node current &#x3D; root;</span><br><span class="line"></span><br><span class="line">        while (current !&#x3D; null) &#123;</span><br><span class="line">            &#x2F;&#x2F;当前值比查找值大，搜索左子树</span><br><span class="line">            if (current.data &gt; key) &#123;</span><br><span class="line">                current &#x3D; current.leftNode;</span><br><span class="line">                &#x2F;&#x2F;当前值比查找值小，搜索右子树</span><br><span class="line">            &#125; else if (current.data &lt; key) &#123;</span><br><span class="line">                current &#x3D; current.rightNode;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                return current;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return null;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public boolean insert(int data) &#123;</span><br><span class="line"></span><br><span class="line">        Node newNode &#x3D; new Node(data);</span><br><span class="line">        &#x2F;&#x2F;当前树为空树，没有任何节点</span><br><span class="line">        if (root &#x3D;&#x3D; null) &#123;</span><br><span class="line">            root &#x3D; newNode;</span><br><span class="line">            return true;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            Node current &#x3D; root;</span><br><span class="line">            Node parentNode &#x3D; null;</span><br><span class="line"></span><br><span class="line">            while (current !&#x3D; null) &#123;</span><br><span class="line">                parentNode &#x3D; current;</span><br><span class="line">                &#x2F;&#x2F;当前值比插入值大，搜索左子节点</span><br><span class="line">                if (current.data &gt; data) &#123;</span><br><span class="line">                    current &#x3D; current.leftNode;</span><br><span class="line">                    &#x2F;&#x2F;左子节点为空，直接将新值插入到该节点</span><br><span class="line">                    if (current &#x3D;&#x3D; null) &#123;</span><br><span class="line">                        parentNode.leftNode &#x3D; newNode;</span><br><span class="line">                        return true;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    current &#x3D; current.rightNode;</span><br><span class="line">                    if (current &#x3D;&#x3D; null) &#123;</span><br><span class="line">                        parentNode.rightNode &#x3D; newNode;</span><br><span class="line">                        return true;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public boolean delete(int key) &#123;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 中序遍历</span><br><span class="line">     *</span><br><span class="line">     * @param current</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public void infixOrder(Node current) &#123;</span><br><span class="line"></span><br><span class="line">        if (current !&#x3D; null) &#123;</span><br><span class="line">            infixOrder(current.leftNode);</span><br><span class="line">            System.out.println(current.data + &quot; &quot;);</span><br><span class="line">            infixOrder(current.rightNode);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 前序遍历</span><br><span class="line">     *</span><br><span class="line">     * @param current</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public void preOrder(Node current) &#123;</span><br><span class="line">        if (current !&#x3D; null) &#123;</span><br><span class="line">            System.out.println(current.data + &quot; &quot;);</span><br><span class="line">            preOrder(current.leftNode);</span><br><span class="line">            preOrder(current.rightNode);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 后序遍历</span><br><span class="line">     *</span><br><span class="line">     * @param current</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public void postOrder(Node current) &#123;</span><br><span class="line"></span><br><span class="line">        if (current !&#x3D; null) &#123;</span><br><span class="line">            postOrder(current.leftNode);</span><br><span class="line">            postOrder(current.rightNode);</span><br><span class="line">            System.out.println(current.data + &quot; &quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 找到最大的节点</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public Node findMax() &#123;</span><br><span class="line">        Node current &#x3D; root;</span><br><span class="line">        Node maxNode &#x3D; current;</span><br><span class="line">        while (current !&#x3D; null) &#123;</span><br><span class="line">            maxNode &#x3D; current;</span><br><span class="line">            current &#x3D; current.rightNode;</span><br><span class="line">        &#125;</span><br><span class="line">        return maxNode;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 查找最小节点</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public Node finMin() &#123;</span><br><span class="line">        Node current &#x3D; root;</span><br><span class="line">        Node minNode &#x3D; current;</span><br><span class="line">        while (current !&#x3D; null) &#123;</span><br><span class="line">            minNode &#x3D; current;</span><br><span class="line">            current &#x3D; current.leftNode;</span><br><span class="line">        &#125;</span><br><span class="line">        return minNode;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Node getRoot() &#123;</span><br><span class="line">        return root;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setRoot(Node root) &#123;</span><br><span class="line">        this.root &#x3D; root;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        BinaryTree bt &#x3D; new BinaryTree();</span><br><span class="line">        bt.insert(50);</span><br><span class="line">        bt.insert(20);</span><br><span class="line">        bt.insert(80);</span><br><span class="line">        bt.insert(10);</span><br><span class="line">        bt.insert(30);</span><br><span class="line">        bt.insert(60);</span><br><span class="line">        bt.insert(90);</span><br><span class="line">        bt.insert(25);</span><br><span class="line">        bt.insert(85);</span><br><span class="line">        bt.insert(100);</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;infixOrder:&quot;);</span><br><span class="line">        bt.infixOrder(bt.root);</span><br><span class="line">        System.out.println(&quot;preOrder:&quot;);</span><br><span class="line">        bt.preOrder(bt.root);</span><br><span class="line">        System.out.println(&quot;postOrder:&quot;);</span><br><span class="line">        bt.postOrder(bt.root);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;max:&quot; + bt.findMax().data);</span><br><span class="line">        System.out.println(&quot;min:&quot; + bt.finMin().data);</span><br><span class="line">        System.out.println(bt.find(100));</span><br><span class="line">        System.out.println(bt.find(200));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://www.cnblogs.com/ysocean/p/8032642.html">参考资料</a></p>
]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法11-红黑树</title>
    <url>/2019-04-09/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%9511-%E7%BA%A2%E9%BB%91%E6%A0%91/</url>
    <content><![CDATA[<p>二叉搜索树对于某个节点而言，其左子树的节点的关键值都小于该节点的关键值，右子树的所有节点的关键值都大于该节点的关键值。二叉搜索树作为一种数据结构，</p>
<p>增删改查的时间复杂度都是log以2为底n的对数，但是这个复杂度都是爱平衡的二叉搜索树上提现的，也就是如果插入的数据是随机的，则效率很高，但是如果是有序的从下到大的则，树为全部在右边。</p>
<p><img src="/images/datastructure/%E5%81%8F%E5%90%91%E7%9A%84%E6%A0%91.png" alt="偏向的树"></p>
<p>从小到大的都在右边，则这链表没有区别了。时间复杂度是o(n)。所示时间复杂度是在log以2为底n的对数和o(n)</p>
<h1 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h1><p>那么为了能够以较快的时间O(logN)来搜索一棵树，我们需要保证树总是平衡的（或者大部分是平衡的），也就是说每个节点的左子树节点个数和右子树节点个数尽量相等。红-黑树的就是这样的一棵平衡树</p>
<p>对一个要插入的数据项（删除也是），插入例程要检查会不会破坏树的特征，如果破坏了，程序就会进行纠正，根据需要改变树的结构，从而保持树的平衡。</p>
<h2 id="红黑树的特征"><a href="#红黑树的特征" class="headerlink" title="红黑树的特征"></a>红黑树的特征</h2><p>有两个特征</p>
<ol>
<li>节点都有颜色；</li>
<li>在插入和删除的过程中，要遵循保持这些颜色的不同排列规则；</li>
</ol>
<p>第一个很好理解，在红-黑树中，每个节点的颜色或者是黑色或者是红色的。当然也可以是任意别的两种颜色，这里的颜色用于标记，我们可以在节点类Node中增加一个boolean型变量isRed，以此来表示颜色的信息。</p>
<p>第二点，在插入或者删除一个节点时，必须要遵守的规则称为红-黑规则：<br>1.每个节点不是红色就是黑色的；<br>2.根节点总是黑色的；<br>3.如果节点是红色的，则它的子节点必须是黑色的（反之不一定）,(也就是从每个叶子到根的所有路径上不能有两个连续的红色节点)；<br>4.从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。</p>
<p>新插入的节点颜色总是红色的，</p>
<p>这是因为插入一个红色节点比插入一个黑色节点违背红-黑规则的可能性更小，原因是插入黑色节点总会改变黑色高度（违背规则4），但是插入红色节点只有一半的机会会违背规则3（因为父节点是黑色的没事，父节点是红色的就违背规则3）。</p>
<p>另外违背规则3比违背规则4要更容易修正。当插入一个新的节点时，可能会破坏这种平衡性，那么红-黑树是如何修正的呢？</p>
<h2 id="红黑树的自我修正"><a href="#红黑树的自我修正" class="headerlink" title="红黑树的自我修正"></a>红黑树的自我修正</h2><p>红-黑树主要通过三种方式对平衡进行修正，改变节点颜色、左旋和右旋。</p>
<h3 id="改变节点颜色"><a href="#改变节点颜色" class="headerlink" title="改变节点颜色"></a>改变节点颜色</h3><p>新插入的节点为15，一般新插入颜色都为红色，那么我们发现直接插入会违反规则3，改为黑色却发现违反规则4。这时候我们将其父节点颜色改为黑色，父节点的兄弟节点颜色也改为黑色。通常其祖父节点50颜色会由黑色变为红色，但是由于50是根节点，所以我们这里不能改变根节点颜色。</p>
<p><img src="/images/datastructure/%E6%94%B9%E5%8F%98%E8%8A%82%E7%82%B9%E9%A2%9C%E8%89%B2.png" alt="改变节点颜色"></p>
<h3 id="右旋"><a href="#右旋" class="headerlink" title="右旋"></a>右旋</h3><p>首先要说明的是节点本身是不会旋转的，旋转改变的是节点之间的关系，选择一个节点作为旋转的顶端，如果做一次右旋，这个顶端节点会向下和向右移动到它右子节点的位置，它的左子节点会上移到它原来的位置。右旋的顶端节点必须要有左子节点。</p>
<p><img src="/images/datastructure/%E5%8F%B3%E6%97%8B.png" alt="右旋"></p>
<h3 id="左旋"><a href="#左旋" class="headerlink" title="左旋"></a>左旋</h3><p>左旋的顶端节点必须要有右子节点。</p>
<p><img src="/images/datastructure/%E5%B7%A6%E6%97%8B.png" alt="左旋"></p>
<p>我们改变颜色也是为了帮助我们判断何时执行什么旋转，而旋转是为了保证树的平衡。光改变节点颜色是不能起到任何作用的，旋转才是关键的操作，在新增节点或者删除节点之后，可能会破坏二叉树的平衡，那么何时执行旋转以及执行什么旋转，这是我们需要重点关注的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.algorithm.tree.rbtree;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 红黑树节点类</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * 节点类和二叉树的节点类差不多，只不过在其基础上增加了一个 boolean 类型的变量来表示节点的颜色</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-04-10 12:18 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class RBNode&lt;T extends Comparable&lt;T&gt;&gt; &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 颜色</span><br><span class="line">     *&#x2F;</span><br><span class="line">    boolean color;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 关键值</span><br><span class="line">     *&#x2F;</span><br><span class="line">    T key;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 左子节点</span><br><span class="line">     *&#x2F;</span><br><span class="line">    RBNode&lt;T&gt; left;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 右子节点</span><br><span class="line">     *&#x2F;</span><br><span class="line">    RBNode&lt;T&gt; right;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 父节点</span><br><span class="line">     *&#x2F;</span><br><span class="line">    RBNode&lt;T&gt; parent;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    RBNode&lt;T&gt; root;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public RBNode(boolean color, T key, RBNode&lt;T&gt; left, RBNode&lt;T&gt; right, RBNode&lt;T&gt; parent) &#123;</span><br><span class="line">        this.color &#x3D; color;</span><br><span class="line">        this.key &#x3D; key;</span><br><span class="line">        this.left &#x3D; left;</span><br><span class="line">        this.right &#x3D; right;</span><br><span class="line">        this.parent &#x3D; parent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取节点的关键值</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public T getKey() &#123;</span><br><span class="line">        return key;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 打印节点的关键值和颜色信息</span><br><span class="line">     *&#x2F;</span><br><span class="line">    @Override</span><br><span class="line">    public String toString() &#123;</span><br><span class="line">        return &quot;&quot; + key + (this.color ? &quot;R&quot; : &quot;B&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;*************对红黑树节点x进行左旋操作 ******************&#x2F;</span><br><span class="line"></span><br><span class="line">    &#x2F;***</span><br><span class="line">     *</span><br><span class="line">     * 左旋示意图：对节点x进行左旋</span><br><span class="line">     *     p                       p</span><br><span class="line">     *    &#x2F;                       &#x2F;</span><br><span class="line">     *   x                       y</span><br><span class="line">     *  &#x2F; \                     &#x2F; \</span><br><span class="line">     * lx  y      -----&gt;       x  ry</span><br><span class="line">     *    &#x2F; \                 &#x2F; \</span><br><span class="line">     *   ly ry               lx ly</span><br><span class="line">     *</span><br><span class="line">     * 左旋做了三件事：</span><br><span class="line">     * 1. 将y的左子节点赋给x的右子节点,并将x赋给y左子节点的父节点(y左子节点非空时)</span><br><span class="line">     * 2. 将x的父节点p(非空时)赋给y的父节点，同时更新p的子节点为y(左或右)</span><br><span class="line">     * 3. 将y的左子节点设为x，将x的父节点设为y</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private void leftRotate(RBNode&lt;T&gt; x) &#123;</span><br><span class="line">        &#x2F;&#x2F;1. 将y的左子节点赋给x的右子节点，并将x赋给y左子节点的父节点(y左子节点非空时)</span><br><span class="line">        RBNode&lt;T&gt; y &#x3D; x.right;</span><br><span class="line"></span><br><span class="line">        x.right &#x3D; y.left;</span><br><span class="line">        if (y.left !&#x3D; null) &#123;</span><br><span class="line">            y.left.parent &#x3D; x;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;2. 将x的父节点p(非空时)赋给y的父节点，同时更新p的子节点为y(左或右)</span><br><span class="line">        y.parent &#x3D; x.parent;</span><br><span class="line">        if (x.parent &#x3D;&#x3D; null) &#123;</span><br><span class="line">            this.root &#x3D; y;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            if (x &#x3D;&#x3D; x.parent.left) &#123;</span><br><span class="line">                x.parent.left &#x3D; y;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                x.parent.right &#x3D; y;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 3. 将y的左子节点设为x，将x的父节点设为y</span><br><span class="line">        y.left &#x3D; x;</span><br><span class="line">        x.parent &#x3D; y;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;*************对红黑树节点y进行右旋操作 ******************&#x2F;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 左旋示意图：对节点y进行右旋</span><br><span class="line">     * p                   p</span><br><span class="line">     * &#x2F;                   &#x2F;</span><br><span class="line">     * y                   x</span><br><span class="line">     * &#x2F; \                 &#x2F; \</span><br><span class="line">     * x  ry   -----&gt;      lx  y</span><br><span class="line">     * &#x2F; \                     &#x2F; \</span><br><span class="line">     * lx  rx                   rx ry</span><br><span class="line">     * 右旋做了三件事：</span><br><span class="line">     * 1. 将x的右子节点赋给y的左子节点,并将y赋给x右子节点的父节点(x右子节点非空时)</span><br><span class="line">     * 2. 将y的父节点p(非空时)赋给x的父节点，同时更新p的子节点为x(左或右)</span><br><span class="line">     * 3. 将x的右子节点设为y，将y的父节点设为x</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private void rightRotate(RBNode&lt;T&gt; y) &#123;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;1. 将y的左子节点赋给x的右子节点，并将y赋给x右子节点的父节点(x右子节点非空时)</span><br><span class="line">        RBNode&lt;T&gt; x &#x3D; y.left;</span><br><span class="line">        y.left &#x3D; x.right;</span><br><span class="line">        if (x.right !&#x3D; null) &#123;</span><br><span class="line">            x.right.parent &#x3D; y;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;2. 将x的父节点p(非空时)赋给y的父节点，同时更新p的子节点为y(左或右)</span><br><span class="line">        x.parent &#x3D; y.parent;</span><br><span class="line"></span><br><span class="line">        if (y.parent &#x3D;&#x3D; null) &#123;</span><br><span class="line">            &#x2F;&#x2F;如果y的父节点为空(即y为根节点)，则旋转后将x设为根节点</span><br><span class="line">            this.root &#x3D; x;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            if (y &#x3D;&#x3D; y.parent.left) &#123;</span><br><span class="line">                &#x2F;&#x2F;则将x也设置为左子节点</span><br><span class="line">                y.parent.left &#x3D; x;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                &#x2F;&#x2F;否则将x设置为右子节点</span><br><span class="line">                y.parent.right &#x3D; x;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;3. 将x的左子节点设为y，将y的父节点设为y</span><br><span class="line">        x.right &#x3D; y;</span><br><span class="line">        y.parent &#x3D; x;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="插入操作"><a href="#插入操作" class="headerlink" title="插入操作"></a>插入操作</h3><p>这与二叉搜索树中实现的思路一样，这里不再赘述，主要看看方法里面最后一步insertFixUp(node)操作。因为插入后可能会导致树的不平衡，insertFixUp(node) 方法里主要是分情况讨论，分析何时变色，何时左旋，何时右旋。我们先从理论上分析具体的情况，然后再看insertFixUp(node) 的具体实现。</p>
<p>　　如果是第一次插入，由于原树为空，所以只会违反红-黑树的规则2，所以只要把根节点涂黑即可；如果插入节点的父节点是黑色的，那不会违背红-黑树的规则，什么也不需要做；但是遇到如下三种情况，我们就要开始变色和旋转了：</p>
<p>　　①、插入节点的父节点和其叔叔节点（祖父节点的另一个子节点）均为红色。</p>
<p>　　②、插入节点的父节点是红色的，叔叔节点是黑色的，且插入节点是其父节点的右子节点。</p>
<p>　　③、插入节点的父节点是红色的，叔叔节点是黑色的，且插入节点是其父节点的左子节点。</p>
<p>　　下面我们挨个分析这三种情况都需要如何操作，然后给出实现代码。</p>
<p>　　在下面的讨论中，使用N,P,G,U表示关联的节点。N(now)表示当前节点，P(parent)表示N的父节点，U(uncle)表示N的叔叔节点，G(grandfather)表示N的祖父节点，也就是P和U的父节点。</p>
<p>由于插入过程和删除过程比较复杂就不做分析。。。</p>
<h3 id="红黑树的效率"><a href="#红黑树的效率" class="headerlink" title="红黑树的效率"></a>红黑树的效率</h3><p>红黑树的查找、插入和删除时间复杂度都为O(log2N)，额外的开销是每个节点的存储空间都稍微增加了一点，因为一个存储红黑树节点的颜色变量。插入和删除的时间要增加一个常数因子，因为要进行旋转，平均一次插入大约需要一次旋转，因此插入的时间复杂度还是O(log2N),(时间复杂度的计算要省略常数)，但实际上比普通的二叉树是要慢的。</p>
<p>大多数应用中，查找的次数比插入和删除的次数多，所以应用红黑树取代普通的二叉搜索树总体上不会有太多的时间开销。而且红黑树的优点是对于有序数据的操作不会慢到O(N)的时间复杂度。</p>
<p><a href="https://www.cnblogs.com/ysocean/p/8004211.html">参考</a></p>
]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法2-数组</title>
    <url>/2019-02-26/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%952-%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<h1 id="java数组介绍"><a href="#java数组介绍" class="headerlink" title="java数组介绍"></a>java数组介绍</h1><p>在Java中，数组是用来存放同一种数据类型的集合，注意只能存放同一种数据类型(Object类型数组除外)</p>
<h2 id="数组的声明"><a href="#数组的声明" class="headerlink" title="数组的声明"></a>数组的声明</h2><p>数据类型[] 数组名称 = new 数据类型[数组长度];</p>
<p>数据类型[] 数组名称 = {数组元素1，数组元素2，数组元素3…..}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;声明数组1,声明一个长度为3，只能存放int类型的数据</span><br><span class="line">int [] myArray &#x3D; new int[3];</span><br><span class="line">&#x2F;&#x2F;声明数组2,声明一个数组元素为 1,2,3的int类型数组</span><br><span class="line">int [] myArray2 &#x3D; &#123;1,2,3&#125;;</span><br></pre></td></tr></table></figure>

<p>数组的下标从0开始，但是length属性记录的是数组的长度。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;声明数组2,声明一个数组元素为 1,2,3的int类型数组，记着不是myArray2.length-1</span><br><span class="line">int [] myArray2 &#x3D; &#123;1,2,3&#125;;</span><br><span class="line">for(int i &#x3D; 0 ; i &lt; myArray2.length ; i++)&#123;</span><br><span class="line">    System.out.println(myArray2[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.dataStructure;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-02-26 10:57 PM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyArray &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;实现 增、删、查、迭代功能</span><br><span class="line"></span><br><span class="line">    private int [] intArray;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 数组的元素的个数</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int elems;</span><br><span class="line"></span><br><span class="line">    private int length;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 构造一个长度为50的数组</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public MyArray() &#123;</span><br><span class="line">        elems &#x3D; 0;</span><br><span class="line">        length &#x3D; 50;</span><br><span class="line">        intArray &#x3D; new int[length];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取数组的有效长度</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public int getSize()&#123;</span><br><span class="line">        return elems;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 遍历数组</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public void display() &#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; elems; i++) &#123;</span><br><span class="line">            System.out.println(intArray[i] + &quot; &quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 数组中添加元素</span><br><span class="line">     *</span><br><span class="line">     * @param value</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean add(int value) &#123;</span><br><span class="line"></span><br><span class="line">        if (length &#x3D;&#x3D; elems) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            intArray[elems] &#x3D; value;</span><br><span class="line">            elems++;</span><br><span class="line">        &#125;</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 根据下标获取元素</span><br><span class="line">     * @param i</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public int getElems(int i) &#123;</span><br><span class="line"></span><br><span class="line">        if (i &lt; 0 || i &gt; elems) &#123;</span><br><span class="line">            System.out.println(&quot;数组下标越界&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        return intArray[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 查找元素 查找的元素如果存在则返回下标值，如果不存在，返回 -1</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public int find(int value) &#123;</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; elems; i++) &#123;</span><br><span class="line">            if (value &#x3D;&#x3D; intArray[i]) &#123;</span><br><span class="line">                return i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 如果要删除的值不存在，直接返回 false;否则返回true，删除成功</span><br><span class="line">     *</span><br><span class="line">     * @param value</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean delete(int value) &#123;</span><br><span class="line"></span><br><span class="line">        int k &#x3D; find(value);</span><br><span class="line">        if (k &#x3D;&#x3D; -1) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            if (k &#x3D;&#x3D; elems - 1) &#123;</span><br><span class="line">                elems--;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                for (int i &#x3D; 0; i &lt; elems - 1; i++) &#123;</span><br><span class="line">                    intArray[elems] &#x3D; intArray[elems + 1];</span><br><span class="line">                &#125;</span><br><span class="line">                elems--;</span><br><span class="line">            &#125;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 修改成功返回true，修改失败返回false</span><br><span class="line">     *</span><br><span class="line">     * @param oldValue</span><br><span class="line">     * @param newValue</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean modify(int oldValue, int newValue) &#123;</span><br><span class="line">        int i &#x3D; find(oldValue);</span><br><span class="line">        if (i &#x3D;&#x3D; -1) &#123;</span><br><span class="line">            System.out.println(&quot;需要修改的数据不存在&quot;);</span><br><span class="line">            return false;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            intArray[i] &#x3D; newValue;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        MyArray myArray &#x3D; new MyArray();</span><br><span class="line">        myArray.add(1);</span><br><span class="line">        myArray.add(12);</span><br><span class="line">        myArray.add(13);</span><br><span class="line">        myArray.add(14);</span><br><span class="line">        myArray.add(15);</span><br><span class="line"></span><br><span class="line">        myArray.display();</span><br><span class="line">        System.out.println(&quot;find 12:&quot; + myArray.find(12));</span><br><span class="line">        System.out.println(&quot;find 10:&quot; + myArray.find(10));</span><br><span class="line">        myArray.delete(10);</span><br><span class="line">        System.out.println(&quot;get i&#x3D;2 :&quot; + myArray.getElems(2));</span><br><span class="line">        System.out.println(&quot;size:&quot; + myArray.getSize());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="数组的局限性"><a href="#数组的局限性" class="headerlink" title="数组的局限性"></a>数组的局限性</h1><p>1.插入快，对于无序数组，上面我们实现的数组就是无序的，即元素没有按照从大到小或者某个特定的顺序排列，只是按照插入的顺序排列。无序数组增加一个元素很简单，只需要在数组末尾添加元素即可，但是有序数组却不一定了，它需要在指定的位置插入<br>2.查找慢，当然如果根据下标来查找是很快的。但是通常我们都是根据元素值来查找，给定一个元素值，对于无序数组，我们需要从数组第一个元素开始遍历，直到找到那个元素。有序数组通过特定的算法查找的速度会比无需数组快，后面我们会讲各种排序算法。<br>3.删除慢，根据元素值删除，我们要先找到该元素所处的位置，然后将元素后面的值整体向前面移动一个位置。也需要比较多的时间。<br>4.数组一旦创建后，大小就固定了，不能动态扩展数组的元素个数。如果初始化你给一个很大的数组大小，那会白白浪费内存空间，如果给小了，后面数据个数增加了又添加不进去了。</p>
]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法3-冒泡、选择、插入排序算法</title>
    <url>/2019-02-26/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%953-%E5%86%92%E6%B3%A1%E3%80%81%E9%80%89%E6%8B%A9%E3%80%81%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h1><p>实现步骤如下：</p>
<p>1.比较相邻的元素。如果第一个比第二个大，就交换他们两个；<br>2.对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数（也就是第一波冒泡完成）；<br>3.针对所有的元素重复以上的步骤，除了最后一个；<br>4.持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。</p>
<p><img src="/images/datastructure/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F.png" alt="冒泡排序"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.algorithm.sort;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-02-26 11:29 PM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class BubbleSort2 &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static int[] sort(int[] intArray) &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        if (intArray.length &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            return new int[0];</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;这里for循环表示总共需要比较多少轮</span><br><span class="line">        for (int i &#x3D; 0; i &lt; intArray.length; i++) &#123;</span><br><span class="line">            &#x2F;&#x2F;这里for循环表示每轮比较参与的元素下标</span><br><span class="line">            for (int j &#x3D; 1; j &lt; intArray.length; j++) &#123;</span><br><span class="line">                if (intArray[j - 1] &gt; intArray[j]) &#123;</span><br><span class="line">                    int temp;</span><br><span class="line">                    temp &#x3D; intArray[j - 1];</span><br><span class="line">                    intArray[j - 1] &#x3D; intArray[j];</span><br><span class="line">                    intArray[j] &#x3D; temp;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(&quot;第&quot; + i + &quot;次排序完为:&quot;);</span><br><span class="line">            display(intArray);</span><br><span class="line">        &#125;</span><br><span class="line">        return intArray;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;&#x2F; 遍历显示数组</span><br><span class="line">    public static void display(int[] array) &#123;</span><br><span class="line">        for (int anArray : array) &#123;</span><br><span class="line">            System.out.print(anArray + &quot; &quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int[] array &#x3D; &#123;3, 0, 1, 90, 2, -1, 4&#125;;</span><br><span class="line">        sort(array);</span><br><span class="line">        System.out.println(&quot;最后的结果为：&quot;);</span><br><span class="line">        display(array);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="冒泡排序解释"><a href="#冒泡排序解释" class="headerlink" title="冒泡排序解释"></a>冒泡排序解释</h2><p>冒泡排序是由两个for循环构成，第一个for循环的变量 i 表示总共需要多少轮比较，第二个for循环的变量 j 表示每轮参与比较的元素下标【0,1，……，length-i】，因为每轮比较都会出现一个最大值放在最右边，所以每轮比较后的元素个数都会少一个，</p>
<p>这也是为什么 j 的范围是逐渐减小的。相信大家理解之后快速写出一个冒泡排序并不难。</p>
<h2 id="冒泡排序性能分析"><a href="#冒泡排序性能分析" class="headerlink" title="冒泡排序性能分析"></a>冒泡排序性能分析</h2><p>假设参与比较的数组元素个数为 N，则第一轮排序有 N-1 次比较，第二轮有 N-2 次，如此类推，这种序列的求和公式为：</p>
<p>（N-1）+（N-2）+…+1 = N*（N-1）/2</p>
<p>当 N 的值很大时，算法比较次数约为 N2/2次比较，忽略减1。</p>
<p>假设数据是随机的，那么每次比较可能要交换位置，可能不会交换，假设概率为50%，那么交换次数为 N2/4。不过如果是最坏的情况，初始数据是逆序的，那么每次比较都要交换位置。</p>
<p>交换和比较次数都和N2 成正比。由于常数不算大 O 表示法中，忽略 2 和 4，那么冒泡排序运行都需要 O(N2) 时间级别。</p>
<p>其实无论何时，只要看见一个循环嵌套在另一个循环中，我们都可以怀疑这个算法的运行时间为 O(N2)级，外层循环执行 N 次，内层循环对每一次外层循环都执行N次（或者几分之N次）。这就意味着大约需要执行N2次某个基本操作。</p>
<h1 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h1><p>选择排序是每一次从待排序的数据元素中选出最小的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。</p>
<ul>
<li><p>从待排序序列中，找到关键字最小的元素</p>
</li>
<li><p>如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换</p>
</li>
<li><p>从余下的 N - 1 个元素中，找出关键字最小的元素，重复(1)、(2)步，直到排序结束</p>
</li>
</ul>
<p><img src="/images/datastructure/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F.png" alt="选择排序"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static int[] sort(int[] array) &#123;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;总共进行n-1轮比较</span><br><span class="line">        for (int i &#x3D; 0; i &lt; array.length - 1; i++) &#123;</span><br><span class="line">            int min &#x3D; i;</span><br><span class="line">            &#x2F;&#x2F;每轮需要比较的次数</span><br><span class="line">            for (int j &#x3D; i + 1; j &lt; array.length; j++) &#123;</span><br><span class="line">                if (array[j] &lt; array[min]) &#123;</span><br><span class="line">                    &#x2F;&#x2F;记录目前能找到的最小值元素的下标</span><br><span class="line">                    min &#x3D; j;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            if (i !&#x3D; min) &#123;</span><br><span class="line">                int temp &#x3D; array[i];</span><br><span class="line">                array[i] &#x3D; array[min];</span><br><span class="line">                array[min] &#x3D; temp;</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F;第 i轮排序的结果为</span><br><span class="line">            System.out.print(&quot;第&quot; + (i + 1) + &quot;轮排序后的结果为:&quot;);</span><br><span class="line">            display(array);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return array;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;遍历显示数组</span><br><span class="line">    public static void display(int[] array) &#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; array.length; i++) &#123;</span><br><span class="line">            System.out.print(array[i] + &quot; &quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        int[] array &#x3D; &#123;4, 2, 8, 9, 5, 7, 6, 1, 3&#125;;</span><br><span class="line">        &#x2F;&#x2F;未排序数组顺序为</span><br><span class="line">        System.out.println(&quot;未排序数组顺序为：&quot;);</span><br><span class="line">        display(array);</span><br><span class="line">        System.out.println(&quot;-----------------------&quot;);</span><br><span class="line">        array &#x3D; sort(array);</span><br><span class="line">        System.out.println(&quot;-----------------------&quot;);</span><br><span class="line">        System.out.println(&quot;经过选择排序后的数组顺序为：&quot;);</span><br><span class="line">        display(array);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;&#96;&#96;</span><br><span class="line"></span><br><span class="line">## 选择排序性能分析</span><br><span class="line"></span><br><span class="line">选择排序和冒泡排序执行了相同次数的比较：N*（N-1）&#x2F;2，但是至多只进行了N次交换。</span><br><span class="line"></span><br><span class="line">当 N 值很大时，比较次数是主要的，所以和冒泡排序一样，用大O表示是O(N2) 时间级别。但是由于选择排序交换的次数少，所以选择排序无疑是比冒泡排序快的。当 N 值较小时，如果交换时间比选择时间大的多，那么选择排序是相当快的</span><br><span class="line"></span><br><span class="line"># 插入排序</span><br><span class="line"></span><br><span class="line">直接插入排序基本思想是每一步将一个待排序的记录，插入到前面已经排好序的有序序列中去，直到插完所有元素为止。</span><br><span class="line"></span><br><span class="line">插入排序还分为直接插入排序、二分插入排序、链表插入排序、希尔排序等等，这里我们只是以直接插入排序讲解，后面讲高级排序的时候会将其他的。</span><br><span class="line"></span><br><span class="line">![插入排序](&#x2F;images&#x2F;datastructure&#x2F;插入排序.png)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>package com.chen.algorithm.sort;</p>
<p>/**</p>
<ul>
<li>@author :  chen weijie</li>
<li>@Date: 2019-03-01 12:35 AM</li>
<li>/<br>public class InsertSort {</li>
</ul>
<pre><code>public static int[] sort(int[] array) &#123;

    int j;
    //从下标为1的元素开始选择合适的位置插入，因为下标为0的只有一个元素，默认是有序的
    for (int i = 1; i &lt; array.length; i++) &#123;
        //记录要插入的数据
        int temp = array[i];
        j = i;
        //从已经排序的序列最右边的开始比较，找到比其小的数
        while (j &gt; 0 &amp;&amp; temp &lt; array[j - 1]) &#123;
            //向后挪动
            array[j] = array[j - 1];
            j--;
        &#125;
        //存在比其小的数，插入
        array[j] = temp;
    &#125;
    return array;
&#125;

//遍历显示数组
public static void display(int[] array) &#123;
    for (int i = 0; i &lt; array.length; i++) &#123;
        System.out.print(array[i] + &quot; &quot;);
    &#125;
    System.out.println();
&#125;

public static void main(String[] args) &#123;
    int[] array = &#123;4, 2, 8, 9, 5, 7, 6, 1, 3&#125;;
    //未排序数组顺序为
    System.out.println(&quot;未排序数组顺序为：&quot;);
    display(array);
    System.out.println(&quot;-----------------------&quot;);
    array = sort(array);
    System.out.println(&quot;-----------------------&quot;);
    System.out.println(&quot;经过插入排序后的数组顺序为：&quot;);
    display(array);
&#125;</code></pre>
<p>}</p>
<pre><code>
## 插入排序性能分析

在第一轮排序中，它最多比较一次，第二轮最多比较两次，一次类推，第N轮，最多比较N-1次。因此有 1+2+3+...+N-1 = N*（N-1）/2。

假设在每一轮排序发现插入点时，平均只有全体数据项的一半真的进行了比较，我们除以2得到：N*（N-1）/4。用大O表示法大致需要需要 O(N2) 时间级别。

复制的次数大致等于比较的次数，但是一次复制与一次交换的时间耗时不同，所以相对于随机数据，插入排序比冒泡快一倍，比选择排序略快。

这里需要注意的是，如果要进行逆序排列，那么每次比较和移动都会进行，这时候并不会比冒泡排序快。

# 总结

上面讲的三种排序，冒泡、选择、插入用大 O 表示法都需要 O(N2) 时间级别。一般不会选择冒泡排序，虽然冒泡排序书写是最简单的，但是平均性能是没有选择排序和插入排序好的。

选择排序把交换次数降低到最低，但是比较次数还是挺大的。当数据量小，并且交换数据相对于比较数据更加耗时的情况下，可以应用选择排序。

在大多数情况下，假设数据量比较小或基本有序时，插入排序是三种算法中最好的选择。








</code></pre>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法4-栈</title>
    <url>/2019-03-01/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%954-%E6%A0%88/</url>
    <content><![CDATA[<p>栈和队列被用作程序员的工具，它们作为构思算法的辅助工具，而不是完全的数据存储工具。这些数据结构的生命周期比数据库类型的结构要短得多，在程序执行期间它们才被创建，通常用它们去执行某项特殊的业务，执行完成之后，它们就被销毁。这里的它们就是——栈和队列。</p>
<h1 id="栈的基本概念"><a href="#栈的基本概念" class="headerlink" title="栈的基本概念"></a>栈的基本概念</h1><p>栈（英语：stack）又称为堆栈或堆叠，栈作为一种数据结构，是一种只能在一端进行插入和删除操作的特殊线性表。</p>
<p>它按照先进后出的原则存储数据，先进入的数据被压入栈底，最后的数据在栈顶，需要读数据的时候从栈顶开始弹出数据（最后一个数据被第一个读出来）。栈具有记忆作用，对栈的插入与删除操作中，不需要改变栈底指针。</p>
<p>栈是允许在同一端进行插入和删除操作的特殊线性表。允许进行插入和删除操作的一端称为栈顶(top)，另一端为栈底(bottom)；栈底固定，而栈顶浮动；栈中元素个数为零时称为空栈。插入一般称为进栈（PUSH），删除则称为退栈（POP）。</p>
<p>由于堆叠数据结构只允许在一端进行操作，因而按照后进先出（LIFO, Last In First Out）的原理运作。栈也称为后进先出表</p>
<p><img src="/images/datastructure/%E6%A0%88.png" alt="栈"></p>
<h2 id="代码实现简单的栈"><a href="#代码实现简单的栈" class="headerlink" title="代码实现简单的栈"></a>代码实现简单的栈</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.dataStructure.stack;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-03-05 11:47 PM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyStack &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 栈的实际元素</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int[] array;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 当前元素的个数</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int top;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 栈的容量</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int maxSize;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public MyStack(int size) &#123;</span><br><span class="line">        this.maxSize &#x3D; size;</span><br><span class="line">        array &#x3D; new int[size];</span><br><span class="line">        top &#x3D; -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 插入元素</span><br><span class="line">     *</span><br><span class="line">     * @param value</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public void push(int value) &#123;</span><br><span class="line">        if (top &lt; maxSize - 1) &#123;</span><br><span class="line">            array[++top] &#x3D; value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 弹出元素</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public int pop() &#123;</span><br><span class="line">        return array[top--];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 访问栈顶元素</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public int peep() &#123;</span><br><span class="line">        return array[top];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 栈是否是空</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean isEmpty() &#123;</span><br><span class="line">        return (top &#x3D;&#x3D; -1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean isFull() &#123;</span><br><span class="line">        return (maxSize - 1) &#x3D;&#x3D; top;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        MyStack myStack &#x3D; new MyStack(4);</span><br><span class="line"></span><br><span class="line">        myStack.push(10);</span><br><span class="line">        myStack.push(20);</span><br><span class="line">        myStack.push(1);</span><br><span class="line">        myStack.push(-1);</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;isFull:&quot; + myStack.isFull());</span><br><span class="line">        System.out.println(&quot;peek:&quot; + myStack.peep());</span><br><span class="line"></span><br><span class="line">        while (!myStack.isEmpty()) &#123;</span><br><span class="line">            System.out.println(&quot;弹出：&quot; + myStack.pop());</span><br><span class="line">            System.out.println(&quot;栈内元素个数：&quot; + myStack.top);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这个栈是用数组实现的，内部定义了一个数组，一个表示最大容量的值以及一个指向栈顶元素的top变量。构造方法根据参数规定的容量创建一个新栈，push()方法是向栈中压入元素，指向栈顶的变量top加一，使它指向原顶端数据项上面的一个位置，并在这个位置上存储一个数据。</p>
<p>pop()方法返回top变量指向的元素，然后将top变量减一，便移除了数据项。要知道 top 变量指向的始终是栈顶的元素。</p>
<h2 id="产生的问题"><a href="#产生的问题" class="headerlink" title="产生的问题"></a>产生的问题</h2><p>①、上面栈的实现初始化容量之后，后面是不能进行扩容的（虽然栈不是用来存储大量数据的），如果说后期数据量超过初始容量之后怎么办？（自动扩容）</p>
<p>②、我们是用数组实现栈，在定义数组类型的时候，也就规定了存储在栈中的数据类型，那么同一个栈能不能存储不同类型的数据呢？（声明为Object）</p>
<p>③、栈需要初始化容量，而且数组实现的栈元素都是连续存储的，那么能不能不初始化容量呢？（改为由链表实现）</p>
<h1 id="增强功能版栈"><a href="#增强功能版栈" class="headerlink" title="增强功能版栈"></a>增强功能版栈</h1><p>这个模拟的栈在JDK源码中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.dataStructure.stack;</span><br><span class="line"></span><br><span class="line">import java.util.Arrays;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-03-06 12:31 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class ArrayStack &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * object类型的数组可以存储任意类型</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private Object[] elementData;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 指向栈顶的指针</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int top;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 栈的容量</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int size;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public ArrayStack() &#123;</span><br><span class="line"></span><br><span class="line">        this.elementData &#x3D; new Object[10];</span><br><span class="line">        this.top &#x3D; -1;</span><br><span class="line">        this.size &#x3D; 10;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public ArrayStack(int initialCapacity) &#123;</span><br><span class="line"></span><br><span class="line">        if (initialCapacity &lt; 0) &#123;</span><br><span class="line">            throw new IllegalArgumentException(&quot;栈的初始容量不得小于0：&quot; + initialCapacity);</span><br><span class="line">        &#125;</span><br><span class="line">        this.elementData &#x3D; new Object[initialCapacity];</span><br><span class="line">        this.top &#x3D; -1;</span><br><span class="line">        this.size &#x3D; initialCapacity;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public Object push(Object value) &#123;</span><br><span class="line">        isGrow(top + 1);</span><br><span class="line">        elementData[++top] &#x3D; value;</span><br><span class="line">        return value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public void remove(int top) &#123;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;栈顶元素置为null</span><br><span class="line">        elementData[top] &#x3D; null;</span><br><span class="line">        this.top--;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public boolean isEmpty() &#123;</span><br><span class="line">        return top &#x3D;&#x3D; -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public Object peek() &#123;</span><br><span class="line"></span><br><span class="line">        if (top &#x3D;&#x3D; -1) &#123;</span><br><span class="line">            return null;</span><br><span class="line">        &#125;</span><br><span class="line">        return elementData[top];</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public Object pop() &#123;</span><br><span class="line">        Object object &#x3D; peek();</span><br><span class="line">        remove(top);</span><br><span class="line">        return object;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public boolean isGrow(int minCapacity) &#123;</span><br><span class="line"></span><br><span class="line">        int oldCapacity &#x3D; size;</span><br><span class="line">        &#x2F;&#x2F;如果当前元素压入栈之后总容量大于前面定义的容量，则需要扩容</span><br><span class="line">        if (oldCapacity &lt;&#x3D; minCapacity) &#123;</span><br><span class="line">            &#x2F;&#x2F;定义扩大之后栈的总容量</span><br><span class="line">            int newCapacity &#x3D; 0;</span><br><span class="line">            if ((oldCapacity &lt;&lt; 1) - Integer.MAX_VALUE &gt; 0) &#123;</span><br><span class="line">                newCapacity &#x3D; Integer.MAX_VALUE;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                newCapacity &#x3D; (oldCapacity &lt;&lt; 1);&#x2F;&#x2F;左移一位，相当于*2</span><br><span class="line">            &#125;</span><br><span class="line">            this.size &#x3D; newCapacity;</span><br><span class="line">            int[] newArray &#x3D; new int[size];</span><br><span class="line">            elementData &#x3D; Arrays.copyOf(elementData, size);</span><br><span class="line">            return true;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        ArrayStack stack &#x3D; new ArrayStack(3);</span><br><span class="line">        stack.push(1);</span><br><span class="line">        &#x2F;&#x2F;System.out.println(stack.peek());</span><br><span class="line">        stack.push(2);</span><br><span class="line">        stack.push(3);</span><br><span class="line">        stack.push(&quot;abc&quot;);</span><br><span class="line">        System.out.println(stack.peek());</span><br><span class="line">        stack.pop();</span><br><span class="line">        stack.pop();</span><br><span class="line">        stack.pop();</span><br><span class="line">        System.out.println(stack.peek());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="利用栈反转输出字符串"><a href="#利用栈反转输出字符串" class="headerlink" title="利用栈反转输出字符串"></a>利用栈反转输出字符串</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public class RevertString &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        String str &#x3D; &quot;how are you &quot;;</span><br><span class="line">        char[] charArray &#x3D; str.toCharArray();</span><br><span class="line">        ArrayStack myStack &#x3D; new ArrayStack();</span><br><span class="line">        for (char c : charArray) &#123;</span><br><span class="line">            myStack.push(c);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        while (!myStack.isEmpty()) &#123;</span><br><span class="line">            System.out.print(myStack.pop());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="利用栈判断分隔符是否匹配"><a href="#利用栈判断分隔符是否匹配" class="headerlink" title="利用栈判断分隔符是否匹配　　"></a>利用栈判断分隔符是否匹配　　</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.dataStructure.stack;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 利用栈判断分隔符是否匹配</span><br><span class="line"> * 比如：&lt;abc[123]abc&gt;这是符号相匹配的，如果是 &lt;abc[123&gt;abc] 那就是不匹配的。</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * 　对于 12&lt;a[b&#123;c&#125;]&gt;，我们分析在栈中的数据：遇到匹配正确的就消除</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-03-06 1:04 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class TestMatch &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;遇到左边分隔符了就push进栈，遇到右边分隔符了就pop出栈，看出栈的分隔符是否和这个有分隔符匹配</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        ArrayStack arrayStack &#x3D; new ArrayStack(3);</span><br><span class="line"></span><br><span class="line">        String str &#x3D; &quot;12&lt;a[b&#123;c&#125;]&gt;&quot;;</span><br><span class="line"></span><br><span class="line">        char[] chars &#x3D; str.toCharArray();</span><br><span class="line"></span><br><span class="line">        for (char c : chars) &#123;</span><br><span class="line"></span><br><span class="line">            switch (c) &#123;</span><br><span class="line"></span><br><span class="line">                case &#39;&#123;&#39;:</span><br><span class="line">                case &#39;[&#39;:</span><br><span class="line">                case &#39;&lt;&#39;:</span><br><span class="line">                    arrayStack.push(c);</span><br><span class="line">                    break;</span><br><span class="line">                case &#39;&#125;&#39;:</span><br><span class="line">                case &#39;]&#39;:</span><br><span class="line">                case &#39;&gt;&#39;:</span><br><span class="line">                    if (!arrayStack.isEmpty()) &#123;</span><br><span class="line">                        char ch &#x3D; arrayStack.pop().toString().toCharArray()[0];</span><br><span class="line">                        if (c &#x3D;&#x3D; &#39;&#125;&#39; &amp;&amp; ch !&#x3D; &#39;&#123;&#39; || c &#x3D;&#x3D; &#39;]&#39; &amp;&amp; ch !&#x3D; &#39;[&#39; ||</span><br><span class="line">                                c &#x3D;&#x3D; &#39;&gt;&#39; &amp;&amp; ch !&#x3D; &#39;&lt;&#39;) &#123;</span><br><span class="line">                            System.out.println(&quot;Error:&quot; + ch + &quot;-&quot; + c);</span><br><span class="line"></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    break;</span><br><span class="line">                default:</span><br><span class="line">                    break;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>栈要利用它的先进后出的特性处理数据。</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法5-队列</title>
    <url>/2019-03-06/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%955-%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[<h1 id="队列的基本概念"><a href="#队列的基本概念" class="headerlink" title="队列的基本概念"></a>队列的基本概念</h1><p>队列（queue）是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。队列中没有元素时，称为空队列。</p>
<p>队列的数据元素又称为队列元素。在队列中插入一个队列元素称为入队，从队列中删除一个队列元素称为出队。因为队列只允许在一端插入，在另一端删除，所以只有最早进入队列的元素才能最先从队列中删除，故队列又称为先进先出。</p>
<h1 id="队列的分类"><a href="#队列的分类" class="headerlink" title="队列的分类"></a>队列的分类</h1><p>队列分为：</p>
<p>①、单向队列（Queue）：只能在一端插入数据，另一端删除数据。</p>
<p>②、双向队列（Deque）：每一端都可以进行插入数据和删除数据操作。</p>
<p>③、这里我们还会介绍一种队列——优先级队列，优先级队列是比栈和队列更专用的数据结构，在优先级队列中，数据项按照关键字进行排序，关键字最小（或者最大）的数据项往往在队列的最前面，而数据项在插入的时候都会插入到合适的位置以确保队列的有序。</p>
<h1 id="java模拟单向队列"><a href="#java模拟单向队列" class="headerlink" title="java模拟单向队列"></a>java模拟单向队列</h1><p>①、与栈不同的是，队列中的数据不总是从数组的0下标开始的，移除一些队头front的数据后，队头指针会指向一个较高的下标位置，如下图：</p>
<p><img src="/images/datastructure/%E9%98%9F%E5%88%971.png" alt="队列1"></p>
<p>②、我们在设计时，队列中新增一个数据时，队尾的指针rear 会向上移动，也就是向下标大的方向。移除数据项时，队头指针 front 向上移动。那么这样设计好像和现实情况相反，比如排队买电影票，队头的买完票就离开了，然后队伍整体向前移动。在计算机中也可以在队列中删除一个数之后，队列整体向前移动，但是这样做效率很差。我们选择的做法是移动队头和队尾的指针。</p>
<p>③、如果向第②步这样移动指针，相信队尾指针很快就移动到数据的最末端了，这时候可能移除过数据，那么队头会有空着的位置，然后新来了一个数据项，由于队尾不能再向上移动了，为了避免队列不满却不能插入新的数据，我们可以让队尾指针绕回到数组开始的位置，这也称为“循环队列”。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.dataStructure.queue;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-03-07 12:13 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyQueue &#123;</span><br><span class="line"></span><br><span class="line">    private Object[] queArray;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 队列总大小</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int maxSize;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 前端</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int front;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 后端</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int fear;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 队列中实际元素个数</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private int nItems;</span><br><span class="line"></span><br><span class="line">    public MyQueue(int s) &#123;</span><br><span class="line">        this.maxSize &#x3D; s;</span><br><span class="line">        this.queArray &#x3D; new Object[maxSize];</span><br><span class="line">        front &#x3D; 0;</span><br><span class="line">        fear &#x3D; -1;</span><br><span class="line">        nItems &#x3D; 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 返回队列的大小</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public int getSize() &#123;</span><br><span class="line">        return nItems;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 队列是否为空</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean isEmpty() &#123;</span><br><span class="line">        return nItems &#x3D;&#x3D; 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 队列是否满了</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean isFull() &#123;</span><br><span class="line">        return maxSize &#x3D;&#x3D; nItems;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 查看队头元素</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public Object peekFront() &#123;</span><br><span class="line">        return queArray[front];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 移除元素</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public Object remove() &#123;</span><br><span class="line"></span><br><span class="line">        Object removeValue &#x3D; null;</span><br><span class="line">        if (!isEmpty()) &#123;</span><br><span class="line">            removeValue &#x3D; peekFront();</span><br><span class="line">            front++;</span><br><span class="line">            if (front &#x3D;&#x3D; maxSize) &#123;</span><br><span class="line">                front &#x3D; 0;</span><br><span class="line">            &#125;</span><br><span class="line">            nItems--;</span><br><span class="line">            return removeValue;</span><br><span class="line">        &#125;</span><br><span class="line">        return removeValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 队列中新增元素</span><br><span class="line">     *</span><br><span class="line">     * @param value</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public void insert(Object value) &#123;</span><br><span class="line"></span><br><span class="line">        if (isFull()) &#123;</span><br><span class="line">            System.out.println(&quot;队列已满！！！&quot;);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            if (fear &#x3D;&#x3D; maxSize - 1) &#123;</span><br><span class="line">                fear &#x3D; -1;</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F;队尾指针加1，然后在队尾指针处插入新的数据</span><br><span class="line">            queArray[++fear] &#x3D; value;</span><br><span class="line">            nItems++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        MyQueue myQueue &#x3D; new MyQueue(4);</span><br><span class="line"></span><br><span class="line">        myQueue.insert(10);</span><br><span class="line">        myQueue.insert(20);</span><br><span class="line">        myQueue.insert(30);</span><br><span class="line">        myQueue.insert(40);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;获取队头元素</span><br><span class="line">        System.out.println(&quot;myQueue.peekFront():&quot; + myQueue.peekFront());</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;移除元素</span><br><span class="line">        myQueue.remove();</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;插入元素</span><br><span class="line">        myQueue.insert(50);</span><br><span class="line">        myQueue.insert(60);</span><br><span class="line"></span><br><span class="line">        for (Object a : myQueue.queArray) &#123;</span><br><span class="line">            System.out.println(&quot;a:&quot; + a);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="优先级队列"><a href="#优先级队列" class="headerlink" title="优先级队列"></a>优先级队列</h1><p>优先级队列（priority queue）是比栈和队列更专用的数据结构，在优先级队列中，数据项按照关键字进行排序，关键字最小（或者最大）的数据项往往在队列的最前面，而数据项在插入的时候都会插入到合适的位置以确保队列的有序。</p>
<p>数组实现优先级队列，声明为int类型的数组，关键字是数组里面的元素，在插入的时候按照从大到小的顺序排列，也就是越小的元素优先级越高。</p>
<h1 id="总结之前的数据结构"><a href="#总结之前的数据结构" class="headerlink" title="总结之前的数据结构"></a>总结之前的数据结构</h1><p>①、栈、队列（单向队列）、优先级队列通常是用来简化某些程序操作的数据结构，而不是主要作为存储数据的。</p>
<p>②、在这些数据结构中，只有一个数据项可以被访问。</p>
<p>③、栈允许在栈顶压入（插入）数据，在栈顶弹出（移除）数据，但是只能访问最后一个插入的数据项，也就是栈顶元素。</p>
<p>④、队列（单向队列）只能在队尾插入数据，对头删除数据，并且只能访问对头的数据。而且队列还可以实现循环队列，它基于数组，数组下标可以从数组末端绕回到数组的开始位置。</p>
<p>⑤、优先级队列是有序的插入数据，并且只能访问当前元素中优先级别最大（或最小）的元素。</p>
<p>⑥、这些数据结构都能由数组实现，但是可以用别的机制（后面讲的链表、堆等数据结构）实现。</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法7-链表</title>
    <url>/2019-02-22/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%957-%E9%93%BE%E8%A1%A8/</url>
    <content><![CDATA[<p>我们知道数组是一种通用的数据结构，能用来实现栈、队列等很多数据结构。而链表也是一种使用广泛的通用数据结构，它也可以用来作为实现栈、队列等数据结构的基础，基本上除非需要频繁的通过下标来随机访问各个数据，否则很多使用数组的地方都可以用链表来代替。</p>
<p>但是我们需要说明的是，链表是不能解决数据存储的所有问题的，它也有它的优点和缺点。本篇博客我们介绍几种常见的链表，分别是单向链表、双端链表、有序链表、双向链表以及有迭代器的链表。并且会讲解一下抽象数据类型（ADT）的思想，如何用 ADT 描述栈和队列，如何用链表代替数组来实现栈和队列。</p>
<h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><p>链表通常由一连串节点组成，每个节点包含任意的实例数据（data fields）和一或两个用来指向上一个/或下一个节点的位置的链接（”links”）</p>
<p>链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针(Pointer)。</p>
<h1 id="单向链表"><a href="#单向链表" class="headerlink" title="单向链表"></a>单向链表</h1><p>单链表是链表中结构最简单的。一个单链表的节点(Node)分为两个部分，第一个部分(data)保存或者显示关于节点的信息，另一个部分存储下一个节点的地址。最后一个节点存储地址的部分指向空值。</p>
<p>单向链表只可向一个方向遍历，一般查找一个节点的时候需要从第一个节点开始每次访问下一个节点，一直访问到需要的位置。而插入一个节点，对于单向链表，我们只提供在链表头插入，只需要将当前插入的节点设置为头节点，next指向原头节点即可。删除一个节点，我们将该节点的上一个节点的next指向该节点的下一个节点。</p>
<p><img src="/images/datastructure/%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8%E7%BB%93%E6%9E%84.png" alt="单向链表结构"></p>
<p><img src="/images/datastructure/%E5%9C%A8%E8%A1%A8%E5%A4%B4%E5%A2%9E%E5%8A%A0%E8%8A%82%E7%82%B9.png" alt="在表头增加节点"></p>
<p><img src="/images/datastructure/%E5%88%A0%E9%99%A4%E8%8A%82%E7%82%B9.png" alt="删除节点"></p>
<h2 id="单向链表的实现"><a href="#单向链表的实现" class="headerlink" title="单向链表的实现"></a>单向链表的实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.dataStructure.linklistnode;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 单链表的具体实现</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-02-21 11:35 PM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class SingleLinkedList &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;链表节点的个数</span><br><span class="line">    private int size;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;头节点</span><br><span class="line">    private Node head;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private class Node &#123;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;每个节点的数据</span><br><span class="line">        private Object data;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;每个节点指向下一个节点的连接</span><br><span class="line">        private Node next;</span><br><span class="line"></span><br><span class="line">        public Node(Object data) &#123;</span><br><span class="line">            this.data &#x3D; data;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 单链表的表头添加元素</span><br><span class="line">     *</span><br><span class="line">     * @param data</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public Object addHead(Object data) &#123;</span><br><span class="line"></span><br><span class="line">        Node newHead &#x3D; new Node(data);</span><br><span class="line">        if (size &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            head &#x3D; newHead;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            newHead.next &#x3D; head;</span><br><span class="line">            head &#x3D; newHead;</span><br><span class="line">        &#125;</span><br><span class="line">        size++;</span><br><span class="line"></span><br><span class="line">        return head;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 删除链表头节点</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public Object deleteHead() &#123;</span><br><span class="line">        Object data &#x3D; head.data;</span><br><span class="line">        head &#x3D; head.next;</span><br><span class="line">        size--;</span><br><span class="line">        return data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 找到指定元素返回节点Node，找不到返回null</span><br><span class="line">     *</span><br><span class="line">     * @param data</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public Node find(Object data) &#123;</span><br><span class="line"></span><br><span class="line">        Node current &#x3D; head;</span><br><span class="line"></span><br><span class="line">        int tempSize &#x3D; size;</span><br><span class="line">        while (tempSize &gt; 0) &#123;</span><br><span class="line">            if (data.equals(current.data)) &#123;</span><br><span class="line">                return current;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                current &#x3D; current.next;</span><br><span class="line">                tempSize--;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        return null;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 删除指定元素，删除成功返回true</span><br><span class="line">     *</span><br><span class="line">     * @param data</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean delete(Object data) &#123;</span><br><span class="line"></span><br><span class="line">        if (size &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        Node current &#x3D; head;</span><br><span class="line">        Node previous &#x3D; head;</span><br><span class="line"></span><br><span class="line">        while (current.data !&#x3D; data) &#123;</span><br><span class="line">            if (current.next &#x3D;&#x3D; null) &#123;</span><br><span class="line">                return false;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                previous &#x3D; current;</span><br><span class="line">                current &#x3D; current.next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;如果删除的节点是第一个节点</span><br><span class="line">        if (current &#x3D;&#x3D; head) &#123;</span><br><span class="line">            head &#x3D; current.next;</span><br><span class="line">            size--;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            &#x2F;&#x2F;删除的节点不是第一个节点</span><br><span class="line">            previous.next &#x3D; current.next;</span><br><span class="line">            size--;</span><br><span class="line">        &#125;</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 判断链表是不是空</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean isEmpty() &#123;</span><br><span class="line">        return size &#x3D;&#x3D; 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;显示节点信息</span><br><span class="line">    public void display() &#123;</span><br><span class="line">        if (size &gt; 0) &#123;</span><br><span class="line">            Node node &#x3D; head;</span><br><span class="line">            int tempSize &#x3D; size;</span><br><span class="line">            &#x2F;&#x2F;当前链表只有一个节点</span><br><span class="line">            if (tempSize &#x3D;&#x3D; 1) &#123;</span><br><span class="line">                System.out.println(&quot;[&quot; + node.data + &quot;]&quot;);</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">            while (tempSize &gt; 0) &#123;</span><br><span class="line">                if (node.equals(head)) &#123;</span><br><span class="line">                    System.out.print(&quot;[&quot; + node.data + &quot;-&gt;&quot;);</span><br><span class="line">                &#125; else if (node.next &#x3D;&#x3D; null) &#123;</span><br><span class="line">                    System.out.print(node.data + &quot;]&quot;);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    System.out.print(node.data + &quot;-&gt;&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">                node &#x3D; node.next;</span><br><span class="line">                tempSize--;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            &#x2F;&#x2F;如果链表一个节点都没有，直接打印[]</span><br><span class="line">            System.out.println(&quot;[]&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        SingleLinkedList singleLinkedList &#x3D; new SingleLinkedList();</span><br><span class="line">        singleLinkedList.addHead(&quot;A&quot;);</span><br><span class="line">        singleLinkedList.addHead(&quot;B&quot;);</span><br><span class="line">        singleLinkedList.addHead(&quot;C&quot;);</span><br><span class="line">        singleLinkedList.addHead(&quot;D&quot;);</span><br><span class="line"></span><br><span class="line">        singleLinkedList.display();</span><br><span class="line">        singleLinkedList.delete(&quot;B&quot;);</span><br><span class="line">        singleLinkedList.display();</span><br><span class="line">        System.out.println(&quot;find:&quot; + singleLinkedList.find(&quot;D&quot;));</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="用单向链表实现栈"><a href="#用单向链表实现栈" class="headerlink" title="用单向链表实现栈"></a>用单向链表实现栈</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.dataStructure.linklistnode;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 用单向链表实现栈</span><br><span class="line"> * 栈的pop()方法和push()方法，对应于链表的在头部删除元素deleteHead()以及在头部增加元素addHead()。</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-03-08 12:57 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class StackSingleLink &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private SingleLinkedList linkedList;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public StackSingleLink(SingleLinkedList linkedList) &#123;</span><br><span class="line">        this.linkedList &#x3D; linkedList;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void push(Object data) &#123;</span><br><span class="line">        linkedList.addHead(data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public Object pop() &#123;</span><br><span class="line">        return linkedList.deleteHead();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public boolean isEmpty() &#123;</span><br><span class="line">        return linkedList.isEmpty();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="双端链表"><a href="#双端链表" class="headerlink" title="双端链表"></a>双端链表</h1><p>对于单项链表，我们如果想在尾部添加一个节点，那么必须从头部一直遍历到尾部，找到尾节点，然后在尾节点后面插入一个节点。这样操作很麻烦，如果我们在设计链表的时候多个对尾节点的引用，那么会简单很多。</p>
<p><img src="/images/datastructure/%E5%8F%8C%E7%AB%AF%E9%93%BE%E8%A1%A8.png" alt="双端链表"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.dataStructure.linknode;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 双端队列</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-03-13 11:12 PM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class DoublePointLinkedList &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private Node head;</span><br><span class="line"></span><br><span class="line">    private Node tail;</span><br><span class="line"></span><br><span class="line">    private int size;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private class Node &#123;</span><br><span class="line"></span><br><span class="line">        private Object data;</span><br><span class="line"></span><br><span class="line">        private Node next;</span><br><span class="line"></span><br><span class="line">        public Node(Object data) &#123;</span><br><span class="line">            this.data &#x3D; data;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public DoublePointLinkedList() &#123;</span><br><span class="line">        this.head &#x3D; null;</span><br><span class="line">        this.tail &#x3D; null;</span><br><span class="line">        this.size &#x3D; 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 头部添加节点</span><br><span class="line">     *</span><br><span class="line">     * @param data</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public void addHead(Object data) &#123;</span><br><span class="line"></span><br><span class="line">        Node node &#x3D; new Node(data);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;如果链表为空，那么头节点和尾节点都是该新增节点</span><br><span class="line">        if (size &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            size &#x3D; 0;</span><br><span class="line">            head &#x3D; node;</span><br><span class="line">            tail &#x3D; node;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            node.next &#x3D; head;</span><br><span class="line">            head &#x3D; node;</span><br><span class="line">            size++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public void addTail(Object data) &#123;</span><br><span class="line"></span><br><span class="line">        Node node &#x3D; new Node(data);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;如果链表为空，那么头节点和尾节点都是该新增节点</span><br><span class="line">        if (size &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            size &#x3D; 0;</span><br><span class="line">            head &#x3D; node;</span><br><span class="line">            tail &#x3D; node;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            node.next &#x3D; tail;</span><br><span class="line">            tail &#x3D; node;</span><br><span class="line">            size++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 删除头节点</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean deleteHead() &#123;</span><br><span class="line"></span><br><span class="line">        if (size &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (head.next &#x3D;&#x3D; null) &#123;</span><br><span class="line">            head &#x3D; null;</span><br><span class="line">            tail &#x3D; null;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            head &#x3D; head.next;</span><br><span class="line">        &#125;</span><br><span class="line">        size--;</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 判断是否为空</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public boolean isEmpty() &#123;</span><br><span class="line">        return (size &#x3D;&#x3D; 0);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获得链表的节点个数</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public int getSize() &#123;</span><br><span class="line">        return size;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 显示节点信息</span><br><span class="line">     *&#x2F;</span><br><span class="line"></span><br><span class="line">    public void display() &#123;</span><br><span class="line">        if (size &gt; 0) &#123;</span><br><span class="line">            Node node &#x3D; head;</span><br><span class="line">            int tempSize &#x3D; size;</span><br><span class="line">            if (tempSize &#x3D;&#x3D; 1) &#123;&#x2F;&#x2F;当前链表只有一个节点</span><br><span class="line">                System.out.println(&quot;[&quot; + node.data + &quot;]&quot;);</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">            while (tempSize &gt; 0) &#123;</span><br><span class="line">                if (node.equals(head)) &#123;</span><br><span class="line">                    System.out.print(&quot;[&quot; + node.data + &quot;-&gt;&quot;);</span><br><span class="line">                &#125; else if (node.next &#x3D;&#x3D; null) &#123;</span><br><span class="line">                    System.out.print(node.data + &quot;]&quot;);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    System.out.print(node.data + &quot;-&gt;&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">                node &#x3D; node.next;</span><br><span class="line">                tempSize--;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println();</span><br><span class="line">        &#125; else &#123;&#x2F;&#x2F;如果链表一个节点都没有，直接打印[]</span><br><span class="line">            System.out.println(&quot;[]&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h1><p>我们知道单向链表只能从一个方向遍历，那么双向链表它可以从两个方向遍历。</p>
<p><img src="/images/datastructure/%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8.png" alt="双向链表"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.dataStructure.linknode;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 双向链表</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-03-13 11:49 PM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class TwoWayLinkedList &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private int size;</span><br><span class="line"></span><br><span class="line">    private Node head;</span><br><span class="line"></span><br><span class="line">    private Node tail;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public class Node &#123;</span><br><span class="line"></span><br><span class="line">        private Object data;</span><br><span class="line"></span><br><span class="line">        private Node next;</span><br><span class="line"></span><br><span class="line">        private Node prew;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        public Node(Object data) &#123;</span><br><span class="line">            this.data &#x3D; data;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public TwoWayLinkedList() &#123;</span><br><span class="line">        this.size &#x3D; 0;</span><br><span class="line">        this.head &#x3D; null;</span><br><span class="line">        this.tail &#x3D; null;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public void addHead(Object data) &#123;</span><br><span class="line"></span><br><span class="line">        Node node &#x3D; new Node(data);</span><br><span class="line">        if (size &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            head &#x3D; node;</span><br><span class="line">            tail &#x3D; node;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            head.prew &#x3D; node;</span><br><span class="line">            node.next &#x3D; head;</span><br><span class="line">            head &#x3D; node;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        size++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public void addTail(Object data) &#123;</span><br><span class="line"></span><br><span class="line">        Node node &#x3D; new Node(data);</span><br><span class="line">        if (size &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            head &#x3D; node;</span><br><span class="line">            tail &#x3D; node;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            node.prew &#x3D; tail;</span><br><span class="line">            tail.next &#x3D; node;</span><br><span class="line">            tail &#x3D; node;</span><br><span class="line">        &#125;</span><br><span class="line">        size++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public Node deleteHead() &#123;</span><br><span class="line"></span><br><span class="line">        Node temp &#x3D; head;</span><br><span class="line">        if (size &gt; 0) &#123;</span><br><span class="line">            head &#x3D; head.next;</span><br><span class="line">            head.prew &#x3D; null;</span><br><span class="line">            size--;</span><br><span class="line">        &#125;</span><br><span class="line">        return temp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Node deleteTail() &#123;</span><br><span class="line"></span><br><span class="line">        Node temp &#x3D; tail;</span><br><span class="line">        if (size &gt; 0) &#123;</span><br><span class="line">            tail &#x3D; head.prew;</span><br><span class="line">            tail.next &#x3D; null;</span><br><span class="line">            size--;</span><br><span class="line">        &#125;</span><br><span class="line">        return temp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>java数据结构和算法8-递归</title>
    <url>/2019-03-14/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%958-%E9%80%92%E5%BD%92/</url>
    <content><![CDATA[<h1 id="递归的定义"><a href="#递归的定义" class="headerlink" title="递归的定义"></a>递归的定义</h1><p>递归就是在运行的过程中调用自己，必须具备三个要素：</p>
<p>1.边界条件；<br>2.递归前进段；<br>3.递归返回段；</p>
<p>当边界条件不满足时，递归前进；当边界条件满足时，递归返回。</p>
<h1 id="第一个数的阶乘"><a href="#第一个数的阶乘" class="headerlink" title="第一个数的阶乘"></a>第一个数的阶乘</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.algorithm.recursion;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 求一个数的阶乘</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-03-14 11:53 PM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class Recursion &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * for循环处理阶乘</span><br><span class="line">     * @param n</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public static int getFactorialFor(int n) &#123;</span><br><span class="line"></span><br><span class="line">        int temp &#x3D; 1;</span><br><span class="line">        if (n &lt; 0) &#123;</span><br><span class="line">            return -1;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            for (int i &#x3D; 1; i &lt;&#x3D; n; i++) &#123;</span><br><span class="line">                temp &#x3D; temp * i;</span><br><span class="line">                System.out.println(&quot;i&#x3D;&#x3D;&#x3D;&quot; + i + &quot;,temp&#x3D;&#x3D;&quot; + temp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return temp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static int getFactorial(int n) &#123;</span><br><span class="line">        if (n &gt;&#x3D; 0) &#123;</span><br><span class="line">            if (n &#x3D;&#x3D; 0) &#123;</span><br><span class="line">                return 1;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                return n * getFactorial(n - 1);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        System.out.println(getFactorialFor(3));</span><br><span class="line">        System.out.println(getFactorial(0));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="递归的二分查找"><a href="#递归的二分查找" class="headerlink" title="递归的二分查找"></a>递归的二分查找</h1><p>二分查找的数组一定是有序的</p>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>在有序数组array[]中，不断将数组的中间值（mid）和被查找的值比较，如果被查找的值等于array[mid],就返回下标mid; 否则，就将查找范围缩小一半。如果被查找的值小于array[mid], 就继续在左半边查找;如果被查找的值大于array[mid],  就继续在右半边查找。 直到查找到该值或者查找范围为空时， 查找结束。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 找到目标值返回数组下标，找不到返回-1</span><br><span class="line"> *</span><br><span class="line"> * @param array</span><br><span class="line"> * @param key</span><br><span class="line"> * @return</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static int findTwoPoint(int[] array, int key) &#123;</span><br><span class="line"></span><br><span class="line">    if (array &#x3D;&#x3D; null || array.length &#x3D;&#x3D; 0) &#123;</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int min &#x3D; 0;</span><br><span class="line">    int max &#x3D; array.length - 1;</span><br><span class="line"></span><br><span class="line">    while (max &gt;&#x3D; min) &#123;</span><br><span class="line"></span><br><span class="line">        int mid &#x3D; (max + min) &#x2F; 2;</span><br><span class="line"></span><br><span class="line">        if (key &#x3D;&#x3D; array[mid]) &#123;</span><br><span class="line">            return mid;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (key &gt; array[mid]) &#123;</span><br><span class="line"></span><br><span class="line">            min &#x3D; mid + 1;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (key &lt; array[mid]) &#123;</span><br><span class="line">            max &#x3D; mid - 1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return -1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 递归二分查找</span><br><span class="line"> *</span><br><span class="line"> * @param low   低位</span><br><span class="line"> * @param high  高位</span><br><span class="line"> * @param array 有序数组</span><br><span class="line"> * @param key   要查找的值</span><br><span class="line"> * @return</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static int sort(int low, int high, int[] array, int key) &#123;</span><br><span class="line"></span><br><span class="line">    while (low &lt; high) &#123;</span><br><span class="line">        int mid &#x3D; (low + high) &#x2F; 2;</span><br><span class="line"></span><br><span class="line">        if (key &#x3D;&#x3D; array[mid]) &#123;</span><br><span class="line">            return mid;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (key &gt; array[mid]) &#123;</span><br><span class="line">            low &#x3D; mid + 1;</span><br><span class="line">            sort(low, high, array, key);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (key &lt; array[mid]) &#123;</span><br><span class="line">            high &#x3D; mid - 1;</span><br><span class="line">            sort(low, high, array, key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return -1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="汉诺塔问题"><a href="#汉诺塔问题" class="headerlink" title="汉诺塔问题"></a>汉诺塔问题</h1><p>我们都将其看做只有两个盘子。假设有 N 个盘子在塔座A上，我们将其看为两个盘子，其中(N-1)~1个盘子看成是一个盘子，最下面第N个盘子看成是一个盘子，那么解决办法为：</p>
<p>　　①、先将A塔座的第(N-1)~1个盘子看成是一个盘子，放到中介塔座B上，然后将第N个盘子放到目标塔座C上。</p>
<p>　　②、然后A塔座为空，看成是中介塔座，B塔座这时候有N-1个盘子，将第(N-2)~1个盘子看成是一个盘子，放到中介塔座A上，然后将B塔座的第(N-1)号盘子放到目标塔座C上。</p>
<p>　　③、这时候A塔座上有(N-2)个盘子，B塔座为空，又将B塔座视为中介塔座，重复①，②步骤，直到所有盘子都放到目标塔座C上结束。</p>
<p>简单来说，跟把大象放进冰箱的步骤一样，递归算法为：</p>
<p>　　①、从初始塔座A上移动包含n-1个盘子到中介塔座B上。</p>
<p>　　②、将初始塔座A上剩余的一个盘子（最大的一个盘子）放到目标塔座C上。</p>
<p>　　③、将中介塔座B上n-1个盘子移动到目标塔座C上。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void move(int dish, String from, String temp, String to) &#123;</span><br><span class="line"></span><br><span class="line">    if (dish &#x3D;&#x3D; 1) &#123;</span><br><span class="line">        System.out.println(&quot;将盘子&quot; + dish + &quot;从塔座&quot; + from + &quot;移动到目标塔座&quot; + to);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        &#x2F;&#x2F;A为初始塔，B为目标塔，C为中介塔</span><br><span class="line">        move(dish - 1, from, to, temp);</span><br><span class="line">        System.out.println(&quot;将盘子&quot; + dish + &quot;从塔座&quot; + from + &quot;移动到目标塔座&quot; + to);</span><br><span class="line">        &#x2F;&#x2F;B为初始塔，C为目标塔，A是中介塔</span><br><span class="line">        move(dish - 1, temp, from, to);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.algorithm.recursion;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 归并排序</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * 　归并算法的中心是归并两个已经有序的数组。归并两个有序数组A和B，就生成了第三个有序数组C。数组C包含数组A和B的所有数据项。</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2019-03-25 11:31 PM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MergeSort &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static int[] sort(int[] a, int[] b) &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        int aNum &#x3D; 0, bNum &#x3D; 0, cNum &#x3D; 0;</span><br><span class="line"></span><br><span class="line">        int[] c &#x3D; new int[a.length + b.length];</span><br><span class="line"></span><br><span class="line">        while (aNum &lt; a.length &amp;&amp; bNum &lt; b.length) &#123;</span><br><span class="line">            &#x2F;&#x2F;将更小的复制给c数组</span><br><span class="line">            if (a[aNum] &gt; b[bNum]) &#123;</span><br><span class="line">                c[cNum++] &#x3D; b[bNum++];</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                c[cNum++] &#x3D; a[aNum++];</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F;如果a数组全部赋值到c数组了，但是b数组还有元素，则将b数组剩余元素按顺序全部复制到c数组</span><br><span class="line">            while (aNum &#x3D;&#x3D; a.length &amp;&amp; bNum &lt; b.length) &#123;</span><br><span class="line">                c[cNum++] &#x3D; b[bNum++];</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F;如果b数组全部赋值到c数组了，但是a数组还有元素，则将a数组剩余元素按顺序全部复制到c数组</span><br><span class="line">            while (bNum &#x3D;&#x3D; b.length &amp;&amp; aNum &lt; a.length) &#123;</span><br><span class="line">                c[cNum++] &#x3D; a[aNum++];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return c;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        int[] a &#x3D; &#123;2, 5, 7, 8, 9, 10&#125;;</span><br><span class="line">        int[] b &#x3D; &#123;1, 2, 3, 5, 6, 10, 29&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        int[] c &#x3D; sort(a, b);</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; c.length - 1; i++) &#123;</span><br><span class="line">            System.out.println(c[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>















]]></content>
      <categories>
        <category>递归</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>jvm调优</title>
    <url>/2020-06-10/jvm%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[<h4 id="什么情况下需要调优？"><a href="#什么情况下需要调优？" class="headerlink" title="什么情况下需要调优？"></a>什么情况下需要调优？</h4><blockquote>
<p> JVM 内存分配不合理最直接的表现就是频繁的 GC，这会导致上下文切换等性能问题，从而降低系统的吞吐量、增加系统的响应时间。</p>
<p> 因此，如果你在线上环境或性能测试时，发现频繁的 GC，且是正常的对象创建和回收，这个时候就需要考虑调整 JVM 内存分配了，从而减少 GC 所带来的性能开销。</p>
<ul>
<li><p>调整晋升到老年代的晋升年龄；-XX:PetenureSizeThreshold</p>
</li>
<li><p>年轻带和老年代 –XX:NewRatio  1：2；</p>
</li>
<li><p>Eden：survivor  -XX:SurvivorRatio：8</p>
</li>
<li><p>动态调整  -XX:+UseAdaptiveSizePolicy  </p>
</li>
<li><p>查询虚拟机默认的堆大小</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MacBook-Pro:conf zhuningning$ java -XX:+PrintFlagsFinal -version | grep HeapSize</span><br><span class="line">    uintx ErgoHeapSizeLimit                         &#x3D; 0                                   &#123;product&#125;</span><br><span class="line">    uintx HeapSizePerGCThread                       &#x3D; 87241520                            &#123;product&#125;</span><br><span class="line">    uintx InitialHeapSize                          :&#x3D; 268435456                           &#123;product&#125;</span><br><span class="line">    uintx LargePageHeapSizeThreshold                &#x3D; 134217728                           &#123;product&#125;</span><br><span class="line">    uintx MaxHeapSize                              :&#x3D; 4294967296                          &#123;product&#125;</span><br><span class="line">java version &quot;1.8.0_161&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_161-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)</span><br></pre></td></tr></table></figure>

<p>使用gc日志方便查看问题</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- -XX:PrintGCTimeStamps：打印 GC 具体时间；</span><br><span class="line">- -XX:PrintGCDetails ：打印出 GC 详细日志；</span><br><span class="line">- -Xloggc: path：GC 日志生成路径</span><br></pre></td></tr></table></figure>


</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka源码剖析-consumer</title>
    <url>/2019-09-12/kafka%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-consumer/</url>
    <content><![CDATA[<h1 id="consumer简介"><a href="#consumer简介" class="headerlink" title="consumer简介"></a>consumer简介</h1><p>kafkaConsumer提供了一套封装良好的api，开发人员可以使用api轻松实现从服务端拉取消息，开发人员不必关系与kafka服务端的交互，比如网络管理、心跳检测、请求超时重试等底层操作，也不需要关心订阅topic的分区数量、分区leader副本的网络拓扑以及rebalance等操作，<br>而且kafka还有自动commit offset的功能；</p>
<h1 id="传递保证语义"><a href="#传递保证语义" class="headerlink" title="传递保证语义"></a>传递保证语义</h1><p>旧版本消费者的进度是记录在zookeeper中，为了缓解其压力，在服务端有一个名为 _consumer_offsets 的内部topic中记录消费进度，当出现rebalance操作时，对分区重新分配，rebalance操作完成后，消费者就可以重新读取offsets topic中的记录的offset，并从此位置继续消费。</p>
<p>consumer的poll方法返回的是最后一个消息的offset，为了避免消息丢失，建议处理完之后再poll消息，当然也可以手动commit  commitSync()以及commitAsync() 方法。</p>
<h2 id="消息的传递保证有三个级别"><a href="#消息的传递保证有三个级别" class="headerlink" title="消息的传递保证有三个级别"></a>消息的传递保证有三个级别</h2><ul>
<li>至多一次  at most once:可能会丢失，绝不会重复传递；</li>
<li>至少一次  at least once ：消息绝不会丢失，可能会重复传递；</li>
<li>恰好一次 exactly once：每条消息只会被传递一次</li>
</ul>
<p>至多一次一般不会出现、如果kafka保证传递的幂等性则使用至少一次也是没有问题的、恰好一次首先要保证不会产生重复的消息，其次消费者不能重复拉取相同的消息；</p>
<h3 id="恰好一次-生产者"><a href="#恰好一次-生产者" class="headerlink" title="恰好一次-生产者"></a>恰好一次-生产者</h3><p>网络抖动可能出现至少一次的情况，所以为了实现恰好一次有以下两种方案：</p>
<ul>
<li>每个分区只有一个生产者写入消息，当出现异常或者超时的情况时，生产者要查询此分区的最后一个消息，用来决定后续操作时消息重传还是继续；</li>
<li>为每个消息添加一个全局唯一主键，生产者不做特殊处理，按照之前的方式进行重传，保证至少一次，有消费者去去重；</li>
</ul>
<h3 id="恰好一次-消费者"><a href="#恰好一次-消费者" class="headerlink" title="恰好一次-消费者"></a>恰好一次-消费者</h3><p>拉取消息消费完之后，提交offset前出现宕机，这样重启后还会处理刚才那部分消息；拉取消息后先提交offset，宕机导致处理失败，则导致已提交的部分未做处理； 为了实现恰好一次有以下方案</p>
<ul>
<li>消费者关闭自动提交offset的功能，且不再手动提交offset，这样就不适用offsets topic这个内部topic来记录其offset，而是有消费者自己保存offset在db中，用使用的原子性来实现确切一次的功能。消费者可以使用consumer.seek()方法手动设置消费位置，从此offset处开始继续消费；</li>
</ul>
<h3 id="rebalance-操作"><a href="#rebalance-操作" class="headerlink" title="rebalance 操作"></a>rebalance 操作</h3><p>我们不知道rebalance操作以及那个分区分配给了哪个消费者，我们可以通过向consumer添加consumerReBalanceListener接口来解决这个问题：</p>
<ul>
<li>onPartitionsRevoked()方法：调用时机是consumer停止拉取数据之后。rebalance之前，我们可以在此方法中实现手动提交offset，这就避免了rebalance导致的重复消费的问题；</li>
<li>onPartitionAssigned()方法：调用时机是rebalance完成之后，consumer开始拉取数据之前，我们可以在此方法中调整或者自定义offset值。</li>
</ul>
<p>通过使用consumerReBalanceListener接口和seek()方法，我们就可以从关系型数据库中获取offset并手动设置了。</p>
<h1 id="consumer-group-rebalance-设计"><a href="#consumer-group-rebalance-设计" class="headerlink" title="consumer group rebalance 设计"></a>consumer group rebalance 设计</h1><p>最开始的时候交由zookeeper管理，严重依赖zookeeper，而且会产生羊群效应，脑裂问题；</p>
<p>之后交由broker管理，造成服务端的压力过大，而且要求服务端实现分配partition的方法，如果需要重新实现分配partition的策略，则需要修改服务端代码；</p>
<p>最后优化为交给消费者管理，0.9的版本进行了重新设计；</p>
<ul>
<li>具体的策略</li>
</ul>
<p>当消费者查找到管理当前consumer group的groupCoordinator后，就会进入join group阶段，consumer首先会向groupCoordinator发送joinGroupRequest请求，其中包含消费者的相关信息；</p>
<p>服务端的groupCoordinator收到joinGroupRequest后会暂存消息，收集到全部的消费者后，会根据joinGroupRequest中的信息来确定consumer group中的可用的消费者，从中选取一个消费者成为group leader，还会选取使用的分区分配策略，最后将这些消息封装成joinGroupResponse返回给消费者；</p>
<p>虽然每个消费者都会收到joinGroupResponse,但是只有group leader收到的joinGroupResponse中封装了所有的消费者信息，当消费者确定自己是group leader后，会根据消费者的信息以及选定的分区策略来进行分区分配；</p>
<p>在synchronizing group state阶段，每个消费者会发送syncGroupRequest到groupCoordinator，但是只有group leader的syncGroupRequest请求中保函了分区的分配结果， groupCoordinator根据group leader的分区结果形成syncGroupResponse返回给所有的consumer。</p>
<h1 id="kafkaConsumer分析"><a href="#kafkaConsumer分析" class="headerlink" title="kafkaConsumer分析"></a>kafkaConsumer分析</h1><p>kafkaConsumer对外暴露了多个api，它是线程不安全的，可以使用线程池，线程池中的每个线程拥有一个kafkaProducer实例</p>
<ul>
<li>subscribe():订阅指定的topic，并为消费者自动分配分区；</li>
<li>assign():用户手动订阅指定的topic，并指定消费者的分区；</li>
<li>commit(): 提交消费者其实消费的位置；</li>
<li>seek()：指定消费者的起始位置；</li>
<li>poll(): 负责从服务端获取消息；</li>
<li>pause() /resume()方法，暂停或者继续consumer，暂定后poll()方法会返回空；</li>
</ul>
<h2 id="SubScribeState"><a href="#SubScribeState" class="headerlink" title="SubScribeState"></a>SubScribeState</h2><p><img src="/images/kafka/consumer/SubScribeState.png" alt="SubScribeState"></p>
<h1 id="rebalance操作"><a href="#rebalance操作" class="headerlink" title="rebalance操作"></a>rebalance操作</h1><h2 id="哪种情况下会出发rebalance"><a href="#哪种情况下会出发rebalance" class="headerlink" title="哪种情况下会出发rebalance"></a>哪种情况下会出发rebalance</h2><ol>
<li>有新的消费者加入consumerGroup</li>
<li>有新的消费者宕机下线</li>
<li>有消费者主动退出consumerGroup</li>
<li>consumerGroup订阅任一topic出现分区数量的变化</li>
<li>消费者取消对topic的订阅</li>
</ol>
<h3 id="第一阶段"><a href="#第一阶段" class="headerlink" title="第一阶段"></a>第一阶段</h3><ul>
<li>第一步检查是否需要重新查找groupCoordinator，主要是检查Coordinator字段是否为空以及与groupCoordinator之间的连接是正常；</li>
<li>第二步查找集群负载最低的node节点，并创建groupCoordinatorRequest,调用client.sent()方法将请求放入unsent队列中等待发送，并返回future对象，返回的对象经过compose方法适配，返回给heartbeatCompletionHandler;</li>
<li>第三步调用consumerNetClient.poll(future) 方法，groupCoordinatorRequest请求发送出去，此处使用阻塞的方式发送，知道收到groupCoordinatorResponse响应或异常完成，</li>
<li>第四步检查返回的RequestFuture<Void> 对象，如果出现retriableException异常，则调用ConsumerNetWorkClient.awaitMetadataUpdate()方法阻塞更新metadata中记录的集群元素后跳转到步骤一继续操作。如果不是RetriableException则直接报错；</li>
<li>第五步如果找到GroupCoordinator节点，但是网络连接失败，则将其unsent中对应的请求秦孔，并将coordinator字段置为空，重新查找GroupCoordinator</li>
</ul>
<h3 id="第二阶段"><a href="#第二阶段" class="headerlink" title="第二阶段"></a>第二阶段</h3><p>在成功查找到GroupCoordinator之后进入Join group阶段，在此阶段消费者会向GroupCoordinator发送joinGroupRequest请求，并处理响应</p>
<p><img src="/images/kafka/consumer/joinGroup.png" alt="joinGroupRequest"></p>
<p>在进行完joinGroupRequest之后要进行joinGroupResponse()方法，</p>
<p><img src="/images/kafka/consumer/joinGroupResponse.png" alt="joinGroupResponse"></p>
<h3 id="第三阶段"><a href="#第三阶段" class="headerlink" title="第三阶段"></a>第三阶段</h3><p>在完成分区分配后，要进入synchronizing group state阶段，主要逻辑是向groupCoordinator发送syncGroupRequest，并处理syncGroupResponse响应。</p>
<p><img src="/images/kafka/consumer/onjoinComplete.png" alt="onjoinComplete"></p>
<h1 id="offset"><a href="#offset" class="headerlink" title="offset"></a>offset</h1><p>offset commit 分为同步和异步提交以及手动提交，手动提交就是调用异步提交。</p>
<p><img src="/images/kafka/consumer/offsetCommit.png" alt="offsetCommit"></p>
<h2 id="fetch-offset"><a href="#fetch-offset" class="headerlink" title="fetch offset"></a>fetch offset</h2><p>在rebalance结束后，每个消费者都确定了其需要消费的分区，在开始消费之前，消费者需要确定拉取消息的其实位置，假设之前已经将最后的消费者提交到了groupCoordinator中，groupCoordinator将其提交到内部的offset_topic中.此时消费者需要通过offsetFetchRequest 请求上次提交的位置，从此继续消费。</p>
<h1 id="fetcher"><a href="#fetcher" class="headerlink" title="fetcher"></a>fetcher</h1><p>fetcher类的功能发送请求获取指定的消息集合，并更新消费位置。而且需要拉取最新的postion，有earlist、latest两种策略，上面两种策略都会发送offsetsRequest，请求指定的offset。</p>
]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka consumer</tag>
      </tags>
  </entry>
  <entry>
    <title>linux入门-文件管理</title>
    <url>/2018-06-01/linux%E5%85%A5%E9%97%A8-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h1 id="文件和目录管理"><a href="#文件和目录管理" class="headerlink" title="文件和目录管理"></a>文件和目录管理</h1><p>1.FHS(文件系统层次标准)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin 常见的用户指令</span><br><span class="line">&#x2F;boot 内核和启动文件</span><br><span class="line">&#x2F;dev 设备文件</span><br><span class="line">&#x2F;etc 系统和服务的配置文件</span><br><span class="line">&#x2F;home 系统默认的普通用户的家目录</span><br><span class="line">&#x2F;lib 系统的函数库目录</span><br><span class="line">&#x2F;lost+found ext3文件系统需要的目录，用于磁盘检查</span><br><span class="line">&#x2F;mnt 系统加载文件系统时常用的挂载点</span><br><span class="line">&#x2F;opt 第三方软件安装目录</span><br><span class="line">&#x2F;proc 虚拟文件系统</span><br><span class="line">&#x2F;root root用户的家目录</span><br><span class="line">&#x2F;sbin 存放系统管理命令</span><br><span class="line">&#x2F;tmp 临时文件的存放目录</span><br><span class="line">&#x2F;usr 存放与用户直接相关的文件和目录</span><br><span class="line">&#x2F;media 系统用来挂载光驱等临时文件系统的挂载点</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2.绝对路径</p>
<p>  绝对路径是以‘/’开头的路径</p>
<p>  pwd 查看当前文件所在的路径</p>
<p>3.特殊目录</p>
<p>每个目录下都有两个文件 （.）(..) 所有以.开始的文件都是隐藏文件 </p>
<p>./代表当前目录 ../代表上层目录</p>
<p>使用ls -la可以看到隐藏文件</p>
<p>4.相对路径</p>
<p>   cd ..进入上层目录   cd / 进入根目录</p>
<p>5.文件的操作</p>
<p>1）创建文件 touch test.txt  如果创建时该文件已经存在，则不会改变文件的内容，会改变文件的创建时间</p>
<p>2）删除文件 rm  test.txt 然后会提示 输入y 确定删除，输入n 反悔</p>
<p>3）移动文件 mv test.txt  /home/chen  后面带有两个参数 第一个时要被移动的文件 第二个参数要移动到的目录； 如果第二个参数是文件名字 则表示重命名操作</p>
<p>4）查看文件 cat  test.txt    如果带一个参数cat -n test.txt  则会显示文件行号</p>
<p>5）查看文件的头部 head -n 100 test.txt  显示文件的前100行</p>
<p>6）查看文件的尾部 tail -n 100 test.txt   更重要的可以使用 tail -f test.txt 动态的追踪文件的尾部 </p>
<p>7）dos格式的文本转换成unix格式的文本 dos2unix</p>
<p>6.目录的相关操作</p>
<ol>
<li><p>进入目录 cd    change directory的缩写</p>
</li>
<li><p>创建目录 mkdir  test/      可以使用-p 参数一次创建一个目录和其子目录  mkdir  -p  dir1/dir2</p>
</li>
<li><p>删除目录 rm  如果目录不为空，则需要先删除目录中的文件。或者可以使用rm -r 删除 ，而rm -rf，则时强制无提示的删除目录以及目录下的文件</p>
</li>
</ol>
<p>4)复制文件或者目录 cp 第一个参数是要复制的源文件，第二个是要复制到的目录或者复制后的文件名字。</p>
<p>cp test.txt  test2.txt (改名字) </p>
<p>cp  test.txt  /temp/ (复制到temp目录下不改名字)  </p>
<p>cp  test.txt  /temp/test2.txt (复制到temp目录下改名字)</p>
<p>复制目录则需要加 -r      cp  -r dir1  dir2</p>
<p>5)文件的时间戳 使用touch命令可以修改文件的时间戳</p>
<p>7.权限含义详解：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drwxrwxr-x  2 zhuningning zhuningning 4096 Sep 11 23:21 dir1&#x2F;</span><br><span class="line"></span><br><span class="line">权限分为三种： r 代表可读，用4表示。 w 代表可写，用2表示。 x 代表可执行，用1表示。 </span><br><span class="line">-rw-r--r--  的解释如下, ：</span><br><span class="line">第一位的‘-’ 代表文件类型。 【&#39;d&#39; 代表目录，&#39;|&#39; 代表链接 ，‘-’代表普通文件】。</span><br><span class="line">第二位到第四位的‘rw-’，代表该文件的所有者对该文件的权限。</span><br><span class="line">第五位到第七位的‘r--’，代表该文件所在的组的其他用户对该文件的权限。</span><br><span class="line">第八位到第十位的‘r--’，代表其他组的用户对该文件的权限。</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">chmod命令：使用例： chmod 760 目录&#x2F;文件，</span><br><span class="line">意思是 给该目录&#x2F;文件的所有者对该目录&#x2F;文件赋予rwx权限，给该目录&#x2F;文件所在的组的其他用户对该目录&#x2F;文件赋予rw-权限，给其他组的用户对该目录&#x2F;文件赋予---权限。</span><br><span class="line"> </span><br><span class="line">chmod 755 abc ：赋予abc权限rwxr-xr-x。</span><br><span class="line">chmod u&#x3D;rwx,g&#x3D;rx,o&#x3D;rx abc ：同上 u&#x3D;用户权限  g&#x3D;组权限 o&#x3D;不同组其他用户权限。</span><br><span class="line">chmod u-x,g+w abc ：给abc去除用户执行的权限，增加组写的权限。-表示去除  +表示增加</span><br><span class="line">chmod a+r abc ：给所有用户添加读的权限。</span><br><span class="line">chmod -R 754 abc ：给abd目录以及目录下的文件赋予权限754</span><br><span class="line"> </span><br><span class="line">改变拥有者（chown）和用户组（chgrp）命令：</span><br><span class="line">chown xiaoming abc ：改变abc的拥有者为xiaoming。</span><br><span class="line">chgrp root abc ：改变abc所属的组为root。</span><br><span class="line">chown root .&#x2F;abc ： 改变abc目录的所有者是root。</span><br><span class="line">chown -R root .&#x2F;abc ：改变abc目录及其下面的所有目录和文件的所有者是root。参数-R 是递归的意思。</span><br><span class="line"></span><br><span class="line">文件的隐藏属性：lsattr test.txt     chattr +a test.txt   表示文件不可以被删除，即使root权限也不可以；  chattr +i test.txt   表示文件不可以被删除&#x2F;修改，即使root权限也不可以</span><br><span class="line">suid权限 （u权限）普通用户可以使用root的身份来执行命令 chmod u+s  files 来授权</span><br><span class="line">sgid 权限（g权限） 组可以使用root身份来执行名  chmod g+s 来授权</span><br><span class="line">sticky权限（s权限），只能使用在目录上，设置了这种权限，任何用户可以创建和修改文件，但是只有文件的创建者和root用户可以删除自己的文件 chmod o+t  dir </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>8.系统创建文件和目录的默认权限</p>
<p>umask（遮罩值） 对于uid大于 99的 umask为022 否则为002 </p>
<p>文件的默认权限是 666 目录的权限是777 </p>
<p>root用户的文件权限是644 目录权限是 755</p>
<p>普通用户的文件权限是664 目录是775</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">给用户组添加SGID权限:</span><br><span class="line">chmod g+s somefile</span><br><span class="line"></span><br><span class="line">给用户添加SUID权限</span><br><span class="line">chmod u+s somefile</span><br></pre></td></tr></table></figure>
<p>Sticky权限还能用于设置在目录上,设置了这种权限的目录,任何用户都可以在该目录创建或者修改文件,但是该文件的创建者和root用户可以删除这个文件</p>
<p>9.查看文件类型（可以显示文件的特殊属性）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">file  &#x2F;tmp&#x2F;</span><br><span class="line">该目录是一个拥有sticky属性的目录  &#x2F;tmp&#x2F;: sticky, directory</span><br><span class="line"></span><br><span class="line">file  &#x2F;etc&#x2F;passwd</span><br><span class="line">该文件是一个ASCII编码的文本文件  &#x2F;etc&#x2F;passwd: ASCII text</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="10">
<li>查找文件</li>
</ol>
<p>1)一般查找 find PATH -name FILENAME   //在某个路径下查找文件</p>
<p>2）locate fileName  //该命令依赖于一个数据库，一般执行命令之前需要执行updatedb命令来更新数据库</p>
<p>3）which/whereis  fileName  //该命令从系统的path变量所定义的目录中找到可执行文件的绝对路径 ，而whereis除此之外还可以还能找到其相关的二进制文件</p>
<p>11.压缩文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gzip和gunzip 用来压缩和解压单个文件</span><br><span class="line"></span><br><span class="line">tar不仅可以打包文件，还可以讲整个目录中的全部文件整合成一个包，整合包的同时还可以使用gzip进行压缩。可以使用.tar.gz作为后缀简写为.tgz</span><br><span class="line"></span><br><span class="line">tar -zcvf boot.tgz &#x2F;boot </span><br><span class="line"></span><br><span class="line">-z代表使用gzip进行压缩，-c表示创建压缩文件 -v表示是显示当前被压缩的文件，-f代表使用文件名字 也就是boot.tgz</span><br><span class="line"></span><br><span class="line">tar -zxvf  boot.tgz -C &#x2F;tmp  </span><br><span class="line"> -x表示解压的意思  -C 执行解压到&#x2F;tmp命令</span><br><span class="line"> </span><br><span class="line">bzip2 fileName  进行压缩</span><br><span class="line">-z参数进行强制压缩   -d进行强制解压</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>12 .查看文件的大小</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ll -h test.txt</span><br><span class="line">-rwxrwxrwx 1 zhuningning zhuningning 152M Feb  7  2017 crossover_16.1.0-1.deb*</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux文件管理</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka源码剖析-快速入门</title>
    <url>/2018-04-05/kafka%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>kafka是一种分布式的,基于发布订阅的消息系统.由scala语言编写的.由linkedin于2011年开源,2012年10月从apache孵化器毕业的顶级项目.</p>
<h2 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h2><ol>
<li><strong>kafka具有近乎实时的消息处理能力</strong>,面对海量消息的查询和存储也能高效的处理.kafka消息存储在磁盘中,它以顺序读写的方式访问磁盘,从而避免了随机读写磁盘导致的性能瓶颈.</li>
<li><strong>kafka支持批量读写消息,并且会对消息进行批量压缩</strong>.这样提高了网络的利用率,也提高了压缩效率.</li>
<li><strong>kafka支持消息分区,每个分区中的消息可以保证顺序传输,而分区之间的消息可以并发操作,这样提高了kafka的并发能力</strong>.</li>
<li>kafka支持在线增加分区,支持在线水平扩展.</li>
<li>kafka支持为多个分区创建多个副本,其中只会有一个leader副本负责读写,其它副本负责与leader进行同步,提高了数据的容灾能力,kafka将会将leader副本均匀的分布在集群中的进服务器上,实现性能的最大化.</li>
</ol>
<h2 id="kafka的应用场景"><a href="#kafka的应用场景" class="headerlink" title="kafka的应用场景"></a>kafka的应用场景</h2><ol>
<li>kafka可以作为传统的消息中间件,实现消息队列和消息的发布订阅.</li>
<li>kafka可以作为系统中的数据总线,将其接入多个子系统,子系统可以将消息推送到kafka中进行保存,之后流转到目的的系统中.</li>
<li>kafka可以作为日志收集中心,多个系统产生的日志统一收集到kafka中,然后由数据分析平台进行统一管理.日志会被kafka持久化到硬盘,同时支持离线数据处理和实时数据处理.</li>
<li>kafka可以作为数据库主从同步的工具.</li>
</ol>
<h2 id="以kafka为中心的解决方案"><a href="#以kafka为中心的解决方案" class="headerlink" title="以kafka为中心的解决方案"></a>以kafka为中心的解决方案</h2><p>kafka的作用</p>
<ol>
<li><p><strong>解耦合</strong>,开发人员不需要知道各个子系统/服务/存储之间的关系,只需要面向kafka编程即可.两者只需要知道消息存放的topic和消息中的数据的格式即可.简单说,一个扮演生生产者一个扮演消费者,kafka是消息队列.</p>
</li>
<li><p><strong>数据持久化</strong>.网络传输时不可靠的,kafka把数据以消息的形式持久化到磁盘.即使kafka出现宕机,数据也不会丢失.kafka还提供了<strong>日志清理和日志压缩</strong>等功能.另外在磁盘操作中,耗时最长的是寻址时间,kafka采用<strong>顺序读写</strong>的方式,实现了高吞吐.</p>
</li>
<li><p><strong>扩展和容灾</strong> kafka的每个topic可以分为多个partition(分区),每个分区有多个replica(副本),实现了消息的冗余备份.各个分区中的消息是不同的,类似于数据库水平切分的思想.提高了并发读写能力.同一分区的不同副本之间存储的是相同的消息,副本之间是一主多存的关系,其中leader负责消息的读写,follower负责与leader进行备份,如果leader出现故障,follower重新选取leader副本提供服务.这样,通过分区的数量实现水平扩展,通过副本的数量提高容灾能力.</p>
<p>而且kafka的consumer端采用的是pull拉取消息,consumer端保存消息消费的具体位置,如果宕机重启后,consumer自己决定何时从哪消费消息;</p>
<p>kafka的consumer水平扩展,可以让多个consumer加入一个consumer组.在一个consumer group中,每个分区只能分配给一个consumer消费,当kafka服务端增加分区后,consumer group中可以添加consumer来提高consumer group的消费能力,当consumer group中的某个consumer出现故障时,会通过rebalance操作,将下线consumer消费的分区分配给其它consumer进行消费.当然一个consumer group可以订阅多个topic,每个consumer可以同时处理多个分区.</p>
</li>
<li><p><strong>顺序保证</strong>,kafka保证一个partition中的消息的有序性,不保证多个partition之间的数据有序性.</p>
</li>
<li><p><strong>缓冲和峰值处理能力</strong>,kafka的吞吐量较大,kafka能够顶住突发的访问压力,不会因为突发的压力造成系统崩溃不可用.</p>
</li>
<li><p><strong>异步通信</strong> ,提高处理其它的能力.</p>
</li>
</ol>
<h1 id="kafka的核心概念"><a href="#kafka的核心概念" class="headerlink" title="kafka的核心概念"></a>kafka的核心概念</h1><h2 id="消息"><a href="#消息" class="headerlink" title="消息"></a>消息</h2><p>消息是kafka最基本的数据单位,消息是由一串字节构成,其中主要由key和value组成,其中key和value都是byte数组.key的主要作用时根据一定的策略将消息路由到指定的同一分区中,保证消息的顺序.</p>
<h2 id="topic-分区-partition-log"><a href="#topic-分区-partition-log" class="headerlink" title="topic/分区(partition)/log"></a>topic/分区(partition)/log</h2><p>topic是用于存储消息的逻辑概念,是一个消息集合.每个topic可以划分成多个分区,同一topic下的不同分区包含的信息是不同的.每个消息在被添加到分区中会被分配一个offset,它时消息在该分区中的唯一编号,kafka通过offset保证消息在分区内的顺序,同一分区中的消息是有序的,不同的分区内的消息,kafka不能保证其顺序性.</p>
<p>分区是kafka水平扩展的基础,增加kafka的分区可以增加kafka的并行处理能力.</p>
<p>分区在逻辑上对应一个log,当消息写入分区时,实际上是写入到了分区对应的log中.log是一个逻辑概念,对应磁盘上的一个文件夹,log由多个segment组成,每个segment对饮一个日志文件和索引文件.每一个日志文件是有大小限制的.索引文件采用稀疏索引的方式,大小并不会很大,在运行时将其映射到内存,提高索引速度.</p>
<p>kafka的topic在每个机器上是以文件存储的,而这些文件呢,会分目录,partition就是文件的目录.</p>
<h2 id="保留策略和日志压缩"><a href="#保留策略和日志压缩" class="headerlink" title="保留策略和日志压缩"></a>保留策略和日志压缩</h2><p>kafka中有两种保留策略,一种时根据消息保留的时间,一种时根据topic存储消息的大小.kafka有一个线程定时检查消息的大小.</p>
<p>此外kafka还会进行日志压缩,消息的key与value对应的值时不断变化的,消费者只关心最新value值,开启kafka的日志压缩功能,定期将相同可以的消息进行合并,只留最新的value的值.</p>
<h2 id="broker"><a href="#broker" class="headerlink" title="broker"></a>broker</h2><p>一个kafka服务器就是一个broker,broker的主要工作就是接收生产者的消息,分配offset,保存到硬盘.接收消费者和其它broker的请求,并根据请求类型处理并返回相应.</p>
<h2 id="副本-replica"><a href="#副本-replica" class="headerlink" title="副本(replica)"></a>副本(replica)</h2><p>kafka对消息进行冗余备份,每个partition有多个副本,每个副本中的消息有多个副本.选出一个leader副本负责读写请求.follower副本只是进行冗余备份和容错.</p>
<h2 id="ISR-In-Sync-Replica"><a href="#ISR-In-Sync-Replica" class="headerlink" title="ISR (In-Sync Replica)"></a>ISR (In-Sync Replica)</h2><p>ISR表示目前可用且与leader相差不多的副本集合,在broker宕机后重新选举新的leader继续对外提供服务.ISR集合必须满足以下条件</p>
<ol>
<li>副本所在的节点必须维持着与zookeeper的联系</li>
<li>副本最后一条消息的offset与leader副本的最有一条消息的offset的差值不能超过指定值.</li>
</ol>
<p>某个副本可能由于某种原因从ISR集合中退出,在满足以上条件后,会重新加入ISR集合.</p>
<h2 id="HW-LEO"><a href="#HW-LEO" class="headerlink" title="HW/LEO"></a>HW/LEO</h2><p>highWaterMark标记了一个特殊的offset,当消费者消费消息的时候,只能拉取到HW之前的消息,HW之后的消息对消费者来说时不可见的,HW也是由LEADER副本管理,当ISR集合中全部非follower副本都拉取HW制定消息进行同步后,leader副本会增加hw的值.</p>
<p>log end offset 是所有的副本都会标记的一个offset,它指向最后追加到当前副本的最后一个消息,当生产者向leader追加消息的时候,leader副本的leo标记会增加;当follower副本成功从leader副本中拉取消息更新到本地的时候,foller副本的leo就会增加,当isr集合中的所有的副本都完成了该消息的leo增加,则leader副本会增加HW.</p>
<h2 id="副本的同步复制"><a href="#副本的同步复制" class="headerlink" title="副本的同步复制"></a>副本的同步复制</h2><p>同步复制要求所有的能工作的follower副本完成复制,这条消息才会被认为提交成功.一旦有一个follower副本出现故障,就导致HW无法完成递增,消息就无法提交,生产者拿不到消息,这样故障的follower副本会拖慢整个体系的性能.</p>
<h2 id="副本的异步复制"><a href="#副本的异步复制" class="headerlink" title="副本的异步复制"></a>副本的异步复制</h2><p>异步复制中,leader副本收到生产者推送的消息后,就会被认为该消息提交成功,follower副本异步的从leader中同步消息.这样设计虽然避免了同步复制的问题,但同样存在一定的风险.</p>
<p>假设follower副本同步的消息比较慢,它保存的消息圆圆落后于leader副本,此时leader副本突然宕机进行选举的时候,副本会丢失消息.</p>
<p>此时ISR集合策略解决了这种问题. 当follower复制消息较慢的时候,副本被踢出isr集合.follower副本在更新消息的时候时批量写磁盘.</p>
<h2 id="Cluster-controller"><a href="#Cluster-controller" class="headerlink" title="Cluster/controller"></a>Cluster/controller</h2><p>多个broker可以做成一个cluster对外提供服务,每个cluster当中会选举出一个broker担任controller,controller是kafka集群的指挥中心,其它broker听从controller指挥实现功能,</p>
<p>controller负责管理分区的状态,管理每个分区的副本状态/监听zookeeper中的数据变化等工作,controller也是一主多从的实现.</p>
<h2 id="生产者-producer"><a href="#生产者-producer" class="headerlink" title="生产者(producer)"></a>生产者(producer)</h2><p>生产者的主要工作时生产消息,并将消息安装一定的规则推送到topic的分区中.例如根据消息的key的hash值选择分区或按照轮训全部分区的方式.</p>
<p>ACK，是指服务器收到消息之后，是存下来之后，再给客户端返回，还是直接返回</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">该参数是设置的,request.required.acks</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;0: 不等服务器ack就返回了，性能最高，可能丢数据 </span><br><span class="line">&#x2F;&#x2F;1. leader确认消息存下来了，再返回 </span><br><span class="line">&#x2F;&#x2F;all: leader和当前ISR中所有replica都确认消息存下来了，再返回（这种方式最可靠）</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="同步发送和异步发送"><a href="#同步发送和异步发送" class="headerlink" title="同步发送和异步发送"></a>同步发送和异步发送</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">所谓异步发送，就是指客户端有个本地缓冲区，消息先存放到本地缓冲区，然后有后台线程来发送。</span><br><span class="line"></span><br><span class="line">在异步发送下，有以下4个参数需要配置：</span><br><span class="line">（1）队列的最大长度 </span><br><span class="line">buffer.memory &#x2F;&#x2F;缺省为33554432, 即32M</span><br><span class="line"></span><br><span class="line">（2）队列满了，客户端是阻塞，还是抛异常出来（缺省是true) </span><br><span class="line">block.on.buffer.full </span><br><span class="line">&#x2F;&#x2F;true: 阻塞消息 </span><br><span class="line">&#x2F;&#x2F;false：抛异常</span><br><span class="line"></span><br><span class="line">（3）发送的时候，可以批量发送的数据量 </span><br><span class="line">batch.size &#x2F;&#x2F;缺省16384字节，即16K</span><br><span class="line"></span><br><span class="line">（4）最长等多长时间，批量发送 </span><br><span class="line">linger.ms &#x2F;&#x2F;缺省是0 </span><br><span class="line">&#x2F;&#x2F;类似TCP&#x2F;IP协议中的linger algorithm，&gt; 0 表示发送的请求，会在队列中积攥，然后批量发送。</span><br><span class="line"></span><br><span class="line">很显然，异步发送可以提高发送的性能，但一旦客户端挂了，就可能丢数据。</span><br><span class="line">对于RabbitMQ, ActiveMQ，他们都强调可靠性，因此不允许非ACK的发送，也没有异步发送模式。Kafka提供了这个灵活性，允许使用者在性能与可靠性之间做权衡。</span><br><span class="line"></span><br><span class="line">（5）消息的最大长度 </span><br><span class="line">max.request.size &#x2F;&#x2F;缺省是1048576，即1M</span><br><span class="line"></span><br><span class="line">这个参数会影响batch的大小，如果单个消息的大小 &gt; batch的最大值(16k)，那么batch会相应的增大</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="消费者-consumer"><a href="#消费者-consumer" class="headerlink" title="消费者(consumer)"></a>消费者(consumer)</h2><p>消费者的主要工作时从topic中拉取消息,对消息进行消费.每个消费者消费哪个分区,消费到哪个位置都是有consumer自己维护的,这样减少了server端的开销,同时减少服务端宕机带来的风险.</p>
<p>消费者采用pull的方式进行消费,这样消费者可以根据自己的消费能力进行处理.</p>
<p>在kafka里面，是保证消息不漏，也就是at least once。至于重复消费问题，需要业务自己去保证，比如业务加判重表。</p>
<h2 id="消费者组-consumer-group"><a href="#消费者组-consumer-group" class="headerlink" title="消费者组(consumer group)"></a>消费者组(consumer group)</h2><p>在kafka中,多个consumer组成一个consumer group ,一个consumer只能属于一个consumer group.consumer group保证其订阅的topic的每个分区只能被分配给此consumer group中的一个消费者处理.如果不同的consumer group 订阅了同一个topic ,各个消费者组之间彼此不会干扰.</p>
<p>kafka消费者组是逻辑上的订阅者.kafka还通过消费者组实现了水平扩展和故障转移.</p>
<p>当消费者数量超过分区的数量时,会造成消费者分不到分区,从而造成消费者的浪费.</p>
<h2 id="kafka集群的架构"><a href="#kafka集群的架构" class="headerlink" title="kafka集群的架构"></a>kafka集群的架构</h2><p><img src="/images/kafka/introduce/kafka%E9%9B%86%E7%BE%A4%E7%9A%84%E6%9E%B6%E6%9E%84.png" alt="kafka集群的架构"></p>
<p>生产者会根据业务逻辑生产消息,之后根据路由规则将消息发送到制定分区的leader副本所在的broker上,在kafka的服务端接收到消息后,会将消息追加到log中保存,之后follower副本会与leader副本进行同步,当isr集合中所有副本都完成了消息的同步后,则leader副本的hw会增加,并向生产者返回相应,</p>
<p>当消费者加入到consumer group时,会出发rebalance操作将分区分配给不同的消费者消费.随后,消费者会会恢复其消费位置,并向kafka服务端发送拉取的请求,leader副本会验证请求的offset及其它信息,最后返回.</p>
<h1 id="搭建kafka源码环境"><a href="#搭建kafka源码环境" class="headerlink" title="搭建kafka源码环境"></a>搭建kafka源码环境</h1><ol>
<li><p><a href="https://blog.csdn.net/he582754810/article/details/53837142">scala环境</a></p>
</li>
<li><p><a href="https://blog.csdn.net/hejjiiee/article/details/53510209">安装grandle</a></p>
</li>
<li><p><a href="https://blog.csdn.net/Yan_Chou/article/details/53322429">安装zookeeper环境</a></p>
</li>
<li><p>源码构建</p>
</li>
</ol>
<p>在kafka源码目录下,执行gradle idea命令</p>
<p>遇到问题 <a href="https://www.cnblogs.com/jun1019/p/7440468.html">源码构建报错</a></p>
<ol start="5">
<li>安装scala插件</li>
</ol>
<p>在idea中安装scala插件</p>
<ol start="6">
<li>配置启动kafka</li>
</ol>
<p>在kafka服务端使用log4j输出日志,启动前需要把config下的 log4j.properties 配置文件放到core的/scala/main/scala 下,然后运行程序</p>
<ol start="7">
<li>kafka启动参数配置</li>
</ol>
<p><img src="/images/kafka/introduce/kakfa%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE.png" alt="kakfa启动参数配置"></p>
]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka源码剖析</tag>
      </tags>
  </entry>
  <entry>
    <title>linux入门-文件系统</title>
    <url>/2018-06-08/linux%E5%85%A5%E9%97%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h1 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h1><p>1.文件系统其实就是组织文件的方法。<br>linux支持多种文件系统，最常用的就是ext2  /ext3<br>linux系统都具有通用的结构，包括：超级快 i节点 数据块 目录块四个部分。<br>ext3相对于ext2的优势时其支持日志功能。<br>磁盘分区分为主分区和扩展分区，一块磁盘最多可以扩展4个主分区。<br>磁盘分区完成后需要进行创建文件系统的操作，最后讲该分区挂载到系统中的某个挂载点才可以使用。</p>
<ol start="2">
<li>fdisk 创建文件系统<br>mount 挂载磁盘   挂载点只能是目录  （暂时挂载）<br>/etc/sftab 设置启动自动挂载 </li>
</ol>
<p>3.磁盘检查<br>当磁盘出现逻辑错误时，可以使用fsck来尝试修复。（但是此时磁盘必须时未挂载的状态，可以使用umount命令进行卸载）<br>umount  /DEVICE/PATH 卸载挂载盘（参数可以时设备路径或者挂载点）<br>使用fsck -t TYPE  /DEVICE/PATH   TYPE可以是ext2 ext3 最后时设备的全路径</p>
<p>4.linux的逻辑卷<br>逻辑卷是使用逻辑卷组管理（LVM）创建出来的设备，LVM时介于硬盘裸设备和文件系统的中间层。<br>物理卷（PV）   卷组（VG）时物理组的集合，逻辑卷(LV)是从PV中划出来的一块逻辑磁盘。<br>5.创建物理卷：（pvcreate pvdisplay）<br>首先提供一个磁盘，然后创建三个分区 fdisk    /dev/sdc<br>fdisk -l 查看是否创建成功<br>修改各个分区的id为8e<br>创建PV  pvcreate /dev/sdc1<br>pvscan 查看系统中的PV，pvdisplay可以显示更详细的信息。</p>
<p>6.创建并查询卷组（vgcreate  vgdisplay）<br>创建卷组：vgcreate VG_NAME DEVICE1   DEVICE2  </p>
<p>7.扩容卷组（vgextend）<br>扩展卷组：vgextend VG_NAME DEVICE1 DEVICE2</p>
<p>8.创建逻辑卷（lvcreate lvdisplay）<br>有了卷组就可以创建逻辑卷 lvcreate  -L SIZE -n LV_NAME VG_NAME    -L制定逻辑卷的大小size表示具体逻辑卷的大小 -n表示逻辑卷的名称</p>
<ol start="9">
<li>创建文件系统并挂载<br>逻辑卷和使用福利分区一样，需要先创建文件系统  挂载后才能被系统使用。<br>创建文件系统    mkfs.ext3 /dev/first_VG/first_LV<br>创建一个挂载点  mkdir /root/newLV<br>挂载 mount  /dev/first_VG/first_LV/root/newLV</li>
</ol>
<p>10.硬链接<br>在linux系统中，所有的文件都会有一个编号，成为索引节点。多个文件名指向同一索引节点，这种链接称为硬链接。<br>删除一个链接不会影响索引节点本身和其他链接，只有最后一个链接被删除时，文件的数据块以及目录的链接才会被释放。<br>硬链接有两个限制：<br>不允许给目录创建硬链接；<br>只有在同一个文件系统的文件才可以创建链接。</p>
<p>ls  -li显示文件<br>4849841 drwxr-xr-x  2 zhuningning zhuningning      4096 Sep 11 20:32 ./<br>第一列表示索引节点<br> 第三列表示源文件的关联数，<br>只有此数为0的时候才会真正的被文件系统删除</p>
<p>创建方法： ln  test.txt  test_ln    为test.txt 文件创建链接</p>
<p>11.软链接<br>是指一个包含了另一个文件路径名的文件，可以指向任意文件或者目录，他也不可以跨文件系统。<br>如果删除了源文件，软链接则会断链。(在linux下，会使用特殊标记表示该文件时断链。)<br>源文件和软链接文件的inode时不一样的，代表他们时2个不一样的文件。<br>创建软链接 ln -s  test.txt  test_ln.txt</p>
<h1 id="字符处理"><a href="#字符处理" class="headerlink" title="字符处理"></a>字符处理</h1><p>1.管道：它时一个固定大小的缓冲区，该缓冲区的大小为一字节。<br>2.它可以把一个命令的输入内容当做下一个命令的输入内容，两个命令之间只需要使用管道符  “|” 连接即可。<br>3. 比如：<br>ls -l  /etc/init.d/ |more (第一个命令的输入作为第二个命令的输入)<br>4.grep是基于行的文本搜索工具，<br>参数：<br>-i 不区分大小写<br>-c 统计包含匹配的行数<br>-n 输出行号<br>-v反向匹配</p>
<p>5.sort 对输出内容直接排序<br>参数<br>-n 采用数字排序<br>-t 指定分隔符<br>-k 指定第几行<br>-r 反向排序</p>
<p>cat  sort.txt  | sort<br>默认按照每行的第一个字母进行排序<br>a:4<br>b:3<br>c:2<br>d:1<br>e:5<br>f:11</p>
<p>cat sort.txt |sort -t “:” -k 2<br>d:1<br>f:11<br>c:2<br>b:3<br>a:4<br>e:5</p>
<p>6.uniq 删除连续的完全一致的行<br>参数：<br>-i 忽略大小写<br>-c 计算重复行数<br>cat uniq.txt |uniq<br>abc<br>123<br>abc<br>123<br>cat uniq.txt |sort|uniq -c<br> 2 123<br>          2 abc</p>
<p>7.使用cut截取文本<br>cut  -f 指定的行  -d ‘分隔符’<br>cat /etc/passwd |cut -f1 -d ‘:’</p>
<p>cut -c 指定列的字符<br>cat /etc/passwd |cut -c1-5,7-10</p>
<p>8 split 分割文件</p>
<p>9 paste合并文件</p>
<p>10.split</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux,文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title>linux入门-用户管理</title>
    <url>/2018-02-10/linux%E5%85%A5%E9%97%A8-%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h1 id="linux用户和用户组"><a href="#linux用户和用户组" class="headerlink" title="linux用户和用户组"></a>linux用户和用户组</h1><p>linux是一个多用户分时系统,想要使用系统必须使用账号,而且账号必须设置密码.各个用户可以设置不同的文件权限,保证不同用户的数据安全.各个账号都有对应的用户id和用户组id.</p>
<h2 id="UID和GID"><a href="#UID和GID" class="headerlink" title="UID和GID"></a>UID和GID</h2><p>为了区分不同的用户,我们可以根据用户名去区分,但是对于OS,它其实是没有意义的字符串.linux采用32位的整数来记录用户id,简称UID,计算机会记录用户id和用户名称的关系.linux用户分为三种:普通用户,根用户和系统用户.</p>
<ul>
<li>普通用户</li>
</ul>
<p>普通用户是指使用linux系统的真是用户,这类用户的用户名/密码/权限都有详细的设置.普通用户只能在家目录/系统临时目录或其它授权的目录下操作.普通用户的id从500开始.</p>
<ul>
<li>根用户</li>
</ul>
<p>根用户也是root用户,它的id为0,也就是超级用户.root用户拥有对系统的完全控制权.</p>
<ul>
<li>系统用户</li>
</ul>
<p>系统用户是指系统运行时必须要有的用户,但并不是真实的使用者.id范围为1至500</p>
<h2 id="查看当前用户的groupId和userId"><a href="#查看当前用户的groupId和userId" class="headerlink" title="查看当前用户的groupId和userId"></a>查看当前用户的groupId和userId</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~$ id</span><br><span class="line">uid&#x3D;1000(zhuningning) gid&#x3D;1000(zhuningning) 组&#x3D;1000(zhuningning),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),113(lpadmin),128(sambashare)</span><br></pre></td></tr></table></figure>
<h2 id="查看用户所属的用户组"><a href="#查看用户所属的用户组" class="headerlink" title="查看用户所属的用户组"></a>查看用户所属的用户组</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~$ groups</span><br><span class="line">zhuningning adm cdrom sudo dip plugdev lpadmin sambashare</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="查看当前登录的用户"><a href="#查看当前登录的用户" class="headerlink" title="查看当前登录的用户"></a>查看当前登录的用户</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~$ who</span><br><span class="line">zhuningning tty7         2018-05-31 02:04 (:0)</span><br><span class="line">zhuningning@ubuntu:~$ w</span><br><span class="line"> 23:23:19 up 21:19,  1 user,  load average: 0.47, 0.52, 0.31</span><br><span class="line">USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT</span><br><span class="line">zhuningn tty7     :0               02:04   21:19m  2:18   0.20s &#x2F;sbin&#x2F;upstart --user</span><br><span class="line">zhuningning@ubuntu:~$ users</span><br><span class="line">zhuningning</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="记录系统的用户名和密码的信息的文件"><a href="#记录系统的用户名和密码的信息的文件" class="headerlink" title="记录系统的用户名和密码的信息的文件"></a>记录系统的用户名和密码的信息的文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &#x2F;etc&#x2F;passwd</span><br><span class="line">cat &#x2F;etc&#x2F;shadow</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="查看隐藏的文件"><a href="#查看隐藏的文件" class="headerlink" title="查看隐藏的文件"></a>查看隐藏的文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;home$ ls -la</span><br><span class="line">总用量 20</span><br><span class="line">drwxr-xr-x  5 root        root        4096 Sep 10  2017 .</span><br><span class="line">drwxr-xr-x 24 root        root        4096 May  9 07:06 ..</span><br><span class="line">drwxr-xr-x  2        1003        1003 4096 Sep 10  2017 chenweijie</span><br><span class="line">drwxr-xr-x  2 chenwj      chenwj      4096 Sep 10  2017 chenwj</span><br><span class="line">drwxr-xr-x 51 zhuningning zhuningning 4096 May 31 02:04 zhuningning</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="新建用户"><a href="#新建用户" class="headerlink" title="新建用户"></a>新建用户</h2><ol>
<li>adduser john 添加用户</li>
<li>useradd -u 555 user1   为用户user1指定uId ,当然该id必须是唯一的</li>
<li>useradd -g user1 user2   为用户user2指定用户组为user1 </li>
<li>useradd -d /home/mydir3 user3  为user3指定家目录</li>
</ol>
<h2 id="修改密码"><a href="#修改密码" class="headerlink" title="修改密码"></a>修改密码</h2><p>用户创建后没有密码是不可以登录系统的，只有设置了密码才可以登录系统。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;home$ sudo passwd chenweijie</span><br><span class="line">输入新的 UNIX 密码： </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="关于添加用户以及授权的操作"><a href="#关于添加用户以及授权的操作" class="headerlink" title="关于添加用户以及授权的操作"></a>关于添加用户以及授权的操作</h2><p>1.adduser  chenweijie 添加用户</p>
<p>2.授权 修改 /etc/sudoers 文件，找到下面一行，在root下面添加一行，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Allow root to run any commands anywhere</span><br><span class="line">root    ALL&#x3D;(ALL)     ALL</span><br><span class="line">chenweijie   ALL&#x3D;(ALL)     ALL</span><br></pre></td></tr></table></figure>

<p>3.语法:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">     useradd 选项 用户名</span><br><span class="line">语义:</span><br><span class="line">  -c comment            指定一段注释性描述。</span><br><span class="line">  -d 目录                   指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。</span><br><span class="line">  -g 用户组               指定用户所属的用户组。</span><br><span class="line">  -G 用户组 用户组   指定用户所属的附加组。</span><br><span class="line">  -s Shell文件            指定用户的登录Shell。</span><br><span class="line">  -u 用户号               指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号。</span><br><span class="line">  用户名                   指定新用户的登录名。</span><br><span class="line">userdel 选项 用户名</span><br><span class="line"></span><br><span class="line">选项:</span><br><span class="line">  -r,  把用户的主目录一起删除。</span><br><span class="line"> usermod 选项 用户名</span><br><span class="line">选项:</span><br><span class="line">   包括-c, -d, -m, -g, -G, -s, -u以及-o等,</span><br><span class="line">   这些选项的意义与useradd命令中的选项一样，可以为用户指定新的资源值。另外，有些系统可以使用如下选项：</span><br><span class="line">   -l 新用户名  指定一个新的账号，即将原来的用户名改为新的用户名。</span><br><span class="line"></span><br><span class="line">usermod -G groupname username 给已有的用户增加工作组</span><br><span class="line">newgrp   groupName 切换到用户组 以获取该组的权限</span><br><span class="line">groups 查看该当前用户所属的用户组，第一个是主要用户组。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="关于用户权限的操作"><a href="#关于用户权限的操作" class="headerlink" title="关于用户权限的操作"></a>关于用户权限的操作</h2><p>添加组的命令： groupadd 组名 。 （在root管理权限）</p>
<p>查看linux中所有组的信息： cat /etc/group 。</p>
<p>创建用户，并同时指定将该用户分配到哪个组里： useradd -g 组名 用户名。 （在root管理权限）</p>
<p>查看linux中所有用户的信息： cat /etc/passwd 。</p>
<p>更改某个用户所在的组： usermod -g 组名 用户名。 （在root管理权限）</p>
<h2 id="用户的切换"><a href="#用户的切换" class="headerlink" title="用户的切换"></a>用户的切换</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">exit 退出当前用户。</span><br><span class="line"></span><br><span class="line">su - 切换到用root用户是，不但身份变成了root ，而且还可以是用root的用户环境。</span><br><span class="line"></span><br><span class="line">sudo 是在sudo后加上要使用的命令，但是需要为该用户配置 &#x2F;etc&#x2F;sudoers 中的权限 </span><br><span class="line">        root    ALL&#x3D;(ALL:ALL) ALL 改命令表示该用户可以在任何地方登录后执行任何人的任何命令。</span><br><span class="line">        但是每次需要输入密码，如果想要不输入密码，则可以在最后设置为 NOPASSWD :ALL</span><br><span class="line">su是切换用户，su -是切换用户并且使用用户的环境，而sudo并没有切换用户，而是使用用户的身份和权限执行了命令。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="例行任务管理"><a href="#例行任务管理" class="headerlink" title="例行任务管理"></a>例行任务管理</h2><p>1.单一时刻执行一次任务  at      atrm</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">at  now + 20 minutes </span><br><span class="line">&#x2F;sbin&#x2F;shutdown -h now</span><br><span class="line">执行组合键 ctrl+D</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.atq</p>
<p>查看任务队列</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~$ atq</span><br><span class="line">4    Fri Jun  1 01:05:00 2018 a zhuningning</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>3.atrm taskNum</p>
<p>删除任务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~$ atrm 4</span><br><span class="line">zhuningning@ubuntu:~$ atq</span><br><span class="line">zhuningning@ubuntu:~$</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>4.周期性的执行任务  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">先启动:service crond start </span><br><span class="line"></span><br><span class="line">编辑：crontab -e</span><br><span class="line"> </span><br><span class="line">查看任务:crontab -l </span><br><span class="line"></span><br><span class="line">删除所有的任务 : crontab -r </span><br><span class="line"></span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux入门</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-Sentinel</title>
    <url>/2018-01-26/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-Sentinel/</url>
    <content><![CDATA[<p>Sentinel是redis的高可用性(High availability)的解决方案.有一个或者多个Sentinel的实例组成的Sentinel系统可以监视任意多个主服务器以及这些主服务器下的从服务器.当主服务下线的时候,从服务器会成为主服务器来执行主服务器的任务.</p>
<p>双环代表主服务器,单环代表从服务器</p>
<p><img src="/images/redis/sentinel/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BB%A5Sentinel%E7%B3%BB%E7%BB%9F.png" alt="服务器以Sentinel系统"></p>
<p>在主服务下线的时候,三个从服务器停止对主服务器的复制.</p>
<p><img src="/images/redis/sentinel/%E4%B8%BB%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8B%E7%BA%BF.png" alt="主服务器下线"></p>
<p>当server1的下线时间超过用户设定的下线时长上限时,sentinel系统会对server1进行故障转移.</p>
<ol>
<li>首先sentinel系统挑选server1属下的其中一个从服务器,并将这个被选中的从服务器升级为新的主服务器.</li>
<li>之后,sentinel系统会向server1属下的所有从服务器发送新的复制指令,让他们成为新的主服务器的从服务器.当所有的从服务器都开始复制新的主服务器时,故障转移操作执行完毕.</li>
<li>另外,sentinel会继续监视server1,并在它重新上线时,将他设置为新的主服务器的从服务器.</li>
</ol>
<p><img src="/images/redis/sentinel/%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E4%BB%A5%E5%8F%8A%E5%8E%9F%E6%9D%A5%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%81%A2%E5%A4%8D.png" alt="故障转移以及原来的服务器恢复"></p>
<h1 id="启动并初始化Sentinel"><a href="#启动并初始化Sentinel" class="headerlink" title="启动并初始化Sentinel"></a>启动并初始化Sentinel</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redis-3.2.10&#x2F;src$ .&#x2F;redis-sentinel ..&#x2F;sentinel.conf &amp;</span><br><span class="line">[2] 13772</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redis-3.2.10&#x2F;src$ 13772:X 27 Jan 01:05:25.512 * Increased maximum number of open files to 10032 (it was originally set to 1024).</span><br><span class="line">                _._                                                  </span><br><span class="line">           _.-&#96;&#96;__ &#39;&#39;-._                                             </span><br><span class="line">      _.-&#96;&#96;    &#96;.  &#96;_.  &#39;&#39;-._           Redis 3.2.10 (00000000&#x2F;0) 64 bit</span><br><span class="line">  .-&#96;&#96; .-&#96;&#96;&#96;.  &#96;&#96;&#96;\&#x2F;    _.,_ &#39;&#39;-._                                   </span><br><span class="line"> (    &#39;      ,       .-&#96;  | &#96;,    )     Running in sentinel mode</span><br><span class="line"> |&#96;-._&#96;-...-&#96; __...-.&#96;&#96;-._|&#39;&#96; _.-&#39;|     Port: 26379</span><br><span class="line"> |    &#96;-._   &#96;._    &#x2F;     _.-&#39;    |     PID: 13772</span><br><span class="line">  &#96;-._    &#96;-._  &#96;-.&#x2F;  _.-&#39;    _.-&#39;                                   </span><br><span class="line"> |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  </span><br><span class="line"> |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |           http:&#x2F;&#x2F;redis.io        </span><br><span class="line">  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   </span><br><span class="line"> |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  </span><br><span class="line"> |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |                                  </span><br><span class="line">  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   </span><br><span class="line">      &#96;-._    &#96;-.__.-&#39;    _.-&#39;                                       </span><br><span class="line">          &#96;-._        _.-&#39;                                           </span><br><span class="line">              &#96;-.__.-&#39;                                               </span><br><span class="line"></span><br><span class="line">13772:X 27 Jan 01:05:25.514 # WARNING: The TCP backlog setting of 511 cannot be enforced because &#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;somaxconn is set to the lower value of 128.</span><br><span class="line">13772:X 27 Jan 01:05:25.514 # Sentinel ID is 9aa0e1e3a36ac2fa2e414ba752645816167f943e</span><br><span class="line">13772:X 27 Jan 01:05:25.514 # +monitor master mymaster 127.0.0.1 6379 quorum 2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>启动Sentinel的时候,它要执行以下操作</p>
<ol>
<li>初始化服务器。</li>
<li>将普通 Redis 服务器使用的代码替换成 Sentinel 专用代码。</li>
<li>初始化 Sentinel 状态。</li>
<li>根据给定的配置文件， 初始化 Sentinel 的监视主服务器列表。</li>
<li>创建连向主服务器的网络连接。</li>
</ol>
<h2 id="初始化服务器"><a href="#初始化服务器" class="headerlink" title="初始化服务器"></a>初始化服务器</h2><p>首先， 因为 Sentinel 本质上只是一个运行在特殊模式下的 Redis 服务器， 所以启动 Sentinel 的第一步， 就是初始化一个普通的 Redis 服务器， 具体的步骤和《服务器》一章介绍的类似。</p>
<p>不过， 因为 Sentinel 执行的工作和普通 Redis 服务器执行的工作不同， 所以 Sentinel 的初始化过程和普通 Redis 服务器的初始化过程并不完全相同。</p>
<h2 id="使用-Sentinel-专用代码"><a href="#使用-Sentinel-专用代码" class="headerlink" title="使用 Sentinel 专用代码"></a>使用 Sentinel 专用代码</h2><p>比如说， 普通 Redis 服务器使用 redis.h/REDIS_SERVERPORT 常量的值作为服务器端口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define REDIS_SERVERPORT 6379</span><br></pre></td></tr></table></figure>
<p>而 Sentinel 则使用 sentinel.c/REDIS_SENTINEL_PORT 常量的值作为服务器端口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define REDIS_SENTINEL_PORT 26379</span><br></pre></td></tr></table></figure>

<p> Redis 服务器不能执行诸如 SET 、 DBSIZE 、 EVAL 等等这些命令 —— 因为服务器根本没有在命令表中载入这些命令： PING 、 SENTINEL 、 INFO 、 SUBSCRIBE 、 UNSUBSCRIBE 、 PSUBSCRIBE 和 PUNSUBSCRIBE 这七个命令就是客户端可以对 Sentinel 执行的全部命令了。</p>
<h2 id="初始化Sentinel状态"><a href="#初始化Sentinel状态" class="headerlink" title="初始化Sentinel状态"></a>初始化Sentinel状态</h2><p>在应用了 Sentinel 的专用代码之后， 接下来， 服务器会初始化一个 sentinel.c/sentinelState 结构</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct sentinelState &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 当前纪元，用于实现故障转移</span><br><span class="line">    uint64_t current_epoch;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 保存了所有被这个 sentinel 监视的主服务器</span><br><span class="line">    &#x2F;&#x2F; 字典的键是主服务器的名字</span><br><span class="line">    &#x2F;&#x2F; 字典的值则是一个指向 sentinelRedisInstance 结构的指针</span><br><span class="line">    dict *masters;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 是否进入了 TILT 模式？</span><br><span class="line">    int tilt;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 目前正在执行的脚本的数量</span><br><span class="line">    int running_scripts;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 进入 TILT 模式的时间</span><br><span class="line">    mstime_t tilt_start_time;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 最后一次执行时间处理器的时间</span><br><span class="line">    mstime_t previous_time;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 一个 FIFO 队列，包含了所有需要执行的用户脚本</span><br><span class="line">    list *scripts_queue;</span><br><span class="line"></span><br><span class="line">&#125; sentinel;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="初始化-Sentinel-状态的-masters-属性"><a href="#初始化-Sentinel-状态的-masters-属性" class="headerlink" title="初始化 Sentinel 状态的 masters 属性"></a>初始化 Sentinel 状态的 masters 属性</h2><p>Sentinel 状态中的 masters 字典记录了所有被 Sentinel 监视的主服务器的相关信息， 其中：</p>
<ol>
<li>字典的键是被监视主服务器的名字。</li>
<li>而字典的值则是被监视主服务器对应的 sentinel.c/sentinelRedisInstance 结构。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct sentinelRedisInstance &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 标识值，记录了实例的类型，以及该实例的当前状态</span><br><span class="line">    int flags;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 实例的名字</span><br><span class="line">    &#x2F;&#x2F; 主服务器的名字由用户在配置文件中设置</span><br><span class="line">    &#x2F;&#x2F; 从服务器以及 Sentinel 的名字由 Sentinel 自动设置</span><br><span class="line">    &#x2F;&#x2F; 格式为 ip:port ，例如 &quot;127.0.0.1:26379&quot;</span><br><span class="line">    char *name;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 实例的运行 ID</span><br><span class="line">    char *runid;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 配置纪元，用于实现故障转移</span><br><span class="line">    uint64_t config_epoch;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 实例的地址</span><br><span class="line">    sentinelAddr *addr;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; SENTINEL down-after-milliseconds 选项设定的值</span><br><span class="line">    &#x2F;&#x2F; 实例无响应多少毫秒之后才会被判断为主观下线（subjectively down）</span><br><span class="line">    mstime_t down_after_period;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; SENTINEL monitor &lt;master-name&gt; &lt;IP&gt; &lt;port&gt; &lt;quorum&gt; 选项中的 quorum 参数</span><br><span class="line">    &#x2F;&#x2F; 判断这个实例为客观下线（objectively down）所需的支持投票数量</span><br><span class="line">    int quorum;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; SENTINEL parallel-syncs &lt;master-name&gt; &lt;number&gt; 选项的值</span><br><span class="line">    &#x2F;&#x2F; 在执行故障转移操作时，可以同时对新的主服务器进行同步的从服务器数量</span><br><span class="line">    int parallel_syncs;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; SENTINEL failover-timeout &lt;master-name&gt; &lt;ms&gt; 选项的值</span><br><span class="line">    &#x2F;&#x2F; 刷新故障迁移状态的最大时限</span><br><span class="line">    mstime_t failover_timeout;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">&#125; sentinelRedisInstance;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Sentinel启动时会载入以下内容的配置文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#####################</span><br><span class="line"># master1 configure #</span><br><span class="line">#####################</span><br><span class="line"></span><br><span class="line">sentinel monitor master1 127.0.0.1 6379 2</span><br><span class="line"></span><br><span class="line">sentinel down-after-milliseconds master1 30000</span><br><span class="line"></span><br><span class="line">sentinel parallel-syncs master1 1</span><br><span class="line"></span><br><span class="line">sentinel failover-timeout master1 900000</span><br><span class="line"></span><br><span class="line">#####################</span><br><span class="line"># master2 configure #</span><br><span class="line">#####################</span><br><span class="line"></span><br><span class="line">sentinel monitor master2 127.0.0.1 12345 5</span><br><span class="line"></span><br><span class="line">sentinel down-after-milliseconds master2 50000</span><br><span class="line"></span><br><span class="line">sentinel parallel-syncs master2 5</span><br><span class="line"></span><br><span class="line">sentinel failover-timeout master2 450000</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/images/redis/sentinel/master1%E7%9A%84%E5%AE%9E%E4%BE%8B%E7%BB%93%E6%9E%84.png" alt="master1的实例结构"></p>
<p><img src="/images/redis/sentinel/master2%E7%9A%84%E5%AE%9E%E4%BE%8B%E7%BB%93%E6%9E%84.png" alt="master2的实例结构"></p>
<p><img src="/images/redis/sentinel/sentinel%E7%8A%B6%E6%80%81%E4%BB%A5%E5%8F%8Amaster%E5%AD%97%E5%85%B8.png" alt="sentinel状态以及master字典"></p>
<h2 id="创建连向主服务器的网络连接"><a href="#创建连向主服务器的网络连接" class="headerlink" title="创建连向主服务器的网络连接"></a>创建连向主服务器的网络连接</h2><p>对于每个被 Sentinel 监视的主服务器来说， Sentinel 会创建两个连向主服务器的异步网络连接：</p>
<ol>
<li>一个是命令连接， 这个连接专门用于向主服务器发送命令， 并接收命令回复。</li>
<li>另一个是订阅连接， 这个连接专门用于订阅主服务器的 <strong>sentinel</strong>:hello 频道。</li>
</ol>
<h1 id="获取主服务器的信息"><a href="#获取主服务器的信息" class="headerlink" title="获取主服务器的信息"></a>获取主服务器的信息</h1><p>Sentinel默认会以每十秒一次的频率,通过命令连接向被监视的<strong>主服务</strong>器发送INFO命令.并通过分析info命令的回复来获取主服务器的当前信息.</p>
<p><img src="/images/redis/sentinel/info%E5%91%BD%E4%BB%A4%E7%9A%84%E5%9B%9E%E5%A4%8D.png" alt="info命令的回复"></p>
<p>Sentinel在分析info命令返回的信息中对应的从服务器的实例是否在slave字典中存在而做出相应的操作.</p>
<p><img src="/images/redis/sentinel/%E4%B8%BB%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E5%AE%83%E7%9A%84%E4%B8%89%E4%B8%AA%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8.png" alt="主服务器和它的三个从服务器"></p>
<h1 id="获取从服务器信息"><a href="#获取从服务器信息" class="headerlink" title="获取从服务器信息"></a>获取从服务器信息</h1><p>当Sentinel发现主服务器有新的从服务器出现时.Sentinel除了会为这个新的从服务器创建相应的实例结构外,Sentinel还会创建连接到从服务器的命令连接和订阅连接.</p>
<p><img src="/images/redis/sentinel/sentinel%E4%B8%8E%E5%90%84%E4%B8%AA%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BB%BA%E7%AB%8B%E5%91%BD%E4%BB%A4%E8%BF%9E%E6%8E%A5%E5%92%8C%E8%AE%A2%E9%98%85%E8%BF%9E%E6%8E%A5.png" alt="sentinel与各个从服务器建立命令连接和订阅连接"></p>
<p>Sentinel默认会以每十秒一次的频率,通过命令连接向被监视的<strong>从服务</strong>器发送INFO命令.并通过分析info命令的回复来获取主服务器的当前信息.</p>
<p><img src="/images/redis/sentinel/%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%9B%9E%E5%A4%8D.png" alt="从服务器的回复"></p>
<p><img src="/images/redis/sentinel/%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%9E%E4%BE%8B%E7%BB%93%E6%9E%84.png" alt="从服务器的实例结构"></p>
<h1 id="向主服务器和从服务器发送信息"><a href="#向主服务器和从服务器发送信息" class="headerlink" title="向主服务器和从服务器发送信息"></a>向主服务器和从服务器发送信息</h1><p>默认情况下,Sentinel会以每两秒一次的频率,通过命令连接向所有被监视的主服务器和从服务器发送以下格式命令:</p>
<p><img src="/images/redis/sentinel/sentinel%E5%8F%91%E9%80%81%E5%91%BD%E4%BB%A4%E7%9A%84%E6%A0%BC%E5%BC%8F.png" alt="sentinel发送命令的格式"></p>
<h1 id="接收来自主服务器和从服务器的频道信息"><a href="#接收来自主服务器和从服务器的频道信息" class="headerlink" title="接收来自主服务器和从服务器的频道信息"></a>接收来自主服务器和从服务器的频道信息</h1><p>每个Sentinel连接的服务器.Sentinel既会通过命令连接向服务器的<em>Sentinel</em>:hello频道发送信息.又通过订阅连接从服务器的<em>Sentinel</em>:hello频道接收信息.</p>
<p>对于多个Sentinel来说,一个Sentinel发送的信息会被其它Sentinel接收到,以更新他们对监视服务器的认知.</p>
<h2 id="更新Sentinels字典"><a href="#更新Sentinels字典" class="headerlink" title="更新Sentinels字典"></a>更新Sentinels字典</h2><p>每个Sentinel实例中的Sentinels字典中保存这其它Sentinel实例的信息.各个Sentinel的ip和port就是该Sentinel字典中的key,而value就是Sentinel的实体结构</p>
<p>每次接收来自其它实例的信息时,各个实例都会更新其它实例在自己字典中的信息.</p>
<h2 id="创建连向其它Sentinel的命令连接"><a href="#创建连向其它Sentinel的命令连接" class="headerlink" title="创建连向其它Sentinel的命令连接"></a>创建连向其它Sentinel的命令连接</h2><p>当Sentinel通过频道信息发现一个新的Sentinel时,它不仅会为Sentinel在Sentinels字典中创建相应的实例结构,还会创建一个连向新Sentinel的命令连接.而新的Sentinel也会创建连向这个Sentinel的连接,最终监视同一个服务器的多个Sentinel会形成相互连接的网络</p>
<p>这样,各个Sentinel会通过其它Sentinel发来的命令交换信息.</p>
<ul>
<li>注意 Sentinel之间不会创建订阅连接.</li>
</ul>
<h1 id="检测主观下线状态"><a href="#检测主观下线状态" class="headerlink" title="检测主观下线状态"></a>检测主观下线状态</h1><p>默认Sentinel会以每秒一次的频率向所有与它创建了命令连接的实例(主从服务器,其它Sentinel在内)发送ping命令,通过他们的回复来判断他们是否在线.</p>
<p>Sentinel配置文件中的Down-after-milliseconds选项制定了Sentinel判断实例进入主观下线所需的时间长度.如果在该时间内无回复,则Sentinel会改变这个实例的对应的实例结构,在flags属性中打开SRI_S_Down表示,标志这该实例进入主管下线状态.</p>
<p>由于多个Sentinel的毫秒数设置的可能不同,所以各个Sentinel主观认为某个实例是否下线时不同的.</p>
<h1 id="检查客观下线状态"><a href="#检查客观下线状态" class="headerlink" title="检查客观下线状态"></a>检查客观下线状态</h1><p>当Sentinel将一个主服务器判断为主管下线之后,为了确认这个主服务器是否真的下线了,他会向同样监视这个主服务器的Sentinel进行询问.当从其它的Sentinel那接收到足够数量的已下线判断后,Sentinel会将主服务器判定为客观下线,并对主服务器执行故障转移操作</p>
<h2 id="发送Sentinel-is-master-down-by-addr命令"><a href="#发送Sentinel-is-master-down-by-addr命令" class="headerlink" title="发送Sentinel is-master-down-by-addr命令"></a>发送Sentinel is-master-down-by-addr命令</h2><p>![Sentinel is-master-down-by-addr各个参数的意义](/images/redis/sentinel/Sentinel is-master-down-by-addr各个参数的意义.png)</p>
<h2 id="接收Sentinel-is-master-down-by-addr命令"><a href="#接收Sentinel-is-master-down-by-addr命令" class="headerlink" title="接收Sentinel is-master-down-by-addr命令"></a>接收Sentinel is-master-down-by-addr命令</h2><p>![Sentinel is-master-down-by-addr回复的意义](/images/redis/sentinel/Sentinel is-master-down-by-addr回复的意义.png)</p>
<h2 id="接收Sentinel-is-master-down-by-addr的回复"><a href="#接收Sentinel-is-master-down-by-addr的回复" class="headerlink" title="接收Sentinel is-master-down-by-addr的回复"></a>接收Sentinel is-master-down-by-addr的回复</h2><p>根据Sentinel同意主服务器已下线的数量(quorum参数的值),当达到所需的数量,则将主服务器的flags属性的SRI_O_DOWN标示打开,表示主服务器已经进入客观下线状态</p>
<p>Sentinel monitor master 127.0.0.1 6379 2 包括当前的Sentinel在日,有2个Sentinel觉得主服务器已经下线,则当前Sentinel才会将主服务器判断为客观下线.</p>
<h1 id="选举领头-Sentinel"><a href="#选举领头-Sentinel" class="headerlink" title="选举领头 Sentinel"></a>选举领头 Sentinel</h1><p>当一个主服务器被判定为客观下线时.监视这个下线主服务器的各个Sentinel会进行协商,选举一个领头Sentinel,并由它对下线主服务器进行故障转移.</p>
<p>选举领头Sentinel的法则:</p>
<p><img src="/images/redis/sentinel/%E9%80%89%E4%B8%BE%E9%A2%86%E5%A4%B4Sentinel%E7%9A%84%E6%B3%95%E5%88%991.png" alt="选举领头Sentinel的法则1"></p>
<p><img src="/images/redis/sentinel/%E9%80%89%E4%B8%BE%E9%A2%86%E5%A4%B4Sentinel%E7%9A%84%E6%B3%95%E5%88%992.png" alt="选举领头Sentinel的法则2"></p>
<h1 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h1><p>领头的Sentinel对已下线的主服务器执行故障转移,操作如下</p>
<ol>
<li>在已下线的主服务器属下的所有从服务器里面,选一个从服务器将其转换为主服务器.</li>
<li>让已下线的服务器属下的所有从服务器改为复制新的主服务器.</li>
<li>将已下线的主服务器设置为新的主服务器的从服务器,待其上线后,它将成为新的额主服务器的从服务器.</li>
</ol>
<h2 id="选出的新的主服务器"><a href="#选出的新的主服务器" class="headerlink" title="选出的新的主服务器"></a>选出的新的主服务器</h2><p>故障转移操作的第一步就是在已下线的主服务器的属下的所有从服务器中,选出一个状态良好.数据完整的从服务器,然后向这个从服务器发送slave no one命令.将它由从服务器变为主服务器.</p>
<p>主服务的挑选规则:</p>
<p><img src="/images/redis/sentinel/%E4%B8%BB%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%8C%91%E9%80%89%E8%A7%84%E5%88%99.png" alt="主服务的挑选规则"></p>
<h2 id="修改从服务器的复制目标"><a href="#修改从服务器的复制目标" class="headerlink" title="修改从服务器的复制目标"></a>修改从服务器的复制目标</h2><p>当新的主服务器出现之后,领头Sentinel下一步做的就是让所有的从服务器去复制新的主服务器.这一动作通过<strong>领头Sentinel</strong>向从服务器发送SLAVEOF命令来实现</p>
<p><img src="/images/redis/sentinel/%E8%AE%A9%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%A4%8D%E5%88%B6%E6%96%B0%E7%9A%84%E4%B8%BB%E6%9C%8D%E5%8A%A1%E5%99%A8.png" alt="让从服务器复制新的主服务器"></p>
<p><img src="/images/redis/sentinel/server3%E5%92%8Cserver4%E6%88%90%E4%B8%BAserver2%E7%9A%84%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8.png" alt="server3和server4成为server2的从服务器"></p>
<h2 id="让旧的主服务器成为从服务器"><a href="#让旧的主服务器成为从服务器" class="headerlink" title="让旧的主服务器成为从服务器"></a>让旧的主服务器成为从服务器</h2><p>由于旧的主服务器已经下线,所以这种操作时保存在在server1对应的实例结构里面的.当server1重新上线后,Sentinel会向它发送SLAVEOF命令,让server1成为server2的从服务器.</p>
<p><img src="/images/redis/sentinel/server1%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BF%E6%88%90%E4%B8%BAserver2%E7%9A%84%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8.png" alt="server1重新上线成为server2的从服务器"></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Sentinel,redis</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-事件</title>
    <url>/2018-01-14/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E4%BA%8B%E4%BB%B6/</url>
    <content><![CDATA[<p>redis服务器时一个事件驱动程序,服务器需要处理以下两类事件.</p>
<ul>
<li><p>文件事件:redis服务器通过套接字与客户端进行连接.而文件事件就是服务器对套接字的抽象.服务器与客户端的通信会产生相应的文件事件,服务器监听并处理这些事件来完成一些列网络操作.</p>
</li>
<li><p>时间事件:redis服务器中的一些操作需要在给定的时间点执行,而时间事件就是对这类定时操作的抽象</p>
</li>
</ul>
<h1 id="文件事件"><a href="#文件事件" class="headerlink" title="文件事件"></a>文件事件</h1><p>redis基于Reactor模式开发了自己的网络事件处理器:这个处理器被成为文件处理器.</p>
<p>文件事件处理器使用I/O多路复用来监听多个套接字,并根据套接字目前执行的任务来为套接字关联不同的事件处理器</p>
<p>当被监听的套接字准备好执行连接应答/读取/写入/关闭操作时,与操作对应的文件事件就会产生.这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件.</p>
<h2 id="文件事件处理器的构成"><a href="#文件事件处理器的构成" class="headerlink" title="文件事件处理器的构成"></a>文件事件处理器的构成</h2><p>以下是文件事件处理器的四个组成部分:</p>
<p><img src="/images/redis/event/%E6%96%87%E4%BB%B6%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E5%99%A8.png" alt="文件事件处理器"></p>
<p>文件事件会并发的出现,但是I/O多路复用程序总是会将所有产生事件的套接字放到一个队列,然后通过队列进行后续处理.</p>
<h2 id="事件的类型"><a href="#事件的类型" class="headerlink" title="事件的类型"></a>事件的类型</h2><p>当客户端变得可读时(客户端对套接字执行write操作,或者执行close操作)或者有新的应答套接字出现时(客户端对服务器监听的套接字执行connect操作) 套接字产生<strong>AE_READABLE</strong>事件.</p>
<p>当套接字变得可读时(客户端对套接字执行read操作) 套接字产生<strong>AE_WRITEABLE</strong>事件</p>
<p>多路复用程序允许服务器同时监听以上两种事件,文件时间分配器会优先处理读事件,然后处理写事件.</p>
<h2 id="文件事件处理器"><a href="#文件事件处理器" class="headerlink" title="文件事件处理器"></a>文件事件处理器</h2><p>redis为文件事件编写了多个处理器:连接应答处理器,命令请求处理器,命令回复处理器,复制处理器</p>
<h1 id="时间事件"><a href="#时间事件" class="headerlink" title="时间事件"></a>时间事件</h1><p>redis时间事件分为定时事件和周期性事件</p>
<p>时间事件的属性:</p>
<ol>
<li>id:服务器为时间事件创建的全局唯一ID,从小到大递增.</li>
<li>when:毫秒精度的UNIX时间戳,记录了事件的到达事件.</li>
<li>timeProc:事件处理器,一个函数.时间事件到达后,服务器就会调用相应的处理器来处理事件.</li>
</ol>
<p>如果事件处理器返回一个AE_NOMORE 那么这个事件为定时事件,该事件在被处理一次后就不再执行,而是被删除.</p>
<p>如果返回一个非AE_NOMORE 的这个事件时周期性事件,处理玩后,服务器会根据返回值对时间事件的属性when进行更新.</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>服务器的时间时间都放在一个无需链表中.运行时遍历整个链表,发现到达的时间事件,并调用相应的时间处理器.</p>
<p>如下:</p>
<p><img src="/images/redis/event/%E9%93%BE%E8%A1%A8%E8%BF%9E%E6%8E%A5%E8%B5%B7%E6%9D%A5%E7%9A%84%E4%B8%89%E4%B8%AA%E6%97%B6%E9%97%B4%E4%BA%8B%E4%BB%B6.png" alt="链表连接起来的三个时间事件"></p>
<p><img src="/images/redis/event/%E6%97%B6%E9%97%B4%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E5%99%A8%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="时间事件处理器伪代码实现"></p>
<h2 id="时间事件的应用实例-severCron函数"><a href="#时间事件的应用实例-severCron函数" class="headerlink" title="时间事件的应用实例:severCron函数"></a>时间事件的应用实例:severCron函数</h2><p>持续运行的服务器需要对自身的资源和状态进行检查和调整.主要由serverCron函数来执行,主要功能如下:</p>
<p><img src="/images/redis/event/serverCron%E5%87%BD%E6%95%B0%E7%9A%84%E6%89%A7%E8%A1%8C%E7%9A%84%E5%8A%9F%E8%83%BD.png" alt="serverCron函数的执行的功能"></p>
<p>serverCron函数每秒运行10次.</p>
<h1 id="事件的调度和执行"><a href="#事件的调度和执行" class="headerlink" title="事件的调度和执行"></a>事件的调度和执行</h1><p>事件的调度和执行规则</p>
<p><img src="/images/redis/event/%E4%BA%8B%E4%BB%B6%E7%9A%84%E8%B0%83%E5%BA%A6%E5%92%8C%E6%89%A7%E8%A1%8C%E8%A7%84%E5%88%991.png" alt="事件的调度和执行规则1"></p>
<p><img src="/images/redis/event/%E4%BA%8B%E4%BB%B6%E7%9A%84%E8%B0%83%E5%BA%A6%E5%92%8C%E6%89%A7%E8%A1%8C%E8%A7%84%E5%88%992.png" alt="事件的调度和执行规则2"></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis事件</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-介绍</title>
    <url>/2017-12-20/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>可基于内存的、也可以持久化的日志型的、key-value形式的非关系型数据库<h2 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h2></li>
<li>是意大利的一家做实时统计系统的公司在使用mysql时，创始人Salvatore Sanfilippo发现mysql的性能非常低下。于2009年开发完成的redis数据库，并将该数据库开源。VMware公司从2010年赞助redis的开发。<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2></li>
<li>读写性能：读110000/s  写 80000/s</li>
<li>value支持的类型：string 、hash 、list 、set、 zset  、BitMap、 HyperLogLog 、 geospatial</li>
<li>所有的操作是原子操作</li>
<li>支持数据库的备份，支持主从备份（master-slave）</li>
<li>支持订阅发布、通知以及key过期等特性<h2 id="相同产品对比"><a href="#相同产品对比" class="headerlink" title="相同产品对比"></a>相同产品对比</h2></li>
<li>名称     类型    数据存储选项      查询类型        附加功能</li>
<li>Redis    使用内存存储（in-memory） 的非关系数据库。字符串、列表、集合、散列表、有序集合。每种数据类型都有自己的专属命令;另外还有批量操作（bulk operation）和不完全（partial）的事务支持;发布与订阅， 主从复制（master/slave replication）， 持久化， 脚本（存储过程，stored procedure）</li>
<li>memcached    使用内存存储的键值缓存;键值之间的映射; 创建命令、读取命令、更新命令、删除命令以及其他几个命令;为提升性能而设的多线程服务器</li>
<li>MySQL    关系数据库;每个数据库可以包含多个表，每个表可以包含多个行； 可以处理多个表的视图（view）； 支持空间（spatial）和第三方扩展;SELECT 、 INSERT 、 UPDATE 、 DELETE 、函数、存储过程;支持ACID性质（需要使用InnoDB）， 主从复制和主主复制 （master/master replication）</li>
<li>PostgreSQL    关系数据库 ;每个数据库可以包含多个表， 每个表可以包含多个行； 可以处理多个表的视图；  支持空间和第三方扩展；支持可定制类型    SELECT 、 INSERT 、 UPDATE 、 DELETE 、内置函数、自定义的存储过程    支持ACID性质，主从复制， 由第三方支持的多主复制 （multi-master replication）</li>
<li>MongoDB    使用硬盘存储（on-disk）的非关系文档存储;每个数据库可以包含多个表， 每个表可以包含多个无schema （schema-less）的BSON文档;创建命令、读取命令、更新命令、删除命令、条件查询命令，等等;    支持map-reduce操作，主从复制，分片， 空间索引（spatial index）</li>
</ul>
<h2 id="redis服务器命令"><a href="#redis服务器命令" class="headerlink" title="redis服务器命令"></a>redis服务器命令</h2><ul>
<li>启动服务命令  ./redis-server &amp;</li>
<li>启动客户端命令  ./redis-cli -h 127.0.0.1 -p 6379 -a password (远程启动)</li>
<li>ping 检测是否启动 如果启动返回的是pong</li>
<li>查看配置的命令 config get *   或者 info</li>
<li>保存当前数据库的数据到磁盘 save</li>
<li>恢复数据只需将备份文件（dump.rdb）放到安装目录启动服务即可（config get dir）</li>
<li>查看所有客户端 client list</li>
<li>查看数据库key的数量  dbsize</li>
<li>删除所有数据库的key  flushall</li>
</ul>
<h2 id="数据类型的基本命令"><a href="#数据类型的基本命令" class="headerlink" title="数据类型的基本命令"></a>数据类型的基本命令</h2><ul>
<li>String   存：set key value  取：get key  一个键最大存储512M</li>
<li>hash     存：hmset  key  name chen age 27   取 hgetall key (取一组数据)  hget key filed   删除：hdel key field2</li>
<li>list     存：lpush key value    取：lrange key index0   indexN</li>
<li>set      存: sadd key member  取：smembers key (不允许重复)</li>
<li>zset     存：zadd key score member  取:zrangebyscore  key 100 10000      或 zrange key 0 1000</li>
</ul>
<h2 id="keys操作命令"><a href="#keys操作命令" class="headerlink" title="keys操作命令"></a>keys操作命令</h2><ul>
<li>del key  删除操作</li>
<li>exists key 是否存在</li>
<li>expire key n  设置超时时间（s）</li>
<li>persist key  移除key的超时时间</li>
<li>ttl key  查看key的剩余超时时间 （-1代表永久存在）</li>
<li>rename  key newKey   修改key的名称</li>
<li>type key 返回可以的类型</li>
</ul>
<h2 id="发布订阅模式"><a href="#发布订阅模式" class="headerlink" title="发布订阅模式"></a>发布订阅模式</h2><ul>
<li>订阅：subscribe channel</li>
<li>发布：publish channel “some thing”</li>
</ul>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><ul>
<li>开始事务 命令入队 执行事务</li>
<li>multi    command   exec</li>
</ul>
<h2 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h2><ul>
<li>查看是否设置密码： config get requirepass</li>
<li>设置密码: config set requirepass “password”</li>
<li>登录验证: auth password</li>
</ul>
<h2 id="redis分区"><a href="#redis分区" class="headerlink" title="redis分区"></a>redis分区</h2><h2 id="java使用redis的相关操作"><a href="#java使用redis的相关操作" class="headerlink" title="java使用redis的相关操作"></a>java使用redis的相关操作</h2><h2 id="redis的数据类型的内部实现"><a href="#redis的数据类型的内部实现" class="headerlink" title="redis的数据类型的内部实现"></a>redis的数据类型的内部实现</h2><p><strong>首先Redis内部使用一个redisObject对象来表示所有的key和value。</strong></p>
<p>字段包括：数据类型（type）、编码方式（encoding）、数据指针（ptr）、虚拟内存（vm）、其他信息 （…）</p>
<p><code>type的值</code>：(String，hash，list，set，sorted set)</p>
<p><code>encoding</code> (raw,int,ht,zipmap,linkedlist,ziplist,intset)</p>
<p><code>vm字段</code>，只有打开了Redis的虚拟内存功能，此字段才会真正的分配内存，该功能默认是关闭状态的</p>
<p><strong>字符串</strong>可以被编码为 raw (常规字符串) 或者int (用字符串表示64位无符号整数这种编码方式是为了节省空间).</p>
<p><strong>列表类型</strong>可以被编码为ziplist 或者 linkedlist. ziplist 是为了节省较小的列表空间而设计一种特殊编码方式.</p>
<p><strong>集合被编码</strong>为 intset 或者 hashtable. intset 是为了存储数字的较小集合而设计的一种特殊编码方式.</p>
<p><strong>哈希表</strong>可以被编码为 zipmap 或者hashtable. zipmap 是专为了较小的哈希表而设计的一种特殊编码方式</p>
<p><strong>有序集合</strong>被编码为ziplist 或者 skiplist 格式. ziplist可以表示较小的有序集合, skiplist 表示任意大小多的有序集合.</p>
<h2 id="基本数据类型介绍"><a href="#基本数据类型介绍" class="headerlink" title="基本数据类型介绍"></a>基本数据类型介绍</h2><h3 id="String："><a href="#String：" class="headerlink" title="String："></a>String：</h3><ul>
<li>常用命令：</li>
</ul>
<p>set,get,decr,incr 等。</p>
<ul>
<li>应用场景：</li>
</ul>
<p>String是最常用的一种数据类型，普通的key/value存储都可以归为此类。</p>
<ul>
<li>实现方式：</li>
</ul>
<p>默认存储是二进制安全的字符串，被redisObject所引用，当遇到incr、decr操作时。将其转为数值型进行计算，此时redisObject的encoding类型为int</p>
<h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><ul>
<li>常用命令：</li>
</ul>
<p>hget,hset,hgetall 等。</p>
<ul>
<li>应用场景：</li>
</ul>
<p>根据用户id查找用户的姓名，年龄，出生地等信息。</p>
<ul>
<li>存储方式 </li>
</ul>
<p>1.key为id 将他的基本信息存到一个对象后以序列化的方式存储。 序列化发序列化成本高<br>2.key为id：姓名  key为id：年龄 多个key-value键值对存储。    多个键值对 不好维护<br>3.采用hash存储</p>
<ul>
<li>实现方式</li>
</ul>
<p>当成员较少时，为了节省内存，value的redisObject采用的encoding是zipmap；当数量增大时自动转为HashMap，此时encoding是ht这个限制可以在配置文件中指定（默认配置在redis根目录下的redis.conf中）</p>
<h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><ul>
<li>常用命令：</li>
</ul>
<p>lpush,rpush,lpop,rpop,lrange等。</p>
<ul>
<li>应用场景：</li>
</ul>
<p>Redis list的应用场景非常多，比如各种粉丝列表，不需要排序的列表</p>
<ul>
<li>实现方式：</li>
</ul>
<p>list的实现为一个双向链表，即可以支持反向查找和遍历。<br>如果redisObject的type成员值是REDIS_LIST类型的，则当该list的元素个数小于配置值list-max-ziplist-entries且元素值字符串的长度小于配置值list-max-ziplist-value则可以编码成 REDIS_ENCODING_ZIPLIST 类型存储，否则采用 Dict 来存储(Dict实际是Hash Table的一种实现，list采用ziplist数据结构存储数据，（默认配置在redis根目录下的redis.conf中）</p>
<h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><ul>
<li>常用命令：</li>
</ul>
<p>sadd,spop,smembers,sunion 等。</p>
<ul>
<li>应用场景：</li>
</ul>
<p>set类似于list，但可以自动排重。当你需要一个要求元素不能重复的集合是可以使用set</p>
<ul>
<li>实现方式：</li>
</ul>
<p>当set集合中的元素为整数且元素个数小于配置set-max-intset-entries值时，使用intset数据结构存储(int16_t类型、int32_t 类型、 int64_t 类型。至于怎么选择是那种类型的数组，是根据其保存的值的取值范围来决定的).否则转化为Dict结构，Dict实际是Hash Table的一种实现</p>
<h3 id="Sorted-set"><a href="#Sorted-set" class="headerlink" title="Sorted set"></a>Sorted set</h3><ul>
<li>常用命令：</li>
</ul>
<p>zadd,zrange,zrem,zcard等</p>
<ul>
<li>使用场景：</li>
</ul>
<p>当你需要一个有序的并且不重复的集合列表，那么 可以选择sorted set数据结构</p>
<ul>
<li>实现方式：</li>
</ul>
<p>Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的 是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率</p>
<h2 id="redis版本介绍"><a href="#redis版本介绍" class="headerlink" title="redis版本介绍"></a>redis版本介绍</h2><p><a href="http://book.51cto.com/art/201704/538507.htm">redis版本介绍</a></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis设计与实现</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-发布与订阅</title>
    <url>/2018-01-21/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E5%8F%91%E5%B8%83%E4%B8%8E%E8%AE%A2%E9%98%85/</url>
    <content><![CDATA[<p>redis的订阅与发布功能由publish subscribe psubscribe等命令组成.客户端可以订阅<strong>多个频道</strong>或者<strong>订阅多个模式</strong>.从而成为这些明道的订阅者.当其它客户端向这些频道发送消息,这些地订阅者可以收到.</p>
<p><img src="/images/redis/subscribe/%E5%B0%86%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E5%88%B0%E9%A2%91%E9%81%93%E8%AE%A2%E9%98%85%E8%80%85%E5%92%8C%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%AE%A2%E9%98%85%E8%80%85.png" alt="将消息发送到频道订阅者和匹配模式的订阅者"></p>
<p>订阅一个news.it频道和以及接收到其它客户端向这个频道发送来的信息.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">订阅者</span><br><span class="line">127.0.0.1:6379&gt; subscribe &quot;news.it&quot;</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">1) &quot;subscribe&quot;</span><br><span class="line">2) &quot;news.it&quot;</span><br><span class="line">3) (integer) 1</span><br><span class="line"></span><br><span class="line">1) &quot;message&quot;</span><br><span class="line">2) &quot;news.it&quot;</span><br><span class="line">3) &quot;hello&quot;</span><br><span class="line">1) &quot;message&quot;</span><br><span class="line">2) &quot;news.it&quot;</span><br><span class="line">3) &quot;test&quot;</span><br><span class="line"></span><br><span class="line">发布者</span><br><span class="line">127.0.0.1:6379&gt; publish &quot;news.it&quot; hello</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; publish &quot;news.it&quot; test</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="频道的订阅与退订"><a href="#频道的订阅与退订" class="headerlink" title="频道的订阅与退订"></a>频道的订阅与退订</h1><p>当一个客户端执行 SUBSCRIBE 命令， 订阅某个或某些频道的时候， 这个客户端与被订阅频道之间就建立起了一种订阅关系。</p>
<p>Redis 将所有频道的订阅关系都保存在服务器状态的 pubsub_channels 字典里面， 这个字典的键是某个被订阅的频道， 而键的值则是一个链表， 链表里面记录了所有订阅这个频道的客户端：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct redisServer &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 保存所有频道的订阅关系</span><br><span class="line">    dict *pubsub_channels;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>一个pubsub_channels字典示例:</p>
<p><img src="/images/redis/subscribe/%E4%B8%80%E4%B8%AApubsub_channels%E5%AD%97%E5%85%B8%E7%A4%BA%E4%BE%8B.png" alt="一个pubsub_channels字典示例"></p>
<h2 id="订阅频道"><a href="#订阅频道" class="headerlink" title="订阅频道"></a>订阅频道</h2><p>每当客户端执行 SUBSCRIBE 命令， 订阅某个或某些频道的时候， 服务器都会将客户端与被订阅的频道在 pubsub_channels 字典中进行关联。</p>
<ol>
<li>如果频道已经有其他订阅者， 那么它在 pubsub_channels 字典中必然有相应的订阅者链表， 程序唯一要做的就是将客户端添加到订阅者链表的末尾。</li>
<li>如果频道还未有任何订阅者， 那么它必然不存在于 pubsub_channels 字典， 程序首先要在 pubsub_channels 字典中为频道创建一个键， 并将这个键的值设置为空链表， 然后再将客户端添加到链表， 成为链表的第一个元素。</li>
</ol>
<p>SUBSCRIBE 命令的实现可以用以下伪代码来描述：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def subscribe(*all_input_channels):</span><br><span class="line"></span><br><span class="line">    # 遍历输入的所有频道</span><br><span class="line">    for channel in all_input_channels:</span><br><span class="line"></span><br><span class="line">        # 如果 channel 不存在于 pubsub_channels 字典（没有任何订阅者）</span><br><span class="line">        # 那么在字典中添加 channel 键，并设置它的值为空链表</span><br><span class="line">        if channel not in server.pubsub_channels:</span><br><span class="line">            server.pubsub_channels[channel] &#x3D; []</span><br><span class="line"></span><br><span class="line">        # 将订阅者添加到频道所对应的链表的末尾</span><br><span class="line">        server.pubsub_channels[channel].append(client)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="退订频道"><a href="#退订频道" class="headerlink" title="退订频道"></a>退订频道</h2><p>UNSUBSCRIBE 命令的行为和 SUBSCRIBE 命令的行为正好相反 —— 当一个客户端退订某个或某些频道的时候， 服务器将从 pubsub_channels 中解除客户端与被退订频道之间的关联：</p>
<ol>
<li>程序会根据被退订频道的名字， 在 pubsub_channels 字典中找到频道对应的订阅者链表， 然后从订阅者链表中删除退订客户端的信息。</li>
<li>如果删除退订客户端之后， 频道的订阅者链表变成了空链表， 那么说明这个频道已经没有任何订阅者了， 程序将从 pubsub_channels 字典中删除频道对应的键。</li>
</ol>
<h1 id="模式的订阅与退订"><a href="#模式的订阅与退订" class="headerlink" title="模式的订阅与退订"></a>模式的订阅与退订</h1><p>与频道类似,服务器将所有模式的订阅关系都保存在服务器状态的pubsub_pattterns属性里面:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct redisServer &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 保存所有模式的订阅关系</span><br><span class="line">    list *pubsub_pattterns;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>pubsub_pattterns是一个链表,链表中每个及诶点都包含着pubsub_patttern结构,这个结构的pattern属性记录了被订阅的模式,而client记录了订阅模式的客户端.</p>
<p><img src="/images/redis/subscribe/pubsub_pattterns%E9%93%BE%E8%A1%A8%E7%9A%84%E5%AE%9E%E4%BE%8B.png" alt="pubsub_pattterns链表的实例"></p>
<h2 id="订阅模式"><a href="#订阅模式" class="headerlink" title="订阅模式"></a>订阅模式</h2><p>每个客户端执行psubscribe命令的订阅某个模式的时候,服务器会对每个订阅的模式执行以下两个操作.</p>
<ol>
<li>新建一个pubsub_patttern的结构,将新结构的pattern属性设置为被订阅的模式,clients属性升值而为订阅模式的客户端.</li>
<li>将pubsub_patttern结构添加到pubsub_pattterns链表的尾端.</li>
</ol>
<p>执行psubscribe “news.*”</p>
<p><img src="/images/redis/subscribe/%E6%89%A7%E8%A1%8Cpsubscribe%E5%90%8E%E7%9A%84%E9%93%BE%E8%A1%A8.png" alt="执行psubscribe后的链表"></p>
<h2 id="退订模式"><a href="#退订模式" class="headerlink" title="退订模式"></a>退订模式</h2><p>当punsubscribe执行的时候,服务器将遍历pubsub_pattterns链表,查找并删除那些pattern模式为被退订模式.</p>
<h1 id="发送消息"><a href="#发送消息" class="headerlink" title="发送消息"></a>发送消息</h1><p>当一个redis客户端执行publish命令将小心message发送到频道channel的时候,服务器执行以下2个动作:</p>
<ol>
<li>将message发送给channel频道的订阅者;</li>
<li>如果有一个或者多个模式pattern与频道channel相匹配,那么消息message发送给pattern模式的订阅者;</li>
</ol>
<h2 id="将消息发送给频道的订阅者"><a href="#将消息发送给频道的订阅者" class="headerlink" title="将消息发送给频道的订阅者"></a>将消息发送给频道的订阅者</h2><p>将消息发送给channel频道的所有订阅者,就是将pubsub_chanels字典了找到频道的订阅者名单,然后将消息发送给其客户端.</p>
<p><img src="/images/redis/subscribe/%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E8%BF%98%E7%BB%99%E9%A2%91%E9%81%93%E8%AE%A2%E9%98%85%E8%80%85%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="发送消息还给频道订阅者的伪代码实现"></p>
<h2 id="将消息发送给模式订阅者"><a href="#将消息发送给模式订阅者" class="headerlink" title="将消息发送给模式订阅者"></a>将消息发送给模式订阅者</h2><p>将消息发送给channel频道模式相匹配的所有订阅者,就是将pubsub_patterns链表了找到频道相匹配的模式,然后将消息发送给其客户端.</p>
<p><img src="/images/redis/subscribe/%E5%B0%86%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E7%BB%99%E6%A8%A1%E5%BC%8F%E8%AE%A2%E9%98%85%E8%80%85%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="将消息发送给模式订阅者的伪代码实现"></p>
<h1 id="查看订阅信息"><a href="#查看订阅信息" class="headerlink" title="查看订阅信息"></a>查看订阅信息</h1><p>通过pubsub命令查看频道和模式的相关信息.</p>
<h2 id="pubsub-channels-pattern"><a href="#pubsub-channels-pattern" class="headerlink" title="pubsub channels [pattern]"></a>pubsub channels [pattern]</h2><p>返回服务器当前被订阅的频道,其中pattern是可选的参数;</p>
<p><img src="/images/redis/subscribe/pubsub_channel%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="pubsub_channel伪代码实现"></p>
<p>例子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pubsub channels</span><br><span class="line">1) &quot;news.it&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="pubsub-numsub-chanel-1-channel-2…"><a href="#pubsub-numsub-chanel-1-channel-2…" class="headerlink" title="pubsub numsub [chanel-1,channel-2…]"></a>pubsub numsub [chanel-1,channel-2…]</h2><p>接收任意多个频道作为输入参数,并返回这些频道的订阅数量</p>
<p><img src="/images/redis/subscribe/pubsub_numsub%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="pubsub_numsub伪代码实现"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pubsub numsub &quot;news.it&quot;</span><br><span class="line">1) &quot;news.it&quot;</span><br><span class="line">2) (integer) 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="PUBSUB-NUMPAT"><a href="#PUBSUB-NUMPAT" class="headerlink" title="PUBSUB NUMPAT"></a>PUBSUB NUMPAT</h2><p>返回服务器当前被订阅模式的数量,其实就是返回pubsub_patterns的链表的长度.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pubsub numpat</span><br><span class="line">(integer) 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>


























]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis-发布与订阅</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-复制</title>
    <url>/2018-01-24/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E5%A4%8D%E5%88%B6/</url>
    <content><![CDATA[<p>redis中可以通过slaveof命令或者配置slaveof选项,让一个服务器去复制(replicate)另一个服务器,被复制的服务器为master,对master进行复制的为slave.</p>
<p>从服务器和主服务保存的数据时相同的.这个称为数据库状态一致.</p>
<h1 id="旧版复制功能的实现"><a href="#旧版复制功能的实现" class="headerlink" title="旧版复制功能的实现"></a>旧版复制功能的实现</h1><p>复制功能分为同步(sync)和命令传播(command propagate) 两个操作</p>
<ol>
<li>同步是从服务器的数据库状态更新至主服务器当前所处的数据库状态.</li>
<li>命令传播操作是当主服务器的数据库状态被修改,导致主从服务器的数据库状态出现不一致的时候,让主从服务器的数据库状态回到一致状态.</li>
</ol>
<h2 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h2><p>从服务器对主服务器的同步操作需要通过向主服务器发送 SYNC 命令来完成， 以下是 SYNC 命令的执行步骤：</p>
<ol>
<li>从服务器向主服务器发送 SYNC 命令。</li>
<li>收到 SYNC 命令的主服务器执行 BGSAVE 命令， 在后台生成一个 RDB 文件， 并使用一个缓冲区记录从现在开始执行的所有写命令。</li>
<li>当主服务器的 BGSAVE 命令执行完毕时， 主服务器会将 BGSAVE 命令生成的 RDB 文件发送给从服务器， 从服务器接收并载入这个 RDB 文件， 将自己的数据库状态更新至主服务器执行 BGSAVE 命令时的数据库状态。</li>
<li>主服务器将记录在缓冲区里面的所有写命令发送给从服务器， 从服务器执行这些写命令， 将自己的数据库状态更新至主服务器数据库当前所处的状态。</li>
</ol>
<p><img src="/images/redis/replicate/%E4%B8%BB%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%8C%E6%AD%A5%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt="主从服务器同步的例子"></p>
<h2 id="命令传播"><a href="#命令传播" class="headerlink" title="命令传播"></a>命令传播</h2><p>当同步完成之后,主从服务器的状态在当前时刻时一致的.当主库发生写操作,此时主从的数据时不一致的.主库需要将客户端传来的写操作的命令传递给从库.这样主从数据库才可以保持一致.</p>
<h1 id="旧版复制功能的缺陷"><a href="#旧版复制功能的缺陷" class="headerlink" title="旧版复制功能的缺陷"></a>旧版复制功能的缺陷</h1><p>主从复制分为以下两种情况:</p>
<ol>
<li>初次复制,从服务器从来没有复制过任何主服务器,或者从服务器要复制的主服务器和上一次复制的主服务器不同</li>
<li>断线后的复制,处于命令传播阶段的主从服务器因为网络原因中断了复制,网络恢复后从服务器对主服务器的复制.(断线重连后从服务器需要向主服务器发送sync命令)</li>
</ol>
<p><img src="/images/redis/replicate/%E6%96%AD%E7%BA%BF%E5%90%8E%E9%87%8D%E6%96%B0%E5%A4%8D%E5%88%B6%E4%B8%BB%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt="断线后重新复制主服务器的例子"></p>
<p>其实断线这段时间,主服务器的写操作产生的数据是主从服务器之间的不同.但旧版的复制功能却采用sync命令,这样效率其实非常低.</p>
<h1 id="新版复制功能的实现"><a href="#新版复制功能的实现" class="headerlink" title="新版复制功能的实现"></a>新版复制功能的实现</h1><p>为了解决旧版掉线重连的同步数据地下的缺陷,有了新版复制功能的实现.</p>
<p>新版的复制功能采用PSYNC代替SYNC命令.PSYNC具有完整重同步和部分重同步2种操作,其中完整重同步和SYNC的基本一致,部分重同步是在网络恢复后,将断线期间的写命令发送给从服务器.</p>
<p><img src="/images/redis/replicate/PSYNC%E5%91%BD%E4%BB%A4%E8%BF%9B%E8%A1%8C%E6%96%AD%E7%BA%BF%E5%90%8E%E9%87%8D%E5%A4%8D%E5%88%B6.png" alt="PSYNC命令进行断线后重复制"></p>
<h1 id="部分重同步的实现"><a href="#部分重同步的实现" class="headerlink" title="部分重同步的实现"></a>部分重同步的实现</h1><p>主要包括以下三小结</p>
<h2 id="复制偏移量"><a href="#复制偏移量" class="headerlink" title="复制偏移量"></a>复制偏移量</h2><p>主从服务器都会维护一个复制偏移量.主服务器每次向从服务器传播N个字节,就会将自己的偏移量加上N,从服务器收到偏移量N就会为自己的偏移量加上N.</p>
<p><img src="/images/redis/replicate/%E6%8B%A5%E6%9C%89%E7%9B%B8%E5%90%8C%E5%81%8F%E7%A7%BB%E9%87%8F%E7%9A%84%E4%B8%80%E4%B8%BB%E4%B8%89%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8.png" alt="拥有相同偏移量的一主三从服务器"></p>
<h2 id="复制积压缓冲区"><a href="#复制积压缓冲区" class="headerlink" title="复制积压缓冲区"></a>复制积压缓冲区</h2><p>复制积压缓冲区是由主服务器维护的一个固定长度先进先出的队列.默认大小为1M.</p>
<p>当主服务器进行命令传播时,不仅将命令发送给所有的从服务器,还会将命令写入到复制积压缓冲区里面.</p>
<p><img src="/images/redis/replicate/%E5%A4%8D%E5%88%B6%E7%A7%AF%E5%8E%8B%E7%BC%93%E5%86%B2%E5%8C%BA%E7%9A%84%E6%9E%84%E9%80%A0.png" alt="复制积压缓冲区的构造"></p>
<p>当从服务器重新连接上主服务器后,从服务器会通过PSYNC命令将自己的复制偏移量offset发送给服务器,主服务会根据这个offset来决定执行什么操作.</p>
<p>如果offset偏移量之后的数据(offset+1后的数据),仍然存在与积压缓冲区中,则主服务会对从服务器执行部分重同步操作,否则自己完整重同步操作.</p>
<h2 id="服务器运行id"><a href="#服务器运行id" class="headerlink" title="服务器运行id"></a>服务器运行id</h2><p>除了复制偏移量和复制积压缓冲区外,实现部分重同步还需要用到服务器的运行ID.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; info server</span><br><span class="line"># Server</span><br><span class="line">redis_version:3.2.10</span><br><span class="line">redis_git_sha1:00000000</span><br><span class="line">redis_git_dirty:0</span><br><span class="line">redis_build_id:e84c37c0154af52a</span><br><span class="line">redis_mode:standalone</span><br><span class="line">os:Linux 4.4.0-109-generic x86_64</span><br><span class="line">arch_bits:64</span><br><span class="line">multiplexing_api:epoll</span><br><span class="line">gcc_version:5.4.0</span><br><span class="line">process_id:22916</span><br><span class="line">run_id:1976d153c2f5dd6d9c62808b92dddbe572950c88 &#x2F;&#x2F;40个随机的16进制字符组成</span><br><span class="line">tcp_port:6379</span><br><span class="line">uptime_in_seconds:180</span><br><span class="line">uptime_in_days:0</span><br><span class="line">hz:10</span><br><span class="line">lru_clock:6863212</span><br><span class="line">executable:&#x2F;usr&#x2F;local&#x2F;redis-3.2.10&#x2F;src&#x2F;.&#x2F;redis-server</span><br><span class="line">config_file:&#x2F;usr&#x2F;local&#x2F;redis-3.2.10&#x2F;redis.conf</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>从服务器对主服务器进行初次同步的时候,主服务会将自己的run id传递给从服务器.断线重连后会将此id传递给主服务器,如果id和主服务器的相同,则尝试执行部分同步操作.否则执行全同步操作.</p>
<h1 id="PSYNC命令的实现"><a href="#PSYNC命令的实现" class="headerlink" title="PSYNC命令的实现"></a>PSYNC命令的实现</h1><p>PSYNC命令执行完整重同步和部分重同步时可能遇到的情况.</p>
<p><img src="/images/redis/replicate/PSYNC%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E5%AE%8C%E6%95%B4%E9%87%8D%E5%90%8C%E6%AD%A5%E5%92%8C%E9%83%A8%E5%88%86%E9%87%8D%E5%90%8C%E6%AD%A5%E6%97%B6%E5%8F%AF%E8%83%BD%E9%81%87%E5%88%B0%E7%9A%84%E6%83%85%E5%86%B5.png" alt="PSYNC命令执行完整重同步和部分重同步时可能遇到的情况"></p>
<h1 id="复制的实现"><a href="#复制的实现" class="headerlink" title="复制的实现"></a>复制的实现</h1><p>从服务通过 SLAVEOF <master_ip> <master_port> 复制主服务的数据</p>
<h2 id="设置主服务器的地址和端口"><a href="#设置主服务器的地址和端口" class="headerlink" title="设置主服务器的地址和端口"></a>设置主服务器的地址和端口</h2><p>执行SLAVEOF 127.0.0.1 6379命令后,从服务将主服务器的ip和端口设置到自己的服务器属性里.</p>
<p><img src="/images/redis/replicate/%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8A%B6%E6%80%81.png" alt="从服务器的服务器状态"></p>
<h2 id="建立套接字连接"><a href="#建立套接字连接" class="headerlink" title="建立套接字连接"></a>建立套接字连接</h2><p>从服务器设置ip和端口号成功后,创建连向主服务器的套接字连接.创建成功后,从服务器会为这个套接字关联一个专门用于处理复制工作的文件事件处理器.</p>
<p>主服务器在接收从服务器的套接字连接之后,将为该套接字创建相应的客户端状态.而此时从服务器可以看做时连接向主服务器的客户端.此时从服务器同事具有服务器和客户端两个身份.</p>
<h2 id="发送ping命令"><a href="#发送ping命令" class="headerlink" title="发送ping命令"></a>发送ping命令</h2><p>虽然建立起连接,但是主从服务器从未通信,</p>
<ol>
<li>以此来检测套接字的读写状态是否正常.</li>
<li>检测主服务器能否正常处理命令.</li>
</ol>
<p>收到的回复</p>
<ol>
<li>timeout表示连接状态不佳.</li>
<li>返回一个错误,表示暂时没法处理命令.</li>
<li>pong,正常.</li>
</ol>
<h2 id="身份验证"><a href="#身份验证" class="headerlink" title="身份验证"></a>身份验证</h2><p>返回pong之后,如果从服务器设置了masterauth参数,那么进行身份验证.否者不进行身份验证.</p>
<p><img src="/images/redis/replicate/%E4%BB%8E%E6%9C%8D%E5%8A%A1%E8%BF%9B%E8%A1%8C%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E5%8F%AF%E8%83%BD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98.png" alt="从服务进行身份验证可能遇到的问题"></p>
<h2 id="发送端口信息"><a href="#发送端口信息" class="headerlink" title="发送端口信息"></a>发送端口信息</h2><p>在身份验证步骤之后,从服务器将执行命令REPLCONF listening-port<port-num>,向主服务器发送从服务器的监听端口号</p>
<p>主服务在接收到这个命令之后,会将端口号记录在从服务器对应的客户端状态的slave_listening_port属性中.目前唯一的作用就是info repication会打印监听的端口号</p>
<h2 id="同步-1"><a href="#同步-1" class="headerlink" title="同步"></a>同步</h2><p>之后,从服务器向主服务器发送PSYNC命令.执行同步,此时主服务器也成为从服务器的客户端,这样主服务才可以在之后的操作中将缓冲区的内容发送过去.而且主从之间才可以保持同步.</p>
<h2 id="命令传播-1"><a href="#命令传播-1" class="headerlink" title="命令传播"></a>命令传播</h2><p>之后,主从服务器进入命令传播阶段.主从服务器的数据保持一致.</p>
<h1 id="心跳检测"><a href="#心跳检测" class="headerlink" title="心跳检测"></a>心跳检测</h1><p>在命令传播阶段,从服务器会默认以每秒一次的频率向主服务发送命令 REPLCONF ACK <replication_offset>,其中replication_offset是从服务器当前的复制偏移量.</p>
<p>作用:</p>
<ol>
<li>检测主从服务器的网络状态</li>
<li>辅助实现min-slaves选项</li>
<li>检测命令丢失</li>
</ol>
<h2 id="检测主从服务器的网络状态"><a href="#检测主从服务器的网络状态" class="headerlink" title="检测主从服务器的网络状态"></a>检测主从服务器的网络状态</h2><p>如果主服务器超过一秒没有收到从服务器的REPLCONF命令,则主服务器认为从服务器出现故障.</p>
<p>info replication命令的lag项表示从服务器上一次向从服务器发送命令距今有多少秒.</p>
<h2 id="辅助实现min-slaves选项"><a href="#辅助实现min-slaves选项" class="headerlink" title="辅助实现min-slaves选项"></a>辅助实现min-slaves选项</h2><p>redis的两个选项</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">min-slaves-to-write 3</span><br><span class="line">min-slaves-to-lag 10</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>表示从服务器的数量少于三个或者三个服务器的值都大于等于10秒,主服务器将拒绝执行写命令.</p>
<h2 id="检测命令丢失"><a href="#检测命令丢失" class="headerlink" title="检测命令丢失"></a>检测命令丢失</h2><p>主服务器在收到从服务器的replication_offset参数后,发现与自己的偏移量不一致,会从复制积压缓冲区中取出数据重新发送.以保证主从数据的同步.这个类似于部分重同步操作.</p>
<ul>
<li>redis2.8版本添加了REPLCONF ACK 命令和复制积压缓冲区,以前的版本中主从复制的命令丢失都不会被发觉.为了保证复制时主从服务器的数据一致性.最好使用2.8+版本</li>
</ul>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis复制</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-持久化</title>
    <url>/2018-01-12/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%8C%81%E4%B9%85%E5%8C%96/</url>
    <content><![CDATA[<h1 id="RDB持久化"><a href="#RDB持久化" class="headerlink" title="RDB持久化"></a>RDB持久化</h1><p>服务器中的非空数据库以及他们的键值对统称为<strong>数据库状态</strong>.</p>
<p>redis是内存数据库,如果不将数据保存到磁盘,一旦服务器进程退出,服务器中的数据库状态也会消失不见.</p>
<p>RDB持久化功能生成的RDB文件时一个经过压缩的二进制文件.通过该文件还可以生成生成RDB文件时的数据库状态.</p>
<h2 id="RDB文件的创建和载入"><a href="#RDB文件的创建和载入" class="headerlink" title="RDB文件的创建和载入"></a>RDB文件的创建和载入</h2><p>save和bgsave命令可以生成RDB文件.</p>
<ol>
<li>save命令会阻塞服务器进程,直到RDB文件创建完毕,阻塞期间,服务器不能处理任何命令请求.</li>
<li>bgsave会派生出一个子进程来创建RDB文件.这期间父进程会处理命令请求.子进程创建完成之后,会通知父进程.</li>
</ol>
<p>RDB文件的载入时在服务器启动时自动执行的,服务器只要检测到有RDB文件存在,就会自动载入.</p>
<h3 id="服务器状态"><a href="#服务器状态" class="headerlink" title="服务器状态"></a>服务器状态</h3><ol>
<li>在执行save命令的过程中,服务器会拒绝任何命令请求;</li>
<li>在执行bgsave命令时,如果执行save和bgsave命令都会被拒绝,而执行bgrewriteaof命令时,会在bgsave命令执行完,才执行.</li>
<li>执行bgrewriteaof命令时,执行bgsave命令会被拒绝,因为这两个命令都是采用子进程去执行.</li>
<li>载入RDB过程中,服务器处于阻塞状态</li>
</ol>
<h2 id="自动间隔性保存"><a href="#自动间隔性保存" class="headerlink" title="自动间隔性保存"></a>自动间隔性保存</h2><p>通过在redis.conf文件中配置save属性,可以让服务器自动执行bgsave命令.</p>
<p>设置保存条件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure>
<p><img src="/images/redis/persistence/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8A%B6%E6%80%81%E4%B8%AD%E7%9A%84%E4%BF%9D%E5%AD%98%E6%9D%A1%E4%BB%B6.png" alt="服务器状态中的保存条件"></p>
<h3 id="dirty计数器和lastsave属性"><a href="#dirty计数器和lastsave属性" class="headerlink" title="dirty计数器和lastsave属性"></a>dirty计数器和lastsave属性</h3><p>dirty属性记录距离上一次成功执行save和bgsave命令之后,服务器对数据库状态(所有数据库)执行了多少次修改操作;</p>
<p>lastsave属性时一个时间戳记录距离上一次成功执行save和bgsave命令的时间;</p>
<h3 id="检查保存条件是否满足"><a href="#检查保存条件是否满足" class="headerlink" title="检查保存条件是否满足"></a>检查保存条件是否满足</h3><p>服务器的周期性函数serverCron默认100毫秒检查一次,其中一次就是检查save选项的条件是否满足</p>
<p><img src="/images/redis/persistence/serverCron%E5%87%BD%E6%95%B0%E6%A3%80%E6%9F%A5%E4%BF%9D%E5%AD%98%E6%9D%A1%E4%BB%B6%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="serverCron函数检查保存条件的过程"></p>
<p>上述时serverCom函数检查save条件的伪代码实现,只要满足一个条件就执行bgsave命令.bgsave命令执行完之后dirty属性会被置为0.</p>
<h2 id="RDB的文件结构"><a href="#RDB的文件结构" class="headerlink" title="RDB的文件结构"></a>RDB的文件结构</h2><p>RDB文件的结构如下</p>
<p><img src="/images/redis/persistence/RDB%E6%96%87%E4%BB%B6%E7%9A%84%E7%BB%93%E6%9E%84.png" alt="RDB文件的结构"></p>
<p>该结构中大写表示常量,小写表示变量和数据.</p>
<ol>
<li>REDIS是长度为5字节的二进制数据,程序在载入的时候通过此标识检查是否为RDB文件.</li>
<li>db_verison 是字符串类型的整数,表示的是RDB文件的版本.</li>
<li>databses表示的时0个或者多个数据库,如果数据库状态为空,则该长度为空.如果时非空,则长度根据数据的数量也会不同.</li>
<li>EOF长度为1个字节,当程序读到这个位置的时候遇到此标识,表示数据库的所有键值对已经全部载入完毕.</li>
<li>check_num时一个8字节的无符号的整数.保存的是一个检验和.是由以上的四个参数计算得出的.在载入时会通过以上四个参数得出的校验和与该参数进行对比,以此来检验RDB文件是否有出错或者损坏的情况.</li>
</ol>
<p><img src="/images/redis/persistence/databases%E4%B8%BA%E7%A9%BA%E7%9A%84RDB%E6%96%87%E4%BB%B6.png" alt="databases为空的RDB文件"></p>
<h3 id="databases部分"><a href="#databases部分" class="headerlink" title="databases部分"></a>databases部分</h3><p><img src="/images/redis/persistence/%E5%B8%A6%E6%9C%892%E4%B8%AA%E9%9D%9E%E7%A9%BA%E6%95%B0%E6%8D%AE%E7%9A%84RDB%E6%96%87%E4%BB%B6%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="带有2个非空数据的RDB文件的数据结构"></p>
<p>每个非空的数据库都会保存成以下三个部分</p>
<p><img src="/images/redis/persistence/RDB%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%93%E6%9E%84.png" alt="RDB文件中的数据库结构"></p>
<ol>
<li>SELECTED时一个1字节的常量,当程序读到该标识的时候,知道接下来是一个数据库号码.</li>
<li>db_number表示的是数据库编号.</li>
<li>key_value_pairs保存着该库里所有的键值对数据.</li>
</ol>
<p>保存了0号库和3号库的完整的RDB文件的结构如下:</p>
<p><img src="/images/redis/persistence/%E5%AE%8C%E6%95%B4%E7%9A%84RDB%E6%96%87%E4%BB%B6%E7%9A%84%E7%BB%93%E6%9E%84.png" alt="完整的RDB文件的结构"></p>
<h3 id="key-value-pairs"><a href="#key-value-pairs" class="headerlink" title="key_value_pairs"></a>key_value_pairs</h3><h4 id="在RDB中的键值对对象"><a href="#在RDB中的键值对对象" class="headerlink" title="在RDB中的键值对对象"></a>在RDB中的键值对对象</h4><p>键值对在RDB文件中由type key value三个部分组成.</p>
<p><img src="/images/redis/persistence/%E4%B8%8D%E5%B8%A6%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%E7%9A%84%E9%94%AE%E5%80%BC%E5%AF%B9.png" alt="不带过期时间的键值对"></p>
<p><img src="/images/redis/persistence/%E5%B8%A6%E6%9C%89%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%E7%9A%84%E9%94%AE%E5%80%BC%E5%AF%B9.png" alt="带有过期时间的键值对"></p>
<p>type表示底层编码或者对象类型,key是字符串对象,ExpireTime_MS 是一个常量告诉程序将来要读到的时一个过期时间戳.</p>
<h4 id="value的编码"><a href="#value的编码" class="headerlink" title="value的编码"></a>value的编码</h4><p>RDB文件中的每个value都是一个对象,编码类型记在type中.</p>
<ul>
<li>字符串对象 (type=REDIS_RDB_TYPE_STRING)</li>
</ul>
<p>字符串对象的编码是Redis_encoding_int,则该对象会以如下的结构保存.其中encoding会是8bit 16bit或者32bit来保存数据</p>
<p><img src="/images/redis/persistence/%E4%BF%9D%E5%AD%98%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%AF%B9%E8%B1%A1INT%E7%BC%96%E7%A0%81.png" alt="保存字符串的对象INT编码"></p>
<p>字符串对象的编码是Redis_encoding_raw,则该对象会以如下的结构保存</p>
<p>如果字符串长度小于等于20,则字符串会被保存为原来的样子,否则会被压缩后在保存(开启rdbcompressiong选项的情况下)</p>
<p><img src="/images/redis/persistence/%E4%BF%9D%E5%AD%98%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AF%B9%E8%B1%A1raw%E7%BC%96%E7%A0%81.png" alt="保存字符串对象raw编码"></p>
<p>REDIS_RDB_ENC_LZF表示采用LZF算法.compressed_len压缩后的长度,origin_len原始长度.compressed_string 压缩后的字符串</p>
<p><img src="/images/redis/persistence/%E6%9C%89%E6%97%A0%E5%8E%8B%E7%BC%A9%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%AF%B9%E6%AF%94.png" alt="有无压缩字符串的对比"></p>
<ul>
<li>列表对象(type=REDIS_RDB_TYPE_LIST)</li>
</ul>
<p>value值是一个编码为REDIS_ENCODING_LINKLIST编码类型的列表对象 结构如下</p>
<p><img src="/images/redis/persistence/linklist%E7%BC%96%E7%A0%81%E5%88%97%E8%A1%A8%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%BF%9D%E5%AD%98%E7%BB%93%E6%9E%84.png" alt="linklist编码列表对象的保存结构"></p>
<ul>
<li>集合对象(type=REDIS_RDB_TYPE_SET)</li>
</ul>
<p>value值是一个编码为REDIS_ENCODING_HT编码类型的集合对象 结构如下</p>
<p><img src="/images/redis/persistence/HT%E7%BC%96%E7%A0%81%E9%9B%86%E5%90%88%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%BF%9D%E5%AD%98%E7%BB%93%E6%9E%84.png" alt="HT编码集合对象的保存结构"></p>
<ul>
<li>hash对象(type=REDIS_RDB_TYPE_HASH)</li>
</ul>
<p>value值是一个编码为REDIS_ENCODING_HT编码类型的hash对象 结构如下</p>
<p><img src="/images/redis/persistence/HT%E7%BC%96%E7%A0%81hash%E8%A1%A8%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%BF%9D%E5%AD%98%E7%BB%93%E6%9E%84.png" alt="HT编码hash表对象的保存结构"></p>
<p><img src="/images/redis/persistence/%E6%9B%B4%E8%AF%A6%E7%BB%86%E7%9A%84HT%E7%BC%96%E7%A0%81hash%E8%A1%A8%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%BF%9D%E5%AD%98%E7%BB%93%E6%9E%84.png" alt="更详细的HT编码hash表对象的保存结构"></p>
<ul>
<li>有序集合对象(type=REDIS_RDB_TYPE_ZSET)</li>
</ul>
<p>value值是一个编码为REDIS_ENCODING_SKIPLISR编码类型的有序集合对象 结构如下</p>
<p><img src="/images/redis/persistence/skiplist%E7%BC%96%E7%A0%81%E7%9A%84%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%E7%9A%84%E4%BF%9D%E5%AD%98%E7%BB%93%E6%9E%84.png" alt="skiplist编码的有序集合的保存结构"></p>
<p><img src="/images/redis/persistence/%E6%9B%B4%E8%AF%A6%E7%BB%86%E7%9A%84skiplist%E7%BC%96%E7%A0%81%E7%9A%84%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%E7%9A%84%E4%BF%9D%E5%AD%98%E7%BB%93%E6%9E%84.png" alt="更详细的skiplist编码的有序集合的保存结构"></p>
<ul>
<li>INTSET编码的集合(type=REDIS_RDB_TYPE_SET_INTSET)</li>
</ul>
<p><img src="/images/redis/persistence/INTSET%E7%BC%96%E7%A0%81%E7%9A%84%E9%9B%86%E5%90%88%E6%8F%8F%E8%BF%B0.png" alt="INTSET编码的集合描述"></p>
<ul>
<li>ZIPLIST编码的列表/hash表/有序集合(type=REDIS_RDB_TYPE_LIST_ZIPLIST/type=REDIS_RDB_TYPE_HASH_ZIPLIST/type=REDIS_RDB_TYPE_ZSET_ZIPLIST)</li>
</ul>
<p><img src="/images/redis/persistence/ziplist%E7%BC%96%E7%A0%81%E7%9A%84RDB%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%8F%8F%E8%BF%B0.png" alt="ziplist编码的RDB数据结构描述"></p>
<h2 id="分析RDB文件"><a href="#分析RDB文件" class="headerlink" title="分析RDB文件"></a>分析RDB文件</h2><p>使用od命令来分析redis服务器产生的RDB文件</p>
<p>实例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redis-3.2.10$ od -c dump.rdb </span><br><span class="line">0000000   R   E   D   I   S   0   0   0   7 372  \t   r   e   d   i   s</span><br><span class="line">0000020   -   v   e   r 006   3   .   2   .   1   0 372  \n   r   e   d</span><br><span class="line">0000040   i   s   -   b   i   t   s 300   @ 372 005   c   t   i   m   e</span><br><span class="line">0000060 302   &quot; 376   X   Z 372  \b   u   s   e   d   -   m   e   m 302</span><br><span class="line">0000100 200 212  \f  \0 377   _   V   4 005 364 005 365   k</span><br><span class="line">0000115</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>简单说几个参数  377代表EOF ,376代表SELECTED ,\0代表 0 </p>
<p>由于不经常用,如想了解具体细节,请自行翻阅其它资料.</p>
<h1 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h1><p>AOF是通过保存服务器所执行的写命令来记录数据库状态的,AOF文件的所有命令均以Redis命令请求协议的格式保存.</p>
<p><img src="/images/redis/persistence/AOF%E6%8C%81%E4%B9%85%E5%8C%96%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="AOF持久化流程图"></p>
<h2 id="AOF持久化的实现"><a href="#AOF持久化的实现" class="headerlink" title="AOF持久化的实现"></a>AOF持久化的实现</h2><p>AOF持久化实现的实现分为三个步骤:追加/文件写入/文件同步</p>
<h3 id="文件的追加"><a href="#文件的追加" class="headerlink" title="文件的追加"></a>文件的追加</h3><p>当AOF持久化功能打开时,服务器执行完一个写命令,会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾</p>
<p><img src="/images/redis/persistence/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%93%E5%86%B2%E5%8C%BA%E5%B1%9E%E6%80%A7.png" alt="服务器缓冲区属性"></p>
<h3 id="AOF文件的写入和同步"><a href="#AOF文件的写入和同步" class="headerlink" title="AOF文件的写入和同步"></a>AOF文件的写入和同步</h3><p>redis的服务器进程就是一个事件循环,这个循环中的文件事件负责接受客户端的命令请求,以及向客户端回复命令;时间事件负责指向serverCron这样的函数运行需要定时运行的函数,</p>
<p>服务器在处理文件事件时可能会指向写命令,使得一些内容被追加到aof_buf缓冲区,所以在服务器每次结束一个循环之前都会调用flushAppendOnlyFile函数.考虑是否将缓冲区中的内容写到AOF文件中</p>
<p>伪代码实现</p>
<p><img src="/images/redis/persistence/%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="事件循环的伪代码实现"></p>
<p>flushAppendOnlyFile函数的行为有appendfsync选项的值来决定,以下是不同的appendfsync值产生的不同的持久化行为</p>
<p><img src="/images/redis/persistence/%E4%B8%8D%E5%90%8C%E7%9A%84appendfsync%E5%80%BC%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%8D%E5%90%8C%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E8%A1%8C%E4%B8%BA.png" alt="不同的appendfsync值产生的不同的持久化行为"></p>
<p>现在操作系统中,在调用write函数写数据到文件的时候,会将数据保存在一个内存缓冲区里面,等到缓冲区的空间被填满,然后才将缓冲区中的内容写入到磁盘.但系统也提供了立即flush的函数.</p>
<ul>
<li>AOF持久化的效率和安全性</li>
</ul>
<p><img src="/images/redis/persistence/AOF%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E6%95%88%E7%8E%87%E5%92%8C%E5%AE%89%E5%85%A8%E6%80%A71.png" alt="AOF持久化的效率和安全性1"></p>
<p><img src="/images/redis/persistence/AOF%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E6%95%88%E7%8E%87%E5%92%8C%E5%AE%89%E5%85%A8%E6%80%A72.png" alt="AOF持久化的效率和安全性2"></p>
<h2 id="AOF文件载入和数据还原"><a href="#AOF文件载入和数据还原" class="headerlink" title="AOF文件载入和数据还原"></a>AOF文件载入和数据还原</h2><p>AOF文件中包含了重建数据库状态所需的所有写命令,所以服务器只要读入并重新执行一遍,就而已还原服务器关闭之前的数据库状态.</p>
<p>由于redis的命令只是在客户端上下文中执行,而载入AOF文件所使用的命令直接来源于AOF文件,而不是网络连接.所以服务器使用了一个没有网络连接的伪客户端来执行命令.具体步骤如:</p>
<p><img src="/images/redis/persistence/AOF%E6%96%87%E4%BB%B6%E8%BD%BD%E5%85%A5%E8%BF%87%E7%A8%8B.png" alt="AOF文件载入过程"></p>
<h2 id="AOF文件的重写"><a href="#AOF文件的重写" class="headerlink" title="AOF文件的重写"></a>AOF文件的重写</h2><p>AOF文件存储的是客户端的写命令,随着服务器运行时间越长,文件会越大.而且AOF文件进行数据还原所需要的时间就越多.所以需要对AOF文件进行重写.</p>
<p>通过重写功能,服务器会创建一个新的AOF文件来替代所有的AOF文件.新文件和原有的文件所存储的数据是一致的,但新文件的剔除了许多冗余的命令,所以新文件的体积通常会小很多.</p>
<p>AOF文件的重写并不需要对现有的文件进行读写操作,而是通过读取当前的数据库服务器状态来实现的.</p>
<p><img src="/images/redis/persistence/AOF%E9%87%8D%E5%86%99%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt="AOF重写的例子"></p>
<p>AOF重写的伪代码实现:</p>
<p><img src="/images/redis/persistence/AOF%E9%87%8D%E5%86%99%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B01.png" alt="AOF重写的伪代码实现1"></p>
<p><img src="/images/redis/persistence/AOF%E9%87%8D%E5%86%99%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B02.png" alt="AOF重写的伪代码实现2"></p>
<p><img src="/images/redis/persistence/AOF%E9%87%8D%E5%86%99%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B03.png" alt="AOF重写的伪代码实现3"></p>
<p>重写后产生的AOF文件</p>
<p><img src="/images/redis/persistence/%E9%87%8D%E5%86%99%E5%90%8E%E7%9A%84AOF%E6%96%87%E4%BB%B6.png" alt="重写后的AOF文件"></p>
<p>重写后的AOF文件对应的数据库:</p>
<p><img src="/images/redis/persistence/%E9%87%8D%E5%86%99%E5%90%8E%E7%9A%84AOF%E6%96%87%E4%BB%B6%E5%AF%B9%E5%BA%94%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93.png" alt="重写后的AOF文件对应的数据库"></p>
<ul>
<li>如果某个键的对应的value的值的个数大于64个,则需要拆成多条命令.</li>
</ul>
<h2 id="AOF后台重写-BGREWRITEAOF功能"><a href="#AOF后台重写-BGREWRITEAOF功能" class="headerlink" title="AOF后台重写(BGREWRITEAOF功能)"></a>AOF后台重写(BGREWRITEAOF功能)</h2><p>由于aof_rewrite函数在有多条数据需要重写的情况下会长时间阻塞线程,由于redis是单线程,所以AOF重写期间(使用aof_rewrite函数)服务器无法处理客户顿的请求.所以redis使用子进程来重写.</p>
<p>子进程执行重写期间数据库仍然有写操作,所以服务器当前的状态和AOF文件所保存的文件不一致.为此redis服务器创建了一个AOF重写缓冲区,它只有在服务器创建子进程之后才会使用,当redis服务器执行完一个写命令之后,它会同事给AOF缓冲区和AOF重写缓冲区发送此命令.</p>
<p>在子进程执行AOF重写期间,服务器需要执行以下三个工作:</p>
<ol>
<li>执行客户端发送过来的命令</li>
<li>执行后的写命令追加到AOF缓冲区</li>
<li>将执行后的写命令追加到AOF重写缓冲区</li>
</ol>
<p>这样会保证AOF缓冲区的内容会定时的写入和同步到AOF文件,现有的AOF文件会正常处理;而且从创建子进程开始所有的写命令都会被放入AOF重写缓冲区</p>
<p>当子进程执行完重写操作后,它会向父进程发送信号,父进程会完成以下工作:</p>
<ol>
<li>将AOF重写缓冲区中的内容写入到新的AOF文件中,以此来保证和数据库的状态一致;</li>
<li>对新的AOF文件进行改名,原子性的覆盖现有的AOF文件,完成新旧文件的替换</li>
</ol>
<p><img src="/images/redis/persistence/AOF%E5%90%8E%E5%8F%B0%E9%87%8D%E5%86%99%E8%BF%87%E7%A8%8B.png" alt="AOF后台重写过程"></p>
<h1 id="系统故障处理"><a href="#系统故障处理" class="headerlink" title="系统故障处理"></a>系统故障处理</h1><h2 id="检查出错的文件"><a href="#检查出错的文件" class="headerlink" title="检查出错的文件"></a>检查出错的文件</h2><ol>
<li>无论是AOF还是快照的方式,将数据持久化到硬盘还是非常有必要的.除此之外,用户还必须对持久化的文件进行备份.最好的备份是把最新的快照或者最新重写的AOF文件备份到别的服务器上.</li>
<li>redis-check-aof和redis-check-dump是在系统发生故障后,检查AOF文件和快照文件的状态,并在有需要的情况下对文件进行修复.</li>
</ol>
<h2 id="更换故障主服务器"><a href="#更换故障主服务器" class="headerlink" title="更换故障主服务器"></a>更换故障主服务器</h2><p>假设A/B两台机器都运行这Redis,其中A时主服务器,B是从服务器.突然A故障坏掉,如何使用同样安装了redis的C服务器作为新的主服务器?</p>
<p>非常简单:首先向B服务器发送一个save命令,让它创建一个新的快照文件.接着将快照文件发送给C,并在C上启动redis,最后让B成为C的从服务器,</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis-check-aof [--fix] &lt;file-aof&gt; 会扫描给定的AOF文件,寻找不正确或者不完整的命令,并且删除出错的命令以及位于出错命令之后的命令.</span><br><span class="line">redis-check-dump &lt;dump.rdb&gt; 目前没有办法修复出错的快照文件</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><a href="http://blog.nosqlfan.com/html/3813.html">另外书籍中推荐了一片redis持久化解密的比较好的博客</a></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis持久化,RDB</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-排序</title>
    <url>/2018-01-23/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h1 id="排序-快速排序算法"><a href="#排序-快速排序算法" class="headerlink" title="排序 (快速排序算法)"></a>排序 (快速排序算法)</h1><p>redis的sort命令可以对列表键/集合键或者有序集合键进行排序</p>
<p>命令如下:</p>
<p>sort key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern …]] [ASC|DESC] [ALPHA] [STORE destination]</p>
<p>例子1: 对列表进行排序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; rpush numbers 5 2 1 4 2</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; LRANGE numbers 0 -1</span><br><span class="line">1) &quot;5&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;1&quot;</span><br><span class="line">4) &quot;4&quot;</span><br><span class="line">5) &quot;2&quot;</span><br><span class="line">127.0.0.1:6379&gt; sort numbers</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;2&quot;</span><br><span class="line">4) &quot;4&quot;</span><br><span class="line">5) &quot;5&quot;</span><br><span class="line">127.0.0.1:6379&gt; sort numbers desc</span><br><span class="line">1) &quot;5&quot;</span><br><span class="line">2) &quot;4&quot;</span><br><span class="line">3) &quot;2&quot;</span><br><span class="line">4) &quot;2&quot;</span><br><span class="line">5) &quot;1&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>例子2: 对集合进行排序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd alphabet a b c d e f g h </span><br><span class="line">(integer) 8</span><br><span class="line">127.0.0.1:6379&gt; smembers alphabet</span><br><span class="line">1) &quot;e&quot;</span><br><span class="line">2) &quot;d&quot;</span><br><span class="line">3) &quot;h&quot;</span><br><span class="line">4) &quot;a&quot;</span><br><span class="line">5) &quot;g&quot;</span><br><span class="line">6) &quot;f&quot;</span><br><span class="line">7) &quot;b&quot;</span><br><span class="line">8) &quot;c&quot;</span><br><span class="line">127.0.0.1:6379&gt; sort alphabet alpha</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;b&quot;</span><br><span class="line">3) &quot;c&quot;</span><br><span class="line">4) &quot;d&quot;</span><br><span class="line">5) &quot;e&quot;</span><br><span class="line">6) &quot;f&quot;</span><br><span class="line">7) &quot;g&quot;</span><br><span class="line">8) &quot;h&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>例子3: 对有序集合进行排序,使用by字段排序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zadd test-result 3.0 jack 3.5 peter 4.0 tom </span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; zrange test-result 0 -1</span><br><span class="line">1) &quot;jack&quot;</span><br><span class="line">2) &quot;peter&quot;</span><br><span class="line">3) &quot;tom&quot;</span><br><span class="line">127.0.0.1:6379&gt; mset peter-number 1 tom-number 2 jack-number 3</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; sort test-result by *-number</span><br><span class="line">1) &quot;peter&quot;</span><br><span class="line">2) &quot;tom&quot;</span><br><span class="line">3) &quot;jack&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="sort命令的实现"><a href="#sort命令的实现" class="headerlink" title="sort命令的实现"></a>sort<key>命令的实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; rpush  numbers 3 1 2</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; sort numbers</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;3&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以上排序的具体实现</p>
<ol>
<li><p>创建一个和 numbers 列表长度相同的数组， 该数组的每个项都是一个 redis.h/redisSortObject 结构， 如图 IMAGE_CREATE_ARRAY 所示。<br><img src="/images/redis/luaandsort/IMAGE_CREATE_ARRAY.png" alt="IMAGE_CREATE_ARRAY"></p>
</li>
<li><p>遍历数组， 将各个数组项的 obj 指针分别指向 numbers 列表的各个项， 构成 obj 指针和列表项之间的一对一关系， 如图 IMAGE_POINT_OBJ 所示。<br><img src="/images/redis/luaandsort/IMAGE_POINT_OBJ.png" alt="IMAGE_POINT_OBJ"></p>
</li>
<li><p>遍历数组， 将各个 obj 指针所指向的列表项转换成一个 double 类型的浮点数， 并将这个浮点数保存在相应数组项的 u.score 属性里面， 如图 IMAGE_SET_SCORE 所示。<br><img src="/images/redis/luaandsort/IMAGE_SET_SCORE.png" alt="IMAGE_SET_SCORE"></p>
</li>
<li><p>根据数组项 u.score 属性的值， 对数组进行数字值排序， 排序后的数组项按 u.score 属性的值从小到大排列， 如图 IMAGE_SORTED 所示。<br><img src="/images/redis/luaandsort/IMAGE_SORTED.png" alt="IMAGE_SORTED"></p>
</li>
</ol>
<ul>
<li>redisSortObject 结构</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct _redisSortObject &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 被排序键的值</span><br><span class="line">    robj *obj;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 权重</span><br><span class="line">    union &#123;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 排序数字值时使用</span><br><span class="line">        double score;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 排序带有 BY 选项的字符串值时使用</span><br><span class="line">        robj *cmpobj;</span><br><span class="line"></span><br><span class="line">    &#125; u;</span><br><span class="line"></span><br><span class="line">&#125; redisSortObject;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="ALPHA选项的实现"><a href="#ALPHA选项的实现" class="headerlink" title="ALPHA选项的实现"></a>ALPHA选项的实现</h2><p>与sort<key> 类似,只不过排序的是字母.按照字母排序而不是数字的大小</p>
<h2 id="ASC和DESC选项的实现"><a href="#ASC和DESC选项的实现" class="headerlink" title="ASC和DESC选项的实现"></a>ASC和DESC选项的实现</h2><p>sort<key> 默认升序排列(ASC), DESC选项是将序排列</p>
<h2 id="BY选项的实现"><a href="#BY选项的实现" class="headerlink" title="BY选项的实现"></a>BY选项的实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zadd test-result 3.0 jack 3.5 peter 4.0 tom </span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; zrange test-result 0 -1</span><br><span class="line">1) &quot;jack&quot;</span><br><span class="line">2) &quot;peter&quot;</span><br><span class="line">3) &quot;tom&quot;</span><br><span class="line">127.0.0.1:6379&gt; mset peter-number 1 tom-number 2 jack-number 3</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; sort test-result by *-number</span><br><span class="line">1) &quot;peter&quot;</span><br><span class="line">2) &quot;tom&quot;</span><br><span class="line">3) &quot;jack&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>该例子中,只是将peter的权重键peter-number 1.0 放到u.score的位置,tom-number 2.0放到u.score的位置,jack-number 3.0放到u.score的位置,然后按照权重排序,输出到客户端.</p>
<h2 id="LIMIT-offset-count-选项"><a href="#LIMIT-offset-count-选项" class="headerlink" title="LIMIT offset count 选项"></a>LIMIT offset count 选项</h2><p>只是在排完序后跳过offset后,取出 count个元素</p>
<h2 id="GET选项"><a href="#GET选项" class="headerlink" title="GET选项"></a>GET选项</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd students &quot;peter&quot; &quot;jack&quot; &quot;tom&quot;</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; sort students alpha</span><br><span class="line">1) &quot;jack&quot;</span><br><span class="line">2) &quot;peter&quot;</span><br><span class="line">3) &quot;tom&quot;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;设置以上三个元素的全名</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; set peter-name &quot;peter white&quot;</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set jack-name &quot;jack snow&quot;</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set tom-name &quot;tom smith&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;sort命令首先对students集合进行排序,得到结果集,获取并返回键 peter-name jack-name tom-name的值</span><br><span class="line">127.0.0.1:6379&gt; sort students alpha get *-name</span><br><span class="line">1) &quot;jack snow&quot;</span><br><span class="line">2) &quot;peter white&quot;</span><br><span class="line">3) &quot;tom smith&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="store-选项"><a href="#store-选项" class="headerlink" title="store 选项"></a>store 选项</h2><p>将排序结果存到store的key中</p>
<h2 id="多个选项的执行顺序"><a href="#多个选项的执行顺序" class="headerlink" title="多个选项的执行顺序"></a>多个选项的执行顺序</h2><ol>
<li>排序:在这一步,命令会使用ALPHA/ASC/或者DESC/BY这几个选项,对输入键进行排序.并得到一个排序结果集.</li>
<li>限制排序结果集的长度.使用limit选项,对结果集的长度进行限制.</li>
<li>获取外部键,在这一步,命令会使用GET选项,根据排序结果集中的元素,以及get选项选定的模式,查找并获取指定的键的值,并用这些值作为新的排序结果集.</li>
<li>保存排序结果集,这这一步,命令会使用store选项,将结果集保存到指定的键上.</li>
<li>向客户端返回结果</li>
</ol>
<h1 id="LUA脚本"><a href="#LUA脚本" class="headerlink" title="LUA脚本"></a>LUA脚本</h1><p>redis从2.6版本开始对LUA脚本的支持,redis客户端可以使用LUA脚本,直接在服务端原子性的执行多条redis命令.</p>
<p>基本命令包括EVAL和EVALSHA,管理命令的四个命令:SCRIPT FLUSH,SCRIPT EXISTS,SCRIPT LOAD,SCRIPT KILL 四个命令.</p>
<p>关于LUA脚本,暂时不学习.</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis排序</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-数据库</title>
    <url>/2018-01-10/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<p>本篇将介绍redis数据库实现的相关操作.包括服务器保存数据库的方法,客户端切换数据库的方法,数据库保存键值对的方法,以及针对数据库的增删改查操作,还有键的过期时间和自动删除过期键的方法.</p>
<h1 id="服务器中的数据库"><a href="#服务器中的数据库" class="headerlink" title="服务器中的数据库"></a>服务器中的数据库</h1><p>redis服务器存在一个redisServer结构中,其中db数组的每一个项都是一个redisDb结构.</p>
<p>如下为服务器结构</p>
<p><img src="/images/redis/database/redisServer%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="redisServer数据结构"></p>
<p>服务器初始化时,根据服务器的dbnum属性来决定创建多少个数据库.默认创建16个数据库</p>
<p><img src="/images/redis/database/redisServer%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%842.png" alt="redisServer数据结构2"></p>
<p>服务器数据库实例如下:</p>
<p><img src="/images/redis/database/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E4%BE%8B.png" alt="服务器数据库实例"></p>
<h1 id="切换数据库"><a href="#切换数据库" class="headerlink" title="切换数据库"></a>切换数据库</h1><p>每个redis客户端都有自己的目标数据库.默认为0,用户可以通过select语句进行切换.</p>
<p>如下为redisClient的数据结构</p>
<p><img src="/images/redis/database/redisClient%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="redisClient的数据结构"></p>
<p>如下展示了客户端的目标数据库为1号数据库.</p>
<p><img src="/images/redis/database/%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E7%9B%AE%E6%A0%87%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BA1%E5%8F%B7%E6%95%B0%E6%8D%AE%E5%BA%93.png" alt="客户端的目标数据库为1号数据库"></p>
<p>redis仍然没有返回当前客户端使用的数据库的命令.所以,谨慎使用多数据库程序.</p>
<h1 id="数据库的空间键"><a href="#数据库的空间键" class="headerlink" title="数据库的空间键"></a>数据库的空间键</h1><p>redisDb结构的<strong>dict字典保存了数据库中的所有键值对.这字典被成为键空间</strong>.</p>
<p>键空间的键就是数据库的键,每个键是一个字符串对象.</p>
<p>键空间的值也是数据库的值,每个值可以时五种对象中的任意一种.</p>
<p><img src="/images/redis/database/%E9%94%AE%E7%A9%BA%E9%97%B4%E7%9A%84redisDb%E7%BB%93%E6%9E%84.png" alt="键空间的redisDb结构"></p>
<p><img src="/images/redis/database/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%94%AE%E7%A9%BA%E9%97%B4%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt="数据库键空间的例子"></p>
<p>数据库键空间时一个字典,所以所有针对数据库的操作,都是对键空间字典来操作的.</p>
<h2 id="添加新键"><a href="#添加新键" class="headerlink" title="添加新键"></a>添加新键</h2><p>添加一个新键值对到数据库,实际上就是将键值对添加到键空间.键为字符串对象,而值则为任意一种类型的Redis对象.</p>
<p>如下为添加一个字符串对象.</p>
<p><img src="/images/redis/database/%E6%B7%BB%E5%8A%A0%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AF%B9%E8%B1%A1%E5%90%8E%E7%9A%84%E9%94%AE%E7%A9%BA%E9%97%B4.png" alt="添加字符串对象后的键空间"></p>
<h2 id="删除键"><a href="#删除键" class="headerlink" title="删除键"></a>删除键</h2><p>执行如下语句后键空间变为如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; del book</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/images/redis/database/%E5%88%A0%E9%99%A4book%E9%94%AE%E5%90%8E%E7%9A%84%E9%94%AE%E7%A9%BA%E9%97%B4.png" alt="删除book键后的键空间"></p>
<h2 id="更新键"><a href="#更新键" class="headerlink" title="更新键"></a>更新键</h2><p>执行如下语句后键空间变为如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; set message &quot;blah blah&quot;</span><br><span class="line">ok</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/images/redis/database/set%E5%91%BD%E4%BB%A4%E6%9B%B4%E6%96%B0message%E9%94%AE.png" alt="set命令更新message键"></p>
<h2 id="对键取值"><a href="#对键取值" class="headerlink" title="对键取值"></a>对键取值</h2><p>执行如下语句后键空间变为如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; get message</span><br><span class="line"></span><br><span class="line">&quot;hello world&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/images/redis/database/get%E5%91%BD%E4%BB%A4%E5%8F%96%E5%80%BC.png" alt="get命令取值"></p>
<h2 id="读写键空间时的维护操作"><a href="#读写键空间时的维护操作" class="headerlink" title="读写键空间时的维护操作"></a>读写键空间时的维护操作</h2><ol>
<li>读取一个键之后,会更新服务器的键空间的命中次数或者不命中的次数. info stats查看</li>
<li>更新LRU操作</li>
<li>如果发现键已经过期,则先删除,再进行下一步操作.</li>
</ol>
<h1 id="设置键的生存时间或者过期时间"><a href="#设置键的生存时间或者过期时间" class="headerlink" title="设置键的生存时间或者过期时间"></a>设置键的生存时间或者过期时间</h1><p>设置 expire 或者pexpire 设置在多长时间后过期,ttl或者pttl查看过期时间</p>
<p>设置 expireat或者pexpireat设置在某一个时间点过期,为unix时间戳</p>
<h2 id="设置过期时间"><a href="#设置过期时间" class="headerlink" title="设置过期时间"></a>设置过期时间</h2><p>以上的四种过期时间命令最终都会转变为 pexpireat命令来执行.</p>
<h2 id="保存过期时间"><a href="#保存过期时间" class="headerlink" title="保存过期时间"></a>保存过期时间</h2><p>redisDb结构的expires字典保存了数据库中所有键的过期时间,我们称这个字典为过期字典.</p>
<ol>
<li>过期字典的键是一个指针,这个指针指向键空间中的某个键对象.</li>
<li>过期字典的值是一个long long类型的整数,这个整数是一个时间戳,保存的键的过期时刻.<br><img src="/images/redis/database/%E5%B8%A6%E6%9C%89%E8%BF%87%E6%9C%9F%E5%AD%97%E5%85%B8%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BE%8B%E5%AD%90.png" alt="带有过期字典的数据库例子"></li>
</ol>
<p>执行pexpireat命令,服务器会在数据库的过期字典中关联给定的数据库键和过期时间.</p>
<p><img src="/images/redis/database/%E6%89%A7%E8%A1%8Cpexireat%E5%91%BD%E4%BB%A4%E4%B9%8B%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93.png" alt="执行pexireat命令之后的数据库"></p>
<p><img src="/images/redis/database/%E6%89%A7%E8%A1%8Cpexpireat%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81.png" alt="执行pexpireat命令的伪代码"></p>
<h2 id="移除过期时间"><a href="#移除过期时间" class="headerlink" title="移除过期时间"></a>移除过期时间</h2><p>persist命令可以移除一个键的过期时间,即在过期字典中查找给定的键,并移除键和值(过期时间)在字典中的关联.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; persist book</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>数据库执行以上代码后的状态</p>
<p><img src="/images/redis/database/%E6%89%A7%E8%A1%8Cpersist%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93.png" alt="执行persist后的数据库"></p>
<h2 id="计算并返回剩余时间"><a href="#计算并返回剩余时间" class="headerlink" title="计算并返回剩余时间"></a>计算并返回剩余时间</h2><p>ttl 和pttl命令是计算键的过期时间和当前时间的差实现的.返回键的剩余剩余生存时间.</p>
<p><img src="/images/redis/database/pttl%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="pttl的伪代码实现"></p>
<p><img src="/images/redis/database/pttl%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B01.png" alt="pttl的伪代码实现1"></p>
<h2 id="过期键的判定"><a href="#过期键的判定" class="headerlink" title="过期键的判定"></a>过期键的判定</h2><p>通过过期字典判断给定键的过期,相对于ttl的实现速度快一些.</p>
<ol>
<li>检查给定的键是否在过期字典中存在,如果存在,则取得过期时间.</li>
<li>判断当前unix时间错是否大约键的过期时间,如果大于则过期,否则未过期.</li>
</ol>
<p>过期键判定的伪代码实现<br><img src="/images/redis/database/%E8%BF%87%E6%9C%9F%E9%94%AE%E5%88%A4%E5%AE%9A%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="过期键判定的伪代码实现"></p>
<h1 id="过期键的删除策略"><a href="#过期键的删除策略" class="headerlink" title="过期键的删除策略"></a>过期键的删除策略</h1><p>如果一个键过期了,它设呢么时候被删除呢?有以下三种策略.</p>
<ol>
<li>定时删除:在设置键的过期时间的同时,创建一个定时器,让定时器在过期时间来临时,立即执行删除操作.</li>
<li>惰性删除:放任过期键不管,但每次从键空间获取键时都要检查键是否过期,如果过期则删除;如果没有过期则返回.</li>
<li>定期删除:每个一段时间,程序就会进行一次减产,删除里面的过期键.至于删除多少过期键,怎么检查,由算法决定.</li>
</ol>
<h2 id="定时删除"><a href="#定时删除" class="headerlink" title="定时删除"></a>定时删除</h2><p>定时删除是对内存最友好的,但是是对cpu不友好的.当某一个时刻,有大量的过期键需要删除的时候会占用大量的cpu时间,而此时如果有查询操作,影响查询效率.而且设置时间事件(采用链表的数据结构实现)事件复杂度为O(n).处理起来不太高效.</p>
<h2 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h2><p>惰性删除对cpu是友好的,只有到了键非删除不可的时候才会被删除.但是对内存是不友好的.当键过期的时候,用户以为键被删除了,其实它还存在于键空间.如果用户痕迹不访问,则它会永远存在.这相当于内存泄露.</p>
<h2 id="定期删除"><a href="#定期删除" class="headerlink" title="定期删除"></a>定期删除</h2><p><strong>定时删除</strong>会占用太多的cpu时间.影响服务的相应时间和吞吐量.<strong>惰性删除</strong>会浪费过多内存,造成内存泄露.</p>
<p>定期删除时上述两种方式的折中策略,定时删除会每隔一段时间执行一次删除过期键的操作,并通过控制执行的市场和频率来减少对cpu时间的影响;除此之外定期删除还有效的减少了内存浪费.</p>
<p>定期删除策略的难点时确定删除操作的执行时间和频率.</p>
<h1 id="redis采用的过期键的删除策略"><a href="#redis采用的过期键的删除策略" class="headerlink" title="redis采用的过期键的删除策略"></a>redis采用的过期键的删除策略</h1><p>定期删除和惰性删除.</p>
<h2 id="惰性删除策略的实现"><a href="#惰性删除策略的实现" class="headerlink" title="惰性删除策略的实现"></a>惰性删除策略的实现</h2><p>惰性删除是采用expireIfNeeded函数来实现的,实现的执行过程如下所示</p>
<p><img src="/images/redis/database/%E6%83%B0%E6%80%A7%E5%88%A0%E9%99%A4%E9%94%AE%E7%AD%96%E7%95%A5%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="惰性删除键策略的执行流程"></p>
<h2 id="定期删除策略的实现"><a href="#定期删除策略的实现" class="headerlink" title="定期删除策略的实现"></a>定期删除策略的实现</h2><p>定期删除策略会调用activeExpireCycle函数实现.每当周期性的调用serverScron函数执行时,就会调用activeExpireCycle.</p>
<p>伪代码实现如下:<br><img src="/images/redis/database/%E5%AE%9A%E6%9C%9F%E5%88%A0%E9%99%A4%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B01.png" alt="定期删除的伪代码实现1"></p>
<p><img src="/images/redis/database/%E5%AE%9A%E6%9C%9F%E5%88%A0%E9%99%A4%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B02.png" alt="定期删除的伪代码实现2"></p>
<h1 id="AOF-RDB和复制功能对过期键的处理"><a href="#AOF-RDB和复制功能对过期键的处理" class="headerlink" title="AOF/RDB和复制功能对过期键的处理"></a>AOF/RDB和复制功能对过期键的处理</h1><h2 id="生成RDB文件"><a href="#生成RDB文件" class="headerlink" title="生成RDB文件"></a>生成RDB文件</h2><p>在执行save命令或者bgsave命令创建一个新的RDB文件时.程序会对数据库中的键进行检查,已过期的键不会保存到新建的RDB文件中.</p>
<h2 id="载入RDB文件"><a href="#载入RDB文件" class="headerlink" title="载入RDB文件"></a>载入RDB文件</h2><p>启动服务器的时候,如果开启了RDB功能,则服务器对RDB文件不行载入:</p>
<p>如果时主服务器模式运行.载入时会检查,未过期的键会被载入到数据库,过期则会被忽略;而从服务器模式运行的,在载入RDB文件的时候,所有键都会被载入.如果从服务器在进行数据同步的时候,从服务器的数据会被清空 </p>
<h2 id="AOF文件写入"><a href="#AOF文件写入" class="headerlink" title="AOF文件写入"></a>AOF文件写入</h2><p>当服务器以AOF持久化模式运行时,如果数据库中的某个键已经过期,但哈没有被删除,则AOF文件不会因此产生任何影响.当过期键被删除的时候会执行一条DEL 命令,来显示的记录该键已经被删除.</p>
<h2 id="AOF重写"><a href="#AOF重写" class="headerlink" title="AOF重写"></a>AOF重写</h2><p>和生成的RDB文件类似,在执行AOF重写的过程中,程序会检查过期的键,如果过期,则不保存到重写的AOF文件中.</p>
<h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><p>在服务器运行在复制模式下时,从服务器的过期键的删除动作由主服务器控制</p>
<ol>
<li>主服务器删除一个过期键之后,会显示的向所有从服务器发送一个DEL命令,告知从服务器删除这个过期键;</li>
<li>从服务器在执行客户端发送的度命令时,即使碰到过期键也不会将过期键删除,而时即系向处理未过期的键一样来处理过期键.(读取一条过期键的数据,会仍然返回结果)</li>
<li>从服务器只有收到住服务器的DEL命令之后,才会删除过期键. <strong>这样可以保证主从数据的一致性.</strong></li>
</ol>
<h1 id="数据库通知"><a href="#数据库通知" class="headerlink" title="数据库通知"></a>数据库通知</h1><p>数据库通知是redis2.8版本增加的功能.</p>
<p>通知分为两类,一种时键空间通知,即通知某一个键执行的所有命令,英译中时键事件通知,他们关注的是某个命令被什么键执行了.</p>
<p>由于数据库通知在实际应用中比较少,所以这里不做过多的介绍.想要详细了解可以自行翻阅相关资料.</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>redis集群-Sentinel</title>
    <url>/2018-02-08/redis%E9%9B%86%E7%BE%A4-Sentinel/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Redis Sentinel是用来实现Redis(2.8+)高可用的一套解决方案。Redis Sentinel由两个部分组成：由一个或者多个Sentinel实例组成Sentinel系统；<strong>由一个主Redis服务器</strong>(Master Redis)和多个从Redis服务器(Slave Redis)组成主从备份的Redis系统。</p>
<p>Sentinel系统本身是一个分布式的系统，它的作用是监视Redis服务器，在Master Redis下线时，自动将某个Slave Redis提升为新的主服务器。Redis系统由Master Redis处理客户端的命令请求，Slave Redis作为主服务器的备份而存在。</p>
<h1 id="Redis-Sentinel主要作用"><a href="#Redis-Sentinel主要作用" class="headerlink" title="Redis Sentinel主要作用"></a>Redis Sentinel主要作用</h1><ul>
<li>监控(Monitoring)：Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。</li>
<li>提醒(Notification)：当被监控的某个Redis服务器出现问题时， Sentinel可以通过API向管理员或者其他应用程序发送通知。</li>
<li>自动故障迁移(Automatic failover)：当一个主服务器不能正常工作时， Sentinel会开始一次自动故障迁移操作，它会将失效主服务器的其中一个从服务器升级为新的主服务器，并让失效主服务器的其他从服务器改为复制新的主服务器；当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址，使得集群可以使用新主服务器代替失效服务器。</li>
</ul>
<h1 id="构建Redis-Sentinel集群"><a href="#构建Redis-Sentinel集群" class="headerlink" title="构建Redis Sentinel集群"></a>构建Redis Sentinel集群</h1><p>主多从的Redis系统中，可以使用多个Sentinel进行监控任务以保证系统足够稳健。此时，不仅Sentinel会同时监控主数据库和从数据库，Sentinel之间也会相互监控.</p>
<h2 id="redis服务器配置-redis-conf文件"><a href="#redis服务器配置-redis-conf文件" class="headerlink" title="redis服务器配置 redis.conf文件"></a>redis服务器配置 redis.conf文件</h2><p>主节点(由于主从节点有可能切换所以涉及密码的两个参数每个节点都需要配置)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">port 7000</span><br><span class="line">requirepass test</span><br><span class="line">masterauth test</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>从节点1 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">port 7001</span><br><span class="line">requirepass test</span><br><span class="line">masterauth test</span><br><span class="line">slaveof 127.0.0.1 7000</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>从节点2</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">port 7002</span><br><span class="line">requirepass test</span><br><span class="line">masterauth test</span><br><span class="line">slaveof 127.0.0.1 7000</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="配置Sentinel-conf-三个文件只有port和日志目录不一样"><a href="#配置Sentinel-conf-三个文件只有port和日志目录不一样" class="headerlink" title="配置Sentinel.conf (三个文件只有port和日志目录不一样)"></a>配置Sentinel.conf (三个文件只有port和日志目录不一样)</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bind 127.0.0.1</span><br><span class="line">port 27000</span><br><span class="line">sentinel monitor mymaster 127.0.0.1 7000 2</span><br><span class="line">sentinel down-after-milliseconds mymaster 5000</span><br><span class="line">sentinel failover-timeout mymaster 180000</span><br><span class="line">sentinel parallel-syncs mymaster 2</span><br><span class="line">sentinel auth-pass mymaster test</span><br><span class="line">logfile &quot;&#x2F;usr&#x2F;local&#x2F;redisSentinel&#x2F;7000&#x2F;sentinelLog&#x2F;log.log&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="配置文件解释"><a href="#配置文件解释" class="headerlink" title="配置文件解释"></a>配置文件解释</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">port 27000</span><br><span class="line">Sentinel实例之间的通讯端口，该端口号默认为26379。</span><br><span class="line"></span><br><span class="line">bind 127.0.0.1</span><br><span class="line">Sentinel默认会绑定到127.0.0.1，这里要在多台机器间通信，我们将它绑定到主机IP上。</span><br><span class="line"></span><br><span class="line">sentinel monitor mymaster 127.0.0.1 7000 2</span><br><span class="line">Sentinel去监视一个名为mymaster的主服务器，这个主服务器的IP地址为127.0.0.1  ，端口号为7000。将这个主服务器判断为失效至少需要2个Sentinel同意，一般设置为N&#x2F;2+1(N为Sentinel总数)。只要同意Sentinel的数量不达标，自动故障迁移就不会执行。</span><br><span class="line"></span><br><span class="line">不过要注意，无论你设置要多少个Sentinel同意才能判断一个服务器失效， 一个Sentinel都需要获得系统中多数Sentinel的支持，才能发起一次自动故障迁移，并预留一个给定的配置纪元。(configuration Epoch ，一个配置纪元就是一个新主服务器配置的版本号)。</span><br><span class="line"></span><br><span class="line">sentinel down-after-milliseconds mymaster 5000</span><br><span class="line">down-after-milliseconds选项指定了Sentinel认为服务器已经断线所需的毫秒数。如果服务器在给定的毫秒数之内，没有返回Sentinel发送的PING命令的回复，或者返回一个错误，那么Sentinel将这个服务器标记为主观下线(subjectively down，简称SDOWN)。</span><br><span class="line"></span><br><span class="line">不过只有一个Sentinel将服务器标记为主观下线并不一定会引起服务器的自动故障迁移，只有在足够数量的Sentinel都将一个服务器标记为主观下线之后，服务器才会被标记为客观下线(objectively down，简称ODOWN)， 这时自动故障迁移才会执行。将服务器标记为客观下线所需的Sentinel数量由对主服务器的配置(sentinel monitor参数)决定。</span><br><span class="line"></span><br><span class="line">sentinel failover-timeout mymaster 180000</span><br><span class="line">如果在多少毫秒内没有把宕掉的那台Master恢复，那Sentinel认为这是一次真正的宕机。在下一次选取时排除该宕掉的Master作为可用的节点，然后等待一定的设定值的毫秒数后再来探测该节点是否恢复，如果恢复就把它作为一台Slave加入Sentinel监测节点群，并在下一次切换时为他分配一个”选取号”。</span><br><span class="line"></span><br><span class="line">sentinel parallel-syncs mymaster 2</span><br><span class="line">parallel-syncs选项指定了在执行故障转移时，最多可以有多少个从服务器同时对新的主服务器进行同步。这个数字越小，完成故障转移所需的时间就越长。</span><br><span class="line"></span><br><span class="line">如果从服务器被设置为允许使用过期数据集(slave-serve-stale-data选项)， 那么你可能不希望所有从服务器都在同一时间向新的主服务器发送同步请求。因为尽管复制过程的绝大部分步骤都不会阻塞从服务器，但从服务器在载入主服务器发来的RDB文件时，仍然会造成从服务器在一段时间内不能处理命令请求。</span><br><span class="line"></span><br><span class="line">如果全部从服务器一起对新的主服务器进行同步，那么就可能会造成所有从服务器在短时间内全部不可用的情况出现。你可以通过将这个值设为1来保证每次只有一个从服务器处于不能处理命令请求的状态。</span><br><span class="line"></span><br><span class="line">sentinel auth-pass mymaster test</span><br><span class="line">当Master设置了密码时，Sentinel连接Master和Slave时需要通过设置参数auth-pass配置相应密码。</span><br><span class="line"></span><br><span class="line">logfile &#x2F;usr&#x2F;local&#x2F;redisSentinel&#x2F;7000&#x2F;sentinelLog&#x2F;log.log</span><br><span class="line">日志文件所在位置，</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="启动sentinel集群"><a href="#启动sentinel集群" class="headerlink" title="启动sentinel集群"></a>启动sentinel集群</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo .&#x2F;src&#x2F;redis-sentinel sentinel.conf &amp;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="通过redis客户端工具查看当前Sentinel的信息"><a href="#通过redis客户端工具查看当前Sentinel的信息" class="headerlink" title="通过redis客户端工具查看当前Sentinel的信息"></a>通过redis客户端工具查看当前Sentinel的信息</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisSentinel&#x2F;7000$ .&#x2F;src&#x2F;redis-cli -p 27000 -h 127.0.0.1 INFO Sentinel</span><br><span class="line"># Sentinel</span><br><span class="line">sentinel_masters:1</span><br><span class="line">sentinel_tilt:0</span><br><span class="line">sentinel_running_scripts:0</span><br><span class="line">sentinel_scripts_queue_length:0</span><br><span class="line">sentinel_simulate_failure_flags:0</span><br><span class="line">master0:name&#x3D;mymaster,status&#x3D;ok,address&#x3D;127.0.0.1:7000,slaves&#x3D;2,sentinels&#x3D;3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Sentinel启动后会输出类似的日志"><a href="#Sentinel启动后会输出类似的日志" class="headerlink" title="Sentinel启动后会输出类似的日志"></a>Sentinel启动后会输出类似的日志</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">21    6839:X 09 Feb 01:14:11.494 # Sentinel ID is b9095b246a20441e432f693f9b9042d7bb605372</span><br><span class="line">22    6839:X 09 Feb 01:14:11.494 # +monitor master mymaster 127.0.0.1 7000 quorum 2</span><br><span class="line">23    6839:X 09 Feb 01:14:11.495 * +slave slave 127.0.0.1:7001 127.0.0.1 7001 @ mymaster 127.0.0.1 7000</span><br><span class="line">24    6839:X 09 Feb 01:14:11.527 * +slave slave 127.0.0.1:7002 127.0.0.1 7002 @ mymaster 127.0.0.1 7000</span><br><span class="line">25    6839:X 09 Feb 01:18:56.295 * +sentinel sentinel 5a18eecd2dcb3ce949a30d15e12dc4e14d3dc73b 127.0.0.1 27001 @ mymaster 127.0.0.1 7000</span><br><span class="line">26    6839:X 09 Feb 01:20:54.521 * +sentinel sentinel 7df87dde32ceeced13dfd020f99c914414b9f474 127.0.0.1 27002 @ mymaster 127.0.0.1 7000</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>+slave和+sentinel分别代表成功发现了从数据库和其他Sentinel。</p>
<h2 id="sentinel-conf文件生成信息"><a href="#sentinel-conf文件生成信息" class="headerlink" title="sentinel.conf文件生成信息"></a>sentinel.conf文件生成信息</h2><p>重新打开sentinel.conf文件，发现Sentinel自动生成了一些信息，记录了监控过程中的状态变化。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">199    # Generated by CONFIG REWRITE</span><br><span class="line">200    sentinel config-epoch mymaster 0</span><br><span class="line">201    sentinel leader-epoch mymaster 0</span><br><span class="line">202    sentinel known-slave mymaster 127.0.0.1 7001</span><br><span class="line">203    sentinel known-slave mymaster 127.0.0.1 7002</span><br><span class="line">204    sentinel known-sentinel mymaster 127.0.0.1 27002 7df87dde32ceeced13dfd020f99c914414b9f474</span><br><span class="line">205    sentinel known-sentinel mymaster 127.0.0.1 27001 5a18eecd2dcb3ce949a30d15e12dc4e14d3dc73b</span><br><span class="line">206    sentinel current-epoch 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="查看Sentinel监控的主从服务器"><a href="#查看Sentinel监控的主从服务器" class="headerlink" title="查看Sentinel监控的主从服务器"></a>查看Sentinel监控的主从服务器</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisSentinel&#x2F;7000$ .&#x2F;src&#x2F;redis-cli -h 127.0.0.1 -p 27000 </span><br><span class="line">127.0.0.1:27000&gt; sentinel master mymaster</span><br><span class="line"> 1) &quot;name&quot;</span><br><span class="line"> 2) &quot;mymaster&quot;</span><br><span class="line"> 3) &quot;ip&quot;</span><br><span class="line"> 4) &quot;127.0.0.1&quot;</span><br><span class="line"> 5) &quot;port&quot;</span><br><span class="line"> 6) &quot;7000&quot;</span><br><span class="line"> 7) &quot;runid&quot;</span><br><span class="line"> 8) &quot;1d998c438067f7fd3ad51742380bf16257fd0877&quot;</span><br><span class="line"> 9) &quot;flags&quot;</span><br><span class="line">10) &quot;master&quot;</span><br><span class="line">11) &quot;link-pending-commands&quot;</span><br><span class="line">12) &quot;0&quot;</span><br><span class="line">13) &quot;link-refcount&quot;</span><br><span class="line">14) &quot;1&quot;</span><br><span class="line">15) &quot;last-ping-sent&quot;</span><br><span class="line">16) &quot;0&quot;</span><br><span class="line">17) &quot;last-ok-ping-reply&quot;</span><br><span class="line">18) &quot;168&quot;</span><br><span class="line">19) &quot;last-ping-reply&quot;</span><br><span class="line">20) &quot;168&quot;</span><br><span class="line">21) &quot;down-after-milliseconds&quot;</span><br><span class="line">22) &quot;5000&quot;</span><br><span class="line">23) &quot;info-refresh&quot;</span><br><span class="line">24) &quot;6675&quot;</span><br><span class="line">25) &quot;role-reported&quot;</span><br><span class="line">26) &quot;master&quot;</span><br><span class="line">27) &quot;role-reported-time&quot;</span><br><span class="line">28) &quot;1804688&quot;</span><br><span class="line">29) &quot;config-epoch&quot;</span><br><span class="line">30) &quot;0&quot;</span><br><span class="line">31) &quot;num-slaves&quot;</span><br><span class="line">32) &quot;2&quot;</span><br><span class="line">33) &quot;num-other-sentinels&quot;</span><br><span class="line">34) &quot;2&quot;</span><br><span class="line">35) &quot;quorum&quot;</span><br><span class="line">36) &quot;2&quot;</span><br><span class="line">37) &quot;failover-timeout&quot;</span><br><span class="line">38) &quot;180000&quot;</span><br><span class="line">39) &quot;parallel-syncs&quot;</span><br><span class="line">40) &quot;2&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="Sentinel验证"><a href="#Sentinel验证" class="headerlink" title="Sentinel验证"></a>Sentinel验证</h1><p>我们让7000节点上的mymaster主动休眠30秒来观察failover过程：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ redis-cli -p 7000 -h 127.0.0.1 -a test DEBUG sleep 30</span><br></pre></td></tr></table></figure>
<p>日志如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisSentinel&#x2F;7000$ .&#x2F;src&#x2F;redis-cli -p 7000 -h 127.0.0.1 -a test DEBUG sleep 30</span><br><span class="line">5303:M 09 Feb 01:47:41.392 # Connection with master lost.</span><br><span class="line">5303:M 09 Feb 01:47:41.393 * Caching the disconnected master state.</span><br><span class="line">5303:M 09 Feb 01:47:41.393 * Discarding previously cached master state.</span><br><span class="line">5303:M 09 Feb 01:47:41.393 * MASTER MODE enabled (user request from &#39;id&#x3D;5 addr&#x3D;127.0.0.1:36346 fd&#x3D;8 name&#x3D;sentinel-5a18eecd-cmd age&#x3D;1727 idle&#x3D;0 flags&#x3D;x db&#x3D;0 sub&#x3D;0 psub&#x3D;0 multi&#x3D;3 qbuf&#x3D;0 qbuf-free&#x3D;32768 obl&#x3D;36 oll&#x3D;0 omem&#x3D;0 events&#x3D;r cmd&#x3D;exec&#39;)</span><br><span class="line">5303:M 09 Feb 01:47:41.395 # CONFIG REWRITE executed with success.</span><br><span class="line">5303:M 09 Feb 01:47:41.463 * 1 changes in 900 seconds. Saving...</span><br><span class="line">5303:M 09 Feb 01:47:41.464 * Background saving started by pid 9725</span><br><span class="line">9725:C 09 Feb 01:47:41.506 * DB saved on disk</span><br><span class="line">9725:C 09 Feb 01:47:41.507 * RDB: 8 MB of memory used by copy-on-write</span><br><span class="line">5303:M 09 Feb 01:47:41.565 * Background saving terminated with success</span><br><span class="line">5312:S 09 Feb 01:47:42.196 # Connection with master lost.</span><br><span class="line">5312:S 09 Feb 01:47:42.196 * Caching the disconnected master state.</span><br><span class="line">5312:S 09 Feb 01:47:42.196 * Discarding previously cached master state.</span><br><span class="line">5312:S 09 Feb 01:47:42.197 * SLAVE OF 127.0.0.1:7001 enabled (user request from &#39;id&#x3D;5 addr&#x3D;127.0.0.1:38372 fd&#x3D;8 name&#x3D;sentinel-5a18eecd-cmd age&#x3D;1728 idle&#x3D;0 flags&#x3D;x db&#x3D;0 sub&#x3D;0 psub&#x3D;0 multi&#x3D;3 qbuf&#x3D;133 qbuf-free&#x3D;32635 obl&#x3D;36 oll&#x3D;0 omem&#x3D;0 events&#x3D;r cmd&#x3D;exec&#39;)</span><br><span class="line">5312:S 09 Feb 01:47:42.200 # CONFIG REWRITE executed with success.</span><br><span class="line">5312:S 09 Feb 01:47:42.284 * 1 changes in 900 seconds. Saving...</span><br><span class="line">5312:S 09 Feb 01:47:42.286 * Background saving started by pid 9726</span><br><span class="line">5312:S 09 Feb 01:47:42.286 * Connecting to MASTER 127.0.0.1:7001</span><br><span class="line">5312:S 09 Feb 01:47:42.287 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">5312:S 09 Feb 01:47:42.287 * Non blocking connect for SYNC fired the event.</span><br><span class="line">5312:S 09 Feb 01:47:42.287 * Master replied to PING, replication can continue...</span><br><span class="line">5312:S 09 Feb 01:47:42.287 * Partial resynchronization not possible (no cached master)</span><br><span class="line">5303:M 09 Feb 01:47:42.287 * Slave 127.0.0.1:7002 asks for synchronization</span><br><span class="line">5303:M 09 Feb 01:47:42.287 * Full resync requested by slave 127.0.0.1:7002</span><br><span class="line">5303:M 09 Feb 01:47:42.287 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">5303:M 09 Feb 01:47:42.289 * Background saving started by pid 9727</span><br><span class="line">5312:S 09 Feb 01:47:42.290 * Full resync from master: 4e882289bf41e7cef05f83f5e1d81fb8ad97e63e:348338</span><br><span class="line">9726:C 09 Feb 01:47:42.345 * DB saved on disk</span><br><span class="line">9726:C 09 Feb 01:47:42.346 * RDB: 6 MB of memory used by copy-on-write</span><br><span class="line">9727:C 09 Feb 01:47:42.366 * DB saved on disk</span><br><span class="line">9727:C 09 Feb 01:47:42.366 * RDB: 8 MB of memory used by copy-on-write</span><br><span class="line">5303:M 09 Feb 01:47:42.368 * Background saving terminated with success</span><br><span class="line">5312:S 09 Feb 01:47:42.368 * MASTER &lt;-&gt; SLAVE sync: receiving 77 bytes from master</span><br><span class="line">5303:M 09 Feb 01:47:42.368 * Synchronization with slave 127.0.0.1:7002 succeeded</span><br><span class="line">5312:S 09 Feb 01:47:42.368 * MASTER &lt;-&gt; SLAVE sync: Flushing old data</span><br><span class="line">5312:S 09 Feb 01:47:42.368 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory</span><br><span class="line">5312:S 09 Feb 01:47:42.368 * MASTER &lt;-&gt; SLAVE sync: Finished with success</span><br><span class="line">5312:S 09 Feb 01:47:42.387 * Background saving terminated with success</span><br><span class="line">OK</span><br><span class="line">5296:M 09 Feb 01:48:05.885 # Connection with slave client id #2 lost.</span><br><span class="line">5296:M 09 Feb 01:48:05.885 # Connection with slave client id #3 lost.</span><br><span class="line">5296:S 09 Feb 01:48:15.954 * SLAVE OF 127.0.0.1:7001 enabled (user request from &#39;id&#x3D;26 addr&#x3D;127.0.0.1:34652 fd&#x3D;26 name&#x3D;sentinel-b9095b24-cmd age&#x3D;10 idle&#x3D;0 flags&#x3D;x db&#x3D;0 sub&#x3D;0 psub&#x3D;0 multi&#x3D;3 qbuf&#x3D;0 qbuf-free&#x3D;32768 obl&#x3D;36 oll&#x3D;0 omem&#x3D;0 events&#x3D;r cmd&#x3D;exec&#39;)</span><br><span class="line">5296:S 09 Feb 01:48:15.956 # CONFIG REWRITE executed with success.</span><br><span class="line">5296:S 09 Feb 01:48:16.010 * 1 changes in 900 seconds. Saving...</span><br><span class="line">5296:S 09 Feb 01:48:16.011 * Background saving started by pid 9733</span><br><span class="line">9733:C 09 Feb 01:48:16.046 * DB saved on disk</span><br><span class="line">9733:C 09 Feb 01:48:16.047 * RDB: 4 MB of memory used by copy-on-write</span><br><span class="line">5296:S 09 Feb 01:48:16.111 * Background saving terminated with success</span><br><span class="line">5296:S 09 Feb 01:48:16.813 * Connecting to MASTER 127.0.0.1:7001</span><br><span class="line">5296:S 09 Feb 01:48:16.813 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">5296:S 09 Feb 01:48:16.813 * Non blocking connect for SYNC fired the event.</span><br><span class="line">5296:S 09 Feb 01:48:16.813 * Master replied to PING, replication can continue...</span><br><span class="line">5296:S 09 Feb 01:48:16.814 * Partial resynchronization not possible (no cached master)</span><br><span class="line">5303:M 09 Feb 01:48:16.815 * Slave 127.0.0.1:7000 asks for synchronization</span><br><span class="line">5303:M 09 Feb 01:48:16.815 * Full resync requested by slave 127.0.0.1:7000</span><br><span class="line">5303:M 09 Feb 01:48:16.815 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">5303:M 09 Feb 01:48:16.816 * Background saving started by pid 9734</span><br><span class="line">5296:S 09 Feb 01:48:16.818 * Full resync from master: 4e882289bf41e7cef05f83f5e1d81fb8ad97e63e:355186</span><br><span class="line">9734:C 09 Feb 01:48:16.855 * DB saved on disk</span><br><span class="line">9734:C 09 Feb 01:48:16.856 * RDB: 6 MB of memory used by copy-on-write</span><br><span class="line">5303:M 09 Feb 01:48:16.859 * Background saving terminated with success</span><br><span class="line">5296:S 09 Feb 01:48:16.859 * MASTER &lt;-&gt; SLAVE sync: receiving 77 bytes from master</span><br><span class="line">5303:M 09 Feb 01:48:16.859 * Synchronization with slave 127.0.0.1:7000 succeeded</span><br><span class="line">5296:S 09 Feb 01:48:16.859 * MASTER &lt;-&gt; SLAVE sync: Flushing old data</span><br><span class="line">5296:S 09 Feb 01:48:16.859 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory</span><br><span class="line">5296:S 09 Feb 01:48:16.860 * MASTER &lt;-&gt; SLAVE sync: Finished with success</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="生产环境推荐"><a href="#生产环境推荐" class="headerlink" title="生产环境推荐"></a>生产环境推荐</h2><p>对于一个最小集群，Redis应该是一个Master带上两个Slave，并且开启下列选项：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">min-slaves-to-write 1</span><br><span class="line">min-slaves-max-lag 10</span><br></pre></td></tr></table></figure>
<p>这样能保证写入Master的同时至少写入一个Slave，如果出现网络分区阻隔并发生failover的时候，可以保证写入的数据最终一致而不是丢失，写入老的Master会直接失败。</p>
<p>Slave可以适当设置优先级，除了0之外(0表示永远不提升为Master)，越小的优先级，越有可能被提示为Master。如果Slave分布在多个机房，可以考虑将和Master同一个机房的Slave的优先级设置的更低以提升他被选为新的Master的可能性。</p>
<p>考虑到可用性和选举的需要，Sentinel进程至少为3个，推荐为5个。如果有网络分区，应当适当分布(比如2个在A机房， 2个在B机房，一个在C机房)等。</p>
<h2 id="增加和移除Sentinel"><a href="#增加和移除Sentinel" class="headerlink" title="增加和移除Sentinel"></a>增加和移除Sentinel</h2><p>增加新的Sentinel实例非常简单，修改好配置文件，启动即可，其他Sentinel会自动发现该实例并加入集群。如果要批量启动一批Sentinel节点，最好以30秒的间隔一个一个启动为好，这样能确保整个 Sentinel集群的大多数能够及时感知到新节点，满足当时可能发生的选举条件。</p>
<p>移除一个Sentinel实例会相对麻烦一些，因为Sentinel不会忘记已经感知到的Sentinel实例，所以最好按照下列步骤来处理：</p>
<ul>
<li>停止将要移除的sentinel进程。</li>
<li>给其余的sentinel进程发送SENTINEL RESET *命令来重置状态，忘记将要移除的sentinel，每个进程之间间隔30秒。</li>
<li>确保所有sentinel对于当前存货的sentinel数量达成一致，可以通过SENTINEL MASTER <mastername>命令来观察，或者查看配置文件。</li>
</ul>
<h2 id="客户端实现"><a href="#客户端实现" class="headerlink" title="客户端实现"></a>客户端实现</h2><p>客户端从过去直接连接Redis ，变成：</p>
<ul>
<li>先连接一个Sentinel实例</li>
<li>使用 SENTINEL get-master-addr-by-name master-name 获取Redis地址信息。</li>
<li>连接返回的Redis地址信息，通过ROLE命令查询是否是Master。如果是，连接进入正常的服务环节。否则应该断开重新查询。</li>
<li>(可选)客户端可以通过SENTINEL sentinels <master-name>来更新自己的Sentinel实例列表。</li>
</ul>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>由于Redis是异步复制，所以Sentinel其实无法达到强一致性，它承诺的是最终一致性：最后一次failover的Redis Master赢者通吃，其他Slave的数据将被丢弃，重新从新的Master复制数据</p>
<p><a href="http://www.yunweipai.com/archives/20444.html">参考Sentinel</a></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title>redis集群-主从配置</title>
    <url>/2018-02-08/redis%E9%9B%86%E7%BE%A4-%E4%B8%BB%E4%BB%8E%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>由于redis支持的redis cluster和redis sentinel 的集群模式为了保证高可用和高负载需要多台服务器.用redis的主从模式,读写分离,是另一种高可用的方案(容灾效果相对不好).</p>
<h1 id="redis主从模式的特点"><a href="#redis主从模式的特点" class="headerlink" title="redis主从模式的特点"></a>redis主从模式的特点</h1><ul>
<li>一个master可以拥有多个slave</li>
<li>多个slave链接同一个master，也可以链接其它slave</li>
<li>主从复制不会阻塞master,在同步数据时，master可以继续处理client请求.</li>
<li>slave 配置为slave-read-only on需要升级为主节点或者写入配置文件中, 而不能在默认slave情况下直接设置</li>
<li>master与slave断开后会检测心跳, 从新建立连接.</li>
<li>可以直接copy DUMP文件从新重启master</li>
<li>在Master为空以后，slave同步数据会抹掉全部数据.</li>
<li>在实际的使用中最好主服务器还是使用50%到65%的内存,剩下的用于bgsave命令的运行和创建记录写命令的缓冲区.</li>
<li>从服务器在同步主服务器的数据的时候,会清空从服务器中的数据,并被替换为主服务器发来的数据.</li>
</ul>
<p>以下为redis的主从配置实战</p>
<h1 id="下载并编译redis源码包"><a href="#下载并编译redis源码包" class="headerlink" title="下载并编译redis源码包"></a>下载并编译redis源码包</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-3.2.10.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxvf redis-3.2.10.tar.gz</span><br><span class="line"></span><br><span class="line">cd &#x2F;redis-3.2.10&#x2F;src&#x2F;</span><br><span class="line"></span><br><span class="line">make</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="配置redis主从"><a href="#配置redis主从" class="headerlink" title="配置redis主从"></a>配置redis主从</h1><p>主：127.0.0.1:6379</p>
<p>从：127.0.0.1:6380</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo mkdir redis-6379 redis-6380</span><br><span class="line"></span><br><span class="line">sudo cp redis-3.2.10&#x2F;* -r redis-6379&#x2F;</span><br><span class="line"></span><br><span class="line">sudo cp redis-3.2.10&#x2F;* -r redis-6380&#x2F;</span><br><span class="line"></span><br><span class="line">sudo mkdir &#x2F;usr&#x2F;local&#x2F;redisSlave&#x2F;redis-6379&#x2F;run  &#x2F;usr&#x2F;local&#x2F;redisSlave&#x2F;redis-6380&#x2F;run</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="配置主节点-redis-config-注意-prod环境需要配置bind-参数"><a href="#配置主节点-redis-config-注意-prod环境需要配置bind-参数" class="headerlink" title="配置主节点 redis.config (注意,prod环境需要配置bind 参数)"></a>配置主节点 redis.config (注意,prod环境需要配置bind 参数)</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">port 6379</span><br><span class="line">daemonize yes</span><br><span class="line">pidfile &#x2F;usr&#x2F;local&#x2F;redisSlave&#x2F;redis-6379&#x2F;run&#x2F;redis_6379.pid</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="配置从节点-redis-config"><a href="#配置从节点-redis-config" class="headerlink" title="配置从节点 redis.config"></a>配置从节点 redis.config</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">port 6380</span><br><span class="line">daemonize yes</span><br><span class="line">pidfile &#x2F;usr&#x2F;local&#x2F;redisSlave&#x2F;redis-6380&#x2F;run&#x2F;redis_6380.pid</span><br><span class="line">slaveof 127.0.0.1 6379</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其它配置采用默认配置即可</p>
<h1 id="启动服务器"><a href="#启动服务器" class="headerlink" title="启动服务器"></a>启动服务器</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisSlave&#x2F;redis-6379$ sudo .&#x2F;src&#x2F;redis-server redis.conf &amp;</span><br><span class="line"></span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisSlave&#x2F;redis-6380$ sudo .&#x2F;src&#x2F;redis-server redis.conf &amp;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="连接客户端测试"><a href="#连接客户端测试" class="headerlink" title="连接客户端测试"></a>连接客户端测试</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisSlave&#x2F;redis-6380$ sudo .&#x2F;src&#x2F;redis-cli -h 127.0.0.1 -p 6380</span><br><span class="line">127.0.0.1:6379&gt; info replication</span><br><span class="line"># Replication</span><br><span class="line">role:master</span><br><span class="line">connected_slaves:1</span><br><span class="line">slave0:ip&#x3D;127.0.0.1,port&#x3D;6380,state&#x3D;online,offset&#x3D;533,lag&#x3D;0</span><br><span class="line">master_repl_offset:533</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:2</span><br><span class="line">repl_backlog_histlen:532</span><br><span class="line">127.0.0.1:6379&gt; set master 127.0.0.1:6379</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set slave 127.0.0.1:6380</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisSlave&#x2F;redis-6379$ sudo .&#x2F;src&#x2F;redis-cli -h 127.0.0.1 -p 6379</span><br><span class="line">127.0.0.1:6380&gt; info replication</span><br><span class="line"># Replication</span><br><span class="line">role:slave</span><br><span class="line">master_host:127.0.0.1</span><br><span class="line">master_port:6379</span><br><span class="line">master_link_status:up</span><br><span class="line">master_last_io_seconds_ago:9</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:750</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br><span class="line">master_repl_offset:0</span><br><span class="line">repl_backlog_active:0</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:0</span><br><span class="line">repl_backlog_histlen:0</span><br><span class="line">127.0.0.1:6380&gt; get master</span><br><span class="line">&quot;127.0.0.1:6379&quot;</span><br><span class="line">127.0.0.1:6380&gt; get slave</span><br><span class="line">&quot;127.0.0.1:6380&quot;</span><br><span class="line">127.0.0.1:6380&gt; set slave test</span><br><span class="line">(error) READONLY You can&#39;t write against a read only slave.</span><br><span class="line">127.0.0.1:6380&gt; </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以上信息中role分别代表master 和slave.</p>
<p>在主节点中set master和slave,在从节点中可以获取到值的信息.表示主从配置成功.</p>
<h1 id="从节点复制从节点"><a href="#从节点复制从节点" class="headerlink" title="从节点复制从节点"></a>从节点复制从节点</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">6381配置和6380的一样都是作为6379的丛节点.</span><br><span class="line"></span><br><span class="line">6382的配置和6380不同的是,slaveof参数为6381</span><br><span class="line"></span><br><span class="line">127.0.0.1:6381&gt; info replication</span><br><span class="line"># Replication</span><br><span class="line">role:slave</span><br><span class="line">master_host:127.0.0.1</span><br><span class="line">master_port:6379</span><br><span class="line">master_link_status:up</span><br><span class="line">master_last_io_seconds_ago:8</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:3284</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:1</span><br><span class="line">slave0:ip&#x3D;127.0.0.1,port&#x3D;6382,state&#x3D;online,offset&#x3D;113,lag&#x3D;0</span><br><span class="line">master_repl_offset:113</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:2</span><br><span class="line">repl_backlog_histlen:112</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">127.0.0.1:6382&gt; info replication</span><br><span class="line"># Replication</span><br><span class="line">role:slave</span><br><span class="line">master_host:127.0.0.1</span><br><span class="line">master_port:6381</span><br><span class="line">master_link_status:up</span><br><span class="line">master_last_io_seconds_ago:8</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:99</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br><span class="line">master_repl_offset:0</span><br><span class="line">repl_backlog_active:0</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:0</span><br><span class="line">repl_backlog_histlen:0</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="主从切换"><a href="#主从切换" class="headerlink" title="主从切换"></a>主从切换</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">主挂掉了后从执行：</span><br><span class="line">src&#x2F;redis-cli -p 6380 slaveof NO ONE</span><br><span class="line"></span><br><span class="line">主恢复后从执行：</span><br><span class="line">src&#x2F;redis-cli -p 6380 slaveof 127.0.0.1 6379</span><br></pre></td></tr></table></figure>

<h1 id="主从配置密码"><a href="#主从配置密码" class="headerlink" title="主从配置密码"></a>主从配置密码</h1><p>主:redis.conf中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">requirepass abc</span><br></pre></td></tr></table></figure>

<p>从:redis.conf中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">masterauth abc</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis 主从</tag>
      </tags>
  </entry>
  <entry>
    <title>web-session和cookie的区别</title>
    <url>/2017-10-14/web-session%E5%92%8Ccookie%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<h2 id="session和cookie时开发中常用到的两个对象。"><a href="#session和cookie时开发中常用到的两个对象。" class="headerlink" title="session和cookie时开发中常用到的两个对象。"></a>session和cookie时开发中常用到的两个对象。</h2><h4 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    cookie是一小段文本信息，伴随着用户请求和页面在web服务器和浏览器之间传递。cookie包含每次用户访问站点用户都可以读取的</span><br><span class="line">信息。(cookie会随着每次http请求一起被传到服务端）</span><br><span class="line">    当你在浏览网站的时候，WEB 服务器会先送一小小资料放在你的计算机上，Cookie 会帮你在网站上所打的文字或是一些选择，都纪</span><br><span class="line">录下来。当下次你再光临同一个网站，WEB 服务器会先看看有没有它上次留下的 Cookie 资料，有的话，就会依据 Cookie里的内容来判</span><br><span class="line">断使用者，送出特定的网页内容给你。 Cookie 的使用很普遍，许多有提供个人化服务的网站，都是利用 Cookie来辨认使用者，以方便</span><br><span class="line">送出使用者量身定做的内容，像是 Web 接口的免费 email 网站，都要用到 Cookie。 </span><br><span class="line">    具体来说cookie机制采用的是在客户端保持状态的方案，而session机制采用的是在服务器端保持状态的方案。</span><br><span class="line">    cookie的内容主要包括：名字，值，过期时间，路径和域。路径与域一起构成cookie的作用范围。若不设置过期时间，则表示这个</span><br><span class="line">cookie的生命期为浏览器会话期间，关闭浏览器窗口，cookie就消失。这种生命期为浏览器会话期的cookie被称为会话cookie。会话</span><br><span class="line">cookie一般不存储在硬盘上而是保存在内存里，当然这种行为并不是规范规定的。若设置了过期时间，浏览器就会把cookie保存到硬</span><br><span class="line">盘上，关闭后再次打开浏览器，这些cookie仍然有效直到超过设定的过期时间。存储在硬盘上的cookie可以在不同的浏览器进程间共</span><br><span class="line">享，比如两个IE窗口。而对于保存在内存里的cookie，不同的浏览器有不同的处理方式。</span><br></pre></td></tr></table></figure>
<h4 id="session"><a href="#session" class="headerlink" title="session"></a>session</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    session我们可以使用它来方便地在服务端保存一些与会话相关的信息。比如常见的登录信息。</span><br><span class="line">    session实现原理：http协议是无状态的，对于一个浏览器发出的多次请求，web服务无法区分是不是来自同一个浏览器。所以会</span><br><span class="line">通过一个sessionid来区分。</span><br><span class="line">    当程序需要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含了一个session标识(称为</span><br><span class="line">session id），如果已包含则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（检索</span><br><span class="line">不到，会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session</span><br><span class="line"> id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保</span><br><span class="line">存。保存这个session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发送给服务器。一般这个</span><br><span class="line">cookie的名字都是类似于SEEESIONID。但cookie可以被人为的禁止，则必须有其他机制以便在cookie被禁止时仍然能够把session id</span><br><span class="line">传递回服务器。</span><br><span class="line">    经常被使用的一种技术叫做URL重写，就是把session id直接附加在URL路径的后面。还有一种技术叫做表单隐藏字段。就是服务器</span><br><span class="line">会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="cookie-和session-的区别："><a href="#cookie-和session-的区别：" class="headerlink" title="cookie 和session 的区别："></a>cookie 和session 的区别：</h4><ol>
<li>cookie数据存放在客户的浏览器上，session数据放在服务器上。</li>
<li>cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗<br>考虑到安全应当使用session。</li>
<li>session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能<br>考虑到减轻服务器性能方面，应当使用COOKIE。</li>
<li>单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。</li>
<li>所以个人建议：<br> 将登陆信息等重要信息存放为SESSION；其他信息如果需要保留，可以放在COOKIE中</li>
</ol>
<p><a href="https://maimai.cn/article/detail?fid=971952342&efid=LLj6y1u5UJki64UG-HamIA">session深入探讨</a></p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>redis,session共享</tag>
      </tags>
  </entry>
  <entry>
    <title>从根上了解mysql-innodb记录存储记录</title>
    <url>/2020-08-07/%E4%BB%8E%E6%A0%B9%E4%B8%8A%E4%BA%86%E8%A7%A3mysql-innodb%E8%AE%B0%E5%BD%95%E5%AD%98%E5%82%A8%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h2 id="innodb的数据结构"><a href="#innodb的数据结构" class="headerlink" title="innodb的数据结构"></a>innodb的数据结构</h2><p>InnoDB采取的方式是：将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为 16 KB</p>
<p>设计了4种不同类型的行格式，分别是Compact、Redundant、Dynamic和Compressed行格式</p>
<h3 id="Compact-格式"><a href="#Compact-格式" class="headerlink" title="Compact 格式"></a>Compact 格式</h3><p><img src="/images/mysql2/compact%E7%BB%93%E6%9E%84.png" alt="compact结构"></p>
<p>我们知道表中的某些列可能存储NULL值，如果把这些NULL值都放到记录的真实数据中存储会很占地方，所以Compact行格式把这些值为NULL的列统一管理起来，存储到NULL值列表中</p>
<p><img src="/images/mysql2/%E8%AE%B0%E5%BD%95%E5%A4%B4%E4%BF%A1%E6%81%AF.png" alt="记录头信息"></p>
<p>主要包括删除标记位、当前记录拥有的记录数、记录类型（普通记录、非叶子节点记录、最小记录、最大记录）、next_record(表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量)</p>
<p>InnoDB表对主键的生成策略：优先使用用户自定义主键作为主键，如果用户没有定义主键，则选取一个Unique键作为主键，如果表中连Unique键都没有定义的话，则InnoDB会为表默认添加一个名为row_id的隐藏列作为主键</p>
<p>一个页一般是16KB，当记录中的数据太多，当前页放不下的时候，会把多余的数据存储到其他页中，这种现象称为行溢出</p>
<h2 id="innndb是如何存储数据的"><a href="#innndb是如何存储数据的" class="headerlink" title="innndb是如何存储数据的"></a>innndb是如何存储数据的</h2><p>InnoDB其实是使用页为基本单位来管理存储空间的，默认的页大小为16KB。</p>
<p>对于InnoDB存储引擎来说，每个索引都对应着一棵B+树，该B+树的每个节点都是一个数据页，数据页之间不必要是物理连续的，因为数据页之间有双向链表来维护着这些页的顺序。</p>
<p>InnoDB的聚簇索引的叶子节点存储了完整的用户记录，也就是所谓的索引即数据，数据即索引。</p>
<p>为了更好的管理这些页，提出了一个表空间或者文件空间（，这个表空间是一个抽象的概念，它可以对应文件系统上一个或多个真实文件（不同表空间对应的文件数量可能不同）。每一个表空间可以被划分为很多很多很多个页。</p>
<h3 id="匹配左边的列"><a href="#匹配左边的列" class="headerlink" title="匹配左边的列"></a>匹配左边的列</h3><p>有个表中有联合索引 idx_name_birthday_phone_number</p>
<ul>
<li>先按照name列的值进行排序。</li>
<li>如果name列的值相同，则按照birthday列的值进行排序。</li>
<li>如果birthday列的值也相同，则按照phone_number的值进行排序。</li>
</ul>
<p>B+树的数据页和记录先是按照name列的值排序的，在name列的值相同的情况下才使用birthday列进行排序，也就是说name列的值不同的记录中birthday的值可能是无序的。而现在你跳过name列直接根据birthday的值去查找，臣妾做不到呀～ 那如果我就想在只使用birthday的值去通过B+树索引进行查找咋办呢？这好办，你再对birthday列建一个B+树索引就行了，创建索引的语法不用我唠叨了吧。</p>
<p>但是需要特别注意的一点是，如果我们想使用联合索引中尽可能多的列，搜索条件中的各个列必须是联合索引中从最左边连续的列。</p>
<h3 id="精确匹配某一列并范围匹配另外一列"><a href="#精确匹配某一列并范围匹配另外一列" class="headerlink" title="精确匹配某一列并范围匹配另外一列"></a>精确匹配某一列并范围匹配另外一列</h3><p>对于同一个联合索引来说，虽然对多个列都进行范围查找时只能用到最左边那个索引列，但是如果左边的列是精确查找，则右边的列可以进行范围查找</p>
<h3 id="使用联合索引进行排序注意事项"><a href="#使用联合索引进行排序注意事项" class="headerlink" title="使用联合索引进行排序注意事项"></a>使用联合索引进行排序注意事项</h3><p>对于联合索引有个问题需要注意，ORDER BY的子句后边的列的顺序也必须按照索引列的顺序给出，如果给出ORDER BY phone_number, birthday, name的顺序，那也是用不了B+树索引</p>
<h3 id="ASC、DESC混用"><a href="#ASC、DESC混用" class="headerlink" title="ASC、DESC混用"></a>ASC、DESC混用</h3><p>使用联合索引的各个排序列的排序顺序必须是一致的。</p>
<h3 id="排序列包含非同一个索引的列"><a href="#排序列包含非同一个索引的列" class="headerlink" title="排序列包含非同一个索引的列"></a>排序列包含非同一个索引的列</h3><p>无法使用索引进行排序</p>
<h3 id="用于分组"><a href="#用于分组" class="headerlink" title="用于分组"></a>用于分组</h3><p>使用B+树索引进行排序是一个道理，分组列的顺序也需要和索引列的顺序一致，也可以只使用索引列中左边的列进行分组</p>
<h3 id="回表"><a href="#回表" class="headerlink" title="回表"></a>回表</h3><p>会使用到两个B+树索引，一个二级索引，一个聚簇索引。 访问二级索引使用顺序I/O，访问聚簇索引使用随机I/O。需要回表的记录越多，使用二级索引的性能就越低。</p>
<h3 id="排序字段的选择"><a href="#排序字段的选择" class="headerlink" title="排序字段的选择"></a>排序字段的选择</h3><ul>
<li>只为用于搜索、排序或分组的列创建索引</li>
<li>考虑列的基数，为基数大的列建立索引；</li>
<li>索引列的类型尽量小，比如int  bigint</li>
<li>索引字符串值的前缀(B+树索引中的记录需要把该列的完整字符串存储起来，而且字符串越长，在索引中占用的存储空间越大)。只索引字符串值的前缀的策略是我们非常鼓励的，尤其是在字符串类型能存储的字符比较多的时候。</li>
<li>只有索引列在比较表达式中单独出现才可以使用索引</li>
<li>为了尽可能少的让聚簇索引发生页面分裂和记录移位的情况，建议让主键拥有AUTO_INCREMENT属性。</li>
<li>定位并删除表中的重复和冗余索引</li>
<li>尽量使用覆盖索引进行查询，避免回表带来的性能损耗。</li>
</ul>
<h2 id="使用mysql的查询"><a href="#使用mysql的查询" class="headerlink" title="使用mysql的查询"></a>使用mysql的查询</h2><h3 id="const-类型的查询"><a href="#const-类型的查询" class="headerlink" title="const 类型的查询"></a>const 类型的查询</h3><p>通过主键或者唯一二级索引列来定位一条记录的访问方法定义为：const。这种const访问方法只能在主键列或者唯一二级索引列和一个常数进行等值比较时才有效</p>
<h3 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h3><p>我们当然可以选择全表扫描来逐一对比搜索条件是否满足要求，我们也可以先使用二级索引找到对应记录的id值，然后再回表到聚簇索引中查找完整的用户记录。由于普通二级索引并不限制索引列值的唯一性，所以可能找到多条对应的记录，如果记录比较少效率还是挺高的。但如果记录多，有可能走的是随机io，所以性能会比较低。</p>
<h3 id="ref-or-null"><a href="#ref-or-null" class="headerlink" title="ref_or_null"></a>ref_or_null</h3><p>不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列的值为NULL的记录也找出来 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &#x3D; &#39;abc&#39; OR key1 IS NULL;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="eq-ref"><a href="#eq-ref" class="headerlink" title="eq_ref"></a>eq_ref</h3><p>在连接查询中对被驱动表使用主键值或者唯一二级索引列的值进行等值查找的查询执行方式称之为：eq_ref</p>
<h3 id="index"><a href="#index" class="headerlink" title="index"></a>index</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 &#x3D; &#39;abc&#39;;</span><br><span class="line"></span><br><span class="line">由于key_part2并不是联合索引idx_key_part最左索引列，所以我们无法使用ref或者range访问方法来执行这个语句</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我们可以直接通过遍历idx_key_part索引的叶子节点的记录来比较key_part2 = ‘abc’这个条件是否成立，把匹配成功的二级索引记录的key_part1, key_part2, key_part3列的值直接加到结果集中就行了。由于二级索引记录比聚簇索记录小的多（聚簇索引记录要存储所有用户定义的列以及所谓的隐藏列，</p>
<p>而二级索引记录只需要存放索引列和主键），而且这个过程也不用进行回表操作，所以直接遍历二级索引比直接遍历聚簇索引的成本要小很多</p>
<h2 id="索引使用的特殊情况"><a href="#索引使用的特殊情况" class="headerlink" title="索引使用的特殊情况"></a>索引使用的特殊情况</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &#x3D; &#39;abc&#39; AND key2 &gt; 1000;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>根据single_table表的统计数据来判断到底使用哪个条件到对应的二级索引中查询扫描的行数会更少，选择那个扫描行数较少的条件到对应的二级索引中查询。</p>
<p>然后将从该二级索引中查询到的结果经过回表得到完整的用户记录后再根据其余的WHERE条件过滤记录。一般来说，等值查找比范围查找需要扫描的行数更少。</p>
<p>因为二级索引的节点中的记录只包含索引列和主键，所以在步骤1中使用idx_key1索引进行查询时只会用到与key1列有关的搜索条件，其余条件，比如key2 &gt; 1000这个条件在步骤1中是用不到的，只有在步骤2完成回表操作后才能继续针对完整的用户记录中继续过滤</p>
<h2 id="索引合并"><a href="#索引合并" class="headerlink" title="索引合并"></a>索引合并</h2><p>某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &#x3D; &#39;a&#39; AND key3 &#x3D; &#39;b&#39;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>第一种方案： 按照某个搜索条件读取一个二级索引，根据从该二级索引得到的主键值进行回表操作，然后再过滤其他的搜索条件。</p>
<p>第二种方案： 按照不同的搜索条件分别读取不同的二级索引，将从多个二级索引得到的主键值取交集，然后进行回表操作。</p>
<p>虽然读取多个二级索引比读取一个二级索引消耗性能，但是读取二级索引的操作是顺序I/O，而回表操作是随机I/O，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数非常少，当节省的因为回表而造成的性能损耗比访问多个二级索引带来的性能损耗更高时，读取多个二级索引后取交集比只读取一个二级索引的成本更低</p>
<ul>
<li>出现索引合并的情况 </li>
</ul>
<ol>
<li>二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况。</li>
<li>主键列可以是范围匹配 （索引合并会把从多个二级索引中查询出的主键值求交集，如果从各个二级索引中查询的到的结果集本身就是已经按照主键排好序的，那么求交集的过程就很easy）</li>
</ol>
<h2 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h2><p><code>内连接</code>中的WHERE子句和ON子句是等价的。</p>
<p>对于<code>外连接</code>的驱动表的记录来说，如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用NULL值填充。</p>
<p>对于内连接来说，驱动表和被驱动表是可以互换的，并不会影响最后的查询结果。但是对于外连接来说左外连接和右外连接的驱动表和被驱动表不能轻易互换。</p>
<h3 id="连接的原理"><a href="#连接的原理" class="headerlink" title="连接的原理"></a>连接的原理</h3><p>两表连接来说，驱动表只会被访问一遍，但被驱动表却要被访问到好多遍。</p>
<h3 id="全表扫描的代价。计算表的统计信息"><a href="#全表扫描的代价。计算表的统计信息" class="headerlink" title="全表扫描的代价。计算表的统计信息"></a>全表扫描的代价。计算表的统计信息</h3><ul>
<li>I/O成本： 将数据和索引从硬盘加载到内存中；读取一个页大小的默认成本1.0</li>
<li>CPU成本： 读取以及检测记录是否满足对应的搜索条件、对结果集进行排序；访问一条记录的成本是0.2</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show table status like &#39;single_table&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>Rows 代表记录的行数，如果是myisam表示的是实际的记录数，innodb表示的是预估值；</li>
<li>Data_length 表示表占用的存储空间字节数。对于使用InnoDB存储引擎的表来说，该值就相当于聚簇索引占用的存储空间大小。 Data_length = 聚簇索引的页面数量 x 每个页面的大小。</li>
</ul>
<h2 id="innodb统计数据"><a href="#innodb统计数据" class="headerlink" title="innodb统计数据"></a>innodb统计数据</h2><p>SHOW TABLES FROM mysql LIKE ‘innodb%’;  // 从mysql库里查询innodb</p>
<p>SELECT * FROM mysql.innodb_index_stats  //从mysql库里查询索引统计信息</p>
<p>ANALYZE TABLE;  // ANALYZE TABLE语句会立即重新计算统计数据，也就是这个过程是同步的</p>
<h2 id="undo-log日志"><a href="#undo-log日志" class="headerlink" title="undo log日志"></a>undo log日志</h2><p>在事务对表中的记录做改动时才会为这个事务分配一个唯一的事务id</p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程编程技术核心-单例模式与多线程</title>
    <url>/2018-05-21/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF%E6%A0%B8%E5%BF%83-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="饿汉模式"><a href="#饿汉模式" class="headerlink" title="饿汉模式"></a>饿汉模式</h1><p>饿汉模式就是使用类的时候已经将对象创建完毕，常见的实现办法就是直接new实例化。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 饿汉模式</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-21 23:31</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyObject &#123;</span><br><span class="line"></span><br><span class="line">    private static MyObject myObject &#x3D; new MyObject();</span><br><span class="line"></span><br><span class="line">    private MyObject() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static MyObject getInstance() &#123;</span><br><span class="line">        &#x2F;&#x2F;此代码版本为立即加载，此代码的缺点是不能有其他实例变量</span><br><span class="line">        &#x2F;&#x2F;因为getInstance()没有同步，所以有可能出现线程安全的问题</span><br><span class="line">        return myObject;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="懒汉模式"><a href="#懒汉模式" class="headerlink" title="懒汉模式"></a>懒汉模式</h1><p>先声明不实例化，只有在调用的时候才实例化。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-21 23:38</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyObject &#123;</span><br><span class="line"></span><br><span class="line">    private static MyObject myObject &#x3D; null;</span><br><span class="line"></span><br><span class="line">    private MyObject() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;懒汉模式，在多线程的情况下会出现同步问题。</span><br><span class="line">    public static MyObject getInstance() &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (myObject &#x3D;&#x3D; null) &#123;</span><br><span class="line">                Thread.sleep(1000);</span><br><span class="line">                myObject &#x3D; new MyObject();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        return myObject;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="懒汉模式2"><a href="#懒汉模式2" class="headerlink" title="懒汉模式2"></a>懒汉模式2</h2><p>在整个方法上加synchronized关键字</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-21 23:48</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyObject &#123;</span><br><span class="line"></span><br><span class="line">    private static MyObject myObject &#x3D; null;</span><br><span class="line"></span><br><span class="line">    private MyObject() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;整个方法上锁，同步方法的效率太低了</span><br><span class="line">    synchronized public static MyObject getInstance() &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (myObject &#x3D;&#x3D; null) &#123;</span><br><span class="line">                Thread.sleep(2000);</span><br><span class="line">                myObject &#x3D; new MyObject();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        return myObject;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="懒汉模式3"><a href="#懒汉模式3" class="headerlink" title="懒汉模式3"></a>懒汉模式3</h2><p>方法中所有代码都上锁</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-21 23:54</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyObject &#123;</span><br><span class="line"></span><br><span class="line">    private static MyObject myObject &#x3D; null;</span><br><span class="line"></span><br><span class="line">    private MyObject() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static MyObject getInstance() &#123;</span><br><span class="line">        &#x2F;&#x2F;同步代码块 getInstance方法中的所有代码都上锁，这样做也会降低运行效率</span><br><span class="line">        synchronized (MyObject.class) &#123;</span><br><span class="line">            if (myObject &#x3D;&#x3D; null) &#123;</span><br><span class="line">                myObject &#x3D; new MyObject();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return myObject;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="懒汉模式4"><a href="#懒汉模式4" class="headerlink" title="懒汉模式4"></a>懒汉模式4</h2><p>方法中部分代码上锁</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-22 00:01</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyObject &#123;</span><br><span class="line"></span><br><span class="line">    private static MyObject myObject &#x3D; null;</span><br><span class="line"></span><br><span class="line">    private MyObject() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;虽然对实例化对象的关键代码进行了同步，从代码结构上看效率得到了提升，但是无法解决多线程安全的问题。</span><br><span class="line">    &#x2F;&#x2F;同时又多个线程访问if (myObject &#x3D;&#x3D; null) ，得到的结果可能不一样。</span><br><span class="line">    public static MyObject getInstance() &#123;</span><br><span class="line">        if (myObject &#x3D;&#x3D; null) &#123;</span><br><span class="line">            synchronized (MyObject.class) &#123;</span><br><span class="line">                myObject &#x3D; new MyObject();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return myObject;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="懒汉模式5-双检查锁机制，既保证了同步代码的异步执行，有保证了单例的效果。"><a href="#懒汉模式5-双检查锁机制，既保证了同步代码的异步执行，有保证了单例的效果。" class="headerlink" title="懒汉模式5 双检查锁机制，既保证了同步代码的异步执行，有保证了单例的效果。"></a>懒汉模式5 双检查锁机制，既保证了同步代码的异步执行，有保证了单例的效果。</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-22 00:14</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyObject &#123;</span><br><span class="line"></span><br><span class="line">    private volatile static MyObject myObject &#x3D; null;</span><br><span class="line"></span><br><span class="line">    private MyObject() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;使用DCL双检查锁机制，既保证了同步代码的异步执行，又保证了单例的效果。</span><br><span class="line">    public static MyObject getInstance() &#123;</span><br><span class="line">        if (myObject &#x3D;&#x3D; null) &#123;</span><br><span class="line">            synchronized (MyObject.class) &#123;</span><br><span class="line">                myObject &#x3D; new MyObject();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return myObject;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="静态内部类实现单例"><a href="#静态内部类实现单例" class="headerlink" title="静态内部类实现单例"></a>静态内部类实现单例</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-22 00:21</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyObject &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;静态内部类</span><br><span class="line">    private static class MyObjectHandler &#123;</span><br><span class="line">        private static MyObject myObject &#x3D; new MyObject();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private MyObject() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static MyObject getInstance() &#123;</span><br><span class="line">        return MyObjectHandler.myObject;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="静态代码块实现单例"><a href="#静态代码块实现单例" class="headerlink" title="静态代码块实现单例"></a>静态代码块实现单例</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.api.util.thread.study.chapter6.singleton8;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-22 00:27</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyObject &#123;</span><br><span class="line"></span><br><span class="line">    private static MyObject myObject &#x3D; null;</span><br><span class="line"></span><br><span class="line">    private MyObject() &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;静态代码块实现单例</span><br><span class="line">    static &#123;</span><br><span class="line">        myObject &#x3D; new MyObject();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static MyObject getInstance() &#123;</span><br><span class="line">        return myObject;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



















]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>单例模式与多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程编程技术核心-多线程其它</title>
    <url>/2018-05-22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF%E6%A0%B8%E5%BF%83-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%85%B6%E5%AE%83/</url>
    <content><![CDATA[<h1 id="线程的状态"><a href="#线程的状态" class="headerlink" title="线程的状态"></a>线程的状态</h1><p>线程状态state枚举类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NEW, &#x2F;&#x2F; 实例化后,未执行start方法的</span><br><span class="line">RUNNABLE,&#x2F;&#x2F;线程进入运行的状态</span><br><span class="line">BLOCKED,&#x2F;&#x2F;受阻塞并等待某个监视器锁的线程处于这种状态</span><br><span class="line">WAITING,&#x2F;&#x2F;无期限地等待另一个线程来执行某一特性操作的线程处于这种状态</span><br><span class="line">TIMED_WAITING,&#x2F;&#x2F;等待另一个线程来执行取决于指定等待时间的操作处于这种状态</span><br><span class="line">TERMINATED，&#x2F;&#x2F;已退出的线程处于这种状态</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/images/thread/%E7%BA%BF%E7%A8%8B%E6%96%B9%E6%B3%95%E4%B8%8E%E7%8A%B6%E6%80%81%E5%85%B3%E7%B3%BB%E5%9B%BE.png" alt="线程方法与状态关系图"></p>
<h2 id="验证-new-runnable和terminated状态"><a href="#验证-new-runnable和terminated状态" class="headerlink" title="验证 new runnable和terminated状态"></a>验证 new runnable和terminated状态</h2><p>new状态是线程实例化后还从未执行start()方法的状态，runnable状态是线程进入运行的转改，terminated状态是线程被销毁时的状态</p>
<h1 id="线程组的使用"><a href="#线程组的使用" class="headerlink" title="线程组的使用"></a>线程组的使用</h1><p>可以把线程归属到某一个线程组中。线程组中可以有线程对象，也可以有线程组，组中还可以有线程。</p>
<p>线程组的作用是，可以批量的管理线程或线程组对象，有效地对线程或线程组对象进行组织。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">    线程组的创建和组内的线程批量停止</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-30 00:50</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class Run &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        ThreadGroup threadGroup &#x3D; new ThreadGroup(&quot;我的线程组&quot;);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            for (int i &#x3D; 0; i &lt; 10; i++) &#123;</span><br><span class="line">                MyThread thread &#x3D; new MyThread(threadGroup, &quot;线层：&quot; + i);</span><br><span class="line">                thread.start();</span><br><span class="line">            &#125;</span><br><span class="line">            Thread.sleep(5000);</span><br><span class="line">            threadGroup.interrupt();</span><br><span class="line">            System.out.println(&quot;调用了interrupt方法。&quot;);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程补漏</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程编程核心技术-LOCK的使用</title>
    <url>/2018-05-16/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF-LOCK%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1 id="ReentrantLock的使用"><a href="#ReentrantLock的使用" class="headerlink" title="ReentrantLock的使用"></a>ReentrantLock的使用</h1><p>synchronized关键字来实现线程间同步互斥，在jdk1.5之后增加的ReentrantLock锁也能达到同样的效果。而且增加了嗅探锁定，多路分支通知功能，而且比synchronized更加灵活。</p>
<h2 id="conditions实现等待通知"><a href="#conditions实现等待通知" class="headerlink" title="conditions实现等待通知"></a>conditions实现等待通知</h2><p> synchronized与wait()和notify()、notifyAll() 方法相结合实现等待通知模式，ReentrantLock锁借助于Condition对象也是可以实现多路通知的功能。</p>
<p> 实现多路通知的功能，也就是一个Lock对象中可以创建多个Condition实例，线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。</p>
<p> 而notify()方法进行通知时，被通知的线程却是由JVM随机选择的。而synchronized就相当于整个LOCK对象中只有一个单一的Condition对象，所有的线程都注册在一个对象身上，线程开始notifyAll()时，需要通知所有waiting线程，没有选择权，会出现相当大的效率问题。</p>
<h2 id="公平锁和非公平锁"><a href="#公平锁和非公平锁" class="headerlink" title="公平锁和非公平锁"></a>公平锁和非公平锁</h2><p>公平锁表示线程获取锁的顺序是按照线程加锁的顺序来分配的，即先来先得的FIFO先进先出的顺序。而非公平锁就是一种获取锁的抢占式机制，是随机获得锁的。某些线程是一直拿不到锁的，所以是不公平的锁了。</p>
<h2 id="方法介绍"><a href="#方法介绍" class="headerlink" title="方法介绍"></a>方法介绍</h2><ul>
<li>ReentrantLock(boolean) 创建是否公平的锁：ReentrantLock(boolean) 是创建是否公平的锁；</li>
<li>lock.getHoldCount()  获取当前线程调用lock的次数； </li>
<li>lock.getQueenLength() 获取正等待获取此锁定的线程估计数 lock.getQueenLength()</li>
<li>getWaitQueueLength(Condition condition) 获取等待与此锁定相关的给定条件Condition的线程估计数，比如有5个线程，每个线程都执行了同一个Condition对象的await()方法，调用getWaitQueueLength(Condition condition) 返回的int值是5 </li>
<li>lock.hasQueuedThread(Thread thread)  查询指定的线程是否正在等待获取此锁定。</li>
<li>lock.hasQueuedThreads() 的作用是查询是否有线程正在等待获取此锁定。</li>
<li>boolean hasWaiters(Condition condition) 查询是否有线程正在等待与此锁定有关的condition条件。</li>
<li>boolean isFair() 判断是不是公平锁</li>
<li>boolean isHeldByCurrentThread()查询当前线程是否保持此锁</li>
<li>boolean isLocked()的作用是查询此锁定是否由任意线程保持</li>
<li>void lockInterruptibly 如果当前线程未被中断则获取锁定，如果已经被中断则出现异常。</li>
<li>boolean tryLock()的作用，仅当在被调用时锁定未被另一个线程保持的情况下，才获取该锁定。</li>
<li>boolean tryLock(long timeout，TimeUnit unit)的作用是，如果锁定在给定等待时间内没有被另一个线程保持，且当前线程未被中断，则获取该锁定。</li>
<li>awaitUninterruptibly() 调用该方法的前提是，当前线程已经成功获得与该条件对象绑定的重入锁，否则调用该方法时会抛出IllegalMonitorStateException。调用该方法后，结束等待的唯一方法是其它线程调用该条件对象的signal()或signalALL()方法。等待过程中如果当前线程被中断，该方法仍然会继续等待，同时保留该线程的中断状态。</li>
</ul>
<h1 id="ReentrantReadWriteLock的使用"><a href="#ReentrantReadWriteLock的使用" class="headerlink" title="ReentrantReadWriteLock的使用"></a>ReentrantReadWriteLock的使用</h1><p>类ReentrantLock 具有完全互斥排他的效果。同一时间只有一个线程在执行ReentrantLock.lock()方法后面的任务。保证了线程的安全性，但是效率非常低下。ReentrantReadWriteLock是一种读写锁。读写锁表示也有两个锁，一个是读操作相关的锁，称为共享锁；一个是和写操作相关的锁，也叫排他锁。也就是多个读锁之间不互斥，读写与写锁互斥，写锁与写锁互斥。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程Lock的使用</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程编程核心技术-java多线程基本方法</title>
    <url>/2018-04-08/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF-java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p><strong>进程</strong>: 进程是操作系统结构的基础,是一次程序的运行;是一个程序及其数据在处理机上顺序执行所发生的活动;是程序在一个数据集合上运行的过程,是系统进行资源分配和调度的独立单位.</p>
<p>指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆栈等组成的，是一个能独立运行的活动实体。</p>
<p><strong>线程</strong>: 进程间独立运行的子任务.是程序执行流的最小单元</p>
<h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><ol>
<li><p>调度：</p>
<pre><code> 在传统的操作系统中，CPU调度和分派的基本单位是进程。而在引入线程的操作系统中，则把线程作为CPU调度和分派的基本单位，进程则作为资源拥有的基本单位，从而使传统进程的两个属性分开，线程编程轻装运行，这样可以显著地提高系统的并发性。同一进程中线程的切换不会引起进程切换，从而避免了昂贵的系统调用，但是在由一个进程中的线程切换到另一进程中的线程，依然会引起进程切换。</code></pre>
</li>
<li><p>并发性：<br>   在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间也可以并发执行，因而使操作系统具有更好的并发性，从而更有效地提高系统资源和系统的吞吐量。例如，在一个为引入线程的单CPU操作系统中，若仅设置一个文件服务进程，当它由于某种原因被封锁时，便没有其他的文件服务进程来提供服务。在引入线程的操作系统中，可以在一个文件服务进程设置多个服务线程。当第一个线程等待时，文件服务进程中的第二个线程可以继续运行；当第二个线程封锁时，第三个线程可以继续执行，从而显著地提高了文件服务的质量以及系统的吞吐量。</p>
</li>
<li><p>拥有资源：<br>   不论是引入了线程的操作系统，还是传统的操作系统，进程都是拥有系统资源的一个独立单位，他可以拥有自己的资源。一般地说，线程自己不能拥有资源（也有一点必不可少的资源），但它可以访问其隶属进程的资源，亦即一个进程的代码段、数据段以及系统资源（如已打开的文件、I/O设备等），可供同一个进程的其他所有线程共享。</p>
</li>
<li><p>独立性：</p>
<pre><code> 在同一进程中的不同线程之间的独立性要比不同进程之间的独立性低得多。这是因为</code></pre>
<p>为防止进程之间彼此干扰和破坏，每个进程都拥有一个独立的地址空间和其它资源，除了共享全局变量外，不允许其它进程的访问。但是同一进程中的不同线程往往是为了提高并发性以及进行相互之间的合作而创建的，它们共享进程的内存地址空间和资源，如每个线程都可以访问它们所属进程地址空间中的所有地址，如一个线程的堆栈可以被其它线程读、写，甚至完全清除。</p>
</li>
<li><p>系统开销：</p>
<pre><code>由于在创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O设备等。因此，操作系统为此所付出的开销将显著地大于在创建或撤消线程时的开销。类似的，在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销也远大于线程切换的开销。此外，由于同一进程中的多个线程具有相同的地址空间，致使他们之间的同步和通信的实现也变得比较容易。在有的系统中，现成的切换、同步、和通信都无需操作系统内核的干预。</code></pre>
</li>
<li><p>支持多处理机系统：</p>
<pre><code>在多处理机系统中，对于传统的进程，即单线程进程，不管有多少处理机，该进程只能运行在一个处理机上。但对于多线程进程，就可以将一个进程中的多个线程分配到多个处理机上，使它们并行执行，这无疑将加速进程的完成。因此，现代处理机OS都无一例外地引入了多线程。</code></pre>
</li>
</ol>
<h1 id="多线程的实现及基本方法"><a href="#多线程的实现及基本方法" class="headerlink" title="多线程的实现及基本方法"></a>多线程的实现及基本方法</h1><p>继承Thread类和实现Runnable接口,thread类也实现了Runnable接口,所以本质上时一样的.但Runnable接口是避免了单继承的缺点.</p>
<p>使用多线程时,代码的调用顺序或者使用顺序和代码的运行结果是无关的.</p>
<p>线程的启动顺序,不代表线程的执行顺序.</p>
<h2 id="实例变量与线程安全"><a href="#实例变量与线程安全" class="headerlink" title="实例变量与线程安全"></a>实例变量与线程安全</h2><p>自定义线程类中的实例变量针对其它线程可以有共享和不共享之分</p>
<ol>
<li>不共享的线程是每个线程有自己运行的代码块.</li>
<li>共享的线程的情况就是多个线程访问同一代码块中的变量.</li>
</ol>
<p>由于多线程共享一段代码的时候(调用run方法),会出现各个线程顺序不定的访问代码.为了实现排队访问同一变量的目的,可以在方法前添加synchronize关键字.</p>
<p>//在执行run方法前,先判断方法是否加synchronize锁,如果上锁,说明其它线程在调用run方法,必须等待其它线程对run方法调用结束后才可以执行run方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ShareVariableThread2 extends Thread &#123;</span><br><span class="line"></span><br><span class="line">    private int i &#x3D; 10;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    synchronized public void run() &#123;</span><br><span class="line">        i--;</span><br><span class="line">        System.out.println(Thread.currentThread().getName() + &quot;计算,count&#x3D;&quot; + i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    ShareVariableThread2 thread2 &#x3D;new ShareVariableThread2();</span><br><span class="line">    Thread t5 &#x3D;new Thread(thread2,&quot;t5&quot;);</span><br><span class="line">    Thread t6 &#x3D;new Thread(thread2,&quot;t6&quot;);</span><br><span class="line">    Thread t7 &#x3D;new Thread(thread2,&quot;t7&quot;);</span><br><span class="line">    Thread t8 &#x3D;new Thread(thread2,&quot;t8&quot;);</span><br><span class="line">    t5.start();</span><br><span class="line">    t6.start();</span><br><span class="line">    t7.start();</span><br><span class="line">    t8.start();</span><br><span class="line">        </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="非线程安全"><a href="#非线程安全" class="headerlink" title="非线程安全"></a>非线程安全</h3><p>非线程安全是指,多线程对同一个对象的同一个变量进行操作的时候会出现值被更改,值不同步的情况,进而影响程序执行的进程.</p>
<p>currentThread()方法 判断正在被哪个线程调用</p>
<p>isAlive()判断线程是否处于活跃状态</p>
<p>sleep()方法使得线程放弃cpu使用时间，N ms</p>
<p>getId()获取线程的唯一id</p>
<h2 id="停止线程的三种方法"><a href="#停止线程的三种方法" class="headerlink" title="停止线程的三种方法"></a>停止线程的三种方法</h2><p>stop()是可以停止一个线程的运行，但是它是线程不安全的，它是不推荐使用的方法，在将来的发布版本中可能被去掉，可能产生不可预料的结果。</p>
<p>interrupt()方法，不会终止一个正在运行的线程。需要加入一个判断才可以完成线程的停止。</p>
<p>正常的run方法完成后线程终结。</p>
<h2 id="停止不了的线程"><a href="#停止不了的线程" class="headerlink" title="停止不了的线程"></a>停止不了的线程</h2><p>调用interrupt()方法仅仅是在当前线程中打了一个停止的标记,并不是真正的停止线程.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void interrupt() &#123;</span><br><span class="line">    if (this !&#x3D; Thread.currentThread())</span><br><span class="line">        checkAccess();</span><br><span class="line"></span><br><span class="line">    synchronized (blockerLock) &#123;</span><br><span class="line">        Interruptible b &#x3D; blocker;</span><br><span class="line">        if (b !&#x3D; null) &#123;</span><br><span class="line">            interrupt0();           &#x2F;&#x2F; Just to set the interrupt flag</span><br><span class="line">            b.interrupt(this);</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    interrupt0();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="判断线程是否处于停止状态"><a href="#判断线程是否处于停止状态" class="headerlink" title="判断线程是否处于停止状态"></a>判断线程是否处于停止状态</h2><p>this.interrupted()  测试当前线程是否已经中断,执行后具有将状态标志置为false的功能;</p>
<p>this.isInterrupted() 测试线程是否是中断状态,但不清除状态标志.</p>
<h2 id="能停止的线程-异常法"><a href="#能停止的线程-异常法" class="headerlink" title="能停止的线程-异常法"></a>能停止的线程-异常法</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 通过判断线程是否是停止状态,如果是停止状态,则停止执行后续代码</span><br><span class="line"> *</span><br><span class="line"> * @author chen weijie</span><br><span class="line"> * @date 2018-04-10 12:03 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class StatusStopThread extends Thread &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; 500000; i++) &#123;</span><br><span class="line"></span><br><span class="line">            if (Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(&quot;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; + i);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class StatusStopThreadTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        StatusStopThread thread &#x3D; new StatusStopThread();</span><br><span class="line">        thread.start();</span><br><span class="line">        try &#123;</span><br><span class="line">            System.out.println(&quot;sleep............&quot;);</span><br><span class="line">            Thread.sleep(1000);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        thread.interrupt();</span><br><span class="line">        System.out.println(&quot;end--------&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>虽然根据线程标记的中断状态,for循环停止了运行,但是’end…..’语句还是输出了,证明线程还是在运行.如何真正中断线程呢? 答案时抛出异常</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 通过抛出异常中断线程</span><br><span class="line"> *</span><br><span class="line"> * @author chen weijie</span><br><span class="line"> * @date 2018-04-10 12:14 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class ExceptionStopThread extends Thread &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line"></span><br><span class="line">        super.run();</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; 5000000; i++) &#123;</span><br><span class="line">            System.out.println(&quot;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; + i);</span><br><span class="line">            if (this.isInterrupted()) &#123;</span><br><span class="line">                System.out.println(&quot;中断....&quot;);</span><br><span class="line">                throw new RuntimeException(&quot;exception interrupt thread&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="在沉睡中终止"><a href="#在沉睡中终止" class="headerlink" title="在沉睡中终止"></a>在沉睡中终止</h2><p>抛出sleep状态被打断的异常</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Connected to the target VM, address: &#39;127.0.0.1:33558&#39;, transport: &#39;socket&#39;</span><br><span class="line">beginning............</span><br><span class="line">在沉睡中被中止.......interrupt</span><br><span class="line">end........</span><br><span class="line">Disconnected from the target VM, address: &#39;127.0.0.1:33558&#39;, transport: &#39;socket&#39;</span><br><span class="line">java.lang.InterruptedException: sleep interrupted</span><br><span class="line">    at java.lang.Thread.sleep(Native Method)</span><br><span class="line">    at com.chen.api.util.thread.study.chapter1.sleepStopException.SleepInterruptThread.run(SleepInterruptThread.java:16)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="暴力停止线程"><a href="#暴力停止线程" class="headerlink" title="暴力停止线程"></a>暴力停止线程</h2><p>暴力终结不会出现在沉睡中interrupt那种抛出异常,非常暴力.</p>
<p>stop被作废,主要是因为,如果强制让线程停止,则有可能使得一些清理性的工作得不到完成.另外一个情况就是对锁定对象进行了”解锁”,导致数据得不到同步的处理.</p>
<h2 id="释放锁的不良后果"><a href="#释放锁的不良后果" class="headerlink" title="释放锁的不良后果"></a>释放锁的不良后果</h2><p>使用stop()释放锁,将会给数据造成不一致的结果,这样程序处理的数据可能遭到破坏.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class SynchronizedObject &#123;</span><br><span class="line"></span><br><span class="line">    private String userName &#x3D;&quot;a&quot;;</span><br><span class="line">    private String passWord&#x3D;&quot;aa&quot;;</span><br><span class="line">  synchronized  public void printString(String userName,String passWord)&#123;</span><br><span class="line"></span><br><span class="line">        this.userName &#x3D;userName;</span><br><span class="line">        try &#123;</span><br><span class="line">            Thread.sleep(100000);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        this.passWord&#x3D;passWord;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">public class MyThread extends Thread &#123;</span><br><span class="line">    private SynchronizedObject object;</span><br><span class="line">    public MyThread(SynchronizedObject object) &#123;</span><br><span class="line">        this.object &#x3D; object;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        object.printString(&quot;b&quot;, &quot;bb&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        SynchronizedObject object &#x3D; new SynchronizedObject();</span><br><span class="line">        MyThread myThread &#x3D; new MyThread(object);</span><br><span class="line">        myThread.start();</span><br><span class="line">        Thread.sleep(500);</span><br><span class="line">        myThread.stop();</span><br><span class="line">        System.out.println(object.getUserName() + &quot;----------&quot; + object.getPassWord());</span><br><span class="line">    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="return-停止线程"><a href="#return-停止线程" class="headerlink" title="return 停止线程"></a>return 停止线程</h2><p>return和抛出异常都可以停止线程,但是建议使用抛出异常的方式,因为这样可以在catch块中向上抛,使得线程停止的事件得以传播.</p>
<h2 id="暂停线程"><a href="#暂停线程" class="headerlink" title="暂停线程"></a>暂停线程</h2><p>suspend()方法是中断线程的,resume()是唤醒线程的.</p>
<p>这两方法的缺点: </p>
<ol>
<li>独占,容易造成同步对象的独占,使得其它线程无法访问公共同步对象.</li>
<li>不同步,这两个方法容易出现线程的暂停而导致数据不同步的情况.</li>
</ol>
<h2 id="yeild方法"><a href="#yeild方法" class="headerlink" title="yeild方法"></a>yeild方法</h2><p>该方法的作用是放弃当前的cpu资源,将它让给其它的任务去占用,但是放弃的时间不确定,所以有可能刚刚放弃,马上又获得cpu的时间了.</p>
<h2 id="线程的优先级"><a href="#线程的优先级" class="headerlink" title="线程的优先级"></a>线程的优先级</h2><p>cpu会优先执行优先级比较高的线程对象中的任务.所以优先级高的线程会比优先级低的线程获取更多的cpu时间;</p>
<p>cpu尽量尽量将执行资源让给优先级比较高的线程执行.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * Changes the priority of this thread.</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * First the &lt;code&gt;checkAccess&lt;&#x2F;code&gt; method of this thread is called</span><br><span class="line"> * with no arguments. This may result in throwing a</span><br><span class="line"> * &lt;code&gt;SecurityException&lt;&#x2F;code&gt;.</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * Otherwise, the priority of this thread is set to the smaller of</span><br><span class="line"> * the specified &lt;code&gt;newPriority&lt;&#x2F;code&gt; and the maximum permitted</span><br><span class="line"> * priority of the thread&#39;s thread group.</span><br><span class="line"> *</span><br><span class="line"> * @param newPriority priority to set this thread to</span><br><span class="line"> * @exception  IllegalArgumentException  If the priority is not in the</span><br><span class="line"> *               range &lt;code&gt;MIN_PRIORITY&lt;&#x2F;code&gt; to</span><br><span class="line"> *               &lt;code&gt;MAX_PRIORITY&lt;&#x2F;code&gt;.</span><br><span class="line"> * @exception  SecurityException  if the current thread cannot modify</span><br><span class="line"> *               this thread.</span><br><span class="line"> * @see        #getPriority</span><br><span class="line"> * @see        #checkAccess()</span><br><span class="line"> * @see        #getThreadGroup()</span><br><span class="line"> * @see        #MAX_PRIORITY</span><br><span class="line"> * @see        #MIN_PRIORITY</span><br><span class="line"> * @see        ThreadGroup#getMaxPriority()</span><br><span class="line"> *&#x2F;</span><br><span class="line">public final void setPriority(int newPriority) &#123;</span><br><span class="line">    ThreadGroup g;</span><br><span class="line">    checkAccess();</span><br><span class="line">    if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) &#123;</span><br><span class="line">        throw new IllegalArgumentException();</span><br><span class="line">    &#125;</span><br><span class="line">    if((g &#x3D; getThreadGroup()) !&#x3D; null) &#123;</span><br><span class="line">        if (newPriority &gt; g.getMaxPriority()) &#123;</span><br><span class="line">            newPriority &#x3D; g.getMaxPriority();</span><br><span class="line">        &#125;</span><br><span class="line">        setPriority0(priority &#x3D; newPriority);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p> 线程优先级分为10个 但JDK定义了三个常量: MIN_PRIORITY=1  NORM_PRIORITY=5  MAX_PRIORITY=10 </p>
<p> 线程优先级的继承性: 比如A线程启动B线程,则B线程的优先级与A是一样的.</p>
<h2 id="优先级具有随机性"><a href="#优先级具有随机性" class="headerlink" title="优先级具有随机性"></a>优先级具有随机性</h2><p> 优先级较高的线程会获取较多的cpu资源,所以两个具有相同任务的线程优先级不同,优先级高的线程的任务先执行完毕,但不是绝对的,因为线程的优先级具有随机性.</p>
<h2 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h2><p> java线程中有2种: 一种是守护线程,另一种是用户线程</p>
<ol>
<li><p>守护线程时一种特殊的线程,他的特性有陪伴的含义,当进程中不存在非守护线程了,守护进程自动销毁.</p>
</li>
<li><p>任何一个守护线程都是整个JVM中所有非守护线程的保姆.只要当前JVM中存在任何一个非守护线程没有结束,守护线程就在工作,当最后一个非守护线程结束时没守护线程才随着JVM一同结束同坐,</p>
</li>
<li><p>Daemon的作用时为其它线程的运行提供遍历服务,守护线程最典型的应用就是GC,他就是一个很称职的守护者.</p>
</li>
</ol>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>java多线程基本方法</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程编程核心技术-对象及变量的并发访问</title>
    <url>/2018-04-12/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF-%E5%AF%B9%E8%B1%A1%E5%8F%8A%E5%8F%98%E9%87%8F%E7%9A%84%E5%B9%B6%E5%8F%91%E8%AE%BF%E9%97%AE/</url>
    <content><![CDATA[<h1 id="synchronize同步方法"><a href="#synchronize同步方法" class="headerlink" title="synchronize同步方法"></a>synchronize同步方法</h1><p>非线程安全其实是在多个线程对同一个对象中的实例变量进行并发访问的时候发生,产生的后果就是脏读,也就是被读到的数据是被更改过的.</p>
<p>线程安全就是获得实例变量的值时经过同步处理的,不会出现脏读的现象.</p>
<h2 id="方法内的变量为线程安全的"><a href="#方法内的变量为线程安全的" class="headerlink" title="方法内的变量为线程安全的"></a>方法内的变量为线程安全的</h2><p>非线程安全问题存在于实例变量,如果是方法内部的私有变量则不存在非线程安全问题.</p>
<h2 id="实例变量非线程安全"><a href="#实例变量非线程安全" class="headerlink" title="实例变量非线程安全"></a>实例变量非线程安全</h2><p>多个线程共同访问一个对象中的实例变量,则可能出现非线程安全问题.如果对象仅有一个实例变量,则可能出现覆盖的情况</p>
<p>在两个线程访问同一个对象中的同步方法时,一定是线程安全的.</p>
<h2 id="多个对象多个锁"><a href="#多个对象多个锁" class="headerlink" title="多个对象多个锁"></a>多个对象多个锁</h2><p>关键字synchronize取得的锁都是对象锁,而不是把一段代码或者方法当做锁,哪个线程先执行synchronize关键字的方法,哪个线程就持有该方法所持有该方法所属对象的锁LOCK,其它线程只能等待,前提是,多个线程访问的是同一个对象.</p>
<p>如果多个线程访问的时多个对象,JVM会创建多个锁.</p>
<h2 id="synchronize方法与锁对象"><a href="#synchronize方法与锁对象" class="headerlink" title="synchronize方法与锁对象"></a>synchronize方法与锁对象</h2><p>调用关键字synchronize声明的方法一定时排队运行的,只有共享的资源的读写才需要同步化.</p>
<p>结论:</p>
<p>A线程先持有object对象的lock锁,B线程可以异步的调用object对象中的非synchronize类型的方法;</p>
<p>A线程先持有object对象的lock锁,B线程如果在这是调用object对象中synchronize类型的方法 需要等待,也就是同步</p>
<h2 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h2><p>虽然在赋值时进行了同步,但在取值时有可能出现一些意想不到的意外,这就是脏读.发生脏读的情况就是在读取实例变量时,此值已经被其它线程进行了修改.</p>
<p>结论:</p>
<p>当A线程调用anyObject对象加synchronized关键字的X方法时,A线程就获得了X的方法锁.更准确的说,是获得了对象的锁,所以其它线程必须等待A线程执行完毕才可以调用X方法,但B线程可以调用其它的非synchronized同步方法;</p>
<p>当A线程调用anyObject对象加入synchronized关键字的方法X时,A线程就获得了X方法所在对象的锁,而B线程如果调用synchronized关键字修饰的非X方法时,必须等待A线程将X方法执行完.也就是释放对象锁后才可以调用.</p>
<p>脏读一定出现在操作实例变量的情况下,也就是不同线程争抢实例变量的结果.</p>
<h2 id="synchronized锁重入"><a href="#synchronized锁重入" class="headerlink" title="synchronized锁重入"></a>synchronized锁重入</h2><p>关键字synchronized拥有锁重入的功能,当一个线程得到一个对象锁之后,再次请求此对象锁时,是可以再次获得该对象的锁的.</p>
<p>可重入锁的概念是:自己可以再次获取自己的内部锁,比如一条线程获得了某个对象的锁,此时这个对象所还没有释放,当其再次获取这个对象锁的时候,还是可以获得的,如果不可锁重入的话,就会造成死锁.</p>
<p>可重入锁时支持在父子类继承的环境中的.</p>
<h2 id="出现异常-锁自动释放"><a href="#出现异常-锁自动释放" class="headerlink" title="出现异常,锁自动释放"></a>出现异常,锁自动释放</h2><p>当一个线程执行的代码出现异常时,其所持有的锁会自动释放.</p>
<h2 id="同步不具有继承性"><a href="#同步不具有继承性" class="headerlink" title="同步不具有继承性"></a>同步不具有继承性</h2><p>同步不可以继承</p>
<h1 id="synchronized同步语句块"><a href="#synchronized同步语句块" class="headerlink" title="synchronized同步语句块"></a>synchronized同步语句块</h1><p>用关键字synchronized声明方法在某些情况下时有弊端的,比如A线程调用B方法去执行一个长时间的任务,那么B线程必须等待比较长时间.这种情况下可以使用synchronized同步语句块来解决.</p>
<h2 id="用同步代码块解决同步方法的弊端"><a href="#用同步代码块解决同步方法的弊端" class="headerlink" title="用同步代码块解决同步方法的弊端"></a>用同步代码块解决同步方法的弊端</h2><p>可以使用synchronized代码块解决synchronized方法的弊端.</p>
<h2 id="一半异步-一半同步"><a href="#一半异步-一半同步" class="headerlink" title="一半异步,一半同步"></a>一半异步,一半同步</h2><p>不在synchronized块中就是异步执行,在synchronized块中就是同步执行.</p>
<h2 id="synchronized代码块间的同步性"><a href="#synchronized代码块间的同步性" class="headerlink" title="synchronized代码块间的同步性"></a>synchronized代码块间的同步性</h2><p>在使用同步synchronized(this)代码块时需要注意,当一个线程访问object的一个synchronized(this)同步代码块时.其它线程对同一个object中所有其它synchronized(this) 代码块的访问将被阻塞,这就说明synchronized使用的对象监视器时一个.</p>
<h2 id="验证synchronized-this-代码块时锁定当前对象的"><a href="#验证synchronized-this-代码块时锁定当前对象的" class="headerlink" title="验证synchronized(this) 代码块时锁定当前对象的"></a>验证synchronized(this) 代码块时锁定当前对象的</h2><p>和synchronized方法一样,synchronized(this)也是锁定当前对象的</p>
<h2 id="将任意对象作为对象监视器"><a href="#将任意对象作为对象监视器" class="headerlink" title="将任意对象作为对象监视器"></a>将任意对象作为对象监视器</h2><h3 id="synchronized代码块或者方法"><a href="#synchronized代码块或者方法" class="headerlink" title="synchronized代码块或者方法"></a>synchronized代码块或者方法</h3><p>多个线程调用同一个对象中的不同名称的synchronized同步方法或者synchronized(this)同步代码块时,调用的效果就是按顺序执行,也就是同步的,阻塞的.</p>
<p>这就是说synchronized同步方法或者同步代码块有两种作用:</p>
<ol>
<li><p>对其它的同步方法或者同步代码块调用呈阻塞状态;</p>
</li>
<li><p>同一时间只有一个线程可以执行synchronized同步方法或者同步代码块中的代码</p>
</li>
</ol>
<h3 id="synchronized-非this-同步代码块"><a href="#synchronized-非this-同步代码块" class="headerlink" title="synchronized(非this)同步代码块"></a>synchronized(非this)同步代码块</h3><p>除了以上说过的synchronized(this) 同步代码块,还可以使用任意对象作为对象监视器来实现同步的功能,这个任意对象大多数是实例变量或者方法的参数,使用格式为synchronized(非this对象)</p>
<ol>
<li><p>在多个线程持有对象监视器为同一个对象的前提下,同一时间只有一个线程可以执行synchronized(非this对象X)同步代码.</p>
</li>
<li><p>当持有对象监视器为同一个对象的前提下,同一时间只有一个线程可以执行synchronized(非this对象X)同步代码.</p>
</li>
</ol>
<h3 id="synchronized-非this-同步代码块的优点和注意事项"><a href="#synchronized-非this-同步代码块的优点和注意事项" class="headerlink" title="synchronized(非this)同步代码块的优点和注意事项"></a>synchronized(非this)同步代码块的优点和注意事项</h3><p>锁非this对象有一定的优点:如果一个类中有多个synchronized方法.这时虽然能实现同步,但会受到阻塞,所以影响运行效率两单如果使用同步代码块锁非this对象,则synchronized(非this)代码块中的程序与同步方法是异步的,不与其它锁this同步方法争抢this锁,则可以大大提高运行效率.</p>
<p>使用synchronized(非this对象X)同步代码块格式进行同步时,对象监视器必须是同一个对象.即synchronized(非this对象X)同步代码块,持有不同对象的监视器时异步的效果.</p>
<h3 id="使用synchronized-非this对象X-脏读问题"><a href="#使用synchronized-非this对象X-脏读问题" class="headerlink" title="使用synchronized(非this对象X)脏读问题"></a>使用synchronized(非this对象X)脏读问题</h3><p>使用synchronized(非this对象X) 同步代码块,格式也是可以解决脏读问题的.</p>
<p>多个线程调用同一个方法是随机的.</p>
<h3 id="synchronized-非this对象x"><a href="#synchronized-非this对象x" class="headerlink" title="synchronized(非this对象x)"></a>synchronized(非this对象x)</h3><p>synchronized(非this对象x)格式的写法是将X本身作为对象监视器,可以得出以下三种结论:</p>
<ol>
<li>当多个线程执行synchronized(x){}同步代码块时,呈现同步效果.</li>
<li>当其它线程执行x对象中的synchronized方法时呈现同步效果;</li>
<li>当其它线程执行x对象方法中synchronized(this)代码块时也呈现同步效果</li>
</ol>
<h3 id="静态同步synchronized方法与synchronized-class-代码块"><a href="#静态同步synchronized方法与synchronized-class-代码块" class="headerlink" title="静态同步synchronized方法与synchronized(class)代码块"></a>静态同步synchronized方法与synchronized(class)代码块</h3><p>synchronized关键字还可以应用在static静态方法上,如果这样写,就是对你当前的文件对应的class类进行持锁.</p>
<p>synchronized(class)代码块和synchronized static方法的作用一样.</p>
<h3 id="数据类型String的常量池特性"><a href="#数据类型String的常量池特性" class="headerlink" title="数据类型String的常量池特性"></a>数据类型String的常量池特性</h3><p>在JVM中具有String常量池缓存的功能  String a = “a” ; String b =”b”; a == b为true</p>
<p>将synchronized(string) 同步代码块与String联合使用的时候,要注意常量池以带来的一些例外;</p>
<h3 id="同步synchronized方法无线等待与解决"><a href="#同步synchronized方法无线等待与解决" class="headerlink" title="同步synchronized方法无线等待与解决"></a>同步synchronized方法无线等待与解决</h3><p>同步方法容易造成死锁</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @author chen weijie</span><br><span class="line"> * @date 2018-04-17 11:56 PM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class Service &#123;</span><br><span class="line"></span><br><span class="line">    synchronized public void methodA() &#123;</span><br><span class="line">        System.out.println(&quot;methodA begin..&quot;);</span><br><span class="line">        boolean isContinueRun &#x3D; true;</span><br><span class="line">        while (isContinueRun) &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(&quot;methodA end&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    synchronized public void methodB() &#123;</span><br><span class="line">        System.out.println(&quot;methodB begin&quot;);</span><br><span class="line">        System.out.println(&quot;methodB end&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>多个线程在调用 methodA和methodB时,会由于一个线程在等待另一个线程而造成死锁.</p>
<h3 id="线程的死锁"><a href="#线程的死锁" class="headerlink" title="线程的死锁"></a>线程的死锁</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * @author chen weijie</span><br><span class="line"> * @date 2018-04-18 12:11 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class DealThreadTask implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">    public String userName;</span><br><span class="line">    public Object lock1 &#x3D; new Object();</span><br><span class="line">    public Object lock2 &#x3D; new Object();</span><br><span class="line">    public void setFlag(String userName) &#123;</span><br><span class="line">        this.userName &#x3D; userName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        if (userName.equals(&quot;a&quot;)) &#123;</span><br><span class="line">            synchronized (lock1) &#123;</span><br><span class="line">                System.out.printf(&quot;userName&#x3D;&#x3D;&quot; + userName);</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(3000);</span><br><span class="line">                &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            synchronized (lock2) &#123;</span><br><span class="line">                System.out.println(&quot;按lock1---&gt;lock2的代码执行了..&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (userName.equals(&quot;b&quot;)) &#123;</span><br><span class="line">            synchronized (lock2) &#123;</span><br><span class="line">                System.out.printf(&quot;userName&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; + userName);</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(3000);</span><br><span class="line">                &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            synchronized (lock2) &#123;</span><br><span class="line">                System.out.println(&quot;按lock2---&gt;lock1的代码执行了..&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>两个线程互相等待对方的锁而导致的线程死锁;</p>
<h3 id="检查是否有死锁"><a href="#检查是否有死锁" class="headerlink" title="检查是否有死锁"></a>检查是否有死锁</h3><p>jdk自带的工具类,进入bin目录,执行jps命令.得到runId,在执行jstack命令 jstack -l runId</p>
<h3 id="锁对象的改变"><a href="#锁对象的改变" class="headerlink" title="锁对象的改变"></a>锁对象的改变</h3><p>String lock = “aa”;</p>
<p>synchronized(lock){</p>
<p>lock =”bb”;</p>
<p>}</p>
<p>这样会变成另一个锁,对象的值变了,此时都争抢的是变化后的值.所以此时还是同步的.</p>
<p>如果一个对象,它的属性发生变化,运行的结果还是同步的.</p>
<h1 id="volatile关键字"><a href="#volatile关键字" class="headerlink" title="volatile关键字"></a>volatile关键字</h1><p>volatile关键字主要是使得变量在各个线程间可见.</p>
<p>volatile关键字的作用是强制从公共堆栈中取得变量的值,而不是从私有数据栈中取得变量的值.</p>
<p><img src="/images/thread/%E8%AF%BB%E5%8F%96%E5%85%AC%E5%85%B1%E5%86%85%E5%AD%98.png" alt="读取公共内存"></p>
<h2 id="volatile关键字和synchronized关键字之间的区别"><a href="#volatile关键字和synchronized关键字之间的区别" class="headerlink" title="volatile关键字和synchronized关键字之间的区别"></a>volatile关键字和synchronized关键字之间的区别</h2><p>volatile关键字增加了实例变量在多个线程之间的可见性,但是volatile关键字不支持原子性.</p>
<ol>
<li>关键字volatile是线程同步的轻量级的实现,所以volatile性能肯定比synchronized好,并且volatile只能修饰变量,而synchronized可以修饰方法以及代码块.jdk新版本的发布导致synchronized关键字使用的比例还是比较高的.</li>
<li>多线程访问volatile不会发生阻塞,而synchronized会出现阻塞.</li>
<li>volatile能保证数据的可见性,但不能保证原子性.而synchronized可以保证原子性也可以间接保证可见性,因为他会将私有内存和功能内存中的数据做同步.</li>
<li>关键字volatile是解决多个线程之间的可见性,而synchronized关键字解决的是多个线程之间访问资源的同步性.</li>
</ol>
<h2 id="i"><a href="#i" class="headerlink" title="i++"></a>i++</h2><p>关键字volatile提示线程每次从共享内存中读取变量,而不是从私有内存中读取,这样保证了同步数据的可见性.但是不能保存数据操作的原子性,比如i++</p>
<p>i++的操作分为三步:</p>
<ol>
<li>从内存中读取i的值,</li>
<li>计算i的值,</li>
<li>将i的值写入内存</li>
</ol>
<p>假如在第二步的时候,另一个线程也改变了i的值,就会出现脏数据.</p>
<p><img src="/images/thread/%E5%8F%98%E9%87%8F%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.png" alt="变量在内存中工作过程"></p>
<ol>
<li>read和load阶段,从主存复制变量到当前线程工作内存;</li>
<li>use和assign阶段:执行代码.改变共享变量值;</li>
<li>store和write阶段: 用工作内存数据刷新主存对应变量的值;</li>
</ol>
<p>在多线程环境中,use和assign时多次出现的,但这一操作并不是原子性,也就是read和load之后,如果主内存的count变量发生了变化之后,线程工作内存中的值已经加载,不会产生对应的变化,也就是私有内存和公共内存的变量不同步,所以会出现费线程安全问题.</p>
<p>volatile修饰的变量,JVM只保证从主内存加载到工作线程红的值是最新的.也就是volatile关键字只能保证变量读时的可见性,不能保证原子性.就是如果多个线程对一个实例变量访问还是需要加锁同步.</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>线程同步</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程变成核心技术-线程间通信</title>
    <url>/2018-04-22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF-%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/</url>
    <content><![CDATA[<h1 id="等待和通知机制"><a href="#等待和通知机制" class="headerlink" title="等待和通知机制"></a>等待和通知机制</h1><h2 id="不使用等待通知机制实现线程间通信"><a href="#不使用等待通知机制实现线程间通信" class="headerlink" title="不使用等待通知机制实现线程间通信"></a>不使用等待通知机制实现线程间通信</h2><p>使用sleep()和while死循环实现多个线程间通信</p>
<h2 id="等待和通知机制-1"><a href="#等待和通知机制-1" class="headerlink" title="等待和通知机制"></a>等待和通知机制</h2><p>多个线程之间实现通信，可以采用多个线程共享变量，但那种通信机制不是那种等待通知，两个线程完全是主动式的读取一个共享变量。在花费读取时间的基础上，得到值不是自己想要的，所以需要等待通知机制来满足上面的需求。</p>
<h3 id="等待通知机制的实现"><a href="#等待通知机制的实现" class="headerlink" title="等待通知机制的实现"></a>等待通知机制的实现</h3><p>1.wait方法</p>
<p>方法wait()的作用是使当前的执行代码的线程进行等待，wait()方法是object类的方法，该方法用来将当前线程置入“预执行队列”中。并且在wait()方法所在的代码出停止执行，直到接到通知或者被中断为止。在调用wait方法之前，线程必须获得该对象的对象级别的锁，即只能在同步方法或者同步块中调用wait方法，</p>
<p>在执行wait方法后，当前线程释放锁，在wait方法返回前，线程与其他线程竞争重新获得锁。如果调用wait方法时没有获得对象锁，则抛出一个异常。</p>
<p>2.notify方法</p>
<p>如果调用notify方法时，也必须在同步方法或者同步代码块中执行。即线程必须获得对象的对象级别锁。该方法来通知那些等待获得该对象的对象锁的其他线程。如果有多个线程，则线程规划器会挑选一个wait状态的线程，对其发出notify通知。</p>
<p>需要说明的是，notify方法执行后，当前线程不会立马释放对象的锁，呈wait状态的线程也并不会立马获取该对象锁，要等待notify方法线程将程序执行完，也就是退出synchronized代码块，当前线程才会释放锁。</p>
<p>当一个获得对象锁的wait线程运行完毕以后，它会释放掉对象锁。此时如果该对象没有再次使用notify语句，即便该对象已经空闲，其他wait状态的等待线程由于没有获得该对象的通知，还会继续处于阻塞在wait状态，直到这个对象发出notify或者notifyAll</p>
<p>3.两个方法的使用</p>
<p>notify和wait方法必须在被synchronized同步的object的临界区内.通过使用wait方法可以使得处于临界区内的线程进入等待状态,同时释放被同步对象的锁.而notify操作可以唤醒一个因调用wait方法而处于阻塞状态的线程,使其进入就绪状态.使其进入就绪状态.被重新唤醒的线程尝试获得临界区的控制权.</p>
<p>wait方法可以使得调用该方法的线程释放共享资源的锁.然后从运行状态退出.进入等待队列处于阻塞状态,直到被再次唤醒;</p>
<p>notify方法可以随机唤醒等待队列中等待同一资源的一个线程,是该线程退出等待队列,进入可运行状态;</p>
<p>notifyAll方法可以使得所有正在等待队列中的等待同一共享资源的全部线程从等待状态退出,进入可运行状态,优先级高的哪个先运行.</p>
<p>4.线程状态</p>
<p><img src="/images/thread/%E7%BA%BF%E7%A8%8B%E7%9A%84%E8%BF%90%E8%A1%8C%E7%8A%B6%E6%80%81%E5%9B%BE.png" alt="线程的运行状态图"></p>
<p>每个锁对象都有两个队列,一个是就绪队列,一个是阻塞队列.就绪队列存储了将来要获得锁的线程.一个线程被欢喜过后,参会进入就绪队列,等待cpu的调度,反之,一个线程被wait后就会进入阻塞队列,等待下一次被唤醒.</p>
<p>5.wait()方法和sleep()方法</p>
<p>wait方法和sleep方法.wait方法释放锁,sleep方法不释放锁.notify方法也不释放锁.</p>
<p>6.interrupt方法遇到wait方法</p>
<p>当线程呈wait状态时,调用线程对象的interrupt方法,会出现interruptedException异常.</p>
<p>7.notify方法只通知一个线程</p>
<p>8.方法wait(long) 方法的功能是在等待某一时间内是否有线程对锁进行唤醒,如果超过这个时间则自动唤醒.</p>
<p>9.管道流用于在不同线程间传输数据,一个线程发送数据到输出管道,另一个线程从输入管道中读取数据.</p>
<p>pipedInputStream pipedOutPutStream pipedReader pipedWriter</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>1.执行完同步代码块就会释放对象的锁;<br>2.执行同步代码块的过程中,遇到异常而导致线程中止,锁也会释放;<br>3.执行同步代码块的过程中没执行额锁所属对象的wait方法,这个线程就会释放对象所,而此线程对象会进入线程等待池中,等待被唤醒.</p>
<h1 id="join方法的使用"><a href="#join方法的使用" class="headerlink" title="join方法的使用"></a>join方法的使用</h1><p>一个线程等待另一个想成运行完毕，然后才执行一些操作。此时需要使用join()方法，join方法的作用是等待想成对象销毁；</p>
<p><strong>当我们调用某个线程的这个方法时，这个方法会挂起调用线程，直到被调用线程结束执行，调用线程才会继续执行。</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.api.util.thread.study.chapter3.join_test;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * </span><br><span class="line"> * 方法join的作用是使所属的线程对象X正常执行run方法中的任务，而使当前线程Z进行无限制的阻塞，等待线程X销毁后在急需执行线程Z后的代码。</span><br><span class="line"> * </span><br><span class="line"> * </span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-05-15 01:04</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class Run2 &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        Runnable runnable &#x3D; new Runnable() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    int secondValue &#x3D; (int) (Math.random() * 10000);</span><br><span class="line">                    System.out.println(secondValue);</span><br><span class="line"></span><br><span class="line">                    Thread.sleep(secondValue);</span><br><span class="line">                &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            Thread thread &#x3D; new Thread(runnable);</span><br><span class="line">            thread.start();</span><br><span class="line">            thread.join();</span><br><span class="line">            System.out.println(&quot;我想等待thread执行完毕才执行&quot;);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="join-long-和sleep-long-的区别"><a href="#join-long-和sleep-long-的区别" class="headerlink" title="join(long) 和sleep(long)的区别"></a>join(long) 和sleep(long)的区别</h2><p>join的功能内部是使用wait方法来实现的，所以join具有释放锁的特点，sleep方法不释放锁。</p>
<h1 id="ThreadLocal类的使用"><a href="#ThreadLocal类的使用" class="headerlink" title="ThreadLocal类的使用"></a>ThreadLocal类的使用</h1><p>所有线程可以通过使用同一个public static变量来共享一个变量，如果想实现每一个线程都有自己的共享变量就可以使用ThreadLocal来解决。</p>
<p>类ThreadLocal主要就是为每个线程绑定自己的值，可以将ThreadLocal类比喻成全局存放数据的盒子，盒子中可以存储每个线程的私有数据。</p>
<p>线程间的变量具有隔离性。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>线程间通信</tag>
      </tags>
  </entry>
  <entry>
    <title>正则表达式</title>
    <url>/2017-11-20/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p> 正则表达式是个极端强大工具，而且在字符串模式-匹配和字符串模式-替换方面富有弹性，<br>在Sun的Java JDK 1.40版本中，Java自带了支持正则表达式的包。</p>
<p>在java的regex包中，包括了两个类，Pattern(模式类)和Matcher(匹配器类)。Pattern类是用来表达和陈述所要搜索模式的对象，Matcher类是真正影响搜索的对象。</p>
<h3 id="正则表达式的基础知识"><a href="#正则表达式的基础知识" class="headerlink" title="正则表达式的基础知识"></a>正则表达式的基础知识</h3><ul>
<li>句点符号</li>
</ul>
<p>假设你在玩英文拼字游戏，想要找出三个字母的单词，而且这些单词必须以“t”字母开头，以“n”字母结束。另外，假设有一本英文字典，你可以用正则表达式搜索它的全部内容。要构造出这个正则表达式，你可以使用一个通配符——句点符号“.”。这样，完整的表达式就是<strong>t.n</strong>，它匹配“tan”、“ten”、“tin”和“ton”，还匹配“t#n”、“tpn”甚至“t n”，还有其他许多无意义的组合</p>
<ul>
<li>方括号符号</li>
</ul>
<p>为了解决句点符号匹配范围过于广泛这一问题，你可以在方括号（“[]”）里面指定看来有意义的字符。此时，只有方括号里面指定的字符才参与匹配。也就是说，正则表达式“t[aeio]n”只匹配“tan”、“Ten”、“tin”和“ton”。但“Toon”不匹配，因为在方括号之内你只能匹配单个字符</p>
<ul>
<li>“或”符号</li>
</ul>
<p>如果除了上面匹配的所有单词之外，你还想要匹配“toon”，那么，你可以使用“|”操作符。“|”操作符的基本意义就是“或”运算。要匹配“toon”，使用“t(a|e|i|o|oo)n”正则表达式。这里不能使用方扩号，因为方括号只允许匹配单个字符；这里必须使用圆括号“()”。圆括号还可以用来分组</p>
<ul>
<li>表示匹配次数的符号</li>
</ul>
<p><img src="/images/regex/%E8%A1%A8%E7%A4%BA%E6%AC%A1%E6%95%B0%E7%9A%84%E7%AC%A6%E5%8F%B7.jpg"></p>
<p>假设我们要在文本文件中搜索美国的社会安全号码。这个号码的格式是999-99-9999。用来匹配它的正则表达式如图一所示。在正则表达式中，连字符（“-”）有着特殊的意义，它表示一个范围，比如从0到9。因此，匹配社会安全号码中的连字符号时，它的前面要加上一个转义字符“\”。</p>
<p><img src="/images/regex/img1.gif"></p>
<p>假设进行搜索的时候，你希望连字符号可以出现，也可以不出现——即，999-99-9999和999999999都属于正确的格式。这时，你可以在连字符号后面加上“？”数量限定符号，如图二所示：</p>
<p><img src="/images/regex/img2.gif"></p>
<ul>
<li>“否”符号</li>
</ul>
<p>“^”符号称为“否”符号。如果用在方括号内，“^”表示不想要匹配的字符。例如，图四的正则表达式匹配所有单词，但以“X”字母开头的单词除外。</p>
<p><img src="/images/regex/img3.gif"></p>
<ul>
<li>圆括号和空白符号</li>
</ul>
<p>假设要从格式为“June 26, 1951”的生日日期中提取出月份部分，用来匹配该日期的正则表达式可以如图五所示：</p>
<p><img src="/images/regex/img4.gif"></p>
<p>新出现的“\s”符号是空白符号，匹配所有的空白字符，包括Tab字符。如果字符串正确匹配，接下来如何提取出月份部分呢？只需在月份周围加上一个圆括号创建一个组，然后用ORO API（本文后面详细讨论）提取出它的值。修改后的正则表达式如图六所示：</p>
<p><img src="/images/regex/img5.gif"></p>
<ul>
<li>为简便起见，你可以使用一些为常见正则表达式创建的快捷符号</li>
</ul>
<p><img src="/images/regex/%E5%85%B6%E5%AE%83%E7%AC%A6%E5%8F%B7%E8%A1%A8.jpg"></p>
<h3 id="java正则表达式的方法简介"><a href="#java正则表达式的方法简介" class="headerlink" title="java正则表达式的方法简介"></a>java正则表达式的方法简介</h3><h4 id="Pattern：一个Pattern是一个正则表达式经编译后的表现模式。"><a href="#Pattern：一个Pattern是一个正则表达式经编译后的表现模式。" class="headerlink" title="Pattern：一个Pattern是一个正则表达式经编译后的表现模式。"></a>Pattern：一个Pattern是一个正则表达式经编译后的表现模式。</h4><p><img src="/images/regex/pattern%E7%B1%BB%E6%96%B9%E6%B3%95.jpg"></p>
<h4 id="Matcher：一个Matcher对象是一个状态机器，它依据Pattern对象做为匹配模式对字符串展开匹配检查。"><a href="#Matcher：一个Matcher对象是一个状态机器，它依据Pattern对象做为匹配模式对字符串展开匹配检查。" class="headerlink" title="Matcher：一个Matcher对象是一个状态机器，它依据Pattern对象做为匹配模式对字符串展开匹配检查。"></a>Matcher：一个Matcher对象是一个状态机器，它依据Pattern对象做为匹配模式对字符串展开匹配检查。</h4><p><img src="/images/regex/matcher%E7%B1%BB%E6%96%B9%E6%B3%95.jpg"></p>
<h3 id="方法讲解"><a href="#方法讲解" class="headerlink" title="方法讲解"></a>方法讲解</h3><h4 id="Pattern对象"><a href="#Pattern对象" class="headerlink" title="Pattern对象"></a>Pattern对象</h4><p>表示经编译的正则表达式。</p>
<ol>
<li><p>静态的compile( )方法负责将表示正则表达式的字符串编译成Pattern对象。正如上述例程所示的，只要给Pattern的matcher( )方法送一个字符串就能获取一个Matcher对象。接下来就能用Matcher的方法来查询匹配的结果了。</p>
</li>
<li><p>Pattern还有一个能快速判断能否在input里面找到regex的</p>
</li>
<li><p>能返回String数组的split( )方法，它能用regex把字符串分割开来。</p>
</li>
</ol>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"> Pattern p &#x3D; Pattern.compile(&quot;\\d+&quot;);</span><br><span class="line"> Matcher matcher &#x3D; p.matcher(&quot;56&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Boolean flag &#x3D; Pattern.matches(&quot;\\d+&quot;, &quot;test string  34 5&quot;);</span><br><span class="line"></span><br><span class="line">String stringSpit &#x3D;&quot;this is a String!&quot;;</span><br><span class="line">String[] arr2 &#x3D; stringSpit.split(&quot;\\n&quot;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="Matcher对象"><a href="#Matcher对象" class="headerlink" title="Matcher对象"></a>Matcher对象</h4><p>Matcher对象可以通过pattern.matcher(“test”) 传入字符串获得，之后就可以通过matcher对象的方法来查询匹配结果了。</p>
<ol>
<li>boolean matches()  </li>
</ol>
<p>matches( )的前提是Pattern匹配整个字符串</p>
<ol start="2">
<li>boolean lookingAt()</li>
</ol>
<p>lookingAt( )的意思是Pattern匹配字符串的开头。</p>
<ol start="3">
<li>boolean find()</li>
</ol>
<p>find( )的功能是发现CharSequence（传入字符串的）里的，与pattern相匹配的多个字符序列</p>
<ol start="4">
<li>boolean find(int start)</li>
</ol>
<p>它会告诉方法从哪里开始找——即从参数位置开始查找。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">@Test</span><br><span class="line">public void test2() &#123;</span><br><span class="line"></span><br><span class="line">    Pattern pattern &#x3D; Pattern.compile(&quot;\\w+&quot;);</span><br><span class="line"></span><br><span class="line">    Matcher matcher &#x3D; pattern.matcher(&quot;Evening is full of the linnet&#39;s wings&quot;);</span><br><span class="line"></span><br><span class="line">    while (matcher.find()) &#123;</span><br><span class="line">        System.out.println(&quot;match find:&quot; + matcher.group());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int i &#x3D; 0;</span><br><span class="line">    while (matcher.find(i)) &#123;</span><br><span class="line">        System.out.println(matcher.group());</span><br><span class="line">        i++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="Groups"><a href="#Groups" class="headerlink" title="Groups"></a>Groups</h4><p>Group是指里用括号括起来的，能被后面的表达式调用的正则表达式。Group 0 表示整个表达式，group 1表示第一个被括起来的group，以此类推。所以；<br>A(B( C ))D 里面有三个group：group 0是ABCD， group 1是BC，group 2是C。</p>
<p> 下述Matcher方法来使用group：</p>
<ul>
<li>int groupCount( )返回matcher对象中的group的数目。不包括group0。</li>
<li>String group( ) 返回上次匹配操作(比方说find( ))的group 0(整个匹配)</li>
<li>String group(int i)返回上次匹配操作的某个group。如果匹配成功，但是没能找到group，则返回null。</li>
<li>int start(int group)返回上次匹配所找到的，group的开始位置。</li>
</ul>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  @Test</span><br><span class="line">  public void test3() &#123;</span><br><span class="line"></span><br><span class="line">      String poem &#x3D;</span><br><span class="line">              &quot;Twas brillig, and the slithy toves&#x2F;n&quot; +</span><br><span class="line">                      &quot;Did gyre and gimble in the wabe.&#x2F;n&quot; +</span><br><span class="line">                      &quot;All mimsy were the borogoves,&#x2F;n&quot; +</span><br><span class="line">                      &quot;And the mome raths outgrabe.&#x2F;n&#x2F;n&quot; +</span><br><span class="line">                      &quot;Beware the Jabberwock, my son,&#x2F;n&quot; +</span><br><span class="line">                      &quot;The jaws that bite, the claws that catch.&#x2F;n&quot; +</span><br><span class="line">                      &quot;Beware the Jubjub bird, and shun&#x2F;n&quot; +</span><br><span class="line">                      &quot;The frumious Bandersnatch.&quot;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;换行模式 (?m)</span><br><span class="line">      Pattern pattern &#x3D; Pattern.compile(&quot;(?m)(\\S+)\\s+((\\S+)\\s+(\\S+))&quot;);</span><br><span class="line"></span><br><span class="line">      Matcher matcher &#x3D; pattern.matcher(poem);</span><br><span class="line"></span><br><span class="line">      while (matcher.find()) &#123;</span><br><span class="line">          for (int i &#x3D; 0; i &lt;&#x3D; matcher.groupCount(); i++) &#123;</span><br><span class="line">              System.out.println(matcher.group(i));</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="start-和end"><a href="#start-和end" class="headerlink" title="start( )和end( )"></a>start( )和end( )</h4><p>如果匹配成功，start( )会返回此次匹配的开始位置，end( )会返回此次匹配的结束位置，即最后一个字符的下标加一。如果之前的匹配不成功(或者没匹配)，那么无论是调用start( )还是end( )，都会引发一个IllegalStateException。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">    public void test4() &#123;</span><br><span class="line">        String[] input &#x3D; new String[]&#123;</span><br><span class="line">                &quot;Java has regular expressions in 1.4&quot;,</span><br><span class="line">                &quot;regular expressions now expressing in Java&quot;,</span><br><span class="line">                &quot;Java represses oracular expressions&quot;</span><br><span class="line">        &#125;;</span><br><span class="line">        Pattern p1 &#x3D; Pattern.compile(&quot;re\\w*&quot;),</span><br><span class="line">                p2 &#x3D; Pattern.compile(&quot;Java.*&quot;);</span><br><span class="line">        for (int i &#x3D; 0; i &lt; input.length; i++) &#123;</span><br><span class="line">            System.out.println(&quot;input &quot; + i + &quot;: &quot; + input[i]);</span><br><span class="line">            Matcher</span><br><span class="line">                    m1 &#x3D; p1.matcher(input[i]),</span><br><span class="line">                    m2 &#x3D; p2.matcher(input[i]);</span><br><span class="line">            while (m1.find()) &#123;</span><br><span class="line">                System.out.println(&quot;m1.find() &#39;&quot; + m1.group() +</span><br><span class="line">                        &quot;&#39; start &#x3D; &quot; + m1.start() + &quot; end &#x3D; &quot; + m1.end());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            while (m2.find()) &#123;</span><br><span class="line">                System.out.println(&quot;m2.find() &#39;&quot; + m2.group() +</span><br><span class="line">                        &quot;&#39; start &#x3D; &quot; + m2.start() + &quot; end &#x3D; &quot; + m2.end());</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F; No reset() necessary</span><br><span class="line">            if (m1.lookingAt()) &#123;</span><br><span class="line">                System.out.println(&quot;m1.lookingAt() start &#x3D; &quot;</span><br><span class="line">                        + m1.start() + &quot; end &#x3D; &quot; + m1.end());</span><br><span class="line">            &#125;</span><br><span class="line">            if (m2.lookingAt()) &#123;</span><br><span class="line">                System.out.println(&quot;m2.lookingAt() start &#x3D; &quot;</span><br><span class="line">                        + m2.start() + &quot; end &#x3D; &quot; + m2.end());</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F; No reset() necessary</span><br><span class="line">            if (m1.matches()) &#123;</span><br><span class="line">                System.out.println(&quot;m1.matches() start &#x3D; &quot;</span><br><span class="line">                        + m1.start() + &quot; end &#x3D; &quot; + m1.end());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            if (m2.matches()) &#123;</span><br><span class="line">                System.out.println(&quot;m2.matches() start &#x3D; &quot;</span><br><span class="line">                        + m2.start() + &quot; end &#x3D; &quot; + m2.end());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="split"><a href="#split" class="headerlink" title="split( )"></a>split( )</h4><p>所谓分割是指将以正则表达式为界，将字符串分割成String数组。</p>
<ul>
<li><p>String[] split(CharSequence charseq)</p>
</li>
<li><p>String[] split(CharSequence charseq, int limit)</p>
</li>
</ul>
<p>第二个split( )会限定分割的次数,正则表达式是如此重要，以至于有些功能被加进了String类，其中包括split( )(已经看到了)，matches( )，replaceFirst( )以及replaceAll( )。这些方法的功能同Pattern和Matcher的相同。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">@Test</span><br><span class="line">public void test5() &#123;</span><br><span class="line">    String input &#x3D; &quot;This!!unusual use!!of exclamation!!points&quot;;</span><br><span class="line">    System.out.println(Arrays.asList(Pattern.compile(&quot;!!&quot;).split(input)));</span><br><span class="line">    &#x2F;&#x2F; Only do the first three:</span><br><span class="line">    System.out.println(Arrays.asList(Pattern.compile(&quot;!!&quot;).split(input, 3)));</span><br><span class="line">    System.out.println(Arrays.asList(&quot;Aha! String has a split() built in!&quot;.split(&quot; &quot;)));</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="替换操作"><a href="#替换操作" class="headerlink" title="替换操作"></a>替换操作</h4><ul>
<li>replaceFirst(String replacement)将字符串里，第一个与模式相匹配的子串替换成replacement。</li>
<li>replaceAll(String replacement)，将输入字符串里所有与模式相匹配的子串全部替换成replacement。</li>
<li>appendReplacement(StringBuffer sbuf, String replacement)对sbuf进行逐次替换，而不是像replaceFirst( )或replaceAll( )那样，只替换第一个或全部子串。这是个非常重要的方法，因为它可以调用方法来生成replacement(replaceFirst( )和replaceAll( )只允许用固定的字符串来充当replacement)。有了这个方法，你就可以编程区分group，从而实现更强大的替换功能。<br>调用完appendReplacement( )之后，为了把剩余的字符串拷贝回去，必须调用appendTail(StringBuffer sbuf)。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">@Test</span><br><span class="line">   public void test6() &#123;</span><br><span class="line"></span><br><span class="line">       String s &#x3D; &quot;! Here&#39;s a block of text to use as input to\n&quot; +</span><br><span class="line">               &quot;  the regular expression matcher. Note that we&#39;ll\n&quot; +</span><br><span class="line">               &quot;  first extract the block of text by looking for\n&quot; +</span><br><span class="line">               &quot;  the special delimiters, then process the\n&quot; +</span><br><span class="line">               &quot;  extracted block. !&quot;;</span><br><span class="line">       Matcher mInput &#x3D; Pattern.compile(&quot;&#x2F;*!(.*)!*&#x2F;&quot;, Pattern.DOTALL).matcher(s);</span><br><span class="line">       &#x2F;&#x2F; Captured by parentheses</span><br><span class="line">       if (mInput.find())&#123;</span><br><span class="line">           s &#x3D; mInput.group(1);</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F; Replace two or more spaces with a single space:</span><br><span class="line">       s &#x3D; s.replaceAll(&quot; &#123;2,&#125;&quot;, &quot; &quot;);</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F; Replace one or more spaces at the beginning of each</span><br><span class="line">       &#x2F;&#x2F; line with no spaces. Must enable MULTILINE mode:</span><br><span class="line">       s &#x3D; s.replaceAll(&quot;(?m)^ +&quot;, &quot;&quot;);</span><br><span class="line">       System.out.println(s);</span><br><span class="line">       s &#x3D; s.replaceFirst(&quot;[aeiou]&quot;, &quot;(VOWEL1)&quot;);</span><br><span class="line">       StringBuffer sbuf &#x3D; new StringBuffer();</span><br><span class="line">       Pattern p &#x3D; Pattern.compile(&quot;[aeiou]&quot;);</span><br><span class="line">       Matcher m &#x3D; p.matcher(s);</span><br><span class="line">       &#x2F;&#x2F; Process the find information as you</span><br><span class="line">       &#x2F;&#x2F; perform the replacements:</span><br><span class="line">       while (m.find())</span><br><span class="line">           m.appendReplacement(sbuf, m.group().toUpperCase());</span><br><span class="line">       &#x2F;&#x2F; Put in the remainder of the text:</span><br><span class="line">       m.appendTail(sbuf);</span><br><span class="line">       System.out.println(sbuf);</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>mInput的功能是匹配’/<em>!’ 和 ‘!</em>/‘ 之间的文本(注意一下分组用的括号)。接下来，我们将所有两个以上的连续空格全都替换成一个，并且将各行开头的空格全都去掉(为了让这个正则表达式能对所有的行，而不仅仅是第一行起作用，必须启用多行模式)。这两个操作都用了String的replaceAll( )(这里用它更方便)。注意，由于每个替换只做一次，因此除了预编译Pattern之外，程序没有额外的开销。</p>
<p>replaceFirst( )只替换第一个子串。此外，replaceFirst( )和replaceAll( )只能用常量(literal)来替换，所以如果每次替换的时候还要进行一些操作的话，它们是无能为力的。碰到这种情况，得用appendReplacement( )，它能在进行替换的时候想写多少代码就写多少。在上面那段程序里，创建sbuf的过程就是选group做处理，也就是用正则表达式把元音字母找出来，然后换成大写的过程。通常你得在完成全部的替换之后才调用appendTail( )，但是如果要模仿replaceFirst( )(或”replace n”)的效果，你也可以只替换一次就调用appendTail( )。它会把剩下的东西全都放进sbuf。</p>
<p>你还可以在appendReplacement( )的replacement参数里用”$g”引用已捕获的group，其中’g’ 表示group的号码。不过这是为一些比较简单的操作准备的，因而其效果无法与上述程序相比。</p>
<h4 id="reset"><a href="#reset" class="headerlink" title="reset( )"></a>reset( )</h4><p>可以用reset( )方法给现有的Matcher对象配上个新的CharSequence。<br>如果不给参数，reset( )会把Matcher设到当前字符串的开始处。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">@Test</span><br><span class="line">   public void test7() &#123;</span><br><span class="line">       Matcher m &#x3D; Pattern.compile(&quot;[frb][aiu][gx]&quot;)</span><br><span class="line">               .matcher(&quot;fix the rug with bags&quot;);</span><br><span class="line"></span><br><span class="line">       while (m.find()) &#123;</span><br><span class="line">           System.out.println(m.group());</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       m.reset(&quot;fix the rig with rags&quot;);</span><br><span class="line"></span><br><span class="line">       while (m.find()) &#123;</span><br><span class="line">           System.out.println(m.group());</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="回溯模式-上面有例子"><a href="#回溯模式-上面有例子" class="headerlink" title="回溯模式 (上面有例子)"></a>回溯模式 (上面有例子)</h4><p>‘\1’回溯上一个匹配的结果</p>
<p>Pattern pattern =Pattern.compile(“\b(\w+)\s+\1\b”,</p>
<h4 id="模式标志-上面有例子"><a href="#模式标志-上面有例子" class="headerlink" title="模式标志(上面有例子)"></a>模式标志(上面有例子)</h4><p>‘$’表示一行的结尾。但是’$’通常表示整个字符串的结尾，所以这里要明确地告诉正则表达式注意换行符。这一点是由’(?m)’标志完成的</p>
<p><a href="http://blog.csdn.net/allwefantasy/article/details/3136570/">参考资料：JAVA正则表达的必读篇</a></p>
<p><a href="http://tool.oschina.net/uploads/apidocs/jquery/regexp.html">参考资料：正则表达式手册</a></p>
<p><a href="http://tool.oschina.net/regex/">在线正则表达式测试工具</a></p>
]]></content>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解java虚拟机-虚拟机类加载机制</title>
    <url>/2018-11-02/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。</p>
<h1 id="类加载的时机"><a href="#类加载的时机" class="headerlink" title="类加载的时机"></a>类加载的时机</h1><p>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）</p>
<p><img src="/images/jvm/%E7%B1%BB%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.png" alt="类的生命周期"></p>
<p>以下情况才会触发初始化：</p>
<ol>
<li>使用new关键字实例化对象的时候、读取或设置一个类的静态字段；</li>
<li>使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。</li>
<li>当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化</li>
<li>当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个类），虚拟机会先初始化这个主类</li>
<li>动态语言支持的，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化</li>
</ol>
<h2 id="被动引用"><a href="#被动引用" class="headerlink" title="被动引用"></a>被动引用</h2><p>通过子类引用父类的静态字段，不会导致子类初始化；</p>
<p>通过数组定义来引用类，不会触发此类的初始化；</p>
<p>常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。</p>
<h2 id="接口的加载过程的不同"><a href="#接口的加载过程的不同" class="headerlink" title="接口的加载过程的不同"></a>接口的加载过程的不同</h2><p>当一个类在初始化时，要求其父类全部都已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量）才会初始化</p>
<h1 id="类加载的过程"><a href="#类加载的过程" class="headerlink" title="类加载的过程"></a>类加载的过程</h1><h2 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h2><p>加载阶段需要完成三件事情：</p>
<ol>
<li>通过一个类的全限定名来获取定义此类的二进制字节流;</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构;</li>
<li>在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口</li>
</ol>
<p>一个非数组类的加载阶段（准确地说，是加载阶段中获取类的二进制字节流的动作）是开发人员可控性最强的，因为加载阶段既可以使用系统提供的引导类加载器来完成，也可以由用户自定义的类加载器去完成，</p>
<p>对于数组类而言，情况就有所不同，数组类本身不通过类加载器创建，它是由Java虚拟机直接创建的。但数组类与类加载器仍然有很密切的关系，因为数组类的元素类型最终需要类加载器组创建。</p>
<p>数组类的可见性与它的组件类型的可见性一致，如果组件类型不是引用类型，那数组类的可见性将默认为public。</p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。</p>
<ol>
<li>文件格式验证</li>
<li>元数据验证</li>
<li>字节码验证</li>
<li>符号引用验证</li>
</ol>
<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>准备阶段是正式为类变量分配内存并设置变量初始值的阶段。这些变量所使用的内存都将在方法区中进行分配。</p>
<p>这个阶段中有两个容易产生混淆的概念需要强调一下，首先，这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。</p>
<p><img src="/images/jvm/%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%9A%84%E9%9B%B6%E5%80%BC.png" alt="基本数据类型的零值"></p>
<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><p>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。</p>
<p>符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。</p>
<p>直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。</p>
<h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>类初始化阶段是类加载过程的最后一步，前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码（或者说是字节码）。</p>
<p>在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器＜clinit＞（）方法的过程。</p>
<p>＜clinit＞（）方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量</p>
<h1 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h1><p>通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块称为“类加载器”。</p>
<h2 id="类与类加载器"><a href="#类与类加载器" class="headerlink" title="类与类加载器"></a>类与类加载器</h2><p>类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远远不限于类加载阶段。</p>
<p>对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，<br>每一个类加载器，都拥有一个独立的类名称空间。这句话可以表达得更通俗一些：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，<br>否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package cn.chen.exercise.chapter7;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.io.InputStream;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 不同的类加载器对instanceof关键字运算的结果的影响</span><br><span class="line"> *</span><br><span class="line"> * @author Chen WeiJie</span><br><span class="line"> * @date 2018-11-05 22:49:24</span><br><span class="line"> **&#x2F;</span><br><span class="line">public class ClassLoaderTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[]args)throws Exception&#123;</span><br><span class="line">        ClassLoader myLoader&#x3D;new ClassLoader()&#123;</span><br><span class="line">            @Override</span><br><span class="line">            public Class&lt;?&gt;loadClass(String name)throws ClassNotFoundException&#123;</span><br><span class="line">                try&#123;</span><br><span class="line">                    String fileName&#x3D;name.substring(name.lastIndexOf(&quot;.&quot;)+1)+&quot;.class&quot;;</span><br><span class="line">                    InputStream is&#x3D;getClass().getResourceAsStream(fileName);</span><br><span class="line">                    if(is&#x3D;&#x3D;null)&#123;</span><br><span class="line">                        return super.loadClass(name);</span><br><span class="line">                    &#125;</span><br><span class="line">                    byte[]b&#x3D;new byte[is.available()];</span><br><span class="line">                    is.read(b);</span><br><span class="line">                    return defineClass(name,b,0,b.length);</span><br><span class="line">                &#125;catch(IOException e)&#123;</span><br><span class="line">                    throw new ClassNotFoundException(name);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        Object obj&#x3D;myLoader.loadClass(&quot;cn.chen.exercise.chapter7.ClassLoaderTest&quot;).newInstance();</span><br><span class="line">        System.out.println(obj.getClass());</span><br><span class="line">        System.out.println(obj instanceof cn.chen.exercise.chapter7.ClassLoaderTest);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>它可以加载与自己在同一路径下的Class文件。我们使用这个类加载器去加载了一个名为“org.fenixsoft.classloading.ClassLoaderTest”的类，并实例化了这个类的对象。两行输出结<br>果中，从第一句可以看出，这个对象确实是类org.fenixsoft.classloading.ClassLoaderTest实例化出来的对象，但从第二句可以发现，这个对象与类org.fenixsoft.classloading.ClassLoaderTest做<br>所属类型检查的时候却返回了false，这是因为虚拟机中存在了两个ClassLoaderTest类，一个是由系统应用程序类加载器加载的，另外一个是由我们自定义的类加载器加载的，虽然都来<br>自同一个Class文件，但依然是两个独立的类，做对象所属类型检查时结果自然为false</p>
<h2 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h2><h2 id="从Java虚拟机的角度来讲，只存在两种不同的类加载器："><a href="#从Java虚拟机的角度来讲，只存在两种不同的类加载器：" class="headerlink" title="从Java虚拟机的角度来讲，只存在两种不同的类加载器："></a>从Java虚拟机的角度来讲，只存在两种不同的类加载器：</h2><p>一种是启动类加载器（Bootstrap  ClassLoader），这个类加载器使用C++语言实现  ，是虚拟机自身的一部分；另</p>
<p>一种就是所有其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader</p>
<h2 id="从Java开发人员的角度来看，类加载器还可以划分得更细致一些，绝大部分Java程序都会使用到以下3种系统提供的类加载器。"><a href="#从Java开发人员的角度来看，类加载器还可以划分得更细致一些，绝大部分Java程序都会使用到以下3种系统提供的类加载器。" class="headerlink" title="从Java开发人员的角度来看，类加载器还可以划分得更细致一些，绝大部分Java程序都会使用到以下3种系统提供的类加载器。"></a>从Java开发人员的角度来看，类加载器还可以划分得更细致一些，绝大部分Java程序都会使用到以下3种系统提供的类加载器。</h2><ul>
<li>启动类加载器（Bootstrap ClassLoader）：</li>
</ul>
<p>这个类将器负责将存放在＜JAVA_HOME＞\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机<br>识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加<br>载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">Returns the class loader for the class.Some implementations may use null to represent the bootstrap class loader.This method will return null in such</span><br><span class="line">implementations if this class was loaded by the bootstrap class loader.</span><br><span class="line">*&#x2F;</span><br><span class="line">public ClassLoader getClassLoader（）&#123;</span><br><span class="line">ClassLoader cl&#x3D;getClassLoader0（）；</span><br><span class="line">if（cl&#x3D;&#x3D;null）</span><br><span class="line">return null；</span><br><span class="line">SecurityManager sm&#x3D;System.getSecurityManager（）；</span><br><span class="line">if（sm！&#x3D;null）&#123;</span><br><span class="line">ClassLoader ccl&#x3D;ClassLoader.getCallerClassLoader（）；</span><br><span class="line">if（ccl！&#x3D;null＆＆ccl！&#x3D;cl＆＆！cl.isAncestor（ccl））&#123;</span><br><span class="line">sm.checkPermission（SecurityConstants.GET_CLASSLOADER_PERMISSION）；</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">return cl；</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="扩展类加载器（Extension-ClassLoader）"><a href="#扩展类加载器（Extension-ClassLoader）" class="headerlink" title="扩展类加载器（Extension  ClassLoader）"></a>扩展类加载器（Extension  ClassLoader）</h2><p>这个加载器由sun.misc.Launcher $ExtClassLoader实现，它负责加载＜JAVA_HOME＞\lib\ext目录中的，或者被java.ext.dirs系<br>统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。</p>
<h2 id="应用程序类加载器（Application-ClassLoader）"><a href="#应用程序类加载器（Application-ClassLoader）" class="headerlink" title="应用程序类加载器（Application ClassLoader）"></a>应用程序类加载器（Application ClassLoader）</h2><p>这个类加载器由sun.misc.Launcher $App-ClassLoader实现。由于这个类加载器是ClassLoader中的getSystemClassLoader（）方法的返回<br>值，所以一般也称它为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。</p>
<p><img src="/images/jvm/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E7%9A%84%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B.png" alt="类加载器的双亲委派模型"></p>
<p>上图展示的类加载器之间的这种层次关系，称为类加载器的双亲委派模型（Parents Delegation Model）。双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当<br>有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承（Inheritance）的关系来实现，而是都使用组合（Composition）关系来复用父加载器的代码。</p>
<p>双亲委派模型不是一个强制性的约束模型，而是java开发者推荐的一种类加载器实现方式。</p>
<h3 id="双亲委派模型的工作过程是"><a href="#双亲委派模型的工作过程是" class="headerlink" title="双亲委派模型的工作过程是"></a>双亲委派模型的工作过程是</h3><p>如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是<br>如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。</p>
<h3 id="双亲委派模型的好处"><a href="#双亲委派模型的好处" class="headerlink" title="双亲委派模型的好处"></a>双亲委派模型的好处</h3><p>使用双亲委派模型来组织类加载器之间的关系，有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存放在<br>rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。<br>相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，</p>
<p>如果用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，那系统中将会出现多个不同的Object<br>类，Java类型体系中最基础的行为也就无法保证，应用程序也将会变得一片混乱。</p>
<p>如果读者有兴趣的话，可以尝试去编写一个与rt.jar类库中已有类重名的Java类，将会发现可以正常编译，但永远无法被加载运行</p>
<h3 id="双亲委派模型的实现逻辑"><a href="#双亲委派模型的实现逻辑" class="headerlink" title="双亲委派模型的实现逻辑"></a>双亲委派模型的实现逻辑</h3><p>先检查是否已经被加载过，若没有加载则调用父加载器的loadClass（）方法，若父加载器为空则默认使用启动类加载器作为父加载器。如果父类加载失败，抛出</p>
<p>ClassNotFoundException异常后，再调用自己的findClass（）方法进行加载。</p>
<ul>
<li>双亲委派模型的实现</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">protected synchronized Class＜?＞loadClass（String name,boolean resolve）throws ClassNotFoundException</span><br><span class="line">&#123;</span><br><span class="line">&#x2F;&#x2F;首先，检查请求的类是否已经被加载过了</span><br><span class="line">Class c&#x3D;findLoadedClass（name）；</span><br><span class="line">if（c&#x3D;&#x3D;null）&#123;</span><br><span class="line">try&#123;</span><br><span class="line">if（parent！&#x3D;null）&#123;</span><br><span class="line">c&#x3D;parent.loadClass（name,false）；</span><br><span class="line">&#125;else&#123;</span><br><span class="line">c&#x3D;findBootstrapClassOrNull（name）；</span><br><span class="line">&#125;</span><br><span class="line">&#125;catch（ClassNotFoundException e）&#123;</span><br><span class="line">&#x2F;&#x2F;如果父类加载器抛出ClassNotFoundException</span><br><span class="line">&#x2F;&#x2F;说明父类加载器无法完成加载请求</span><br><span class="line">&#125;</span><br><span class="line">if（c&#x3D;&#x3D;null）&#123;</span><br><span class="line">&#x2F;&#x2F;在父类加载器无法加载的时候</span><br><span class="line">&#x2F;&#x2F;再调用本身的findClass方法来进行类加载</span><br><span class="line">c&#x3D;findClass（name）；</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">if（resolve）&#123;</span><br><span class="line">resolveClass（c）；</span><br><span class="line">&#125;</span><br><span class="line">return c；</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>






































]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>虚拟机类加载机制</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能mysql-Mysql的架构和历史</title>
    <url>/2018-11-12/%E9%AB%98%E6%80%A7%E8%83%BDmysql-Mysql%E7%9A%84%E6%9E%B6%E6%9E%84%E5%92%8C%E5%8E%86%E5%8F%B2/</url>
    <content><![CDATA[<ul>
<li>MySQL最重要，最与众不同的特性是它的可插拔式存储引擎架构（将查询处理，系统任务，数据的存储，提取相分离）。</li>
</ul>
<h1 id="MySQL逻辑结构"><a href="#MySQL逻辑结构" class="headerlink" title="MySQL逻辑结构"></a>MySQL逻辑结构</h1><p><img src="/images/mysql/mysql%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="mysql服务器逻辑架构图"></p>
<p>第一层服务：大多数的客户端/服务端的工具或者服务都有类似的架构，比如连接处理、授权处理、安全等。</p>
<p>第二层服务：核心服务都在这一层，包括查询解析、分析、优化、缓存以及所有的内置函数，所有跨存储引擎的功能都在这一层实现。</p>
<p>第三层服务：包含了存储引擎，存储引擎负责mysql的数据存储和提取。</p>
<h2 id="连接管理和安全性"><a href="#连接管理和安全性" class="headerlink" title="连接管理和安全性"></a>连接管理和安全性</h2><p>每个客户端连接都会在服务器进程中拥有一个线程，这个连接的查询只会在单独的线程中执行，该线程都只能轮流在某个cpu中运行，服务器会缓存线程，不需要为每一个新建的连接创建和销毁线程。</p>
<p>当客户端进行连接后，服务器需要对其进行认证。</p>
<h2 id="优化与执行"><a href="#优化与执行" class="headerlink" title="优化与执行"></a>优化与执行</h2><p>mysql会解析查询，并创建内部数据结构（解析树），然后进行各种优化，包括重写查询、决定表的读取顺序、以及选择合适的索引等。用户可以使用关键字提示优化器（hint）影响他的决策进程，<br>也可以使用请求优化解释器优化过程的各个因素。mysql在解析查询之前，服务器会先检查查询缓存，如果有就不必执行查询解析。</p>
<h1 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h1><p>同一时刻修改数据都会产生并发控制的问题，本章主要考虑服务层与存储引擎层。</p>
<h2 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h2><p>共享锁与排它锁也叫读写锁。读锁是共享的，或者是互不阻塞的，多个客户在读取同一个资源互不干扰，写锁是排他的，一个写锁会阻塞其它的写锁和读锁。这样同一时间才会只有一个用户执行写入操作。</p>
<p>实际数据库中，当某个用户在修改某一部分数据时，mysql会通过锁定防止其它用户读取同一数据。</p>
<h2 id="锁的粒度"><a href="#锁的粒度" class="headerlink" title="锁的粒度"></a>锁的粒度</h2><p>提高共享资源的并发性就是让锁定对象更具有选择性，尽量指锁定需要修改的部分数据。锁定的数据越少，则系统的并发度越高。当然，加锁也需要消耗资源，比如获得锁，检查锁是否解除，释放锁等都会有开销。</p>
<p>锁策略是指在锁的开销和数据的安全性之间寻找平衡。一般数据库只是在表上加行锁，而mysql提供了更多选择。</p>
<p>将锁的粒度固定在某个级别可以为某种特定的场景提供更好的性能。</p>
<ul>
<li>表锁（table lock）</li>
</ul>
<p>它是最基本的锁策略，开销最小的锁策略，锁定整张表。一个用户在对表执行写操作需要获得的锁，他会阻塞其它用户对表的读写操作。</p>
<ul>
<li>行级锁 (row lock)</li>
</ul>
<p>行级锁可以最大程度支持并发处理，也是开销最大的锁。</p>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><p>事务内的语句要么执行，要么全部不执行。事务是一个原子性的工作单元，</p>
<h2 id="事务的特性（ACID）"><a href="#事务的特性（ACID）" class="headerlink" title="事务的特性（ACID）"></a>事务的特性（ACID）</h2><ul>
<li>原子性（atomicity）</li>
</ul>
<p>一个事务是不可分割的最小单元，整个事务要么执行，要么全部失败回滚。</p>
<ul>
<li>一致性（consistency）</li>
</ul>
<p>事务总是从一个一致性的状态到另一个一致性的状态，如 A:500-&gt;200  B:100-&gt; 400</p>
<ul>
<li>隔离性（isolation）</li>
</ul>
<p>一个事务所做的修改操作在最终提交以前，对其它事务是不可见的。</p>
<ul>
<li>持久性（durability）</li>
</ul>
<p>一旦事务提交，则所做的修改就会永久的保存到数据库中，即使数据库奔溃，修改的数据也不会丢失。数据库实现ACID需要做更多的额外工作，会增加系统开销。</p>
<h3 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h3><p>sql标准中有4种隔离级别，较低级别的隔离通常可以执行更高的并发，系统的开销也更小。</p>
<ul>
<li><p>未提交读（read uncommitted）：事务中的修改，即使没有提交，对其它事务也是可见的。事务可以读取未提交的数据，这也被称为脏读，这个级别也会导致很多问题，性能也不会好太多，不常用。</p>
</li>
<li><p>提交读(read committed): 大多数的数据库系统的隔离级别都是read committed（mysql不是），一个事务开始时，只能看见已经提交的修改。也叫不可重复读，执行两次的查询可能得到不一样的结果。</p>
</li>
<li><p>可重复读（repeatable read）:解决了脏读的问题，该级别的保证了同一个事务中多次读取同样的结果是一致的，可重复读还是无法解决幻读的问题。所谓幻读是指当某个事务在读取某个范围内的记录时，<br>另一个事务又在该范围内又插入了新的记录，当前事务再次读取该范围的记录时会产生换读。（可重复读是mysql默认事务隔离级别）。</p>
</li>
<li><p>可串行化(serializable)：最高的隔离级别，强制事务串行执行。通过强制事务串行执行避免了幻读。可串行化会在读取的每一行数据上都加锁，所以导致大量的超时和锁争用的问题，很少用。悲观锁。</p>
</li>
</ul>
<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>死锁指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。多个事务同时锁定同一个资源时，也会产生死锁。</p>
<p>处理办法：完备的RDMS包含了死锁检测与死锁超时机制。innoDB存储引擎，越能检测到死锁的循环依赖，立即返回一个错误。innoDB目前采用持有最少行级排他锁的事务进行回滚。</p>
<h3 id="事务日志"><a href="#事务日志" class="headerlink" title="事务日志"></a>事务日志</h3><p>事务日志可以帮助提高事务的效率。可以将修改行为的记录持久化到硬盘的事务日志中，不需要每次都将修改的数据本身持久化到硬盘。事务日志采用追加的方式。</p>
<h3 id="mysql中的事务"><a href="#mysql中的事务" class="headerlink" title="mysql中的事务"></a>mysql中的事务</h3><p>mysql提供了两种事务型的存储引擎，innoDB 和NDB cluster。另外还有一些第三方的存储引擎。</p>
<ul>
<li>自动提交</li>
</ul>
<p>mysql默认的采用自动提交的模式，如果不显式的开始一个事务，每个查询都会被当做一个事务提交操作。autocommit = 0表示禁用，需要手动提交。对于使用mylsam的，不影响使用。</p>
<p>可以通过命令行设置事务的隔离级别：set session transaction isolation level read committed;</p>
<h4 id="在事务中混合使用存储引擎"><a href="#在事务中混合使用存储引擎" class="headerlink" title="在事务中混合使用存储引擎"></a>在事务中混合使用存储引擎</h4><p>mysql服务期层不管理事务，事务是由下层的存储引擎实现的。所以在同一个事务中，使用多种存储引擎是不可靠的。</p>
<p>如果在事务中混了使用了innoDB以及mylsam表，正常提交的情况下不会有问题，但是事务回滚，则非事务型的表的变更就无法撤销，这样导致数据库处于不一致的状态。所以选择合适的存储引擎非常重要。</p>
<p>非事务型的表上的变更不会被报错，只会有提示“某些非事务型的表上的变更不会被回滚”。</p>
<h4 id="隐式和显式锁定"><a href="#隐式和显式锁定" class="headerlink" title="隐式和显式锁定"></a>隐式和显式锁定</h4><p>innoDB是两阶段锁定协议，在事务执行的过程中，随时都可以执行锁定，锁只有在执行commit或者rollback的时候才会释放，并且所有的锁是在同一时刻被释放。这是隐式锁定。innoDB会在需要的时候自动加锁。</p>
<p>建议： 除了使用中禁用了autocommit，可以使用lock tables之外，其它人事时候都不需要显示的执行lock tables和unlock tables语句。</p>
<h2 id="多版本的并发控制-（MVCC）"><a href="#多版本的并发控制-（MVCC）" class="headerlink" title="多版本的并发控制 （MVCC）"></a>多版本的并发控制 （MVCC）</h2><p>mysql的大多数事务型存储引擎实现的都不是简单的行级锁，基于并发性能的考虑都实现了多版本的并发控制（MVCC）</p>
<p>MVCC是行级锁的一个变种，大多数情况下避免了加锁，大部分实现了非阻塞的读操作，写操作也只能锁定必要的行。</p>
<p>MVCC是通过保存数据在某个时间点的快照来实现的。不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始时间的不同，每个事务对同一张表，同一个时刻看到的数据可能是不一样的。</p>
<h3 id="MVCC的实现"><a href="#MVCC的实现" class="headerlink" title="MVCC的实现"></a>MVCC的实现</h3><p>典型的有悲观锁和乐观锁的并发控制。</p>
<p>innoDB的MVCC的实现是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存了行的过期时间，时间值其实是系统版本号。每开始一个新的事务，系统版本号会自动递增。事务开始时刻的系统版本号作为事务的版本号，要用来和查询的每行记录表的版本号进行比较。</p>
<h4 id="在-REPEATABLE-READ-隔离级别下的INNODB的MVCC操作"><a href="#在-REPEATABLE-READ-隔离级别下的INNODB的MVCC操作" class="headerlink" title="在 REPEATABLE READ 隔离级别下的INNODB的MVCC操作"></a>在 REPEATABLE READ 隔离级别下的INNODB的MVCC操作</h4><ul>
<li>SELECT</li>
</ul>
<p>innoDB会根据以下两个条件检查每行记录：</p>
<ol>
<li>innoDB只查找版本早于当前事务版本的数据行（也就是行的系统版本号小于等于事务的系统版本号），这样可以确保事务读取的行要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。</li>
<li>行的删除版本要么未定义，要么大于当前事务版本号，这样可以确保读取到的行，在事务开始之前未被删除。</li>
</ol>
<ul>
<li>INSERT</li>
</ul>
<p>INNODB为新插入的每一行保存当前系统版本号作为行版本号。</p>
<ul>
<li>DELETE</li>
</ul>
<p>INNODB为删除的每一行保存当前系统版本号作为删除标识。</p>
<ul>
<li>UPDATE</li>
</ul>
<p>INNODB 为新插入的一行新纪录，保存当前版本号为行版本号，同时保存当前系统版本号为原来的行作为行删除标识。</p>
<ol>
<li>保存这两个额外的系统版本号，使得大多数操作都可以不用加锁。可以挺高性能，但是需要每行都增加额外的操作空间，需要额外的检查工作。</li>
<li>MVCC只在REPEATABLE READ和READ COMMITTED两个隔离级别下工作。</li>
</ol>
<h2 id="MySql的存储引擎"><a href="#MySql的存储引擎" class="headerlink" title="MySql的存储引擎"></a>MySql的存储引擎</h2><p>mysql将为每个数据库（schema）保存为数据目录下的一个子目录，创建表时，mysql会在数据库子目录下创建一个和表同名的.frm文件保存表的定义</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show table status like &#39;tableName&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>展示表的本身的信息</p>
<h3 id="InnoDB存储引擎"><a href="#InnoDB存储引擎" class="headerlink" title="InnoDB存储引擎"></a>InnoDB存储引擎</h3><ul>
<li><p>innoDB的数据存储在表空间（tablespace）中，表空间是有innoDB管理的一个黑盒子，由一系列的数据文件组成。</p>
</li>
<li><p>innoDB采用MVCC来支持高并发，并且实现了四个标准的隔离级别。默认是可重复读，并且通过间隙锁(next-key locking)策略防止幻读，间隙锁使得innoD不仅锁定查询涉及的行，还会针对索引中的间隙进行锁定，防止幻影行的出现。</p>
</li>
<li><p>innoDB表是基于聚簇索引建立的，聚簇索引对主键查询有很高的性能。不过他的二级索引（非主键索引）必须包含主键列，所以主键列如果很大的话，其它所有索引都会很大。如果表上的索引较多的话，主键应尽量的小。</p>
</li>
<li><p>innoDB内部做了很多优化，包括从磁盘读取数据时采用的可预测性预读，能够自动在内存中创建hash索引以加速读操作的自适应hash索引。</p>
</li>
</ul>
<h3 id="MylSAM存储引擎"><a href="#MylSAM存储引擎" class="headerlink" title="MylSAM存储引擎"></a>MylSAM存储引擎</h3><p>在5.1版本之前，MylSAM是默认的存储引擎，MylSAM提供了大量的特性包括，全文索引，压缩，空间函数等。不支持事务以及行级锁，且在奔溃后无法安全恢复。对于小表，只读的数据可以忍受修复操作，则依然可以继续使用MylSAM。</p>
<h4 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h4><p>MylSAM会将表存储在两个文件：数据文件和索引文件 分别以.MYD和.MYI为扩展名。MylSAM可以包含静态或者动态的行。它可以根据表的定义来确定使用何种格式行。 MAX_ROWS *AVG_ROW_LENGTH决定存储的数据量的大小。</p>
<h4 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h4><ul>
<li><p>加锁和并发：只支持对整张表加锁，而不是针对行。读取操作时对表加共享锁，写入时加排他锁，但是在表有读取查询的同时，可以往表中插入数据（并发插入）。</p>
</li>
<li><p>索引特性：即使是blob、text等长字段，也可以基于前500个字符创建索引。</p>
</li>
<li><p>延迟更新索引：更新的索引不会直接flush，更新的缓存会放到缓冲区中，只有在需要flush或者关闭表时候才会放到硬盘。</p>
</li>
</ul>
<h4 id="MylSAM-压缩表"><a href="#MylSAM-压缩表" class="headerlink" title="MylSAM 压缩表"></a>MylSAM 压缩表</h4><p>如果表在创建并导入数据后，不会再进行修改操作，这样的表适合使用MylSAM存储引擎。MylSAM可以打包pack，压缩表不能直接进行修改，需要解压后修改。压缩表可以减少磁盘占用空间。</p>
<p>MylSAM引擎设计简单，数据以紧密格式存储，所以在某些场景下的性能很好。</p>
<h3 id="选择合适的存储引擎"><a href="#选择合适的存储引擎" class="headerlink" title="选择合适的存储引擎"></a>选择合适的存储引擎</h3><ul>
<li><p>MySql5.5将innoDB作为默认的存储引擎了；</p>
</li>
<li><p>除非需要用到某些innoDB不具备的特性，并且其它办法无法替代，否则都应该优先选择innoDB引擎；</p>
</li>
<li><p>除非万不得已，不建议混合使用多种存储引擎；</p>
</li>
</ul>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql架构</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能mysql-mysql高级特性</title>
    <url>/2018-12-14/%E9%AB%98%E6%80%A7%E8%83%BDmysql-mysql%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</url>
    <content><![CDATA[<h1 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h1><p>分区表的主要目的是将数据按照一个较粗的粒度分在不同的表中。这样做可以将相关的数据放在一起，另外如果想一次批量删除整个分区的数据也变得很方便。</p>
<ul>
<li>分区的好处</li>
</ul>
<p>1.表非常大以至于无法全部都放在内存中，或者表的最后部分有热点数据，其他均是历史数据<br>2.分区表的数据更容易维护，例如想批量删除大量数据可以使用清除整个分区的方式；<br>3.分区表的数据可以分布在不同的物理设备上，高效地利用多个硬件设备；<br>4.可以使用分区表来避免某些特殊的瓶颈；<br>5.备份和恢复独立的分区，非常大的数据集的场景下效果非常好；</p>
<ul>
<li>分区的限制</li>
</ul>
<p>1.一个表最多有1024个分区；<br>2.如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来；<br>3.分区表中无法使用外键约束；</p>
<h2 id="分区表的原理"><a href="#分区表的原理" class="headerlink" title="分区表的原理"></a>分区表的原理</h2><p>分区表由多个相关的底层表实现，这些底层表也是由句柄对象表示，所以我们也是可以直接访问各个分区，</p>
<p>存储引擎管理分区的各个底层表和管理普通表一样，分区表的索引只是在各个底层表上各自加上一个完全相同的索引。</p>
<h3 id="分区表上的操作按照喜爱按的操作逻辑进行"><a href="#分区表上的操作按照喜爱按的操作逻辑进行" class="headerlink" title="分区表上的操作按照喜爱按的操作逻辑进行"></a>分区表上的操作按照喜爱按的操作逻辑进行</h3><ul>
<li>select update delete insert</li>
</ul>
<p>操作一个分区表的时候，分区层先打开并锁住所有的底层表，然后确定哪个分区处理这条数据，再执行操作。</p>
<h3 id="创建分区表"><a href="#创建分区表" class="headerlink" title="创建分区表"></a>创建分区表</h3><ul>
<li>范围分区</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE &#96;test1&#96; (</span><br><span class="line">  &#96;id&#96; char(32) COLLATE utf8mb4_unicode_ci NOT NULL COMMENT &#39;自增主键(guid)&#39;,</span><br><span class="line">  &#96;create_time&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;partition_key&#96; int(8) NOT NULL COMMENT &#39;分区键(格式:yyyyMMdd)&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;,&#96;partition_key&#96;),</span><br><span class="line">  UNIQUE KEY &#96;id_UNIQUE&#96; (&#96;id&#96;,&#96;partition_key&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8mb4 COLLATE&#x3D;utf8mb4_unicode_ci</span><br><span class="line">PARTITION BY RANGE (partition_key)</span><br><span class="line">(PARTITION p0 VALUES LESS THAN (20180619) ENGINE &#x3D; InnoDB,</span><br><span class="line"> PARTITION p20180619 VALUES LESS THAN (20180620) ENGINE &#x3D; InnoDB,</span><br><span class="line"> PARTITION p20180621 VALUES LESS THAN (20180622) ENGINE &#x3D; InnoDB,</span><br><span class="line"> PARTITION p20180622 VALUES LESS THAN (20180623) ENGINE &#x3D; InnoDB,</span><br><span class="line"> PARTITION p20180623 VALUES LESS THAN (20180624) ENGINE &#x3D; InnoDB);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>列表分区</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE employees (</span><br><span class="line">    id INT NOT NULL,</span><br><span class="line">    fname VARCHAR(30),</span><br><span class="line">    lname VARCHAR(30),</span><br><span class="line">    hired DATE NOT NULL DEFAULT &#39;1970-01-01&#39;,</span><br><span class="line">    separated DATE NOT NULL DEFAULT &#39;9999-12-31&#39;,</span><br><span class="line">    job_code INT,</span><br><span class="line">    store_id INT</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">PARTITION BY LIST(store_id)</span><br><span class="line">    PARTITION pNorth VALUES IN (3,5,6,9,17),</span><br><span class="line">    PARTITION pEast VALUES IN (1,2,10,11,19,20),</span><br><span class="line">    PARTITION pWest VALUES IN (4,12,13,14,18),</span><br><span class="line">    PARTITION pCentral VALUES IN (7,8,15,16)</span><br><span class="line">);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>mysql还支持键值分区、hash分区。但是并不常用。partition分区子句中可以使用各种函数，但是返回的值必须是一个整数。</p>
<h1 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h1><p>视图本身是一个虚拟表，不存放任何数据，在使用sql语句访问视图的时候，它返回的数据是从其他表中生成的。视图和表是在同一个命名空间，mysql在很多地方把这两个是同样对待，但是视图不能创建触发器，不能使用drop table命令删除视图。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE VIEW t_user_view AS SELECT * FROM t_user WHERE delete_flag &#x3D; 0;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>实现视图的最简单方法是将select语句的结果存放到临时表中，当需要访问视图的时候，直接访问这个临时表就可以了。</p>
<h2 id="视图的优点"><a href="#视图的优点" class="headerlink" title="视图的优点"></a>视图的优点</h2><p>1.提高代码的重用性，直接将查询的数据放到视图中，查询数据的时候简单查询视图就可以；<br>2.提高了安全性能。可以对不同的用户创建不同的视图；</p>
<h1 id="外键约束"><a href="#外键约束" class="headerlink" title="外键约束"></a>外键约束</h1><p>innoDB是目前mysql中唯一支持外键的内置存储引擎。使用外键是有成本的，外键通常要求每次修改数据时都要在另外一张表中多执行一次查找操作。<br>外键约束的主要目的是控制存储在外键表中的数据，但它还可以控制对主键表中数据的修改。但是实际中通常在业务上保证数据的完整性，而不是使用外键。</p>
<h1 id="存储过程和函数"><a href="#存储过程和函数" class="headerlink" title="存储过程和函数"></a>存储过程和函数</h1><p>SQL语句需要先编译然后执行，而存储过程（Stored Procedure）是一组为了完成特定功能的SQL语句集，经编译后存储在数据库中，用户通过指定存储过程的名字并给定参数（如果该存储过程带有参数）来调用执行它</p>
<p><a href="https://www.cnblogs.com/mark-chan/p/5384139.html">mysql的存储过程</a></p>
<h1 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h1><p>mysql查询缓存保存查询返回的完整结果。当查询命中该缓存，mysql会立刻返回结果，跳过了解析、优化和执行阶段。</p>
<p>查询缓存系统会跟踪查询中涉及的每个表，如果这些表发生变化，那么和这个表相关的所有缓存数据都会失效。这种机制效率低但是实现代价较低，这对于一个非常繁忙的系统来说非常重要。</p>
<h2 id="判断缓存命中"><a href="#判断缓存命中" class="headerlink" title="判断缓存命中"></a>判断缓存命中</h2><p>mysql判断缓存命中的方法很简单，缓存存放在一个引用表中，通过hash值引用。这个hash值包含如下因素：查询本身、当前要查询的数据库、客户端协议的版本等。</p>
<p>如果查询中包含一个不确定的函数，其实是不会存进缓存的，那么在查询缓存中是不可能找到缓存结果的。</p>
<ul>
<li>打开查询缓存会对读写性能带来额外的消耗</li>
</ul>
<p>1.读查询在开始之前必须检查是否命中缓存；<br>2.如果这个读查询可以被缓存，那么执行完之后，mysql如果返现查询缓存中没有这个查询，会将结果存入查询缓存，这会带来额外的系统消耗；<br>3.对写操作也会有影响，因为当对某个表写入数据的时候，mysql必须将对应表的所有缓存都置为失效，如果查询缓存非常大或者碎片非常多，这个操作就会带来很大的系统消耗。</p>
<p>综上，查询缓存会带来系统性能提升，但是如果这些额外消耗不断增加，再加上对查询缓存操作时一个加锁排他操作，消耗是不可忽视的。</p>
<h2 id="查询缓存如何使用内存"><a href="#查询缓存如何使用内存" class="headerlink" title="查询缓存如何使用内存"></a>查询缓存如何使用内存</h2><p>查询缓存是完全存储在内存中的，所以在配置和使用它之前，我们需要先了解它是如何使用内存的。除了查询结果之外，需要缓存的还有狠毒别的维护相关的数据。</p>
<p>基本的管理维护数据结构需要40KB的内存资源，除此之外，mysql用于查询的缓存的内存被分成一个个的数据块，数据块是变长。每一个数据块中，存储了自己的类型、大小和存储的数据本身，还外加一个指向前后数据块的指针。数据块的类型有：存储查询结果、存储查询和数据表的映射、存储查询文本等。</p>
<p>当服务器启动的时候，先初始化查询缓存需要的内存。这些内存池初始是一个完整的空闲块，这个空闲块的大小就是你配置的查询缓存大小再减去维护元数据的数据结构所消耗的空间。</p>
<h2 id="配置和维护查询缓存"><a href="#配置和维护查询缓存" class="headerlink" title="配置和维护查询缓存"></a>配置和维护查询缓存</h2><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><ul>
<li><p>query_cache_type 是否打开查询缓存。OFF、ON或demand。demand表示只有在查询语句中明确写明sql_cache的语句才可以放入查询缓存。</p>
</li>
<li><p>query_cache_size 查询缓存使用的总内存空间，单位是字节。这个值必须是1024的整数倍。</p>
</li>
<li><p>query_cache_min_res_unit 在查询缓存中分配内存时的最小单位。</p>
</li>
<li><p>query_cache_limit mysql可以缓存的最大查询结果。</p>
</li>
<li><p>query_cache_wlock_invalidate 如果某个数据表被其它的连接锁住，是否仍然从查询缓存中返回结果。默认是OFF</p>
</li>
</ul>
<h3 id="减少碎片"><a href="#减少碎片" class="headerlink" title="减少碎片"></a>减少碎片</h3><p>query_cache_min_res_unit合适的值可以帮助减少内存碎片导致的内存空间浪费。</p>
<p>可以使用flush query cache 完成碎片整理。这个命令会将所有的查询缓存重新排序，并将所有的空闲空间都聚集到查询缓存的一块区域上，这个命令并不会将查询缓存清空。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><img src="/images/mysql/%E5%88%86%E5%8C%BA%E8%A1%A8%E5%92%8C%E8%A7%86%E5%9B%BE.png" alt="分区表和视图"></p>
<p><img src="/images/mysql/%E5%A4%96%E9%94%AE%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E4%BA%8B%E5%8A%A1.png" alt="外键存储过程事务"></p>
<p><img src="/images/mysql/%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98.png" alt="查询缓存"></p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql高级特性</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能mysql-schema与数据类型优化</title>
    <url>/2018-11-19/%E9%AB%98%E6%80%A7%E8%83%BDmysql-schema%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="选择优化的数据类型"><a href="#选择优化的数据类型" class="headerlink" title="选择优化的数据类型"></a>选择优化的数据类型</h1><ul>
<li>更小的通常更好</li>
</ul>
<p>一般情况下，使用可以正确存储数据的最小数据类型，更小的类型通常更快，需要更小的磁盘、内存以及cpu缓存。但是需要确保没有低估需要存储的值的范围。</p>
<ul>
<li>简单就好</li>
</ul>
<p>简单的数据类型操作通常需要更少的cpu周期。整型比字符串操作代价更低，字符集和校对规则使字符比较耿复杂；应该使用mysql内建类型而不是使用字符串来存储日期和时间。</p>
<ul>
<li>尽量避免null</li>
</ul>
<p>null值是列的默认属性，最好指定not null,除非真的需要null值。</p>
<p>可为null的列，对mysql来说更难优化，null使得索引、索引统计和值比较都更为复杂，可为null的列会使用更多的存储空间。</p>
<h2 id="整数类型"><a href="#整数类型" class="headerlink" title="整数类型"></a>整数类型</h2><p>有两种存储类型，整数和实数。整数类型 tinyint（8）、smallint（16）、mediumint（24）、int（32）、bigint（64）。位存储空间，范围从-2的（n-1）次幂到2的（n-1）次幂。其中n是存储空间的位数。</p>
<p>整数类型有可选的unsigned属性，表示允许负值，大致可以使得存储范围上限提高一倍。例如tinyint unsigned可以是0-255，而tinyint的存储范围是-128至127</p>
<p>有符号和无符号类型使用相同的存储空间，并具有相同的性能，根据实际情况选择。</p>
<p>mysql可以为整数类型指定宽度，例如int(11)对大多数应用是没有意义的：它不会限制值的合法范围，只是规定mysql的一些交互工具（如mysql命令行客户端）来显示字符的格式，对于存储来说，int(1)和int(20)是一样的。</p>
<h2 id="实数类型"><a href="#实数类型" class="headerlink" title="实数类型"></a>实数类型</h2><ul>
<li><p>实数是带有小数部分的数字。DECIMAL可以存储比bigInt还大的整数。DECIMAL类型用于存储精确的小数，DECIMAL支持精确的计算。cpu不支持对DECIMAL的直接结算，mysql服务器自身实现了DECIMAL的高精度计算。</p>
</li>
<li><p>浮点和DECIMAL类型都可以指定精度。DECIMAL在5.0以上版本允许存储65个数字，DECIMAL实际上不能再计算中使用这么大的数字，因为DECIMAL只是一种存储格式：因为在计算中DECIMAL会转换为DOUBLE类型。</p>
</li>
<li><p>因为需要额外的空间和计算开销，所以应该尽量只在对小数进行精确计算时才使用DECIMAL-例如财务数据，尽量在数据量比较大的情况下使用bigInt代替DECIMAL，将需要存储的货币单位乘以相应的倍数即可。</p>
</li>
</ul>
<h2 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h2><p>每个字符串可以定义自己的字符集和排序规则或者说校对规则。</p>
<h3 id="VARCHAR和CHAR类型"><a href="#VARCHAR和CHAR类型" class="headerlink" title="VARCHAR和CHAR类型"></a>VARCHAR和CHAR类型</h3><p>存储VARCHAR和CHAR值的方式在内存中和磁盘上可能不一样，所以mysql服务器从存储引擎读出的值可能需要转换为另一种存储格式。</p>
<h4 id="VARCHAR"><a href="#VARCHAR" class="headerlink" title="VARCHAR"></a>VARCHAR</h4><ul>
<li><p>VARCHAR存储可变长字符串,最常见。比定长的类型节省空间，只使用必要的空间，row_format=fixed的时候，每一行使用必要的空间。</p>
</li>
<li><p>varchar使用1-2字节记录字符串长度,长度&gt;255用2，&lt;255用1.可以提升性能。但是由于变长，如果update操作使得某个字段空间增长，innodb使用分裂页来使得行放进页内。</p>
</li>
</ul>
<p><strong>适合使用varchar</strong></p>
<p>字符串的最大长度比平均长度的大很多的、列的更新少的（碎片不是问题）、使用UTF-8这样的复杂的字符集，每个字符使用不同的字节数压缩；</p>
<h4 id="CHAR"><a href="#CHAR" class="headerlink" title="CHAR"></a>CHAR</h4><p>定长，总是根据定义的字符串长度分配足够的空间。存储char值时，删除末尾的空格，会根据长度进行填充以方便比较。</p>
<p>适合存储很短的字符串或者值长度接近的。经常变更的数据，char也比varchar更好，定长的char不容易产生过碎片。</p>
<p><code>注意</code>：</p>
<p>某个字符串尾部的空格，varchar类型的会显示，char类型的会被去掉（在末尾填充空格只是存储，显示的时候不会显示）。</p>
<h4 id="binary和varbinary"><a href="#binary和varbinary" class="headerlink" title="binary和varbinary"></a>binary和varbinary</h4><p>存储二进制字符串。存储的是字节码不是字符串；填充binary采用的是\0（零字节）而不是空格，检索时不会去掉填充值；</p>
<p><strong>优势</strong></p>
<p>存储二进制数据，希望mysql使用字节码而不是字符串比较。二进制不仅仅体现在大小写敏感上，比较binary字符串时，每次按照一个字节，根据字节的数值比较，比字符快很多。</p>
<p><code>注意</code>：</p>
<p>使用varchar（5）和varchar（200）存储‘hello’的存储开销是一样的，但是更短的列有很大的优势。更长的列会消耗更多的内存，尤其在使用内存临时表进行排序等操作时更糟糕。</p>
<h3 id="blob和text类型"><a href="#blob和text类型" class="headerlink" title="blob和text类型"></a>blob和text类型</h3><p>都是为大数据存储设计的字符串类型，分别采用二进制和字符方式存储。text是smalltext的同义词，blob是smallblob的同义词</p>
<ul>
<li><p>字符类型：tinytext、smalltext、text、mediumtext、longtext.</p>
</li>
<li><p>二进制类型：tinyblob、smallblob、blob、mediumblob、longblob。</p>
</li>
</ul>
<p>会把每个blob和text当做独立对象处理。存储引擎存储时会做特殊处理，当text、blob太大时，会在行内存储1-4个字节的指针，在专门的外部存储区域存储实际的值。</p>
<p><code>区别</code>：</p>
<p>blob和text区别是使用二进制存储，没有排序规则或字符集，而text类型有字符集和排序规则；</p>
<p>mysql对blob和text的排序与其他类型不同，它支队没格列的最前的max_sort_length字节而不是整个字符串做排序，而不是整个字符串。如果字需要一部分字符，则可以减少max_sort_length的配置。</p>
<p>mysql不能使用它们的全部长度进行索引。</p>
<p><code>注意</code></p>
<p>尽量不要使用blob和text类型存储，无法避免的话在所有用到blob字段的地方使用subString(column,length)将列值转换为字符串。</p>
<h2 id="日期和时间类型"><a href="#日期和时间类型" class="headerlink" title="日期和时间类型"></a>日期和时间类型</h2><p>mysql最小的时间粒度为秒。但是可以使用微秒级的粒度进行计算。mysql提供datetime和timestamp两种日期类型格式。除了特殊情况，通常尽量使用TIMESTAMP，因为它比DATETIME空间效率高。有人会使用整数存储时间截的格式不方便处理。</p>
<p>但是如果需要存储微秒级别的数据则尅使用bigint类型存储微秒级别的时间戳。</p>
<h3 id="DATETIME"><a href="#DATETIME" class="headerlink" title="DATETIME"></a>DATETIME</h3><p>存储范围 1001-9999，精度秒，它吧日期和时间封装到格式为YYYYMMDDHHMMSS的整数中，与时区无关，使用8个字节的存储空间，默认以一种尅排序的无歧义的格式显示，如`2008-01-16 22:37:08``</p>
<h4 id="TIMESTAMP"><a href="#TIMESTAMP" class="headerlink" title="TIMESTAMP"></a>TIMESTAMP</h4><p>可以存储从1970年以来的秒数，使用4个字节存储空间，范围比DATETIME小得多，只能表示1970至2038年，mysql提供了from_unixtime()函数把时间戳转换为日，并提供unix_timestamp（）把日期转换为unix时间戳。</p>
<p>TIMESTAMP依赖时区，服务器、操作系统、客户端连接都有时区设置。它在不同的时区显示的时间是不同的。</p>
<p>TIMESTAMP类型默认为not null，默认为当前的时间。</p>
<h2 id="位数据类型"><a href="#位数据类型" class="headerlink" title="位数据类型"></a>位数据类型</h2><p>mysql有几种存储类型使用紧凑的位存储类型数据，所有这些位类型，不管底层存储的格式和处理方式如何，从技术上来说都还是字符串类型。</p>
<h3 id="BIT"><a href="#BIT" class="headerlink" title="BIT"></a>BIT</h3><p>在mysql5.0之前bit是tinyint的同义词，之后的版本bit是完全不同的数据类型。</p>
<p>bit列在一列中存储一个或多个true/false值， bit(1)定义一个包含单个位的字段，bit位最大的长度为64个位。</p>
<p>bit的行为因存储引擎而异，mylSam会打包所有的bit位，所以17个单独的bit列只需要17个存储位，这样mylSam只能使用三个字节就能存储17个bit列。其它存储引擎如Memory何innoDB，为每个bit位使用一个足够存储的最小整数来存储，所以不能节省存储空间。</p>
<p>mysql把bit位要当做字符串存储，而不是数字类型，咋整数数字上下文的场景检索时，结果是将位字符转化为数字。这个不太好理解，所以大部分应用，最好避免使用这种类型。</p>
<h3 id="SET"><a href="#SET" class="headerlink" title="SET"></a>SET</h3><p>打包set数据集和类型，他在mysql内部是使用一系列的打包的位的集合来表示的。</p>
<h2 id="选择标识符"><a href="#选择标识符" class="headerlink" title="选择标识符"></a>选择标识符</h2><p>标识符类型就是关联表所使用的类型，要考虑这种类型如何计算和比较。例如存储整数使用enum和set类型，在比较时转化为字符串。</p>
<p>enum和set使用存储固定信息。</p>
<p>尽可能避免使用字符串类型作为表示列，因为他们很消耗空间，通常比数字类型慢。尤其在使用MylSAM表里使用字符串作为标识列时要特别小心，MylSAM默认对字符串使用压缩索引，这样会导致查询慢很多。</p>
<h2 id="特殊类型的数据"><a href="#特殊类型的数据" class="headerlink" title="特殊类型的数据"></a>特殊类型的数据</h2><p>某些类型的数据并不能直接与内置类型一直。低于秒级别的时间戳就是一个列子。</p>
<h1 id="Mysql-schema设计中的缺陷"><a href="#Mysql-schema设计中的缺陷" class="headerlink" title="Mysql schema设计中的缺陷"></a>Mysql schema设计中的缺陷</h1><p>虽然有一些普遍的好或坏的设计原，但有一些问题还是由MySQL的实现机制导致的。</p>
<ul>
<li>太多的列</li>
</ul>
<p>mysql的存储引擎API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成个格列。从缓冲中将编码过的列转换成数据结构的操作代价是非常高的。</p>
<ul>
<li>太多的关联</li>
</ul>
<p>表过多的关联回合降低性能，单个查询最好在12个表以内做关联。</p>
<ul>
<li>枚举</li>
</ul>
<p>如果有枚举的情况存在，尽量使用一张字典表或者查找表来找具体的值。</p>
<ul>
<li>NUll</li>
</ul>
<p>尽可能的避免使用null，如果一定要使用空值，可以使用0或者某个特殊的值代替。</p>
<p>但是不要走极端，因为-1带表未知的整数，可能导致代码复杂很多。比如date类型的 not null default ‘0000-00-00 00:00:00’</p>
<p> -*/</p>
<h1 id="范式和反范式"><a href="#范式和反范式" class="headerlink" title="范式和反范式"></a>范式和反范式</h1><p><a href="https://www.cnblogs.com/linjiqin/archive/2012/04/01/2428695.html">数据库的三大范式</a></p>
<h2 id="范式的优点和缺点"><a href="#范式的优点和缺点" class="headerlink" title="范式的优点和缺点"></a>范式的优点和缺点</h2><ul>
<li>范式的更新操作通常比反范式的块；</li>
<li>更好的范式化，更少或者没有重复数据，所以修改更少的数据；</li>
<li>范式化的表通常更小，更好的存储在内存中；</li>
<li>很少有多余的数据以为这检索表数据时更少需要distinct或者group by语句。</li>
</ul>
<p>范式化设计的schema缺点是需要关联，稍微负载一些的查询语句符合范式化的schema可能需要一次关联。</p>
<h2 id="反范式的有点和缺点"><a href="#反范式的有点和缺点" class="headerlink" title="反范式的有点和缺点"></a>反范式的有点和缺点</h2><p>反范式的schema因为所有数据都在一张表中，可以很好的避免关联。</p>
<p>关联是的需要在一个索引中又排序又过滤。如果采用反范式化组织数据，将两张表的字段合并一下，只需要增加一个索引，这样不通过关联写出这个查询，这将会非常高效。</p>
<h2 id="混合范式化和反范式化"><a href="#混合范式化和反范式化" class="headerlink" title="混合范式化和反范式化"></a>混合范式化和反范式化</h2><p>在实际的使用中不用完全范式话，这避免了完全反范式化的插入和删除的问题。</p>
<h1 id="缓存表和汇总表"><a href="#缓存表和汇总表" class="headerlink" title="缓存表和汇总表"></a>缓存表和汇总表</h1><p>有时提升性能最好的方法是在同一张表保存衍生的冗余数据，然后有时也需要创建一张完全独立的汇总表或缓存表。</p>
<p><strong>缓存表</strong>表示存储那些可以简单的从schema其他表获取（但是每次获取的速度比较慢）数据的表。</p>
<p><strong>汇总表</strong>保存的是使用group by语句聚合数据的表，或者被称为累计表。</p>
<h1 id="加快alter-table的操作速度"><a href="#加快alter-table的操作速度" class="headerlink" title="加快alter table的操作速度"></a>加快alter table的操作速度</h1><p>mysql的alter table操作的性能对大表来说是个大问题。mysql执行大部分修改表结构的操作的方法是用新的结构创建一个空表，然后从旧表中查询出所有数据插入新表，然后删除旧表。</p>
<p>这样操作会话费很长时间，如果内存不足而且表又很大，还有很多索引的情况下尤其如此。</p>
<h2 id="大部分alter-table操作导致mysql服务中断。"><a href="#大部分alter-table操作导致mysql服务中断。" class="headerlink" title="大部分alter table操作导致mysql服务中断。"></a>大部分alter table操作导致mysql服务中断。</h2><p>提供2中使用的技巧：</p>
<ul>
<li>现在一台不提供服务的机器上执行alter table操作，然后和提供服务的主库进行切换；</li>
<li>‘影子拷贝’，用要求的表结构创建一张和原表无关的新表，然后通过重命名和删除表交换两张表；</li>
</ul>
<p>假如需要修改某列的默认值，可以直接修改.frm文件中。但是mysql不支持。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table sakila.film alter column rental_duration set DEFAULT 5;</span><br></pre></td></tr></table></figure>

<p>这个语句会直接修改.frm文件不涉及表结构，所以操作是非常快的。</p>
<h2 id="快速创建MylSAM索引"><a href="#快速创建MylSAM索引" class="headerlink" title="快速创建MylSAM索引"></a>快速创建MylSAM索引</h2><p>一个技巧是先禁用索引、载入数据然后重启索引：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table test.load_data disable keys;</span><br><span class="line"></span><br><span class="line">-- load the data</span><br><span class="line"></span><br><span class="line">alter table test.load_data enable keys;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这个对唯一索引无效， disable keys 只对非唯一索引有效。MylSAM会在内存中构造唯一索引，并且为载入的每一行检查唯一性，一旦索引的大小超过了有效内存的大小，载入操作就非常慢。</p>
<h1 id="schema设计原则总结"><a href="#schema设计原则总结" class="headerlink" title="schema设计原则总结"></a>schema设计原则总结</h1><ul>
<li>尽快避免过度设计，例如会导致极其复杂查询的schema设计，或者很多列的表设计；</li>
<li>使用小而简单的合适数据类型，除非真是数据模型中确切需要，否则尽量避免使用NUll值；</li>
<li>尽量使用相同的数据类型存储相似或者相关的值，尤其是要在关联查询中使用到的列；</li>
<li>注意使用可变长字符串，其在临时表和排序时会导致悲观的按照最大长度分配内存；</li>
<li>尽量使用整型定义标识列；</li>
<li>尽量避免使用mysql遗弃的特性（指定浮点数的精度，或者整数显示宽度）小新使用enum和set，最好避免使用bit；</li>
</ul>
]]></content>
      <categories>
        <category>高性能mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能mysql-优化服务器配置以及高可用</title>
    <url>/2018-12-16/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E4%BC%98%E5%8C%96%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="mysql的配置文件"><a href="#mysql的配置文件" class="headerlink" title="mysql的配置文件"></a>mysql的配置文件</h1><p>查找mysql的配置文件的详细参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysqld --help --verbose | less</span><br></pre></td></tr></table></figure>
<p>查找myqsql配置文件放置的默认位置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql --help|grep &#39;my.cnf&#39;</span><br></pre></td></tr></table></figure>


<p>大部分的配置的默认值是最佳配置了，所以最好不要改动太多配置。</p>
<p><img src="/images/mysql/mysql%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.png" alt="基础配置文件"></p>
<p>需要设置数据的位置，pid的配置。使用mysql用户来运行mysqld进程，需要确保这个账户存在，并且拥有操作数据目录的权限，端口设置为默认的3306。innoDB作为默认的存储引擎。</p>
<p>为innoDB配置合适的缓冲池（buffer pool）和日志文件（log file）是必须的。其它的innoDB配置都是可选的。缓冲池大小设置为服务器内存的约75%-80%。</p>
<h2 id="检查服务器的状态"><a href="#检查服务器的状态" class="headerlink" title="检查服务器的状态"></a>检查服务器的状态</h2><p>查看服务器的配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show global status </span><br></pre></td></tr></table></figure>

<h1 id="配置内存使用"><a href="#配置内存使用" class="headerlink" title="配置内存使用"></a>配置内存使用</h1><p>mysql的内存消耗分为可以控制和补课控制的内存。可以按照如下步骤来配置内存：</p>
<p>1.确定可以使用内存的上限；<br>2.确定每个连接mysql需要使用多少内存，例如排序缓冲和临时表；<br>3.确定操作系统需要使用多少内存（包括其他应用）；<br>4.把剩下的内存全部给mysql的缓存，例如innoDB缓冲池；</p>
<h2 id="mysql可以使用多少内存"><a href="#mysql可以使用多少内存" class="headerlink" title="mysql可以使用多少内存"></a>mysql可以使用多少内存</h2><p>mysql都有允许使用的内存上限。mysql是单进程多线程的运行模式。整体可以使用的内存量也许会受操作系统的额限制。</p>
<h2 id="每个连接需要的内存"><a href="#每个连接需要的内存" class="headerlink" title="每个连接需要的内存"></a>每个连接需要的内存</h2><p>myisam_sort_buffer_size设置为256M，连接最多为100个，最坏的情况是使用25G内存，但是这是几乎不可能发生的，使用临时表或复杂的存储过程的查询是导致高内存消耗最可能的原因。</p>
<h2 id="为操作系统保留内存"><a href="#为操作系统保留内存" class="headerlink" title="为操作系统保留内存"></a>为操作系统保留内存</h2><p>给操作系统留2GB或者总内存的5%作为基准，以较大者为准。</p>
<h2 id="为缓存分配内存"><a href="#为缓存分配内存" class="headerlink" title="为缓存分配内存"></a>为缓存分配内存</h2><p>innoDB缓冲池、innoDB日志文件和MyLSAM数据的操作系统缓存、MyLSAM键缓存、查询缓存等；</p>
<h2 id="innoDB缓冲池"><a href="#innoDB缓冲池" class="headerlink" title="innoDB缓冲池"></a>innoDB缓冲池</h2><p>innoDB缓冲池并不仅仅缓存索引，还会缓存行的数据、自适应hash索引、插入缓冲、锁以及其它内部数据结构；innoDB还是用缓冲池来帮助延迟写入，这样就能合并多个写入操作，然后一起顺序的</p>
<p>缓冲池太大，重启服务器也需要花很长时间来预热缓冲池。</p>
<h2 id="MylSAM键缓存"><a href="#MylSAM键缓存" class="headerlink" title="MylSAM键缓存"></a>MylSAM键缓存</h2><p>MylSAM键缓存也成为键缓冲，默认只有一个键缓存，它只是缓存索引，不缓存数据。</p>
<p>索引存储占用的空间：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select sum(index_length) from informathon_schema.tables where engine &#x3D;&#39;mylsam&#39;</span><br></pre></td></tr></table></figure>
<p>key_buffer_size =1G，表示键缓冲的大小。默认的所有的MyLSAM的索引都存储在缓存中。</p>
<h2 id="线程缓存"><a href="#线程缓存" class="headerlink" title="线程缓存"></a>线程缓存</h2><p>线程缓存保存那些当前没有与连接关联但是准备为后面新的连接服务的线程。当一个新的连接创建时，如果缓存中有线程存在，mysql从缓存中删除一个线程，并且把它分配给这个新的连接。当连接关闭时，如果线程缓存还有空间，则把线程返回缓存。</p>
<p>thread_cache_size变量指定了mysql可以保持在缓存中的线程数。</p>
<h2 id="表缓存"><a href="#表缓存" class="headerlink" title="表缓存"></a>表缓存</h2><p>表缓存和线程缓存的概念是相似的，但存储的对象代表的是表。每个在缓存中的对象包含相关表.frm文件的解析结果，加上一些其他数据。</p>
<p>表缓存对于innoDB表没有太大意义。</p>
<h2 id="innoDB数据字典"><a href="#innoDB数据字典" class="headerlink" title="innoDB数据字典"></a>innoDB数据字典</h2><p>innoDB有自己的表缓存，可以成为表定义缓存或者数据字典。当innoDB打开一张表就增加一个对应的对象到数据字典，每张表可能占用4KB或者更多内存，关闭也不会清除，最新的版本添加来了一种缓存过期策略，清除长时间不适用的缓存。</p>
<p>另一个性能问题是打开表时会计算统计信息，这需要很多IO操作，所以代价很高。innoDB没有将统计信息持久化到硬盘，每次打开表都会重新计算（MyLSAM做了持久化）。</p>
<h1 id="配置mysql的IO行为"><a href="#配置mysql的IO行为" class="headerlink" title="配置mysql的IO行为"></a>配置mysql的IO行为</h1><p>有一些配置影响着mysql同步数据到磁盘以及如何做恢复操作，这些操作对性能的响应非常大，因为涉及昂贵的IO操作。</p>
<h2 id="innoDB的IO配置"><a href="#innoDB的IO配置" class="headerlink" title="innoDB的IO配置"></a>innoDB的IO配置</h2><p><img src="/images/mysql/innoDB%E7%9A%84%E7%BC%93%E5%AD%98%E5%92%8C%E6%96%87%E4%BB%B6.png" alt="innoDB的缓存和文件"></p>
<h3 id="innoDB的事务日志"><a href="#innoDB的事务日志" class="headerlink" title="innoDB的事务日志"></a>innoDB的事务日志</h3><p>innoDB使用日志来减少提交事务时的开销，因为日志中已经记录了事务，就无须在每个事务提交时 把缓冲池的脏块刷新到磁盘中。事务修改的数据和索引通常会映射到表空间的随机位置。而innoDB用日志把随机IO变成顺序IO。一旦日志安全写到磁盘，事务就持久化了，即使变更没有写到数据文件。</p>
<p>innoDB最终还是把变更写到数据文件。innoDB使用一个后台线程智能地刷新这些变更到数据文件，这个线程可以批量组合写入。整体的日志文件受innodb_log_file_size和innoDB_log_fules_in_group两个参数影响。</p>
<p>innoDB变更任何数据时，会写一条记录变更记录到内存日志缓冲区，在缓冲区满的时候、事务提交的时候，或者一秒钟，innoDB都会刷写缓冲区的内容到磁盘日志文件。如果有大事务，增减日志缓冲区（innodb_log_buffer_size）来控制日志缓冲区的大小。</p>
<p>innodb_flush_log_at_trx_commit参数的设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 把日志缓冲写到日志文件，每秒钟刷新一次，但是事务提交时不做任何事；</span><br><span class="line"></span><br><span class="line">1 日志缓冲写到日志文件，并且每次事务提交都刷新持久化存储。这个是默认的设置，该设置能保证不会丢失任何已经提交的事务，除非磁盘或者操作系统是伪刷新</span><br><span class="line"></span><br><span class="line">2 每次提交时把日志缓冲写到日志文件，但是并不刷新。但是并不刷新，innodb每秒钟做一次刷新，0与2最重要的不同是，如果mysql进程挂了，2的事务不会丢失。 </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>把日志缓冲写到日志文件和把日志刷新到持久化存储之间的不同是很重要的，在大部分操作系统中，把缓冲写到日志只是简单地把数据从innodb的内存缓冲转移到了操作系统的缓存，也是在内存里，并没有真的把数据写入到持久化存储。</li>
</ul>
<h3 id="innodb表空间"><a href="#innodb表空间" class="headerlink" title="innodb表空间"></a>innodb表空间</h3><p>innodb把数据保存表空间内，本质上是一个由多个磁盘文件组成的虚拟文件系统。innodb用表空间实现很多功能，并不只是存储表和索引。它还保存了回滚日志、插入缓冲、双写缓冲。</p>
<p>通过使用innodb_data_file_path配置项可以定制表空间文件，这些文件都放在innodb_data_home_dir指定的目录下。</p>
<p><img src="/images/mysql/%E8%A1%A8%E7%A9%BA%E9%97%B4%E7%9A%84%E9%85%8D%E7%BD%AE.png" alt="表空间的配置"></p>
<p>回收空间的唯一方式：导出一份数据，关闭mysql，删除所有文件，修改配置，重启，让innodb创建新的数据文件，然后倒入数据。</p>
<h1 id="配置mysql并发"><a href="#配置mysql并发" class="headerlink" title="配置mysql并发"></a>配置mysql并发</h1><p>使用innodb_thread_concurrency变量来控制并发量，它会限制一次性可以有多少线程进入内核，0表示不限制。一般设置 并发值 = cpu数量<em>磁盘数量</em>2</p>
<p>服务器不能在内存临时表中存储blob值，如果一个查询涉及blob值，又需要使用临时表，不管它多小，它都会在磁盘上创建临时表，这样效率很低。临时表可能是查询中最大的开销。可以使用substring（）函数将值转化为varchar</p>
<p>max_connections 默认是100，一般可以设置为300或者500也是可以的。</p>
<p>expire_logs_days 如果启用了二进制日志，应该打开这个选项，可以让服务器在指定的天数之后清理旧的二进制日志。建议设置为7-14天。</p>
<p>max_allowed_packet 控制多大的包可以被接收，默认值可能太大了，如果设置的太小复制可能出问题。通常设置为16MB或者更大。</p>
<p>read_only 这个选项禁止没有特权的用户在备库做变更，只接收从主库传输过来的变更。强烈建议把备库设置为只读模式。</p>
<p>skip_slave_start 阻止mysql视图自动启动复制，因为在不安全的崩溃或其他问题后，启动复制是不安全的，禁用自动启动。</p>
<h1 id="innodb的最重要的两个选项"><a href="#innodb的最重要的两个选项" class="headerlink" title="innodb的最重要的两个选项"></a>innodb的最重要的两个选项</h1><p>innodb_buffer_pool_size 和innodb_log_file_size</p>
<h1 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h1><p>高可用是相对的，100%的高可用是不可能的。高可用性越高，所付出的成本越高。</p>
<h2 id="导致宕机的主要原因"><a href="#导致宕机的主要原因" class="headerlink" title="导致宕机的主要原因"></a>导致宕机的主要原因</h2><p>1.运行环境，包括操作系统、硬盘以及网络。在运行环境的问题中，最普遍的是磁盘空间耗尽；<br>2.性能。最主要的是很糟糕的sql。糟糕的schema以及索引设计。<br>3.数据丢失及损坏；主备数据不一致导致。数据丢失主要是drop table的误操作导致；</p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>优化服务器配置</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能mysql-复制</title>
    <url>/2019-01-27/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E5%A4%8D%E5%88%B6/</url>
    <content><![CDATA[<p>复制功能不仅有利于构建高性能的应用，也是高可用性、可扩展性、灾难恢复、备份以及数据仓库等工作的基础。</p>
<h1 id="复制概述"><a href="#复制概述" class="headerlink" title="复制概述"></a>复制概述</h1><p>复制解决的事让一台服务器的数据与其他服务器保持同步。一台主库的数据可以同步到多台备库上。</p>
<p>mysql支持两种复制方式：基于行的复制和基于语句的复制。两种方式都是通过在主库上记录二进制日志，在备库上重放日志的方式来实现异步的数据复制。所以会存在延迟。</p>
<p>复制通常只会启用二进制日志带来开销，其它的不会。</p>
<h2 id="复制解决的问题"><a href="#复制解决的问题" class="headerlink" title="复制解决的问题"></a>复制解决的问题</h2><ul>
<li>数据分布，可以分布在不同的数据中心；</li>
<li>负载均衡，通过mysql复制可以将读操作分不到不同的服务器上，实现对读密集型的应用的额优化，并且实现很方便。</li>
<li>备份，复制是一种很有意义的技术补充，但复制既不是备份也不能够取代备份；</li>
<li>高可用性和故障切换,复制能够帮助应用避免mysql单点失败，一个包含复制的设计良好的故障切换系统能够显著的缩短宕机的时间。</li>
</ul>
<h2 id="复制如何工作"><a href="#复制如何工作" class="headerlink" title="复制如何工作"></a>复制如何工作</h2><p>复制的步骤：</p>
<p>1.在主库上把数据更改记录到二进制日志中，（binary log），二进制日志事件；<br>2.备库将主库上的日志复制到自己的中继日志（relayLog）中；<br>3.备库读取中继日志中的事件，将其重放到备库数据之上；</p>
<p><img src="/images/mysql/mysql%E5%A4%8D%E5%88%B6%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C.png" alt="mysql复制如何工作"></p>
<p><img src="/images/mysql/%E5%A4%8D%E5%88%B6%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="复制的过程"></p>
<h1 id="配置复制"><a href="#配置复制" class="headerlink" title="配置复制"></a>配置复制</h1><p>步骤：</p>
<p>1.在每台服务器上创建复制账号；<br>2.配置主库和备库；<br>3.通知备库连接到主库并从主库复制数据；</p>
<h2 id="创建复制账号"><a href="#创建复制账号" class="headerlink" title="创建复制账号"></a>创建复制账号</h2><p>mysql会赋予一些特殊的权限给复制线程。在备库运行的IO线程会建立一个到主库的TCP/IP连接，这就意味着在主库创建一个用户，并赋予其合适的权限。备库IO线程以该用户名连接到主库并读取二进制读取其日志。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; grant replication slave,replication client on *.* to repl@&#39;127.0.0.%&#39; identified by &#39;p4ssword&#39;;</span><br><span class="line"></span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br></pre></td></tr></table></figure>

<p><strong>注意</strong> </p>
<p>我们在主库和备库都创建该账号，我们把这个账户限制在本地网络，这是一个特权账号。</p>
<p>复制账户事实上只需要在主库上的replication slave权限，并不一定需要每一端服务器都有replication client权限，为什么需要给备库赋予权限呢？</p>
<p>1.用来监控和管理复制的账号需要replication client权限，并且针对这两种目的使用同一个账号更加容易；<br>2.如果在主库上建立了账号，然后从主库将数据克隆到备库上时，备库也就设置好了，编程主库所需要的配置，这样后续可以方便的交换主库的角色；</p>
<h2 id="配置主库和备库"><a href="#配置主库和备库" class="headerlink" title="配置主库和备库"></a>配置主库和备库</h2><ul>
<li>加入server1是主库，需要打开二进制日志并指定一个服务器id 在主库的my.cnf文件中增加或修改如下内容：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log_bin &#x3D; mysql-bin;</span><br><span class="line">server_id &#x3D; 10</span><br></pre></td></tr></table></figure>
<p>开启了binLog需要重启mysql服务。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; show master status;</span><br><span class="line">+------------------+----------+--------------+------------------+-------------------+</span><br><span class="line">| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |</span><br><span class="line">+------------------+----------+--------------+------------------+-------------------+</span><br><span class="line">| mysql-bin.000001 |      154 |              |                  |                   |</span><br><span class="line">+------------------+----------+--------------+------------------+-------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>
<ul>
<li>备库上也需要在my.cnf中增加类似的配置，而且需要重启服务器；</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log_bin &#x3D; mysql-bin</span><br><span class="line">server_id &#x3D; 2</span><br><span class="line">relay_log &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql-relay-bin</span><br><span class="line">log_slave_updates &#x3D; 1</span><br><span class="line">read_only &#x3D;1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上述配置只有server_id是必须的，replay_log是指中继日志的位置，log_slave_updates表示运行备库将其重放的事件也记录到自身的日志中。</p>
<h2 id="启动复制"><a href="#启动复制" class="headerlink" title="启动复制"></a>启动复制</h2>]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql复制</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM调优总结</title>
    <url>/2018-10-18/JVM%E8%B0%83%E4%BC%98%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="堆大小设置"><a href="#堆大小设置" class="headerlink" title="堆大小设置"></a>堆大小设置</h1><p>对于32位的系统，一般限制在1.5-2G；64位操作系统对内存无限制。</p>
<h2 id="典型设置"><a href="#典型设置" class="headerlink" title="典型设置"></a>典型设置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k</span><br><span class="line"></span><br><span class="line">java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio&#x3D;4 -XX:SurvivorRatio&#x3D;4 -XX:MaxPermSize&#x3D;16m -XX:MaxTenuringThreshold&#x3D;0</span><br><span class="line"></span><br><span class="line">-Xmx3550M 最大堆内存</span><br><span class="line">-Xms3550M 初始内存</span><br><span class="line">-Xmn2G    年轻代内存 这个JVM的大小&#x3D;年轻代大小+年老代的大小+持久代的大小，持久代一般固定为64M，年轻代越大就会减小年老代的大小，此值对系统的性能影响较大，sun官方推荐配置为整个对的3&#x2F;8</span><br><span class="line">-Xss128K  线程栈的大小 设置每个线程栈的大小。jdk5以后每个线程堆栈的大小为1M，以前每个线程栈的大小为256k</span><br><span class="line">-XX:NewRatio&#x3D;4 设置年轻代（包括Eden和Survivor）与老年代的比值（除去持久代）。设置为4 则年轻代与老年代所占比值为1:4，年轻代占整个堆栈的1&#x2F;5</span><br><span class="line">-XX:SurvivorRatio&#x3D;4 设置年轻代中的Eden与Survivor区的大小比值。设置为4，则两个Survivor与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1&#x2F;6</span><br><span class="line">-XX:MaxPermSize&#x3D;16M 设置持久代的大小为16M</span><br><span class="line">-XX:MaxtenuringThreshold&#x3D;0 设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，则可以提高效率。如果设置一个较大值，则年轻对象则会在Survivor区进行多次复制，则可以增加对象在年轻代的存活时间。</span><br></pre></td></tr></table></figure>
<h1 id="回收器选择"><a href="#回收器选择" class="headerlink" title="回收器选择"></a>回收器选择</h1><p>JVM给了三种选择：串行收集器/并行收集器/并发收集器。但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行判断。</p>
<h2 id="吞吐量优先的并行收集器"><a href="#吞吐量优先的并行收集器" class="headerlink" title="吞吐量优先的并行收集器"></a>吞吐量优先的并行收集器</h2><p>并行收集器主要以到达一定的吞吐量为目标，适用于科学技术和后台处理等</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads&#x3D;20</span><br><span class="line">-XX:+UseParallelGC:选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并行收集器，老年代使用串行收集器</span><br><span class="line">-XX：ParallelGCThreads&#x3D;20：配置并行收集器的线程数，即同时多少个线程一起并行垃圾回收。此值最好与处理器数目相等。</span><br><span class="line"></span><br><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads&#x3D;20 -XX:+UseParallelOldGC</span><br><span class="line">-XX:+UseParallelOldGC 配置年老代垃圾收集方式为并行收集。JDK6支持对年老代并行收集</span><br><span class="line"></span><br><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC  -XX:MaxGCPauseMillis&#x3D;100</span><br><span class="line">-XX:+MaxGCPauseMillis&#x3D;100:设置年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代的大小，以蛮子此值。</span><br><span class="line"></span><br><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC  -XX:MaxGCPauseMillis&#x3D;100 -XX:+UseAdaptiveSizePolicy</span><br><span class="line">-XX:+UseAdaptiveSizePolicy:设置此值后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间和收集频率，此值建议使用并行收集器时，一直打开。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="响应时间有限的并发收集器"><a href="#响应时间有限的并发收集器" class="headerlink" title="响应时间有限的并发收集器"></a>响应时间有限的并发收集器</h2><p>并发收集器主要是保证系统的响应时间，减少垃圾收集时的停顿时间。适用于应用服务器、电信领域等。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads&#x3D;20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC</span><br><span class="line">-XX:+UseConcMarkSweepGC 设置老年代为并发收集，配置这个以后 -XX:NewRatio&#x3D;4的配置失效了，原因不明。所以此时年轻代大小最好使用-Xmn设置</span><br><span class="line">-XX:+UseParNewGC 设置年轻代为并行收集。可与CMS收集同时使用。JDK5以上，JVM会根据系统设置自行配置，无需设置此值。</span><br><span class="line"></span><br><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction&#x3D;5 -XX:+UseCMSCompactAtFullCollection</span><br><span class="line">-XX：CMSFullGCsBeforeCompaction:由于并发收集器不对内存空间压缩整理，所以一段时间以后会产生碎片，使得运行效率低下，此值设置运行多少次GC有多少次以后对内存空间进行压缩整理</span><br><span class="line">-XX：+UseCMSCompactFullCollection:打开年老代的压缩，可能会影响性能，但是可以消除碎片</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="辅助信息"><a href="#辅助信息" class="headerlink" title="辅助信息"></a>辅助信息</h1><p>JVM提供了许多命令行参数，打印信息，供调试使用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+PrintGC</span><br><span class="line">输出形式：[GC 118250K-&gt;113543K(130112K), 0.0094143 secs]</span><br><span class="line">        [Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs]</span><br><span class="line"></span><br><span class="line">-XX：+PrintGCDetails</span><br><span class="line">输出形式：[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs]</span><br><span class="line">        [GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs]</span><br><span class="line"></span><br><span class="line">-XX:+PrintGCTimeStamps -XX:+PrintGC：PrintGCTimeStamps可与上面两个混合使用</span><br><span class="line">输出形式：11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs]</span><br><span class="line"></span><br><span class="line">-XX:+PrintGCApplicationConcurrentTime:打印垃圾回收前，程序未中断的执行时间</span><br><span class="line">输出形式：Application time: 0.5291524 seconds</span><br><span class="line"></span><br><span class="line">-XX:+PrintGCApplicationStoppedTime：打印垃圾回收期间程序暂停的时间。可与上面混合使用</span><br><span class="line">输出形式：Total time for which application threads were stopped: 0.0468229 seconds</span><br><span class="line"></span><br><span class="line">-XX:PrintHeapAtGC:打印GC前后的详细堆栈信息</span><br><span class="line">输出形式：</span><br><span class="line">34.702: [GC &#123;Heap before gc invocations&#x3D;7:</span><br><span class="line"> def new generation   total 55296K, used 52568K [0x1ebd0000, 0x227d0000, 0x227d0000)</span><br><span class="line">eden space 49152K,  99% used [0x1ebd0000, 0x21bce430, 0x21bd0000)</span><br><span class="line">from space 6144K,  55% used [0x221d0000, 0x22527e10, 0x227d0000)</span><br><span class="line">  to   space 6144K,   0% used [0x21bd0000, 0x21bd0000, 0x221d0000)</span><br><span class="line"> tenured generation   total 69632K, used 2696K [0x227d0000, 0x26bd0000, 0x26bd0000)</span><br><span class="line">the space 69632K,   3% used [0x227d0000, 0x22a720f8, 0x22a72200, 0x26bd0000)</span><br><span class="line"> compacting perm gen  total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000)</span><br><span class="line">   the space 8192K,  35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000)</span><br><span class="line">    ro space 8192K,  66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000)</span><br><span class="line">    rw space 12288K,  46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)</span><br><span class="line">34.735: [DefNew: 52568K-&gt;3433K(55296K), 0.0072126 secs] 55264K-&gt;6615K(124928K)Heap after gc invocations&#x3D;8:</span><br><span class="line"> def new generation   total 55296K, used 3433K [0x1ebd0000, 0x227d0000, 0x227d0000)</span><br><span class="line">eden space 49152K,   0% used [0x1ebd0000, 0x1ebd0000, 0x21bd0000)</span><br><span class="line">  from space 6144K,  55% used [0x21bd0000, 0x21f2a5e8, 0x221d0000)</span><br><span class="line">  to   space 6144K,   0% used [0x221d0000, 0x221d0000, 0x227d0000)</span><br><span class="line"> tenured generation   total 69632K, used 3182K [0x227d0000, 0x26bd0000, 0x26bd0000)</span><br><span class="line">the space 69632K,   4% used [0x227d0000, 0x22aeb958, 0x22aeba00, 0x26bd0000)</span><br><span class="line"> compacting perm gen  total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000)</span><br><span class="line">   the space 8192K,  35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000)</span><br><span class="line">    ro space 8192K,  66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000)</span><br><span class="line">    rw space 12288K,  46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)</span><br><span class="line">&#125;</span><br><span class="line">, 0.0757599 secs]</span><br><span class="line"></span><br><span class="line">-Xloggc:filename:与上面几个配合使用，把相关日志信息记录到文件以便分析。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="常见配置汇总"><a href="#常见配置汇总" class="headerlink" title="常见配置汇总"></a>常见配置汇总</h1><h2 id="堆设置"><a href="#堆设置" class="headerlink" title="堆设置"></a>堆设置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-Xms:初始堆大小</span><br><span class="line">-Xmx:最大堆大小</span><br><span class="line">-XX:NewSize&#x3D;n:设置年轻代大小</span><br><span class="line">-XX:NewRatio&#x3D;n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1&#x2F;4</span><br><span class="line">-XX:SurvivorRatio&#x3D;n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor&#x3D;3：2，一个Survivor区占整个年轻代的1&#x2F;5</span><br><span class="line">-XX:MaxPermSize&#x3D;n:设置持久代大小</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="收集器设置"><a href="#收集器设置" class="headerlink" title="收集器设置"></a>收集器设置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseSerialGC:设置串行收集器</span><br><span class="line">-XX:+UseParallelGC:设置并行收集器</span><br><span class="line">-XX:+UseParalledlOldGC:设置并行年老代收集器</span><br><span class="line">-XX:+UseConcMarkSweepGC:设置并发收集器</span><br></pre></td></tr></table></figure>

<h2 id="垃圾回收统计信息"><a href="#垃圾回收统计信息" class="headerlink" title="垃圾回收统计信息"></a>垃圾回收统计信息</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+PrintGC</span><br><span class="line">-XX:+PrintGCDetails</span><br><span class="line">-XX:+PrintGCTimeStamps</span><br><span class="line">-Xloggc:filename</span><br></pre></td></tr></table></figure>
<h2 id="并行收集器设置"><a href="#并行收集器设置" class="headerlink" title="并行收集器设置"></a>并行收集器设置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:ParallelGCThreads&#x3D;n:设置并行收集器收集时使用的CPU数。并行收集线程数。</span><br><span class="line">-XX:MaxGCPauseMillis&#x3D;n:设置并行收集最大暂停时间</span><br><span class="line">-XX:GCTimeRatio&#x3D;n:设置垃圾回收时间占程序运行时间的百分比。公式为1&#x2F;(1+n)</span><br></pre></td></tr></table></figure>

<h2 id="并发收集器设置"><a href="#并发收集器设置" class="headerlink" title="并发收集器设置"></a>并发收集器设置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。</span><br><span class="line">-XX:ParallelGCThreads&#x3D;n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。</span><br></pre></td></tr></table></figure>

<h1 id="调优总结"><a href="#调优总结" class="headerlink" title="调优总结"></a>调优总结</h1><h2 id="年轻代大小选择"><a href="#年轻代大小选择" class="headerlink" title="年轻代大小选择"></a>年轻代大小选择</h2><ul>
<li>响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。</li>
<li>吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。</li>
</ul>
<h2 id="年老代大小选择"><a href="#年老代大小选择" class="headerlink" title="年老代大小选择"></a>年老代大小选择</h2><ul>
<li>响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得：</li>
</ul>
<p>并发垃圾收集信息</p>
<p>持久代并发收集次数</p>
<p>传统GC信息</p>
<p>花在年轻代和年老代回收上的时间比例</p>
<p>减少年轻代和年老代花费的时间，一般会提高应用的效率</p>
<ul>
<li>吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。</li>
</ul>
<h2 id="较小堆引起的碎片问题"><a href="#较小堆引起的碎片问题" class="headerlink" title="较小堆引起的碎片问题"></a>较小堆引起的碎片问题</h2><ul>
<li>因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。</span><br><span class="line">-XX:CMSFullGCsBeforeCompaction&#x3D;0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩</span><br></pre></td></tr></table></figure>


</li>
</ul>
<p><a href="https://www.cnblogs.com/wangzhongqiu/p/8908266.html">深入理解java虚拟机</a></p>
<h1 id="自带的内存管理机制"><a href="#自带的内存管理机制" class="headerlink" title="自带的内存管理机制"></a>自带的内存管理机制</h1><p>jconsole JDK自带的内存监测工具，路径jdk bin目录下jconsole.exe，双击可运行。连接方式有两种，第一种是本地方式如调试时运行的进程可以直接连，第二种是远程方式，可以连接以服务形式启动的进程。远程连接方式是：在目标进程的jvm启动参数中添加-Dcom.sun.management.jmxremote.port=1090 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false 1090是监听的端口号具体使用时要进行修改，然后使用IP加端口号连接即可。通过该工具可以监测到当时内存的大小，CPU的使用量以及类的加载，<br>还提供了手动gc的功能。优点是效率高，速度快，在不影响进行运行的情况下监测产品的运行。缺点是无法看到类或者对象之类的具体信息</p>
<h1 id="堆内存的分配策略"><a href="#堆内存的分配策略" class="headerlink" title="堆内存的分配策略"></a>堆内存的分配策略</h1><ul>
<li>策略1</li>
</ul>
<p>当在程序中生成对象时，正常对象会在年轻代中分配空间，如果是过大的对象也可能会直接在年老代生成（据观测在运行某程序时候每次会生成一个十兆的空间用收发消息，这部分内存就会直接在年老代分配）。年轻代在空间被分配完的时候就会发起内存回收，大部分内存会被回收，一部分幸存的内存会被拷贝至Survivor的from区，经过多次回收以后如果from区内存也分配完毕，就会也发生内存回收然后将剩余的对象拷贝至to区。等到to区也满的时候，就会再次发生内存回收然后把幸存的对象拷贝至年老区。</p>
<p>JVM初始分配的内存由-Xms指定，默认是物理内存的1/64；JVM最大分配的内存由 -Xmx指定，默认是物理内存的1/4。默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制；空余堆内存大于70%时，JVM会减少堆 直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx相等以避免在每次GC 后调整堆的大小。</p>
<ul>
<li>策略2</li>
</ul>
<p>对象优先在Eden分配，当新生区没有足够的内存是，通过分配担保机制提前转移到老年代中去</p>
<p>大对象直接进入老年代。大对象是指需要大量连续内存空间的对象，虚拟机提供了参数 -XX:PretenureSizeThreshold（只对Serial，PerNew两个回收器起效），令大于这个值得对象直接在老年代分配，避免了Eden和两个Survival之间发生大量的内存复制。</p>
<p>长期存活的对象将进入老年代。虚拟机给每个对象定义了对象年龄计数器（Age），如果对象在Eden出生，经过第一次Minor GC后依然存活，并且能被Survival容纳的话，将被移动到Survival，对象年龄设为1。对象在Survival中每熬过一次Major GC，年龄就增加1，达到一定程度（默认是15），就会被晋升到老年代。对象晋升老年代的阈值，可以通过参数-XX:MaxTenuringThreShold 指定</p>
<p>动态对象年龄判断。如果在Survival空间中相同年龄所有对象的大小综合超过了Survival空间的一半，年龄大于等于这个年龄的对象都会被晋升到老年代。无需等待年龄超过MaxTenuringThreShold指定的年龄</p>
<p>空间分配担保。只要老年代的连续空间大于新生代对象总和或者历次晋升的平均大小，就进行Major GC，否则进行Full  GC。</p>
<h1 id="JVM常用参数设置"><a href="#JVM常用参数设置" class="headerlink" title="JVM常用参数设置"></a>JVM常用参数设置</h1><h2 id="整体考虑堆大小"><a href="#整体考虑堆大小" class="headerlink" title="整体考虑堆大小"></a>整体考虑堆大小</h2><p>-Xms3550m， 初始化堆大小。通常情况和-Xmx大小设置一样，避免虚拟机频繁自动计算后调整堆大小。 </p>
<p>-Xmx3550m，最大堆大小。</p>
<h2 id="考虑分代设置堆大小"><a href="#考虑分代设置堆大小" class="headerlink" title="考虑分代设置堆大小"></a>考虑分代设置堆大小</h2><p>首先通过jstat等工具查看应用程序正常情况下需要堆大小，再根据实际情况设置。</p>
<h3 id="新生代"><a href="#新生代" class="headerlink" title="新生代"></a>新生代</h3><p>-xmn2g，新生代大小。Sun官方推荐配置为整个堆的3/8。<br>-XX:SurvivorRatio=8。Eden和Survivor的比值。</p>
<h3 id="老年代"><a href="#老年代" class="headerlink" title="老年代"></a>老年代</h3><p>老年代=整个堆大小-新生代-永久代</p>
<h3 id="永久带"><a href="#永久带" class="headerlink" title="永久带"></a>永久带</h3><p>-XX:Permsize=512m,设置永久代初始值。<br>-XX:MaxPermsize=512m，设置永久代的最大值。<br>注：Java8没有永久代说法，它们被称为元空间，-XX:MetaspaceSize=N</p>
<h2 id="考虑虚拟机栈"><a href="#考虑虚拟机栈" class="headerlink" title="考虑虚拟机栈"></a>考虑虚拟机栈</h2><p>每个线程池的堆栈大小。在jdk5以上的版本，每个线程堆栈大小为1m，jdk5以前的版本是每个线程池大小为256k。一般设置256k。<br>-Xss256K.</p>
<h2 id="考虑垃圾收集器"><a href="#考虑垃圾收集器" class="headerlink" title="考虑垃圾收集器"></a>考虑垃圾收集器</h2><h3 id="Serial收集器-串行收集器"><a href="#Serial收集器-串行收集器" class="headerlink" title="Serial收集器(串行收集器)"></a>Serial收集器(串行收集器)</h3><p>历史最悠久的串行收集器。参数-XX:UseSerialGC。不太常用。</p>
<h3 id="ParNew和ParOld收集器-并发收集器"><a href="#ParNew和ParOld收集器-并发收集器" class="headerlink" title="ParNew和ParOld收集器(并发收集器)"></a>ParNew和ParOld收集器(并发收集器)</h3><p>Serial的多线程版本收集器。</p>
<h3 id="Parallel-Scavenge-吞吐量优先垃圾收集器"><a href="#Parallel-Scavenge-吞吐量优先垃圾收集器" class="headerlink" title="Parallel Scavenge(吞吐量优先垃圾收集器)"></a>Parallel Scavenge(吞吐量优先垃圾收集器)</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">并行收集器，不同于多线程收集器ParNew，关注吞吐量的收集器。 </span><br><span class="line">-XX:MaxGCPauseMillis&#x3D;10，设置垃圾收集停顿的最大毫秒数。 </span><br><span class="line">-XX:GCTimeRatio&#x3D;49，垃圾收集器占比，默认是99。 </span><br><span class="line">-XX:+UseAdaptiveSeizPolicy，GC自适应调节策略。 </span><br><span class="line">-XX:+UseParallelGC,虚拟机Server模式默认值，使用Parallel Scavenge + Serial Old进行内存回收。 </span><br><span class="line">-XX:+UseParallelOldGC, 使用Parallel Scavenge + Parallel Old 进行内存回收。</span><br></pre></td></tr></table></figure>

<h3 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CMS作为老年代收集器，不能与Parallel Scavenge并存。可能会有内存碎片问题。 </span><br><span class="line">-XX:+UserConcMarkSweepGC，新生代默认用ParNew收集。也可以用-XX:+UserParNewGC强制指定新生代用ParNew收集 </span><br><span class="line">-XX:ParallelGCThreads&#x3D;4，设置垃圾收集线程数。默认是(CPU数量+3)&#x2F;4。垃圾收集线程数不少于25%，当CPU数量小于4的时候影响大。 </span><br><span class="line">-XX:CMSInitiatingOccupancyFraction&#x3D;80，老年代垃圾占比达到这个阈值开始CMS收集，1.6默认是92。设置过高容易导致并发收集失败，会出现SerialOld收集的情况。 </span><br><span class="line">-XX:+UseCMSCompactAtFullCollection，在FULL GC的时候， 对年老代的压缩增加这个参数是个好习惯。可能会影响性能,但是可以消除碎片。 </span><br><span class="line">-XX:CMSFullGCsBeforeCompaction&#x3D;1，多少次后进行内存压缩。 </span><br><span class="line">-XX:+CMSParallelRemarkEnabled, 为了减少第二次暂停的时间，开启并行remark,降低标记停顿</span><br></pre></td></tr></table></figure>

<h3 id="G1-Garbage-First"><a href="#G1-Garbage-First" class="headerlink" title="G1(Garbage First)"></a>G1(Garbage First)</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseG1GC，谨慎使用，需要经过线上测试，还没有被设置为默认垃圾收集器。 </span><br><span class="line">之前的垃圾收集器收集的范围是新生代或者老年代，而G1垃圾收集器收集的范围包括新生代和老年代整个堆。G1将Java堆划为多个大小相同的独立区域(Region)，垃圾收集单位是Region。G1垃圾收集适合至少大于4G内存得系统。并且不会产生内存空间碎片。</span><br></pre></td></tr></table></figure>

<h3 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:MaxTenuringThreshold&#x3D;30，晋升老年代的年龄。 </span><br><span class="line">-XX:PretenureSizeThreshold&#x3D;?，晋升老年代的对象大小。没设置过。</span><br></pre></td></tr></table></figure>

<h3 id="考虑日志打印"><a href="#考虑日志打印" class="headerlink" title="考虑日志打印"></a>考虑日志打印</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-verbose:gc，打印GC日志 </span><br><span class="line">-XX:+PrintGC，打印GC基本日志 </span><br><span class="line">-XX:+PrintGCDetails，打印GC详细日志 </span><br><span class="line">-XX:+PrintGCTimeStamps，打印相对时间戳 </span><br><span class="line">-XX:+PrintGCApplicationStoppedTime,打印垃圾回收期间程序暂停的时间 </span><br><span class="line">-XX:+PrintGCApplicationConcurrentTime,打印每次垃圾回收前,程序未中断的执行时间 </span><br><span class="line">-XX:+PrintTenuringDistribution：查看每次minor GC后新的存活周期的阈值 </span><br><span class="line">-XX:+PrintTLAB,查看TLAB空间的使用情况 </span><br><span class="line">-Xloggc:filename,把相关日志信息记录到文件以便分析</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="考虑OOM-堆溢出-时保留现场日志"><a href="#考虑OOM-堆溢出-时保留现场日志" class="headerlink" title="考虑OOM(堆溢出)时保留现场日志"></a>考虑OOM(堆溢出)时保留现场日志</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">当抛出OOM时进行heapdump</span><br><span class="line">-XX:+HeapDumpOnOutOfMemoryError,JVM异常自动生成堆转储 </span><br><span class="line">-XX:HeapDumpPath&#x3D;，堆转储文件名</span><br></pre></td></tr></table></figure>











]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM调优</tag>
      </tags>
  </entry>
  <entry>
    <title>《SQL基础》SQL学习指南学习笔记一　数据库的基本概念和操作</title>
    <url>/2017-11-03/SQL%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80%20%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h2 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h2><ol>
<li>实体：数据库用户所关注的对象。</li>
<li>列：存储在表中的独立的数字片段。</li>
<li>行：所有列的一个集合，完整的描述了一个实体或者实体上的某个行为，也称之为记录。</li>
<li>表：行的集合，既可以存在内存中，也可以持久化到硬盘上。</li>
<li>结果集：未持久化表的另一个名字，一般为SQL的查询结果。</li>
<li>主键：用于唯一标识表中的每个行的一个或者多个列。</li>
<li>外键：一个或者多个用于识别其他表中的某一个行的列。</li>
</ol>
<h2 id="使用mysql命令行工具"><a href="#使用mysql命令行工具" class="headerlink" title="使用mysql命令行工具"></a>使用mysql命令行工具</h2><ul>
<li>使用命令行工具可以制定用户名和想要连接的数据库</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">zhuningning@ubuntu:~$ mysql -u lrngsql -p bank</span><br><span class="line">Enter password: </span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 10</span><br><span class="line">Server version: 5.7.20 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2017, Oracle and&#x2F;or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and&#x2F;or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>出现如上的结果表示连接成功。</p>
<h2 id="表的创建"><a href="#表的创建" class="headerlink" title="表的创建"></a>表的创建</h2><ul>
<li>以下为创建表person的语句:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; create table person(</span><br><span class="line">    -&gt; person_id smallint unsigned,</span><br><span class="line">    -&gt; fname varchar(20),</span><br><span class="line">    -&gt; lname varchar(20),</span><br><span class="line">    -&gt; gender enum(&#39;M&#39;,&#39;F&#39;),</span><br><span class="line">    -&gt; birth_date date,</span><br><span class="line">    -&gt; street varchar(20),</span><br><span class="line">    -&gt; ciry varchar(20),</span><br><span class="line">    -&gt; state varchar(20),</span><br><span class="line">    -&gt; country varchar(20),</span><br><span class="line">    -&gt; postal_code varchar(20),</span><br><span class="line">    -&gt; constraint pk_person primary key(person_id)</span><br><span class="line">    -&gt; );</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p>注意以上的gender　enum 类型，可以约束赋值只能为Ｍ和Ｆ；</p>
</li>
<li><p>desc person该语句可以显示表结构；</p>
</li>
<li><p>其中<code>null</code>表示用于各种不能赋值的情况；</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; desc person;</span><br><span class="line">+-------------+----------------------+------+-----+---------+-------+</span><br><span class="line">| Field       | Type                 | Null | Key | Default | Extra |</span><br><span class="line">+-------------+----------------------+------+-----+---------+-------+</span><br><span class="line">| person_id   | smallint(5) unsigned | NO   | PRI | NULL    |       |</span><br><span class="line">| fname       | varchar(20)          | YES  |     | NULL    |       |</span><br><span class="line">| lname       | varchar(20)          | YES  |     | NULL    |       |</span><br><span class="line">| gender      | enum(&#39;M&#39;,&#39;F&#39;)        | YES  |     | NULL    |       |</span><br><span class="line">| birth_date  | date                 | YES  |     | NULL    |       |</span><br><span class="line">| street      | varchar(20)          | YES  |     | NULL    |       |</span><br><span class="line">| ciry        | varchar(20)          | YES  |     | NULL    |       |</span><br><span class="line">| state       | varchar(20)          | YES  |     | NULL    |       |</span><br><span class="line">| country     | varchar(20)          | YES  |     | NULL    |       |</span><br><span class="line">| postal_code | varchar(20)          | YES  |     | NULL    |       |</span><br><span class="line">+-------------+----------------------+------+-----+---------+-------+</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>以下语句可以展示创建表的语句</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; show create table person;</span><br><span class="line">+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| Table  | Create Table                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |</span><br><span class="line">+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| person | CREATE TABLE &#96;person&#96; (</span><br><span class="line">  &#96;person_id&#96; smallint(5) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">  &#96;fname&#96; varchar(20) DEFAULT NULL,</span><br><span class="line">  &#96;lname&#96; varchar(20) DEFAULT NULL,</span><br><span class="line">  &#96;gender&#96; enum(&#39;M&#39;,&#39;F&#39;) DEFAULT NULL,</span><br><span class="line">  &#96;birth_date&#96; date DEFAULT NULL,</span><br><span class="line">  &#96;street&#96; varchar(20) DEFAULT NULL,</span><br><span class="line">  &#96;ciry&#96; varchar(20) DEFAULT NULL,</span><br><span class="line">  &#96;state&#96; varchar(20) DEFAULT NULL,</span><br><span class="line">  &#96;country&#96; varchar(20) DEFAULT NULL,</span><br><span class="line">  &#96;postal_code&#96; varchar(20) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (&#96;person_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;3 DEFAULT CHARSET&#x3D;latin1 |</span><br><span class="line">+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ul>
<li>接下来创建favorite_food表</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; create table favorite_food(</span><br><span class="line">    -&gt; person_id smallint unsigned,</span><br><span class="line">    -&gt; food varchar(20),</span><br><span class="line">    -&gt; constraint pk_favorite_food primary key(person_id,food),</span><br><span class="line">    -&gt; constraint pk_fav_food_person_id foreign key(person_id) references person(person_id)</span><br><span class="line">    -&gt; );</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>其中pk_fav_food_person_id为外键　references person表的person_id，pk_favorite_food为联合主键，他们都属于约束。</li>
</ul>
<h2 id="操作与修改表"><a href="#操作与修改表" class="headerlink" title="操作与修改表"></a>操作与修改表</h2><ul>
<li>修改主键为自动增长</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; alter table person modify person_id smallint unsigned auto_increment;</span><br><span class="line">Query OK, 0 rows affected (0.82 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc person;</span><br><span class="line">+-------------+----------------------+------+-----+---------+----------------+</span><br><span class="line">| Field       | Type                 | Null | Key | Default | Extra          |</span><br><span class="line">+-------------+----------------------+------+-----+---------+----------------+</span><br><span class="line">| person_id   | smallint(5) unsigned | NO   | PRI | NULL    | auto_increment |</span><br><span class="line">| fname       | varchar(20)          | YES  |     | NULL    |                |</span><br><span class="line">| lname       | varchar(20)          | YES  |     | NULL    |                |</span><br><span class="line">| gender      | enum(&#39;M&#39;,&#39;F&#39;)        | YES  |     | NULL    |                |</span><br><span class="line">| birth_date  | date                 | YES  |     | NULL    |                |</span><br><span class="line">| street      | varchar(20)          | YES  |     | NULL    |                |</span><br><span class="line">| ciry        | varchar(20)          | YES  |     | NULL    |                |</span><br><span class="line">| state       | varchar(20)          | YES  |     | NULL    |                |</span><br><span class="line">| country     | varchar(20)          | YES  |     | NULL    |                |</span><br><span class="line">| postal_code | varchar(20)          | YES  |     | NULL    |                |</span><br><span class="line">+-------------+----------------------+------+-----+---------+----------------+</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<ul>
<li>插入数据操作</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; insert into person(person_id,fname,lname,gender,birth_date) values(null,&#39;william&#39;,&#39;turnar&#39;,&#39;M&#39;,&#39;1972-05-27&#39;);</span><br><span class="line">Query OK, 1 row affected (0.06 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意：插入的birth_date　字段的值为字符串类型，mysql数据库会将字符串自动解析为date类型。</p>
<ul>
<li>查询语句</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select * from person;</span><br><span class="line">+-----------+---------+--------+--------+------------+--------+------+-------+---------+-------------+</span><br><span class="line">| person_id | fname   | lname  | gender | birth_date | street | ciry | state | country | postal_code |</span><br><span class="line">+-----------+---------+--------+--------+------------+--------+------+-------+---------+-------------+</span><br><span class="line">|         1 | william | turnar | M      | 1972-05-27 | NULL   | NULL | NULL  | NULL    | NULL        |</span><br><span class="line">+-----------+---------+--------+--------+------------+--------+------+-------+---------+-------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意，生产环境中，最好不要使用 *,这样会加重解析器的负担，使得查询的效率变低。</p>
<ul>
<li>更新语句</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; update person set street&#x3D;&#39;beijing&#39; where person_id&#x3D;1;</span><br><span class="line">Query OK, 1 row affected (0.04 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>删除语句</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; delete from person where person_id &#x3D;1;</span><br><span class="line">Query OK, 1 row affected (0.07 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意 不要忘记where子句，否者会删除表中所有的数据。</p>
<h2 id="导致错误的语句"><a href="#导致错误的语句" class="headerlink" title="导致错误的语句"></a>导致错误的语句</h2><ul>
<li>插入的主键不唯一;</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; insert into person(person_id,fname,lname,gender,birth_date) values(1,&#39;william&#39;,&#39;turnar&#39;,&#39;M&#39;,&#39;1972-05-27&#39;);</span><br><span class="line">ERROR 1062 (23000): Duplicate entry &#39;1&#39; for key &#39;PRIMARY&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>插入不存在的外键;</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; insert into favorite_food values(22222,&#39;noodles&#39;);</span><br><span class="line">ERROR 1452 (23000): Cannot add or update a child row: a foreign key constraint</span><br><span class="line"> fails (&#96;bank&#96;.&#96;favorite_food&#96;, CONSTRAINT &#96;favorite_food_ibfk_1&#96; FOREIGN KEY (&#96;person_id&#96;) REFERENCES &#96;person&#96; (&#96;person_id&#96;))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>由于favorite_food表中的person_id是依赖于person表的，可以将favorite_food看做是person表的子表。</p>
<ul>
<li>列值不合法</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; update person set gender &#x3D;&#39;X&#39; where person_id &#x3D;1;</span><br><span class="line">ERROR 1265 (01000): Data truncated for column &#39;gender&#39; at row 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>gender是枚举类，只接受f 和ｍ</p>
<ul>
<li>无效的日期类型</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; update person set birth_date &#x3D;&#39;DEC-21-1990&#39; where person_id &#x3D;2;</span><br><span class="line">ERROR 1292 (22007): Incorrect date value: &#39;DEC-21-1990&#39; for column &#39;birth_date&#39; at row 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以使用日期转化函数 str_to_date</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">update person set birth_date&#x3D;str_to_date(&#39;DEC-21-1990&#39;,&#39;%b-%d-%Y’) where person_id &#x3D;2;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="mysql的数据类型"><a href="#mysql的数据类型" class="headerlink" title="mysql的数据类型"></a>mysql的数据类型</h2><h3 id="字符型数据"><a href="#字符型数据" class="headerlink" title="字符型数据"></a>字符型数据</h3><p><em>字符类型数据可以分为２种：</em></p>
<ul>
<li>定长的char类型，它需要使用空格向右填充； max  255byte</li>
<li>变长的字符串 varchar类型，不需要向右填充，并且所有的字节数可变。max 65535bye　即 ６４ｋ</li>
<li>当定义一个字符列时，必须制定该列所能存放的字符串的最大长度。</li>
</ul>
<p><em>字符集：</em></p>
<ul>
<li>mysql可以使用各种字符集来存储数据，使用<code>show character set;</code> 可以查看字符集列表，默认的安装数据库时，lantin1字符集会被<br>默认的选为字符集。</li>
<li>可以使用以下语句，在创建数据库的时候制定字符集；</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; create database foreign_sales character set utf8;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><em>文本数据</em></p>
<ul>
<li>当需要存储的数据大于64KB(VARCHAR的上限)　就要使用文本类型：</li>
</ul>
<ul>
<li>tinytext(255 byte) </li>
<li>text(65535 byte) </li>
<li>mediumtext(16777215 byte) </li>
<li>longtext(4294967295 byte) </li>
</ul>
<p><code>需要注意</code>：</p>
<ul>
<li>如果装载的长度超过该类型的最大长度，数据将会被阶段；</li>
<li>文本不会消除数据的尾部空格；</li>
</ul>
<h3 id="数值型数据"><a href="#数值型数据" class="headerlink" title="数值型数据"></a>数值型数据</h3><p><em>整数类型 :</em> 　</p>
<ul>
<li>tinyint : 0-255;</li>
<li>smallint : 0-65535(六万);</li>
<li>mediumint : 0-26777215 (一千六百万);</li>
<li>int : 0-42亿;</li>
<li>bigint : 0　~ ;</li>
</ul>
<p><em>浮点类型：</em></p>
<ul>
<li>float(p,s)</li>
<li>double(p,s)</li>
</ul>
<h3 id="时间数据"><a href="#时间数据" class="headerlink" title="时间数据"></a>时间数据</h3><p>时间类型分为:<br>date    year     time     datetime     timestamp<br>其中后２个是相同的格式，只不过timestamp的范围为　1970-01-01 00:00:00至2037-12-31 23:59:59 且mysql中可以生成timestamp<br>类型的时间数据。</p>
<ul>
<li><a href="http://www.runoob.com/sql/sql-datatypes.html">具体的数据类型参考手册</a></li>
<li><a href="http://www.cnblogs.com/jerrylz/p/5814460.html">java数据类型和mysql数据类型对应表</a>    </li>
</ul>
<h3 id="字符串相关的函数"><a href="#字符串相关的函数" class="headerlink" title="字符串相关的函数"></a>字符串相关的函数</h3><ul>
<li><p>当插入的字符串的长度超过指定的字段的长度时，服务器会抛出异常。这是mysql服务器的默认操作，可以修改其配置，改成截取字符串后插入，不抛出任何异常。</p>
</li>
<li><p>由于mysql中的字符串使用单引号分割，所以字符串中包含单引号时可以使用 ‘\’或者单引号作为转义，即两个单引号。</p>
</li>
<li><p>length()函数返回字符串的个数,这个获取长度时会删除char类型的尾端的空格。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+---------+--------------+------------+-------------+</span><br><span class="line">| cust_id | name         | state_id   | incorp_date |</span><br><span class="line">+---------+--------------+------------+-------------+</span><br><span class="line">|      10 | jamesd &#39;hand | 12-345-678 | 1995-05-01  |</span><br><span class="line">+---------+--------------+------------+-------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select length(name) from business where cust_id&#x3D;10;</span><br><span class="line">+--------------+</span><br><span class="line">| length(name) |</span><br><span class="line">+--------------+</span><br><span class="line">|           12 |</span><br><span class="line">+--------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>REGEXP操作符（模式匹配）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select cust_id,fed_id,fed_id REGEXP &#39;.&#123;3&#125;-.&#123;2&#125;-.&#123;4&#125;&#39; isFomart from customer;</span><br><span class="line">+---------+-------------+----------+</span><br><span class="line">| cust_id | fed_id      | isFomart |</span><br><span class="line">+---------+-------------+----------+</span><br><span class="line">|       1 | 111-11-1111 |        1 |</span><br><span class="line">|       2 | 222-22-2222 |        1 |</span><br><span class="line">|       3 | 333-33-3333 |        1 |</span><br><span class="line">|       4 | 444-44-4444 |        1 |</span><br><span class="line">|       5 | 555-55-5555 |        1 |</span><br><span class="line">|       6 | 666-66-6666 |        1 |</span><br><span class="line">|       7 | 777-77-7777 |        1 |</span><br><span class="line">|       8 | 888-88-8888 |        1 |</span><br><span class="line">|       9 | 999-99-9999 |        1 |</span><br><span class="line">|      10 | 04-1111111  |        0 |</span><br><span class="line">|      11 | 04-2222222  |        0 |</span><br><span class="line">|      12 | 04-3333333  |        0 |</span><br><span class="line">|      13 | 04-4444444  |        0 |</span><br><span class="line">+---------+-------------+----------+</span><br><span class="line">13 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>concat() 返回字符串的字符串函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select concat(fname,&#39; &#39;,lname,&#39; has been a title  &#39;,&#39;since &#39;,start_date) emp_narrative from employee where title &#x3D;&#39;Teller&#39;;</span><br><span class="line">+-----------------------------------------------------+</span><br><span class="line">| emp_narrative                                       |</span><br><span class="line">+-----------------------------------------------------+</span><br><span class="line">| Chris Tucker has been a title  since 2004-09-15     |</span><br><span class="line">| Sarah Parker has been a title  since 2002-12-02     |</span><br><span class="line">| Jane Grossman has been a title  since 2002-05-03    |</span><br><span class="line">| Thomas Ziegler has been a title  since 2000-10-23   |</span><br><span class="line">| Samantha Jameson has been a title  since 2003-01-08 |</span><br><span class="line">| Cindy Mason has been a title  since 2002-08-09      |</span><br><span class="line">| Frank Portman has been a title  since 2003-04-01    |</span><br><span class="line">| Beth Fowler has been a title  since 2002-06-29      |</span><br><span class="line">| Rick Tulman has been a title  since 2002-12-12      |</span><br><span class="line">+-----------------------------------------------------+</span><br><span class="line">9 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>SubString(字段，1，end) - 从某个文本字段提取字符</li>
</ul>
<h3 id="数字相关的函数"><a href="#数字相关的函数" class="headerlink" title="数字相关的函数"></a>数字相关的函数</h3><ul>
<li>mod() 求余操作</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select mod(22.75,5);</span><br><span class="line">+--------------+</span><br><span class="line">| mod(22.75,5) |</span><br><span class="line">+--------------+</span><br><span class="line">|         2.75 |</span><br><span class="line">+--------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p>ceil()和floor()向上和向下取整操作</p>
</li>
<li><p>round()四舍五入操作</p>
</li>
<li><p>ROUND(X,D)： 返回参数X的四舍五入的有 D 位小数的一个数字。如果D为0，结果将没有小数点或小数部分。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select round(1.287,1) as result;</span><br><span class="line">+--------+</span><br><span class="line">| result |</span><br><span class="line">+--------+</span><br><span class="line">|    1.3 |</span><br><span class="line">+--------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>处理有符号数</li>
</ul>
<p>sign()函数余额为负数时返回-1，为0时返回0，为正数时返回1。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select account_id,sign(avail_balance),abs(avail_balance) from account;</span><br><span class="line">+------------+---------------------+--------------------+</span><br><span class="line">| account_id | sign(avail_balance) | abs(avail_balance) |</span><br><span class="line">+------------+---------------------+--------------------+</span><br><span class="line">|          1 |                   1 |            1057.75 |</span><br><span class="line">|          2 |                   1 |             500.00 |</span><br><span class="line">|          3 |                   1 |            3000.00 |</span><br><span class="line">|          4 |                   1 |            2258.02 |</span><br><span class="line">|          5 |                   1 |             200.00 |</span><br><span class="line">|          7 |                   1 |            1057.75 |</span><br><span class="line">|          8 |                   1 |            2212.50 |</span><br><span class="line">|         10 |                   1 |             534.12 |</span><br><span class="line">|         11 |                   1 |             767.77 |</span><br><span class="line">|         12 |                   1 |            5487.09 |</span><br><span class="line">|         13 |                   1 |            2237.97 |</span><br><span class="line">|         14 |                   1 |             122.37 |</span><br><span class="line">|         15 |                   1 |           10000.00 |</span><br><span class="line">|         17 |                   1 |            5000.00 |</span><br><span class="line">|         18 |                   1 |            3487.19 |</span><br><span class="line">|         19 |                   1 |             387.99 |</span><br><span class="line">|         21 |                   1 |             125.67 |</span><br><span class="line">|         22 |                   1 |            9345.55 |</span><br><span class="line">|         23 |                   1 |            1500.00 |</span><br><span class="line">|         24 |                   1 |           23575.12 |</span><br><span class="line">|         25 |                   0 |               0.00 |</span><br><span class="line">|         27 |                   1 |            9345.55 |</span><br><span class="line">|         28 |                   1 |           38552.05 |</span><br><span class="line">|         29 |                   1 |           50000.00 |</span><br><span class="line">+------------+---------------------+--------------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>AVG() - 返回平均值</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">语法：</span><br><span class="line">SELECT AVG(column_name) FROM table_name</span><br><span class="line"></span><br><span class="line">例子：</span><br><span class="line">从 &quot;access_log&quot; 表的 &quot;count&quot; 列获取平均值：</span><br><span class="line"></span><br><span class="line">mysql&gt; select AVG(count) as countASAverage from access_log;</span><br><span class="line">+----------------+</span><br><span class="line">| countASAverage |</span><br><span class="line">+----------------+</span><br><span class="line">|       174.3333 |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">选择访问量高于平均访问量的 &quot;site_id&quot; 和 &quot;count&quot;：</span><br><span class="line">mysql&gt; select site_id,count from access_log where count&gt;(select AVG(count) from access_log);</span><br><span class="line">+---------+-------+</span><br><span class="line">| site_id | count |</span><br><span class="line">+---------+-------+</span><br><span class="line">|       1 |   230 |</span><br><span class="line">|       5 |   205 |</span><br><span class="line">|       3 |   220 |</span><br><span class="line">|       5 |   545 |</span><br><span class="line">|       3 |   201 |</span><br><span class="line">+---------+-------+</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h3 id="日期相关的函数"><a href="#日期相关的函数" class="headerlink" title="日期相关的函数"></a>日期相关的函数</h3><ul>
<li><p>当一个字段为date   dateTime  time timestamp类型的时候，插入一个数据为字符串类型时，则服务器会将字符串转变为该类型。</p>
</li>
<li><p>str_to_date()格式化函数</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; update individual set birth_date &#x3D;STR_TO_DATE(&#39;September 17,2008&#39;,&#39;%M %d, %Y&#39;) where cust_id &#x3D;1;</span><br><span class="line">Query OK, 1 row affected (0.04 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ul>
<li>current_date(),current_time(),current_timestamp() 时间函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select current_date(),current_time(),current_timestamp();</span><br><span class="line">+----------------+----------------+---------------------+</span><br><span class="line">| current_date() | current_time() | current_timestamp() |</span><br><span class="line">+----------------+----------------+---------------------+</span><br><span class="line">| 2017-11-29     | 00:26:22       | 2017-11-29 00:26:22 |</span><br><span class="line">+----------------+----------------+---------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ul>
<li>date_add()函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F;第二个参数包含了3个参数，分别是interval关键字，数量，和时间间隔类型</span><br><span class="line"></span><br><span class="line">mysql&gt; select date_add(current_date(),interval 5 day);</span><br><span class="line">+-----------------------------------------+</span><br><span class="line">| date_add(current_date(),interval 5 day) |</span><br><span class="line">+-----------------------------------------+</span><br><span class="line">| 2017-12-04                              |</span><br><span class="line">+-----------------------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">type 参数可以是下列值：</span><br><span class="line">Type 值</span><br><span class="line">MICROSECOND</span><br><span class="line">SECOND</span><br><span class="line">MINUTE</span><br><span class="line">HOUR</span><br><span class="line">DAY</span><br><span class="line">WEEK</span><br><span class="line">MONTH</span><br><span class="line">QUARTER</span><br><span class="line">YEAR</span><br><span class="line">SECOND_MICROSECOND</span><br><span class="line">MINUTE_MICROSECOND</span><br><span class="line">MINUTE_SECOND</span><br><span class="line">HOUR_MICROSECOND</span><br><span class="line">HOUR_SECOND</span><br><span class="line">HOUR_MINUTE</span><br><span class="line">DAY_MICROSECOND</span><br><span class="line">DAY_SECOND</span><br><span class="line">DAY_MINUTE</span><br><span class="line">DAY_HOUR</span><br><span class="line">YEAR_MONTH</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>last_day()函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select last_day(&#39;2008-09-17&#39;);</span><br><span class="line">+------------------------+</span><br><span class="line">| last_day(&#39;2008-09-17&#39;) |</span><br><span class="line">+------------------------+</span><br><span class="line">| 2008-09-30             |</span><br><span class="line">+------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select last_day(now());</span><br><span class="line">+-----------------+</span><br><span class="line">| last_day(now()) |</span><br><span class="line">+-----------------+</span><br><span class="line">| 2017-11-30      |</span><br><span class="line">+-----------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ul>
<li>dayname() 返回某一天时星期几</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select dayname(&#39;2008-03-27&#39;);</span><br><span class="line">+-----------------------+</span><br><span class="line">| dayname(&#39;2008-03-27&#39;) |</span><br><span class="line">+-----------------------+</span><br><span class="line">| Thursday              |</span><br><span class="line">+-----------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>extract()截取日期的函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select extract(year from now());</span><br><span class="line">+--------------------------+</span><br><span class="line">| extract(year from now()) |</span><br><span class="line">+--------------------------+</span><br><span class="line">|                     2017 |</span><br><span class="line">+--------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ul>
<li>datediff() 返回两个时间的像个的天数 （距今比较远的为第一个参数，则返回整数）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select datediff(&#39;2011-05-03&#39;,&#39;2010-08-03&#39;);</span><br><span class="line">+-------------------------------------+</span><br><span class="line">| datediff(&#39;2011-05-03&#39;,&#39;2010-08-03&#39;) |</span><br><span class="line">+-------------------------------------+</span><br><span class="line">|                                 273 |</span><br><span class="line">+-------------------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>date常用函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">函数            描述</span><br><span class="line">NOW()        返回当前的日期和时间</span><br><span class="line">CURDATE()    返回当前的日期</span><br><span class="line">CURTIME()    返回当前的时间</span><br><span class="line">DATE()        提取日期或日期&#x2F;时间表达式的日期部分</span><br><span class="line">EXTRACT()    返回日期&#x2F;时间的单独部分</span><br><span class="line">DATE_ADD()    向日期添加指定的时间间隔</span><br><span class="line">DATE_SUB()    从日期减去指定的时间间隔</span><br><span class="line">DATEDIFF()    返回两个日期之间的天数</span><br><span class="line">DATE_FORMAT()    用不同的格式显示日期&#x2F;时间</span><br><span class="line"></span><br><span class="line">mysql&gt; select </span><br><span class="line">    -&gt; DATE_FORMAT(NOW(),&#39;%b %d %Y %h:%i %p&#39;) as date1 ,</span><br><span class="line">    -&gt; DATE_FORMAT(NOW(),&#39;%m-%d-%Y&#39;) as date2,</span><br><span class="line">    -&gt; DATE_FORMAT(NOW(),&#39;%d %b %y&#39;) as date3,</span><br><span class="line">    -&gt; DATE_FORMAT(NOW(),&#39;%d %b %y&#39;) as date4;</span><br><span class="line"></span><br><span class="line">+----------------------+------------+-----------+-----------+</span><br><span class="line">| date1                | date2      | date3     | date4     |</span><br><span class="line">+----------------------+------------+-----------+-----------+</span><br><span class="line">| Nov 05 2017 11:05 PM | 11-05-2017 | 05 Nov 17 | 05 Nov 17 |</span><br><span class="line">+----------------------+------------+-----------+-----------+</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>








]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>sql学习指南</tag>
      </tags>
  </entry>
  <entry>
    <title>《SQL基础》SQL学习指南学习笔记三 索引 事务 约束</title>
    <url>/2017-12-03/SQL%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89%20%E7%B4%A2%E5%BC%95%20%E4%BA%8B%E5%8A%A1%20%E7%BA%A6%E6%9D%9F/</url>
    <content><![CDATA[<h1 id="SQL-约束（Constraints）"><a href="#SQL-约束（Constraints）" class="headerlink" title="SQL 约束（Constraints）"></a>SQL 约束（Constraints）</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>SQL约束用于规定表中的数据规则，如果存在违反约束的数据行为，行为将会被约束终止；</p>
<p>约束可以在创建表时规定，或者在创建表之后通过alter table 语句。</p>
<p>如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">语法：</span><br><span class="line">CREATE TABLE table_name</span><br><span class="line">(</span><br><span class="line">column_name1 data_type(size) constraint_name,</span><br><span class="line">column_name2 data_type(size) constraint_name,</span><br><span class="line">column_name3 data_type(size) constraint_name,</span><br><span class="line"></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">例子：</span><br><span class="line">CREATE TABLE www (</span><br><span class="line">    id INT(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">    name VARCHAR(25) NOT NULL DEFAULT &#39;defaultName&#39;,</span><br><span class="line">    createTime DATETIME NOT NULL,</span><br><span class="line">    PRIMARY KEY (id)</span><br><span class="line">)  ENGINE&#x3D;INNODB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;UTF8;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="约束的种类"><a href="#约束的种类" class="headerlink" title="约束的种类"></a>约束的种类</h2><h3 id="NOT-NULL，非空约束"><a href="#NOT-NULL，非空约束" class="headerlink" title="NOT NULL，非空约束"></a>NOT NULL，非空约束</h3><p>指示某列不能存储 NULL 值。（如果不向字段添加值，就无法插入新记录或者更新记录）<br>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">CREATE TABLE Persons</span><br><span class="line">(</span><br><span class="line">P_Id int NOT NULL,</span><br><span class="line">LastName varchar(255) NOT NULL,</span><br><span class="line">FirstName varchar(255),</span><br><span class="line">Address varchar(255),</span><br><span class="line">City varchar(255)</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="UNIQUE-唯一约束"><a href="#UNIQUE-唯一约束" class="headerlink" title="UNIQUE:唯一约束"></a>UNIQUE:唯一约束</h3><p>保证某列的每行必须有唯一的值。（如果字段中添加的值和库里该字段中的值重复，则无法插入或者更新）</p>
<p>例子1：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt;create table tb2(</span><br><span class="line">    tb2_id int unique,</span><br><span class="line">    tb2_name varchar(20),</span><br><span class="line">    tb2_age int,</span><br><span class="line">    unique(tb2_name)</span><br><span class="line">);</span><br><span class="line">Query OK, 0 rows affected (0.40 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into tb2(tb2_id,tb2_name,tb2_age) values(1,&#39;张三&#39;,20);</span><br><span class="line">Query OK, 1 row affected (0.05 sec)</span><br><span class="line"></span><br><span class="line">例子2：</span><br><span class="line">&#x2F;&#x2F;违反唯一约束</span><br><span class="line">mysql&gt; insert into tb2 values(2,&#39;张三&#39;,25);</span><br><span class="line">ERROR 1062 (23000): Duplicate entry &#39;张三&#39; for key &#39;tb2_name&#39;</span><br><span class="line"></span><br><span class="line">例子3：</span><br><span class="line">&#x2F;&#x2F;建表时，创建约束，有约束名</span><br><span class="line">mysql&gt; create table tb3( tb3_id int,tb3_name varchar(20),tb3_age int, constraint no_id unique (tb3_id));</span><br><span class="line">Query OK, 0 rows affected (0.33 sec)</span><br><span class="line"></span><br><span class="line">insert into tb3 values (1,&#39;张三&#39;,20);</span><br><span class="line">insert into tb3(tb3_id,tb3_age) values(2,24);</span><br><span class="line">select * from tb3;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;已经有了tb3_id为1的行记录，再次插入，违反唯一约束</span><br><span class="line">mysql&gt; insert into tb3(tb3_id,tb3_name,tb3_age) values(1,&#39;李四&#39;,&#39;26&#39;);</span><br><span class="line">ERROR 1062 (23000): Duplicate entry &#39;1&#39; for key &#39;no_id&#39;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;给tb3表添加主键约束，主键名为：pk_id</span><br><span class="line">alter table tb3 add constraint pk_id primary key (tb3_id);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;给tb3_name添加唯一约束</span><br><span class="line">alter table tb3 add constraint un_name unique (tb3_name);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;已存在姓名为张三的记录，违反唯一约束</span><br><span class="line">mysql&gt; insert into tb3 values(3,&#39;张三&#39;,29);</span><br><span class="line">ERROR 1062 (23000): Duplicate entry &#39;张三&#39; for key &#39;un_name&#39;</span><br><span class="line"></span><br><span class="line">删除约束</span><br><span class="line">mysql 删除约束的语句，使用index</span><br><span class="line">alter table tb3 drop index un_name;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="PRIMARY-KEY-主键约束"><a href="#PRIMARY-KEY-主键约束" class="headerlink" title="PRIMARY KEY: 主键约束"></a>PRIMARY KEY: 主键约束</h3><p>NOT NULL 和 UNIQUE 的结合。确保某列（或两个列多个列的结合）有唯一标识，有助于更容易更快速地找到表中的一个特定的记录。</p>
<p>特点：PRIMARY KEY 约束唯一标识数据库表中的每条记录。<br>        主键必须包含唯一的值。<br>        主键列不能包含 NULL 值。<br>        每个表都应该有一个主键，并且每个表只能有一个主键。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">CREATE TABLE Persons</span><br><span class="line">(</span><br><span class="line">P_Id int NOT NULL,</span><br><span class="line">LastName varchar(255) NOT NULL,</span><br><span class="line">FirstName varchar(255),</span><br><span class="line">Address varchar(255),</span><br><span class="line">City varchar(255),</span><br><span class="line">PRIMARY KEY (P_Id)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">需要制定约束名称的，且可以制定多个列的主键约束。</span><br><span class="line"></span><br><span class="line">CREATE TABLE Persons</span><br><span class="line">(</span><br><span class="line">P_Id int NOT NULL,</span><br><span class="line">LastName varchar(255) NOT NULL,</span><br><span class="line">FirstName varchar(255),</span><br><span class="line">Address varchar(255),</span><br><span class="line">City varchar(255),</span><br><span class="line">CONSTRAINT pk_PersonID PRIMARY KEY (P_Id,LastName)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">添加主键约束:</span><br><span class="line">ALTER TABLE Persons</span><br><span class="line">ADD PRIMARY KEY (P_Id)</span><br><span class="line">如需命名 PRIMARY KEY 约束，并定义多个列的 PRIMARY KEY 约束，请使用下面的 SQL 语法：</span><br><span class="line">ALTER TABLE Persons ADD CONSTRAINT pk_personId  PRIMARY KEY (P_id,lastName)</span><br><span class="line"></span><br><span class="line">删除主键约束：</span><br><span class="line">ALTER TABLE Persons</span><br><span class="line">DROP  PRIMARY KEY</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="FOREIGN-KEY-外键约束"><a href="#FOREIGN-KEY-外键约束" class="headerlink" title="FOREIGN KEY: 外键约束"></a>FOREIGN KEY: 外键约束</h3><p>保证一个表中的数据匹配另一个表中的值的参照完整性；</p>
<p>约束用于预防破坏表之间连接的行为；</p>
<p>约束也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一；</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">CREATE TABLE Orders</span><br><span class="line">(</span><br><span class="line">O_Id int NOT NULL,</span><br><span class="line">OrderNo int NOT NULL,</span><br><span class="line">P_Id int,</span><br><span class="line">PRIMARY KEY (O_Id),</span><br><span class="line">FOREIGN KEY (P_Id) REFERENCES Persons(P_Id)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;如需命名 FOREIGN KEY 约束，并定义多个列的 FOREIGN KEY 约束，请使用下面的 SQL 语法：</span><br><span class="line">CREATE TABLE Orders</span><br><span class="line">(</span><br><span class="line">O_Id int NOT NULL,</span><br><span class="line">OrderNo int NOT NULL,</span><br><span class="line">P_Id int,</span><br><span class="line">PRIMARY KEY (O_Id),</span><br><span class="line">CONSTRAINT fk_PerOrders FOREIGN KEY (P_Id)</span><br><span class="line">REFERENCES Persons(P_Id)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;当 &quot;Orders&quot; 表已被创建时，如需在 &quot;P_Id&quot; 列创建 FOREIGN KEY 约束</span><br><span class="line">ALTER TABLE Orders</span><br><span class="line">ADD FOREIGN KEY (P_Id)</span><br><span class="line">REFERENCES Persons(P_Id)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;撤销 FOREIGN KEY 约束</span><br><span class="line">ALTER TABLE Orders</span><br><span class="line">DROP FOREIGN KEY fk_PerOrders</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="CHECK-检查约束"><a href="#CHECK-检查约束" class="headerlink" title="CHECK :检查约束"></a>CHECK :检查约束</h3><p>如果对单个列定义 CHECK 约束，那么该列只允许特定的值。 保证列中的值符合指定的条件。</p>
<p>如果对一个表定义 CHECK 约束，那么此约束会基于行中其他列的值在特定的列中对值进行限制。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">下面的 SQL 在 &quot;Persons&quot; 表创建时在 &quot;P_Id&quot; 列上创建 CHECK 约束。CHECK 约束规定 &quot;P_Id&quot; 列必须只包含大于 0 的整数。</span><br><span class="line">CREATE TABLE Persons</span><br><span class="line">(</span><br><span class="line">P_Id int NOT NULL,</span><br><span class="line">LastName varchar(255) NOT NULL,</span><br><span class="line">FirstName varchar(255),</span><br><span class="line">Address varchar(255),</span><br><span class="line">City varchar(255),</span><br><span class="line">CHECK (P_Id&gt;0)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;添加CHECK约束</span><br><span class="line">ALTER TABLE Persons</span><br><span class="line">ADD CHECK (P_Id&gt;0)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;删除约束</span><br><span class="line">ALTER TABLE Persons</span><br><span class="line">DROP CHECK chk_Person</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="DEFAULT-规定没有给列赋值时的默认值。"><a href="#DEFAULT-规定没有给列赋值时的默认值。" class="headerlink" title="DEFAULT - 规定没有给列赋值时的默认值。"></a>DEFAULT - 规定没有给列赋值时的默认值。</h3><p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">CREATE TABLE Persons</span><br><span class="line">(</span><br><span class="line">P_Id int NOT NULL,</span><br><span class="line">LastName varchar(255) NOT NULL,</span><br><span class="line">FirstName varchar(255),</span><br><span class="line">Address varchar(255),</span><br><span class="line">City varchar(255) DEFAULT &#39;Sandnes&#39;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;创建DEFAULT约束</span><br><span class="line">ALTER TABLE Persons</span><br><span class="line">ALTER City SET DEFAULT &#39;SANDNES&#39;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;如需撤销 DEFAULT 约束</span><br><span class="line">ALTER TABLE Persons</span><br><span class="line">ALTER City DROP DEFAULT</span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">每个表可以有多个 UNIQUE 约束，但是每个表只能有一个 PRIMARY KEY 约束。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="AUTO-INCREMENT"><a href="#AUTO-INCREMENT" class="headerlink" title="AUTO INCREMENT"></a>AUTO INCREMENT</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">该字段会使得每次新纪录插入表中时，生成唯一的数字。</span><br><span class="line">可以通过 alter table persons auto_increment&#x3D;100; 将自增值置为需要的值。</span><br><span class="line"></span><br><span class="line">例子：</span><br><span class="line">mysql&gt; create table persons(ID int not null auto_increment,lastName varchar(255) not null ,city varchar(255), PRIMARY KEY(ID));</span><br><span class="line">Query OK, 0 rows affected (0.29 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into persons(lastName,city) values(&#39;zhangsan&#39;,&#39;beijing&#39;);</span><br><span class="line">Query OK, 1 row affected (0.04 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from persons;</span><br><span class="line">+----+----------+---------+</span><br><span class="line">| ID | lastName | city    |</span><br><span class="line">+----+----------+---------+</span><br><span class="line">|  1 | zhangsan | beijing |</span><br><span class="line">+----+----------+---------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; alter table persons auth_increment&#x3D;100;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mysql&gt; insert into persons(lastName,city) values(&#39;lisi&#39;,&#39;handan&#39;);</span><br><span class="line">Query OK, 1 row affected (0.05 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from persons;</span><br><span class="line">+-----+----------+---------+</span><br><span class="line">| ID  | lastName | city    |</span><br><span class="line">+-----+----------+---------+</span><br><span class="line">|   1 | zhangsan | beijing |</span><br><span class="line">| 100 | lisi     | handan  |</span><br><span class="line">+-----+----------+---------+</span><br><span class="line">2 rows in set (0.01 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="级联约束"><a href="#级联约束" class="headerlink" title="级联约束"></a>级联约束</h2><p>有了合适的外键约束后，如果读者视图插入新行或者修改行而导致父表中的外键列并无匹配值，则服务器会抛出异常</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select * from product;</span><br><span class="line">+------------+-------------------------+-----------------+--------------+--------------+</span><br><span class="line">| product_cd | name                    | product_type_cd | date_offered | date_retired |</span><br><span class="line">+------------+-------------------------+-----------------+--------------+--------------+</span><br><span class="line">| AUT        | auto loan               | LOAN            | 2000-01-01   | NULL         |</span><br><span class="line">| BUS        | business line of credit | LOAN            | 2000-01-01   | NULL         |</span><br><span class="line">| CD         | certificate of deposit  | ACCOUNT         | 2000-01-01   | NULL         |</span><br><span class="line">| CHK        | checking account        | ACCOUNT         | 2000-01-01   | NULL         |</span><br><span class="line">| MM         | money market account    | ACCOUNT         | 2000-01-01   | NULL         |</span><br><span class="line">| MRT        | home mortgage           | LOAN            | 2000-01-01   | NULL         |</span><br><span class="line">| SAV        | savings account         | ACCOUNT         | 2000-01-01   | NULL         |</span><br><span class="line">| SBL        | small business loan     | LOAN            | 2000-01-01   | NULL         |</span><br><span class="line">+------------+-------------------------+-----------------+--------------+--------------+</span><br><span class="line">8 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from product_type;</span><br><span class="line">+-----------------+-------------------------------+</span><br><span class="line">| product_type_cd | name                          |</span><br><span class="line">+-----------------+-------------------------------+</span><br><span class="line">| ACCOUNT         | Customer Accounts             |</span><br><span class="line">| INSURANCE       | Insurance Offerings           |</span><br><span class="line">| LOAN            | Individual and Business Loans |</span><br><span class="line">+-----------------+-------------------------------+</span><br><span class="line">3 rows in set (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; update product set product_type_cd &#x3D;&#39;xyz&#39; where product_type_cd &#x3D;&#39;LOAN&#39;;</span><br><span class="line">ERROR 1452 (23000): Cannot add or update a child row: a foreign key constraint fails (&#96;bank&#96;.&#96;product&#96;, CONSTRAINT &#96;fk_product_type_cd&#96; FOREIGN KEY (&#96;product_type_cd&#96;) REFERENCES &#96;product_type&#96; (&#96;product_type_cd&#96;))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在product.product_type_cd列上有外键约束，而product_type表中没有哪一行的product_type_cd的列值为xyz，所有不会更新成功。<br>所谓级联的更新，在删除存在的外键和添加新的外键时包含on update cascade，这些外键约束的变化能够实现传播。</p>
<p>需要做以下修改</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">alter table product add constraint fk_product_type_cd foreign key (product_type_cd) references product_type(product_type_cd) on update cascade;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="SQL索引-INDEX"><a href="#SQL索引-INDEX" class="headerlink" title="SQL索引 INDEX"></a>SQL索引 INDEX</h1><p>CREATE INDEX 语句用于在表中创建索引，在不读取整个表的情况下，索引数据库应用程序可以更快的查找数据。</p>
<p>更新一个包含索引的表需要比更新一个没有索引的表花费更多的时间，这是由于索引本身也需要更新。</p>
<p>索引并不包含实体中的所有数据，而是那些用于定位表中的数据的列，以及描述行信息的列。</p>
<p>innodb引擎是支持事务的行锁引擎；mylsam引擎是不支持事务的表锁引擎，它支持全文索引（文本索引）</p>
<p>一般的索引为b树索引（平衡树索引） 它有一个或者多个分之节点，分之节点又指向单级叶子节点。分支节点用于遍历树，叶节点则保存真正的值和位置信息 。</p>
<h2 id="显示查询执行计划-（待完善）"><a href="#显示查询执行计划-（待完善）" class="headerlink" title="显示查询执行计划 （待完善）"></a>显示查询执行计划 （待完善）</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; explain select * from account where cust_id in(1,5,9,11);</span><br><span class="line">+----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-------------+</span><br><span class="line">| id | select_type | table   | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |</span><br><span class="line">+----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-------------+</span><br><span class="line">|  1 | SIMPLE      | account | NULL       | ALL  | fk_a_cust_id  | NULL | NULL    | NULL |   24 |    33.33 | Using where |</span><br><span class="line">+----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-------------+</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="单列索引"><a href="#单列索引" class="headerlink" title="单列索引"></a>单列索引</h2><p> 下面的 SQL 语句在 “Persons” 表的 “LastName” 列上创建一个名为 “PIndex” 的索引：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE INDEX PIndex ON Persons(LastName);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="唯一索引"><a href="#唯一索引" class="headerlink" title="唯一索引"></a>唯一索引</h2><p>除了常规的索引的用途外，还可以限制索引列出现重复值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; alter table department add unique dept_name_unique_idx(name);</span><br><span class="line">Query OK, 0 rows affected (0.43 sec)</span><br><span class="line">Records: 0  Duplicates: 0  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; show index from department;</span><br><span class="line">+------------+------------+----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| Table      | Non_unique | Key_name             | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |</span><br><span class="line">+------------+------------+----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| department |          0 | PRIMARY              |            1 | dept_id     | A         |           2 |     NULL | NULL   |      | BTREE      |         |               |</span><br><span class="line">| department |          0 | dept_name_unique_idx |            1 | name        | A         |           2 |     NULL | NULL   |      | BTREE      |         |               |</span><br><span class="line">| department |          1 | dept_name_idx        |            1 | name        | A         |           2 |     NULL | NULL   |      | BTREE      |         |               |</span><br><span class="line">+------------+------------+----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="多列索引"><a href="#多列索引" class="headerlink" title="多列索引"></a>多列索引</h2><p> 如果您希望索引不止一个列，您可以在括号中列出这些列的名称，用逗号隔开：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  CREATE INDEX PIndex ON Persons(LastName,FirstName);</span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">mysql&gt; alter table employee add index emp_name_idx(lname,fname);</span><br><span class="line">Query OK, 0 rows affected (0.37 sec)</span><br><span class="line">Records: 0  Duplicates: 0  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; show index from employee;</span><br><span class="line">+----------+------------+----------------+--------------+--------------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| Table    | Non_unique | Key_name       | Seq_in_index | Column_name        | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |</span><br><span class="line">+----------+------------+----------------+--------------+--------------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| employee |          0 | PRIMARY        |            1 | emp_id             | A         |          18 |     NULL | NULL   |      | BTREE      |         |               |</span><br><span class="line">| employee |          1 | fk_e_emp_id    |            1 | superior_emp_id    | A         |           7 |     NULL | NULL   | YES  | BTREE      |         |               |</span><br><span class="line">| employee |          1 | fk_dept_id     |            1 | dept_id            | A         |           3 |     NULL | NULL   | YES  | BTREE      |         |               |</span><br><span class="line">| employee |          1 | fk_e_branch_id |            1 | assigned_branch_id | A         |           4 |     NULL | NULL   | YES  | BTREE      |         |               |</span><br><span class="line">| employee |          1 | emp_name_idx   |            1 | lname              | A         |          18 |     NULL | NULL   |      | BTREE      |         |               |</span><br><span class="line">| employee |          1 | emp_name_idx   |            2 | fname              | A         |          18 |     NULL | NULL   |      | BTREE      |         |               |</span><br><span class="line">+----------+------------+----------------+--------------+--------------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在创建多列索引时，必须仔细考虑那一列作为第一列，那一列作为第二列。</p>
<h2 id="添加索引"><a href="#添加索引" class="headerlink" title="添加索引"></a>添加索引</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; alter table department add index dept_name_idx(name);</span><br><span class="line">Query OK, 0 rows affected (0.35 sec)</span><br><span class="line">Records: 0  Duplicates: 0  Warnings: 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; alter table department drop index dept_name_idx;</span><br><span class="line">Query OK, 0 rows affected (0.20 sec)</span><br><span class="line">Records: 0  Duplicates: 0  Warnings: 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="查看索引"><a href="#查看索引" class="headerlink" title="查看索引"></a>查看索引</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; show index from department;</span><br><span class="line">+------------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| Table      | Non_unique | Key_name      | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |</span><br><span class="line">+------------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| department |          0 | PRIMARY       |            1 | dept_id     | A         |           2 |     NULL | NULL   |      | BTREE      |         |               |</span><br><span class="line">| department |          1 | dept_name_idx |            1 | name        | A         |           2 |     NULL | NULL   |      | BTREE      |         |               |</span><br><span class="line">+------------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="索引的使用"><a href="#索引的使用" class="headerlink" title="索引的使用"></a>索引的使用</h2><p>每一个索引实际上都是一个特殊的表，每次在添加或者删除行时，表中的所有索引都被修改。当数据越来越多时，会拖慢服务器的处理速度</p>
<p>仅仅当出现清晰需求时才添加索引。</p>
<p>如有特殊需求需要索引，可以添加索引，运行程序，然后删除索引。下次也是如此。</p>
<p><strong>默认策略</strong></p>
<ol>
<li>确保所有的逐渐被索引，大部分数据库服务器在创建主键约束的时候会自动生成唯一索引；</li>
<li>为所有被外键约束引用的列创建索引。在服务器准备删除父行时会搜索对应的子行是否存在，它必须发出一个查询搜索列中的特殊值。</li>
<li>大多是日期可以作为索引；</li>
</ol>
<h1 id="CREATE-VIEW-视图"><a href="#CREATE-VIEW-视图" class="headerlink" title="CREATE VIEW 视图"></a>CREATE VIEW 视图</h1><p>视图是基于 SQL 语句的结果集的可视化的表，不同于表的是，视图不涉及数据存储，因此用户不必担心数据会充满磁盘空间、</p>
<p>视图包含行和列，就像一个真实的表。视图中的字段就是来自一个或多个数据库中的真实的表中的字段。</p>
<p>您可以向视图添加 SQL 函数、WHERE 以及 JOIN 语句，也可以呈现数据，就像这些数据来自于某个单一的表一样。</p>
<h2 id="视图的使用情况"><a href="#视图的使用情况" class="headerlink" title="视图的使用情况"></a>视图的使用情况</h2><ol>
<li>可以保证数据的安全性；</li>
<li>数据聚合；</li>
<li>隐藏复杂性；</li>
<li>连接分区数据；</li>
</ol>
<h2 id="创建视图"><a href="#创建视图" class="headerlink" title="创建视图"></a>创建视图</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE VIEW view_name AS</span><br><span class="line">SELECT column_name(s)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE condition</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>视图总是显示最新的数据！每当用户查询视图时，数据库引擎通过使用视图的 SQL 语句重建数据。</p>
<h2 id="查看视图"><a href="#查看视图" class="headerlink" title="查看视图"></a>查看视图</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">SELECT * from view_name;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="更新视图"><a href="#更新视图" class="headerlink" title="更新视图"></a>更新视图</h2><p>满足以下条件，视图则可以被更新。</p>
<ol>
<li>没有使用聚合函数；</li>
<li>没有使用having 或者group by语句；</li>
<li>没有使用union all 、union、distinct语句；</li>
<li>from包括不止一个表或者视图；</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">CREATE OR REPLACE VIEW view_name AS</span><br><span class="line">SELECT column_name(s)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE condition</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="撤销视图"><a href="#撤销视图" class="headerlink" title="撤销视图"></a>撤销视图</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DROP VIEW view_name;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">create view viewTest as select * from persons where ID&gt;10;</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from viewTest;</span><br><span class="line">+-----+----------+--------+</span><br><span class="line">| ID  | lastName | city   |</span><br><span class="line">+-----+----------+--------+</span><br><span class="line">| 100 | lisi     | handan |</span><br><span class="line">+-----+----------+--------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; drop view viewTest;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from viewTest;</span><br><span class="line">ERROR 1146 (42S02): Table &#39;testDB.viewTest&#39; doesn&#39;t exist</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><ol>
<li><p>事务是指，一堆sql要么执行，要么执行，这成为原子性。</p>
</li>
<li><p>说到事务，就必须提锁。锁时数据库服务器用来控制数据资源被并行使用的一种机制。</p>
</li>
<li><p>数据库的写操作必须向服务器申请写锁才能够修改数据。而读操作必须获得读锁才能读取数据。</p>
</li>
<li><p>读写锁是指，一次事务只能有一个写锁不能有读锁或者多个读锁不能有写锁。</p>
</li>
<li><p>服务器要保证从查询开始到查询结束看到一个一致性的数据视图。这个方法成为版本控制。</p>
</li>
<li><p>锁的粒度分为表锁、页锁、行锁。</p>
</li>
<li><p>表锁需要较少的簿记就可以锁定整个表，但是用户增多时他会迅速产生不可接受的等待时间；行锁需要更多的簿记，但是各个用户在不同的行，允许多个用户同时修改一个表。</p>
</li>
<li><p>如果不显式的启动一个事务，单个sql会被独立于其它语句自动提交。启动事务必须先提交一个命令。</p>
</li>
<li><p>mysql服务器时默认的自动提交事务，但是可以修改。</p>
</li>
<li><p>rollback事务回滚，commit提交事务</p>
</li>
</ol>
<p>关于意外情况</p>
<ol>
<li>服务器宕机，服务器重启时事务会自动回滚；</li>
<li>提交一个SQL模式语句，比如alter table会引起当前事务提交和新事务的启动；</li>
<li>提交一个start transcation命令，将会引起一个新事务提交；</li>
<li>因为服务器检测到一个思索并且确定当前事务就是罪魁祸首，则服务器会结束当前事务，然后事务将会被回滚，同时释放错误信息。</li>
</ol>
<h1 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h1><h3 id="元数据的类型"><a href="#元数据的类型" class="headerlink" title="元数据的类型"></a>元数据的类型</h3><ol>
<li>表名</li>
<li>表存储信息（表空间、初始值大小）</li>
<li>存储引擎</li>
<li>列名</li>
<li>列数据类型</li>
<li>默认值</li>
<li>非空列约束</li>
<li>主键列</li>
<li>主键名</li>
<li>主键索引名</li>
<li>索引名</li>
<li>索引类型</li>
<li>索引列</li>
<li>索引列排序顺序</li>
<li>索引存储信息</li>
<li>外键名</li>
<li>外键列</li>
<li>外键的关联表</li>
</ol>
<h3 id="视图的信息模式"><a href="#视图的信息模式" class="headerlink" title="视图的信息模式"></a>视图的信息模式</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select * from information_schema.tables where table_schema&#x3D;&#39;bank&#39; order by 1;</span><br><span class="line">+---------------+--------------+-----------------+------------+--------+---------+------------+------------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+----------------+---------------+</span><br><span class="line">| TABLE_CATALOG | TABLE_SCHEMA | TABLE_NAME      | TABLE_TYPE | ENGINE | VERSION | ROW_FORMAT | TABLE_ROWS | AVG_ROW_LENGTH | DATA_LENGTH | MAX_DATA_LENGTH | INDEX_LENGTH | DATA_FREE | AUTO_INCREMENT | CREATE_TIME         | UPDATE_TIME         | CHECK_TIME | TABLE_COLLATION   | CHECKSUM | CREATE_OPTIONS | TABLE_COMMENT |</span><br><span class="line">+---------------+--------------+-----------------+------------+--------+---------+------------+------------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+----------------+---------------+</span><br><span class="line">| def           | bank         | customer_viewer | VIEW       | NULL   |    NULL | NULL       |       NULL |           NULL |        NULL |            NULL |         NULL |      NULL |           NULL | NULL                | NULL                | NULL       | NULL              |     NULL | NULL           | VIEW          |</span><br><span class="line">| def           | bank         | customer        | BASE TABLE | InnoDB |      10 | Dynamic    |         11 |           1489 |       16384 |               0 |            0 |         0 |             14 | 2017-11-11 23:46:08 | NULL                | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | business        | BASE TABLE | InnoDB |      10 | Dynamic    |          4 |           4096 |       16384 |               0 |            0 |         0 |           NULL | 2017-11-11 23:46:08 | NULL                | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | transaction     | BASE TABLE | InnoDB |      10 | Dynamic    |         21 |            780 |       16384 |               0 |        49152 |         0 |             22 | 2017-11-11 23:46:10 | NULL                | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | branch          | BASE TABLE | InnoDB |      10 | Dynamic    |          4 |           4096 |       16384 |               0 |            0 |         0 |              5 | 2017-11-11 23:46:06 | NULL                | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | product_type    | BASE TABLE | InnoDB |      10 | Dynamic    |          3 |           5461 |       16384 |               0 |            0 |         0 |           NULL | 2017-11-11 23:46:07 | NULL                | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | account         | BASE TABLE | InnoDB |      10 | Dynamic    |         24 |            682 |       16384 |               0 |        65536 |         0 |             30 | 2017-11-11 23:46:09 | 2017-12-01 00:09:25 | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | product         | BASE TABLE | InnoDB |      10 | Dynamic    |          8 |           2048 |       16384 |               0 |        16384 |         0 |           NULL | 2017-12-03 02:17:13 | 2017-12-03 02:17:13 | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | officer         | BASE TABLE | InnoDB |      10 | Dynamic    |          4 |           4096 |       16384 |               0 |        16384 |         0 |              5 | 2017-11-11 23:46:09 | NULL                | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | individual      | BASE TABLE | InnoDB |      10 | Dynamic    |          9 |           1820 |       16384 |               0 |            0 |         0 |           NULL | 2017-11-11 23:46:08 | NULL                | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | employee_vw     | VIEW       | NULL   |    NULL | NULL       |       NULL |           NULL |        NULL |            NULL |         NULL |      NULL |           NULL | NULL                | NULL                | NULL       | NULL              |     NULL | NULL           | VIEW          |</span><br><span class="line">| def           | bank         | employee        | BASE TABLE | InnoDB |      10 | Dynamic    |         18 |            910 |       16384 |               0 |        49152 |         0 |             19 | 2017-12-03 01:19:37 | NULL                | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">| def           | bank         | department      | BASE TABLE | InnoDB |      10 | Dynamic    |          2 |           8192 |       16384 |               0 |            0 |         0 |              4 | 2017-12-03 01:17:04 | NULL                | NULL       | latin1_swedish_ci |     NULL |                |               |</span><br><span class="line">+---------------+--------------+-----------------+------------+--------+---------+------------+------------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------------+----------+----------------+---------------+</span><br><span class="line">13 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="information-schema数据库表说明"><a href="#information-schema数据库表说明" class="headerlink" title="information_schema数据库表说明:"></a>information_schema数据库表说明:</h3><p>　　information_schema数据库是MySQL自带的，它提供了访问数据库元数据的方式。什么是元数据呢？元数据是关于数据的数据，如数据库名或表名，列的数据类型，或访问权限等。有些时候用于表述该信息的其他术语包括“数据词典”和“系统目录”。<br>　　在MySQL中，把 information_schema 看作是一个数据库，确切说是信息数据库。其中保存着关于MySQL服务器所维护的所有其他数据库的信息。如数据库名，数据库的表，表栏的数据类型与访问权 限等。在INFORMATION_SCHEMA中，有数个只读表。它们实际上是视图，而不是基本表，因此，你将无法看到与之相关的任何文件。</p>
<p><strong>SCHEMATA表</strong>：提供了当前mysql实例中所有数据库的信息。是show databases的结果取之此表。</p>
<p><strong>TABLES表</strong>：提供了关于数据库中的表的信息（包括视图）。详细表述了某个表属于哪个schema，表类型，表引擎，创建时间等信息。是show tables from schemaname的结果取之此表。</p>
<p><strong>COLUMNS表</strong>：提供了表中的列信息。详细表述了某张表的所有列以及每个列的信息。是show columns from schemaname.tablename的结果取之此表。</p>
<p><strong>STATISTICS表</strong>：提供了关于表索引的信息。是show index from schemaname.tablename的结果取之此表。</p>
<p><strong>USER_PRIVILEGES</strong>（用户权限）表：给出了关于全程权限的信息。该信息源自mysql.user授权表。是非标准表。</p>
<p><strong>SCHEMA_PRIVILEGES</strong>（方案权限）表：给出了关于方案（数据库）权限的信息。该信息来自mysql.db授权表。是非标准表。</p>
<p><strong>TABLE_PRIVILEGES</strong>（表权限）表：给出了关于表权限的信息。该信息源自mysql.tables_priv授权表。是非标准表。</p>
<p><strong>COLUMN_PRIVILEGES</strong>（列权限）表：给出了关于列权限的信息。该信息源自mysql.columns_priv授权表。是非标准表。</p>
<p><strong>CHARACTER_SETS</strong>（字符集）表：提供了mysql实例可用字符集的信息。是SHOW CHARACTER SET结果集取之此表。</p>
<p><strong>COLLATIONS表</strong>：提供了关于各字符集的对照信息。</p>
<p><strong>COLLATION_CHARACTER_SET_APPLICABILITY</strong>表：指明了可用于校对的字符集。这些列等效于SHOW COLLATION的前两个显示字段。</p>
<p><strong>TABLE_CONSTRAINTS</strong>表：描述了存在约束的表。以及表的约束类型。</p>
<p><strong>KEY_COLUMN_USAGE</strong>表：描述了具有约束的键列。</p>
<p><strong>ROUTINES</strong>表：提供了关于存储子程序（存储程序和函数）的信息。此时，ROUTINES表不包含自定义函数（UDF）。名为“mysql.proc name”的列指明了对应于INFORMATION_SCHEMA.ROUTINES表的mysql.proc表列。</p>
<p><strong>VIEWS</strong>表：给出了关于数据库中的视图的信息。需要有show views权限，否则无法查看视图信息。</p>
<p><strong>TRIGGERS</strong>表：提供了关于触发程序的信息。必须有super权限才能查看该表于触发程序的信息。必须有super权限才能查看该表</p>
]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>sql 学习指南</tag>
      </tags>
  </entry>
  <entry>
    <title>elasticsearch入门教程</title>
    <url>/2018-01-18/elasticsearch%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h1><p>有一张答题记录表，主要字段如下。由于数据量比较大，所以按照学员id的后两位横向分表为100张表。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#96;id&#96; int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">&#96;stu_id&#96; int(11) NOT NULL COMMENT &#39;学员id&#39;,</span><br><span class="line">&#96;stu_total_score&#96; decimal(4,1) DEFAULT NULL COMMENT &#39;学员得分&#39;,, </span><br><span class="line">&#96;t_paper_id&#96; int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;试卷id&#39;,</span><br><span class="line">&#96;total_time&#96; int(11) DEFAULT NULL COMMENT &#39;答题总用时，单位为s&#39;,</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>有一需求，需要实时的根据stu_id获取该学员的paperId下的排名，以及学员排行榜（前10名），规则是按照分数降序、答题时间升序。</p>
<p>方案一：用union all 关键字关联100张表（是按照stu_id分表的），进行排序。然后获取学员的名次和排行榜。（由于数据量巨大，这种方案显然是不可取的）</p>
<p>方案二：使用redis的sorted set类型存储数据，但是细想其实 sorted set只能以一个字段作为排序字段，也是不可取的</p>
<p>方案三: 使用es，将所有的数据入es。</p>
<p>后续在生产环境使用es，由于有实时的查询排行榜的需求，所以在index数据入es的时候，实时的setRefresh操作，这样，在并发量比较大的时候，造成es响应很慢，大概50至60秒。</p>
<p>后来翻阅相关资料，发现es其实根本不适合做排序相关的排行榜需求，我们可以使用redis，将排序的2个字段加权后作为sorted set的score，实时证明，redis才是非常适合做实时排序相关功能的。</p>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="近实时："><a href="#近实时：" class="headerlink" title="近实时："></a>近实时：</h2><p>Elasticsearch 是一个接近实时的搜索平台。这意味着，从索引一个文档直到这个文档能够被搜索到有一个很小的延迟（通常是 1 秒）。</p>
<h2 id="集群（cluster）："><a href="#集群（cluster）：" class="headerlink" title="集群（cluster）："></a>集群（cluster）：</h2><p>一个集群就是由一个或多个节点组织在一起， 它们共同持有你全部的数据， 并一起<strong>提供索引和搜索功能</strong>。 一个集群由一个唯一的名字标识， 这个名字默认就是“elasticsearch”。 这个名字很重要， 因为一个节点只能通过指定某个集群的名字，来加入这个集群。一个集群中只包含一个节点是合法的。另外，你也可以拥有多个集群，集群以名字区分。</p>
<h2 id="节点（node）："><a href="#节点（node）：" class="headerlink" title="节点（node）："></a>节点（node）：</h2><p>一个节点是你集群中的一个服务器，作为集群的一部分，它存储你的数据，参与集群的索引和搜索功能。 和集群类似， 一个节点也是由一个名字来标识的， 默认情况下， 这个名字是一个随机的Marvel角色的名字，这个名字会在节点启动时分配给它。一个节点可以通过配置集群名称的方式来加入一个指定的集群。 默认情况下，每个节点都会被安排加入到一个叫做“elasticsearch”的集群中，这意味着，如果你在你的网络中启动了若干个节点， 并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做“elasticsearch” 的集群中。</p>
<p> <strong>注意：</strong>如果当前你的网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的单节点集群。</p>
<h2 id="索引（index）"><a href="#索引（index）" class="headerlink" title="索引（index）:"></a>索引（index）:</h2><p>一个索引就是一个拥有相似特征的文档的集合。(相当于mysql的db) 。一个索引由一个名字来 标识（必须全部是小写字母的）</p>
<h2 id="类型（type）："><a href="#类型（type）：" class="headerlink" title="类型（type）："></a>类型（type）：</h2><p>在一个索引中，你可以定义一种或多种类型。（相当于mysql的table）一个类型是你的索引的一个逻辑上的分类/分区，其语义完全由你来定。通常，会为具有一组相同字段的文档定义一个类型。</p>
<h2 id="文档（document）："><a href="#文档（document）：" class="headerlink" title="文档（document）："></a>文档（document）：</h2><p>一个文档是一个可被索引的基础信息单元。（相当于mysql的一条数据）文档以JSON格式来表示</p>
<h2 id="分片和复制（shards-and-replicas）："><a href="#分片和复制（shards-and-replicas）：" class="headerlink" title="分片和复制（shards and replicas）："></a>分片和复制（shards and replicas）：</h2><h3 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h3><p>一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点可能<strong>没有这样大的磁盘空间</strong>来存储或者<strong>单个节点处理搜索请求，响应会太慢</strong>。</p>
<ol>
<li>允许你水平分割/扩展你的内容容量</li>
<li>允许你在分片（位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量</li>
</ol>
<p>当你创建一个索引的时候，你可以指定你想要的分片的数量。</p>
<h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><ol>
<li>在分片/节点失败的情况下，复制提供了高可用性。复制分片不与原/主要分片置于同一节点上是非常重要的。</li>
<li>因为搜索可以在所有的复制上并行运行，复制可以扩展你的搜索量/吞吐量</li>
</ol>
<p>分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你不能再改变分片的数量。</p>
<p>默认情况下，Elasticsearch中的每个索引分配5个主分片和1个复制。这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样每个索引总共就有10个分片。</p>
<h1 id="安装-（待补充）"><a href="#安装-（待补充）" class="headerlink" title="安装 （待补充）"></a>安装 （待补充）</h1><p>需要jdk1.7 +  </p>
<p><a href="https://www.elastic.co/downloads/elasticsearch">下载 tar包</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -xvf *.tar.gz</span><br><span class="line">cd bin</span><br><span class="line">.&#x2F;elasticsearch</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="操作集群"><a href="#操作集群" class="headerlink" title="操作集群"></a>操作集群</h1><h2 id="查看集群健康"><a href="#查看集群健康" class="headerlink" title="查看集群健康"></a>查看集群健康</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">get请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;_cat&#x2F;health?v</span><br><span class="line"></span><br><span class="line">epoch      timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent </span><br><span class="line">1516295539 01:12:19  ENT-ES  yellow          1         1     51  51    0    0       51             0                  -                 50.0% </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我们可能得到绿色、黄色或红色三种状态。绿色代表一切正常（集群功能齐全）；黄色意味着所有的数据都是可用的，但是某些复制没有被分配（集群功能齐全）； 红色则代表因为某些原因，某些数据不可用,但是可能你需要尽快修复它，因为你有丢失的数据。</p>
<h2 id="集群节点"><a href="#集群节点" class="headerlink" title="集群节点"></a>集群节点</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;_cat&#x2F;nodes?v</span><br><span class="line"></span><br><span class="line">host           ip             heap.percent ram.percent load node.role master name     </span><br><span class="line">172.16.116.121 172.16.116.121           36          91 0.81 d         *      TEST_ENT </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>TEST_ENT代表的是节点的名称</p>
<h2 id="列出索引"><a href="#列出索引" class="headerlink" title="列出索引"></a>列出索引</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;_cat&#x2F;indices?v</span><br><span class="line"></span><br><span class="line">health status index                         pri rep docs.count docs.deleted store.size pri.store.size </span><br><span class="line">yellow open   teacher_platform_unit           5   1       6634           17      2.3mb          2.3mb </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="添加索引"><a href="#添加索引" class="headerlink" title="添加索引"></a>添加索引</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;?pretty</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot;: true</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">get请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;_cat&#x2F;indices?v</span><br><span class="line"></span><br><span class="line">health status index                         pri rep docs.count docs.deleted store.size pri.store.size </span><br><span class="line">yellow open   customer                        5   1          0            0       650b           650b </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>我们现在有一个叫做 customer 的索引，并且它有5个主分片和1份复制（都是默认值），其中包含0个文档。</p>
<p>由于现在我们只有一个节点在运行，那一份复制就分配不了了（为了高可用），直到当另外一个节点加入到这个集群后，才能分配。一旦那份复制在第二个节点上被复制，这个节点(黄色)的健康状态就会变成绿色。</p>
<h2 id="索引文档"><a href="#索引文档" class="headerlink" title="索引文档"></a>索引文档</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">put请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;external&#x2F;1?pretty </span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;John Doe&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot;: 1,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 2,</span><br><span class="line">    &quot;successful&quot;: 1,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot;: true</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>当你想将文档索引到某个索引的时候，Elasticsearch并不强制要求这个索引被显式地创建。在前面这个例子中，如果customer索引不存在，Elasticsearch将会自动地创建这个索引。</p>
<h2 id="查询文档"><a href="#查询文档" class="headerlink" title="查询文档"></a>查询文档</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">get请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;external&#x2F;1?pretty</span><br><span class="line"></span><br><span class="line">response:</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot;: 1,</span><br><span class="line">  &quot;found&quot;: true,</span><br><span class="line">  &quot;_source&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;John Doe&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">delete请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;external&#x2F;1?pretty</span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;found&quot;: true,</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot;: 2,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 2,</span><br><span class="line">    &quot;successful&quot;: 1,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">get请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;external&#x2F;1?pretty</span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;found&quot;: false</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">delete请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;?pretty</span><br><span class="line"></span><br><span class="line">response:</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot;: true</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="修改数据"><a href="#修改数据" class="headerlink" title="修改数据"></a>修改数据</h2><p>默认情况下，从你索引/更新/删除你的数据动作开始到它出现在你的搜索结果中，大概会有1秒钟的延迟。这和其它的SQL平台不同，它们的数据在一个事务完成之后就会立即可用。</p>
<p>修改前的数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get请求：</span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;external&#x2F;2?pretty  -d</span><br><span class="line"></span><br><span class="line">response:</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;2&quot;,</span><br><span class="line">  &quot;_version&quot;: 2,</span><br><span class="line">  &quot;found&quot;: true,</span><br><span class="line">  &quot;_source&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;John Smith&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>使用一个新的document来修改id为2的数据（replace）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">put请求：</span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;external&#x2F;2?pretty  -d</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;John Wall&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;2&quot;,</span><br><span class="line">  &quot;_version&quot;: 3,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 2,</span><br><span class="line">    &quot;successful&quot;: 1,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot;: false</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>id是可选的，如果不指定，则es会产生一个随机的id。由于没有指定id，则使用的是post请求：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">post请求:</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;external&#x2F;?pretty  -d</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;chenweijie&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;AWEM3CUozADEKUeU9hxP&quot;,</span><br><span class="line">  &quot;_version&quot;: 1,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 2,</span><br><span class="line">    &quot;successful&quot;: 1,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot;: true</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h2><p>Elasticsearch底层并不支持原地更新。在我们想要做一次更新的时候，Elasticsearch先删除旧文档，然后再索引更新的新文档。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">post请求：</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;external&#x2F;1&#x2F;_update?pretty</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Ball&quot;, &quot;age&quot;: 20 &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response:</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot;: 3,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 0,</span><br><span class="line">    &quot;successful&quot;: 0,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="搜索API-（复杂查询）"><a href="#搜索API-（复杂查询）" class="headerlink" title="搜索API （复杂查询）"></a>搜索API （复杂查询）</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REST API 可以通过_search终点(endpoint)来访问</span><br><span class="line"></span><br><span class="line">get请求：</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;_search?q&#x3D;*&amp;pretty</span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 18,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 5,</span><br><span class="line">    &quot;successful&quot;: 5,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 3,</span><br><span class="line">    &quot;max_score&quot;: 1,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;AWEM3CUozADEKUeU9hxP&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;chenweijie&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;2&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;John Wall&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;John tes&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以上搜索等价于 请求体方法的等价搜索是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">post请求</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;customer&#x2F;_search?pretty</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 1,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 5,</span><br><span class="line">    &quot;successful&quot;: 5,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 3,</span><br><span class="line">    &quot;max_score&quot;: 1,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;AWEM3CUozADEKUeU9hxP&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;chenweijie&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;2&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;John Wall&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;customer&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;external&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;John tes&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>我们在customer索引中搜索（ _search终点），并且q=*参数指示Elasticsearch去匹配这个索引中所有的文档。pretty参数仅仅是告诉Elasticsearch返回美观的JSON结果。</p>
<ul>
<li>took：Elasticsearch 执行这个搜索的耗时，以毫秒为单位</li>
<li>timed_out：指明这个搜索是否超时</li>
<li>_shards：指出多少个分片被搜索了，同时也指出了成功/失败的被搜索的shards 的数量</li>
<li>hits：搜索结果</li>
<li>hits.total：匹配查询条件的文档的总数目</li>
<li>hits.hits：真正的搜索结果数组（默认是前10个文档）</li>
</ul>
<ul>
<li>搜索中只返回指定的字段：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">post请求：</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;t_tiku_user_record&#x2F;_search?pretty</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_source&quot;: [</span><br><span class="line">    &quot;knowledgeTreeId&quot;,</span><br><span class="line">    &quot;continousDays&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">response:</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 25,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 5,</span><br><span class="line">    &quot;successful&quot;: 5,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 11,</span><br><span class="line">    &quot;max_score&quot;: 1,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;t_tiku_user_record&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;rank&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;90-10000&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;knowledgeTreeId&quot;: 16,</span><br><span class="line">          &quot;continousDays&quot;: 1</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;t_tiku_user_record&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;rank&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;90-10006&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;knowledgeTreeId&quot;: 16,</span><br><span class="line">          &quot;continousDays&quot;: 1</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>查询条件:stuTotalScore为3000的数据：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">post请求：</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;t_tiku_user_record&#x2F;_search?pretty</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;stuTotalScore&quot;: 3000 &#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">response:</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 60,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 5,</span><br><span class="line">    &quot;successful&quot;: 5,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 1,</span><br><span class="line">    &quot;max_score&quot;: 1,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;t_tiku_user_record&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;rank&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;90-10000&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;knowledgeTreeId&quot;: 16,</span><br><span class="line">          &quot;createTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;updateTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;knowledgeNodeId&quot;: 12,</span><br><span class="line">          &quot;stuTotalScore&quot;: &quot;3000&quot;,</span><br><span class="line">          &quot;endTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;tPaperId&quot;: 100</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ul>
<li>或查询（should）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">post请求：</span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;t_tiku_user_record&#x2F;_search?pretty</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;should&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;stuTotalScore&quot;: 3000 &#125; &#125;,</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;stuTotalScore&quot;: 3001 &#125; &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 32,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 5,</span><br><span class="line">    &quot;successful&quot;: 5,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 2,</span><br><span class="line">    &quot;max_score&quot;: 0.39103588,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;t_tiku_user_record&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;rank&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;90-10001&quot;,</span><br><span class="line">        &quot;_score&quot;: 0.39103588,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;knowledgeTreeId&quot;: 16,</span><br><span class="line">          &quot;createTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;updateTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;knowledgeNodeId&quot;: 12,</span><br><span class="line">          &quot;stuTotalScore&quot;: &quot;3001&quot;,</span><br><span class="line">          &quot;endTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;tPaperId&quot;: 100</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;t_tiku_user_record&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;rank&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;90-10000&quot;,</span><br><span class="line">        &quot;_score&quot;: 0.25427115,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;knowledgeTreeId&quot;: 16,</span><br><span class="line">          &quot;createTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;updateTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;knowledgeNodeId&quot;: 12,</span><br><span class="line">          &quot;stuTotalScore&quot;: &quot;3000&quot;,</span><br><span class="line">          &quot;endTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;tPaperId&quot;: 100</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>且查询（must）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">post请求：</span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;t_tiku_user_record&#x2F;_search?pretty</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;knowledgeTreeId&quot;: 16 &#125; &#125;,</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;stuTotalScore&quot;: 3001 &#125; &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 5,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 5,</span><br><span class="line">    &quot;successful&quot;: 5,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 1,</span><br><span class="line">    &quot;max_score&quot;: 1.5756677,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;t_tiku_user_record&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;rank&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;90-10001&quot;,</span><br><span class="line">        &quot;_score&quot;: 1.5756677,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;knowledgeTreeId&quot;: 16,</span><br><span class="line">          &quot;createTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;updateTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;knowledgeNodeId&quot;: 12,</span><br><span class="line">          &quot;stuTotalScore&quot;: &quot;3001&quot;,</span><br><span class="line">          &quot;endTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;tPaperId&quot;: 100</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="执行过滤器"><a href="#执行过滤器" class="headerlink" title="执行过滤器"></a>执行过滤器</h2><p>文档得分的细节（搜索结果中的_score字段）。这个得分是指定的搜索查询匹配程度的一个相对度量。得分越高，文档越相关，得分越低文档的相关度越低</p>
<p>过滤器的形式提供了另一种查询功能。过滤器在概念上类似于查询，但是它们有非常快的执行速度，这种快的执行速度主要有以下两个原因：</p>
<ol>
<li>过滤器不会计算相关度的得分，所以它们在计算上更快一些</li>
<li>过滤器可以被缓存到内存中，这使得在重复的搜索查询上，其要比相应的查询快出许多。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">post请求：</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;172.16.116.121:9200&#x2F;t_tiku_user_record&#x2F;_search?pretty</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;filtered&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;,</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;range&quot;: &#123;</span><br><span class="line">          &quot;stuTotalScore&quot;: &#123;</span><br><span class="line">            &quot;gte&quot;: 3000,</span><br><span class="line">            &quot;lte&quot;: 3002</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 1,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 5,</span><br><span class="line">    &quot;successful&quot;: 5,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 3,</span><br><span class="line">    &quot;max_score&quot;: 1,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;t_tiku_user_record&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;rank&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;90-10000&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;knowledgeTreeId&quot;: 16,</span><br><span class="line">          &quot;createTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;updateTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;knowledgeNodeId&quot;: 12,</span><br><span class="line">          &quot;stuTotalScore&quot;: &quot;3000&quot;,</span><br><span class="line">          &quot;endTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;tPaperId&quot;: 100</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;t_tiku_user_record&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;rank&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;90-10001&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;knowledgeTreeId&quot;: 16,</span><br><span class="line">          &quot;createTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;updateTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;knowledgeNodeId&quot;: 12,</span><br><span class="line">          &quot;stuTotalScore&quot;: &quot;3001&quot;,</span><br><span class="line">          &quot;endTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;tPaperId&quot;: 100</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;t_tiku_user_record&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;rank&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;90-10002&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;knowledgeTreeId&quot;: 16,</span><br><span class="line">          &quot;createTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;updateTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;knowledgeNodeId&quot;: 12,</span><br><span class="line">          &quot;stuTotalScore&quot;: &quot;3002&quot;,</span><br><span class="line">          &quot;endTime&quot;: &quot;2018-01-18T08:12:57.068Z&quot;,</span><br><span class="line">          &quot;tPaperId&quot;: 100</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="执行聚合"><a href="#执行聚合" class="headerlink" title="执行聚合"></a>执行聚合</h2><p>聚合查询，主要用于统计相关的，在这里不做详细介绍。具体细节可以翻阅其它资料。</p>
<p><a href="https://endymecy.gitbooks.io/elasticsearch-guide-chinese/content/index.html">参考资料</a></p>
]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka源码剖析-server端</title>
    <url>/2019-09-13/kafka%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-server%E7%AB%AF/</url>
    <content><![CDATA[<p><img src="/images/kafka/server/kafka%E7%9A%84zookeeper%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png" alt="kafka的zookeeper存储结构"></p>
<p><a href="https://www.cnblogs.com/huazai007/articles/10990449.html">zookeeper在kafka中的作用</a></p>
<p>整理认识下kafka server端的架构图</p>
<p><img src="/images/kafka/server/server.png" alt="server"></p>
<h1 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h1><h2 id="reactor模式"><a href="#reactor模式" class="headerlink" title="reactor模式"></a>reactor模式</h2><ul>
<li>工作原理</li>
</ul>
<p>1.首先创建serverSocketChannel对象并在selector上注册op_accept事件，serverSocketChannel负责监听指定端口上的连接请求；<br>2.当客户端发起到服务端的网络连接时，服务端的selector监听到此op_accept事件，会触发selector来处理op_accept；<br>3.当acceptor接收到来自客户端的socket连接请求时会为这个连接创建响应的socketChannel，将socketChannel设计为非阻塞模式，并在selector上注册关注的IO事件，如OP_READ,OP_WRITE.此时客户端与服务端的socket连接正式完成。<br>4.当客户端通过上面建立的socket连接想服务端发送请求时，服务端的selector会监听到op_read事件，并触发执行响应的处理逻辑。当服务端向客户端写数据的时候，客户端的selector会监听到op_write事件，并处罚响应的处理逻辑。</p>
<p>注意治理的所有事件处理逻辑都是在同一个线程中完成的。</p>
<p>而kafka使用的事多线程 多个selector的设计实现的</p>
<p><img src="/images/kafka/server/Nio-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png" alt="Nio-多线程模型"></p>
<h2 id="socketServer"><a href="#socketServer" class="headerlink" title="socketServer"></a>socketServer</h2><p><img src="/images/kafka/server/socketServer.png" alt="socketServer"></p>
<p><img src="/images/kafka/server/serverSocket%E6%A0%B8%E5%BF%83%E5%AD%97%E6%AE%B5.png" alt="serverSocket核心字段"></p>
<h2 id="acceptor"><a href="#acceptor" class="headerlink" title="acceptor"></a>acceptor</h2><p>acceptor的主要功能是接收客户端建立连接的请求，创建socket连接并分配给processor处理。</p>
<p>acceptor.run方法是acceptor的核心逻辑，其中完成了对OP_ACCEPT时间的处理。</p>
<p><img src="/images/kafka/server/acceptorRun%E6%96%B9%E6%B3%95.png" alt="acceptorRun方法"></p>
<h2 id="processor"><a href="#processor" class="headerlink" title="processor"></a>processor</h2><p>processor主要用于完成读取请求和写回响应的操作，processor不处理具体业务逻辑</p>
<p><img src="/images/kafka/server/processor%E4%B8%BB%E8%A6%81%E5%8F%82%E6%95%B0.png" alt="processor主要参数"></p>
<p>processor.run()方法实现了从网络连接上读取数据的功能。</p>
<p><img src="/images/kafka/server/processorRun%E6%96%B9%E6%B3%95.png" alt="processorRun方法"></p>
<h2 id="RequestChannel"><a href="#RequestChannel" class="headerlink" title="RequestChannel"></a>RequestChannel</h2><p><img src="/images/kafka/server/RequestChannel.png" alt="RequestChannel"></p>
<p><img src="/images/kafka/server/processor%E5%A4%84%E7%90%86%E8%AF%B7%E6%B1%82.png" alt="processor处理请求"></p>
<h1 id="API层"><a href="#API层" class="headerlink" title="API层"></a>API层</h1><p>kafka的handler线程会取出processor线程，放入requestChannel的请求进行处理，并将产生的响应通过requestChanel传递给processor线程。handler线程属于kafka的api层。</p>
<h2 id="kafkaRequestHandler"><a href="#kafkaRequestHandler" class="headerlink" title="kafkaRequestHandler"></a>kafkaRequestHandler</h2><p>kafkaRequestHandler的主要职责是从RequestChannel获取请求并调用kafkaApis.handle()方法处理请求</p>
<h2 id="kafkaApis"><a href="#kafkaApis" class="headerlink" title="kafkaApis"></a>kafkaApis</h2><p>其是kafka服务器处理请求的入口类，它负责将kafkaRequestHandler传递过来的请求分发到不同的handl*处理方法中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">   * Top-level method that handles all requests and multiplexes to the right api</span><br><span class="line">   *&#x2F;</span><br><span class="line">  def handle(request: RequestChannel.Request) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      trace(&quot;Handling request:%s from connection %s;securityProtocol:%s,principal:%s&quot;.</span><br><span class="line">        format(request.requestDesc(true), request.connectionId, request.securityProtocol, request.session.principal))</span><br><span class="line">      ApiKeys.forId(request.requestId) match &#123;</span><br><span class="line">        case ApiKeys.PRODUCE &#x3D;&gt; handleProducerRequest(request)</span><br><span class="line">        case ApiKeys.FETCH &#x3D;&gt; handleFetchRequest(request)</span><br><span class="line">        case ApiKeys.LIST_OFFSETS &#x3D;&gt; handleOffsetRequest(request)</span><br><span class="line">        case ApiKeys.METADATA &#x3D;&gt; handleTopicMetadataRequest(request)</span><br><span class="line">        case ApiKeys.LEADER_AND_ISR &#x3D;&gt; handleLeaderAndIsrRequest(request)</span><br><span class="line">        case ApiKeys.STOP_REPLICA &#x3D;&gt; handleStopReplicaRequest(request)</span><br><span class="line">        case ApiKeys.UPDATE_METADATA_KEY &#x3D;&gt; handleUpdateMetadataRequest(request)</span><br><span class="line">        case ApiKeys.CONTROLLED_SHUTDOWN_KEY &#x3D;&gt; handleControlledShutdownRequest(request)</span><br><span class="line">        case ApiKeys.OFFSET_COMMIT &#x3D;&gt; handleOffsetCommitRequest(request)</span><br><span class="line">        case ApiKeys.OFFSET_FETCH &#x3D;&gt; handleOffsetFetchRequest(request)</span><br><span class="line">        case ApiKeys.GROUP_COORDINATOR &#x3D;&gt; handleGroupCoordinatorRequest(request)</span><br><span class="line">        case ApiKeys.JOIN_GROUP &#x3D;&gt; handleJoinGroupRequest(request)</span><br><span class="line">        case ApiKeys.HEARTBEAT &#x3D;&gt; handleHeartbeatRequest(request)</span><br><span class="line">        case ApiKeys.LEAVE_GROUP &#x3D;&gt; handleLeaveGroupRequest(request)</span><br><span class="line">        case ApiKeys.SYNC_GROUP &#x3D;&gt; handleSyncGroupRequest(request)</span><br><span class="line">        case ApiKeys.DESCRIBE_GROUPS &#x3D;&gt; handleDescribeGroupRequest(request)</span><br><span class="line">        case ApiKeys.LIST_GROUPS &#x3D;&gt; handleListGroupsRequest(request)</span><br><span class="line">        case ApiKeys.SASL_HANDSHAKE &#x3D;&gt; handleSaslHandshakeRequest(request)</span><br><span class="line">        case ApiKeys.API_VERSIONS &#x3D;&gt; handleApiVersionsRequest(request)</span><br><span class="line">        case ApiKeys.CREATE_TOPICS &#x3D;&gt; handleCreateTopicsRequest(request)</span><br><span class="line">        case ApiKeys.DELETE_TOPICS &#x3D;&gt; handleDeleteTopicsRequest(request)</span><br><span class="line">        case requestId &#x3D;&gt; throw new KafkaException(&quot;Unknown api code &quot; + requestId)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case e: Throwable &#x3D;&gt;</span><br><span class="line">        if (request.requestObj !&#x3D; null) &#123;</span><br><span class="line">          request.requestObj.handleError(e, requestChannel, request)</span><br><span class="line">          error(&quot;Error when handling request %s&quot;.format(request.requestObj), e)</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          val response &#x3D; request.body.getErrorResponse(e)</span><br><span class="line"></span><br><span class="line">          &#x2F;* If request doesn&#39;t have a default error response, we just close the connection.</span><br><span class="line">             For example, when produce request has acks set to 0 *&#x2F;</span><br><span class="line">          if (response &#x3D;&#x3D; null)</span><br><span class="line">            requestChannel.closeConnection(request.processor, request)</span><br><span class="line">          else</span><br><span class="line">            requestChannel.sendResponse(new Response(request, response))</span><br><span class="line"></span><br><span class="line">          error(&quot;Error when handling request %s&quot;.format(request.body), e)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; finally</span><br><span class="line">      request.apiLocalCompleteTimeMs &#x3D; time.milliseconds</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="日志处理"><a href="#日志处理" class="headerlink" title="日志处理"></a>日志处理</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>kafka使用日志文件保存生产者发送的消息，每条消息使用offset值保存它在分区中的偏移量，offset是逻辑值。同一个分区中的消息是顺序写入的。</p>
<p>分区的任一副本都会有响应的log文件；</p>
<p>为了避免日志文件太大，在对应的磁盘上建一个目录，命名规则是topicName-partitionId,log与分区之间是一一对应的；</p>
<p>kafka将log文件通过分段的方式分成多个logSegment文件，logSegment是一个逻辑上的概念，一个LogSegment文件对应磁盘上的一个日志文件和一个索引文件，其中日志文件记录消息，索引文件保存了消息的索引。日志文件大小达到一个阈值是，就会创建新的文件。命令规则是[baseOffset].log, 是第一条消息的offset。</p>
<p><img src="/images/kafka/server/Log%E7%9A%84%E7%BB%93%E6%9E%84.png" alt="Log的结构"></p>
<p>为了提高查询消息的效率，索引文件不并没有为每条消息建立索引项，而是使用稀疏索引方式为文件中的部分消息简历了索引</p>
<p><img src="/images/kafka/server/%E7%B4%A2%E5%BC%95-%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6.png" alt="索引-日志文件"></p>
<h2 id="fileMessageSet"><a href="#fileMessageSet" class="headerlink" title="fileMessageSet"></a>fileMessageSet</h2><p>fileMessageSet在磁盘上对应一个日志文件，它集成了MessageSet抽象类，它分为三部分：8个字节的offset值；4个字节的size表示messageData的大小；这两个部分组成LogOverhead,message data部分保存了消息的数据，逻辑上对应一个Message对象</p>
<p><img src="/images/kafka/server/fileMessageSet%E5%AF%B9%E8%B1%A1.png" alt="fileMessageSet对象"></p>
<p><img src="/images/kafka/server/Message%E7%B1%BB%E6%B6%88%E6%81%AF.png" alt="Message类消息"></p>
<h2 id="ByteBufferMessageSet"><a href="#ByteBufferMessageSet" class="headerlink" title="ByteBufferMessageSet"></a>ByteBufferMessageSet</h2><p>常见的算法是数据量越大压缩率越高；kafka使用的压缩方式是将多个消息一起进行压缩；服务端之间进行传输数据是压缩状态，而消费者从服务端拉取的数据也是压缩的。</p>
<h2 id="offsetIndex"><a href="#offsetIndex" class="headerlink" title="offsetIndex"></a>offsetIndex</h2><p><img src="/images/kafka/server/offsetIndex.png" alt="offsetIndex"> </p>
<h2 id="LogSegment"><a href="#LogSegment" class="headerlink" title="LogSegment"></a>LogSegment</h2><p>LogSegment中封装了一个FileMessageSet和一个offsetIndex对象，提供日志文件和索引文件的读写功能以及其他辅助功能。</p>
<p><img src="/images/kafka/server/LogSegment.png" alt="LogSegment"> </p>
<h3 id="LogSegment的read方法"><a href="#LogSegment的read方法" class="headerlink" title="LogSegment的read方法"></a>LogSegment的read方法</h3><p>四个参数：</p>
<ul>
<li>startOffset:指定读取的其实消息的offset；</li>
<li>maxOffset: 指定读取的结束的offset；</li>
<li>maxSize: 指定读取的最大字节数；</li>
<li>maxPosition: 指定读取的最大无力日志，默认是日志文件的大小；</li>
</ul>
<p>读取日志文件之前需要将startOffset和maxOffset转化为对应的无力地址才能使用；</p>
<p><img src="/images/kafka/server/LogSegmentRead%E6%96%B9%E6%B3%95.png" alt="LogSegmentRead方法"> </p>
<p><img src="/images/kafka/server/Log%E4%BD%BF%E7%94%A8%E8%B7%B3%E8%A1%A8%E7%9A%84%E6%B5%81%E7%A8%8B.png" alt="Log使用跳表的流程"> </p>
<h2 id="Log"><a href="#Log" class="headerlink" title="Log"></a>Log</h2><p>Log是对多个LogSegment对象的顺序组合，形成一个逻辑的日志，为了实现快读定位LogSegment，log使用跳表来对LogSegment进行管理；</p>
<p>jdk中有跳表的实现-concurrentSkipListMap，它是一个线程安全的实现；</p>
<p>在log中将每个LogSegment的baseOffset作为key，LogSegment对象作为value，放入segment这个跳表结构中</p>
<p><img src="/images/kafka/server/Log%E4%BD%BF%E7%94%A8%E8%B7%B3%E8%A1%A8%E7%9A%84%E6%B5%81%E7%A8%8B.png" alt="Log使用跳表的流程"> </p>
<p><img src="/images/kafka/server/logAppend%E6%96%B9%E6%B3%95%E5%A4%A7%E8%87%B4%E6%B5%81%E7%A8%8B.png" alt="logAppend方法大致流程"> </p>
<h2 id="LogManager"><a href="#LogManager" class="headerlink" title="LogManager"></a>LogManager</h2><ul>
<li>简介</li>
</ul>
<p>在一个broker上的所有log都是由LogManager进行管理的，LogManager提供了加载Log、创建Log集合、删除Log集合、查询Log集合等功能，并且启动了3个周期性的后台任务以及多个线程分别是：log-flusher（日志刷写任务）、log-retention（日志保留）任务，检查点刷新任务以及cleaner线程（日志清理）；</p>
<p><img src="/images/kafka/server/%E4%B8%89%E4%B8%AA%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%8F%8F%E8%BF%B0.png" alt="三个周期性任务的描述"></p>
<p><img src="/images/kafka/server/%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9%E5%8A%9F%E8%83%BD.png" alt="日志压缩功能"></p>
<p><img src="/images/kafka/server/%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9-cleaner%E7%BA%BF%E7%A8%8B.png" alt="日志压缩-cleaner线程"></p>
<p><img src="/images/kafka/server/LogManager%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B.png" alt="LogManager初始化流程"></p>
<h1 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h1><h2 id="副本简介"><a href="#副本简介" class="headerlink" title="副本简介"></a>副本简介</h2><p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E7%9A%84%E6%A6%82%E5%BF%B5.png" alt="副本的概念"></p>
<ul>
<li>本地和远程副本</li>
</ul>
<p><img src="/images/kafka/server/%E6%9C%AC%E5%9C%B0%E5%92%8C%E8%BF%9C%E7%A8%8B%E5%89%AF%E6%9C%AC.png" alt="本地和远程副本"></p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E7%9A%84%E6%9B%B4%E6%96%B0%E6%93%8D%E4%BD%9C.png" alt="副本的更新操作"></p>
<h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p>服务端使用partition表示分区，partition负责管理每个副本对应的replica对象，进行leader副本的切换，isr集合的管理以及调用日志存储自行他完成写入消息</p>
<p>partition的核心字段及主要方法：</p>
<p><img src="/images/kafka/server/partition%E7%9A%84%E6%A0%B8%E5%BF%83%E5%AD%97%E6%AE%B5.png" alt="partition的核心字段"></p>
<h3 id="创建副本"><a href="#创建副本" class="headerlink" title="创建副本"></a>创建副本</h3><p><img src="/images/kafka/server/%E5%88%9B%E5%BB%BA%E5%89%AF%E6%9C%AC.png" alt="创建副本"></p>
<h3 id="副本将角色切换"><a href="#副本将角色切换" class="headerlink" title="副本将角色切换"></a>副本将角色切换</h3><p>broker会根据kafkaController发送的leaderAndISRRequest请求控制副本的leader和follower副本角色切换，Partition.makeLeader()是LeaderAndISRRequest中比较重要的环节之一。</p>
<p><img src="/images/kafka/server/makerLeader%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E5%8F%82%E6%95%B0.png" alt="makerLeader中用到的参数"></p>
<p><img src="/images/kafka/server/makeLeader%E4%BB%A3%E7%A0%811.png" alt="makeLeader代码1"></p>
<p><img src="/images/kafka/server/makeLeader%E4%BB%A3%E7%A0%812.png" alt="makeLeader代码2"></p>
<ul>
<li>增加leader副本的HW</li>
</ul>
<p>当isr集合发生增减或是ISR集合中任一副本的LEO发生变化时，都会导致ISR集合中最小的LEO变大。获取ISR集合中最小的LEO作为新的HW，比较现在的HW和新的HW，取较小的作为HW；</p>
<h3 id="ISR集合管理"><a href="#ISR集合管理" class="headerlink" title="ISR集合管理"></a>ISR集合管理</h3><p>partition除了对副本的leader和follower角色进行管理，还需要管理ISR集合。随着follower副本不断与leader副本进行消息同步，follower副本的leo会逐渐后移，并最终赶上leader副本的leo，最终该follower会进入ISR集合。</p>
<p><img src="/images/kafka/server/%E6%B7%BB%E5%8A%A0ISR%E5%85%83%E7%B4%A0%E7%9A%84%E5%AE%9E%E7%8E%B0.png" alt="添加ISR元素的实现"></p>
<p><img src="/images/kafka/server/%E5%87%8F%E5%B0%91ISR%E5%85%83%E7%B4%A0%E7%9A%84%E5%AE%9E%E7%8E%B0.png" alt="减少ISR元素的实现"></p>
<p>SIR集合发生增减的时候，都会将最新的ISR集合保存在zookeeper中。</p>
<h3 id="追加消息"><a href="#追加消息" class="headerlink" title="追加消息"></a>追加消息</h3><p>在分区中，只有leader副本能够处理读写请求，partition.appendMessagesToLeader()方法提供了向leader副本对应的Log中追加消息的功能。当isr集合中副本的数量小于配置的最小的限制，且生产者对可用性有较高的可用性，则不能支架消息，会产生一个NotEnoughReplicasException异常。</p>
<p>否则追加消息到对应的leader副本，尝试增加leader的HW；</p>
<h3 id="checkEnoughReplicasReachOffset"><a href="#checkEnoughReplicasReachOffset" class="headerlink" title="checkEnoughReplicasReachOffset"></a>checkEnoughReplicasReachOffset</h3><p><img src="/images/kafka/server/checkEnoughReplicasReachOffset.png" alt="checkEnoughReplicasReachOffset"></p>
<h2 id="ReplicaManager-副本管理机制"><a href="#ReplicaManager-副本管理机制" class="headerlink" title="ReplicaManager 副本管理机制"></a>ReplicaManager 副本管理机制</h2><p><img src="/images/kafka/server/ReplicaManager1.png" alt="ReplicaManager1"></p>
<p><img src="/images/kafka/server/ReplicaManager2.png" alt="ReplicaManager2"></p>
<h3 id="副本角色切换"><a href="#副本角色切换" class="headerlink" title="副本角色切换"></a>副本角色切换</h3><p>在kafka集群中会选择一个broker称为kafkaController的leader，他负责管理整个kafka集群。controller leader根据partition的leader副本和follower副本的状态向对应的broker节点发送leaderAndIsrRequest，整个请求主要用于副本的角色切换。</p>
<p><img src="/images/kafka/server/leaderAndIsrRequestAndResponse.png" alt="leaderAndIsrRequestAndResponse"></p>
<p><img src="/images/kafka/server/becomeLeaderAndFollower.png" alt="becomeLeaderAndFollower"></p>
<p><img src="/images/kafka/server/makerFollower.png" alt="makerFollower"></p>
<p>updateFollowerLogReadResults()方法主要针对来自follower副本的fetchRequst多了异步处理。</p>
<ul>
<li>更新leader副本上维护的follower副本的各项状态，入LEO等；</li>
<li>更新follower副本不断fetch的消息，最终追上leader副本，可能对ISR集合进行可扩张，同事将ISR集合的记录保存的zookeeper；</li>
<li>检测是否需要后移leader副本的HW；</li>
</ul>
<h3 id="消息同步"><a href="#消息同步" class="headerlink" title="消息同步"></a>消息同步</h3><p>AbstractFetcherManager.addFetcherForPartitions()方法会让follower副本从指定的offset开始与leader副本进行同步。改方法的参数设计brokerAndInitialOffset类，他封装了broker的网络位置信息以及同步的其实offset。</p>
<p><img src="/images/kafka/server/addFetcherForPartitions%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC%E6%B6%88%E6%81%AF.png" alt="addFetcherForPartitions同步副本消息"></p>
<p>removeFetcherForPartitions()方法会停止指定follower副本的同步操作；如果fetcher线程不在为任何分区的follower副本提供同步，则会被shutdown掉。</p>
<p><img src="/images/kafka/server/AddPartitionsAndRemovePartitions.png" alt="AddPartitionsAndRemovePartitions"></p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E8%AF%B7%E6%B1%82%E7%9A%84offset%E8%B6%85%E8%BF%87%E4%BA%86leader%E7%9A%84%E8%8C%83%E5%9B%B4.png" alt="副本请求的offset超过了leader的范围"></p>
<h3 id="关闭副本"><a href="#关闭副本" class="headerlink" title="关闭副本"></a>关闭副本</h3><p><img src="/images/kafka/server/%E5%85%B3%E9%97%AD%E5%89%AF%E6%9C%AC.png" alt="关闭副本"></p>
<h3 id="replicaManager中的定时任务"><a href="#replicaManager中的定时任务" class="headerlink" title="replicaManager中的定时任务"></a>replicaManager中的定时任务</h3><p><img src="/images/kafka/server/replicaManager%E4%B8%AD%E7%9A%84%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.png" alt="replicaManager中的定时任务"></p>
<h3 id="metadataCache"><a href="#metadataCache" class="headerlink" title="metadataCache"></a>metadataCache</h3><p>metadataCache是broker用来缓存整个集群中全部分区状态的组件，kafkaController通过向集群中的broker发送updateMetadataRequest来更新其metadataCache组件中的缓存的数据。</p>
<p><img src="/images/kafka/server/metadataCache%E7%9A%84%E5%AD%97%E6%AE%B5.png" alt="metadataCache的字段"></p>
<ul>
<li>getPartitionMetadata方法的实现</li>
</ul>
<p><img src="/images/kafka/server/getPartitionMetadata%E6%96%B9%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B01.png" alt="getPartitionMetadata方法的实现1"></p>
<p><img src="/images/kafka/server/getPartitionMetadata%E6%96%B9%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B02.png" alt="getPartitionMetadata方法的实现2"></p>
<h1 id="groupCoordinator"><a href="#groupCoordinator" class="headerlink" title="groupCoordinator"></a>groupCoordinator</h1><p>每个broker上会实例化一个groupCoordinator对象，kafka按照consumer group名称将其分配给对应的groupCoordinator进行管理，每个groupCoordinator只负责管理consumer group的一个子集；</p>
<h2 id="groupCoordinator的功能"><a href="#groupCoordinator的功能" class="headerlink" title="groupCoordinator的功能"></a>groupCoordinator的功能</h2><ul>
<li>负责处理joinGroupRequest和syncGroupRequest完成对consumer group中分区的分配工作；</li>
<li>通过GroupMetadataManager和内部的topic维护offset信息，即使出现消费者宕机的情况，也可以找回之前提交的offset；</li>
<li>记录consumer group的相关信息，即使broker宕机导致consumer group 由新的groupCoordinator进行管理，新的groupCoordinator也可以知道consumer Group中的每个消费者负责处理那个分区等信息；</li>
<li>通过心跳检测消费者的状态；</li>
</ul>
<p><img src="/images/kafka/server/MemberMetada%E7%9A%84%E4%B8%BB%E8%A6%81%E5%AD%97%E6%AE%B5.png" alt="MemberMetadata的主要字段"></p>
<p><img src="/images/kafka/server/GroupMetadata%E5%85%83%E6%95%B0%E6%8D%AE%E4%BF%A1%E6%81%AF.png" alt="GroupMetadata元数据信息"></p>
<p>groupMetadata提供了对其字段的操作，包括对members集合的增删，对state的切换，同事需要选择group leader；</p>
<p><img src="/images/kafka/server/%E9%80%89%E6%8B%A9groupLeader.png" alt="选择groupLeader"></p>
<h2 id="groupMetadataManager"><a href="#groupMetadataManager" class="headerlink" title="groupMetadataManager"></a>groupMetadataManager</h2><p>groupMetadataManager是groupCoordinator中负责管理 consumer group元数据以及对应offset信息的组件，groupMetadataManager底层使用offsets topic，以消息的形式存储 consumer group的groupMetadata信息以及其消息的每个每个分区的信息</p>
<p><img src="/images/kafka/server/GroupMetadataManager%E5%AD%97%E6%AE%B5.png" alt="GroupMetadataManager字段"></p>
<ul>
<li>removeGroup方法的实现</li>
</ul>
<p><img src="/images/kafka/server/removeGroup%E6%96%B9%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0.png" alt="removeGroup方法的实现"></p>
<h3 id="查找groupCoordinator"><a href="#查找groupCoordinator" class="headerlink" title="查找groupCoordinator"></a>查找groupCoordinator</h3><p><img src="/images/kafka/server/%E6%9F%A5%E6%89%BEgroupCoordinator.png" alt="查找groupCoordinator"></p>
<p><img src="/images/kafka/server/GroupCoordinator-offsetPartition-ConsumerGroup.png" alt="GroupCoordinator-offsetPartition-ConsumerGroup"></p>
<h3 id="loadGroupsAndOffsets-方法"><a href="#loadGroupsAndOffsets-方法" class="headerlink" title="loadGroupsAndOffsets 方法"></a>loadGroupsAndOffsets 方法</h3><p><img src="/images/kafka/server/loadGroupsAndOffsets.png" alt="loadGroupsAndOffsets"></p>
<h3 id="SyncGroupRequest相关处理"><a href="#SyncGroupRequest相关处理" class="headerlink" title="SyncGroupRequest相关处理"></a>SyncGroupRequest相关处理</h3><p>consumer group中的leader消费者通过SyncGroupRequest将分区的分配结果发送给GroupCoordinator,GroupCoordinator会根据此分配结果形成SyncGroupResponse返回给所有的消费者。</p>
<h3 id="offsetFetchRequest和listGroupRequest处理"><a href="#offsetFetchRequest和listGroupRequest处理" class="headerlink" title="offsetFetchRequest和listGroupRequest处理"></a>offsetFetchRequest和listGroupRequest处理</h3><p><img src="/images/kafka/server/offsetFetchRequest%E5%A4%84%E7%90%86.png" alt="offsetFetchRequest处理"></p>
<h2 id="groupCoordinator分析"><a href="#groupCoordinator分析" class="headerlink" title="groupCoordinator分析"></a>groupCoordinator分析</h2><p><img src="/images/kafka/server/groupCoordinator%E5%90%84%E4%B8%AA%E5%AD%97%E6%AE%B5%E7%9A%84%E5%90%AB%E4%B9%89.png" alt="groupCoordinator各个字段的含义"></p>
<ul>
<li>groupState字段的四个状态</li>
</ul>
<p><img src="/images/kafka/server/groupState%E7%9A%84%E5%9B%9B%E4%B8%AA%E7%8A%B6%E6%80%81.png" alt="groupState的四个状态"></p>
<p><img src="/images/kafka/server/groupState%E7%9A%84%E5%9B%9B%E4%B8%AA%E7%8A%B6%E6%80%81%E8%BD%AC%E5%8C%96.png" alt="groupState的四个状态转化"></p>
<ul>
<li>joinGroup()方法</li>
</ul>
<p><img src="/images/kafka/server/JoinGroup%E6%96%B9%E6%B3%95.png" alt="JoinGroup方法"></p>
<p><img src="/images/kafka/server/dojoinGroup%E6%96%B9%E6%B3%95.png" alt="dojoinGroup方法"></p>
<p><img src="/images/kafka/server/prepareRebalance%E6%96%B9%E6%B3%95.png" alt="prepareRebalance方法"></p>
<ul>
<li>doSyncGroup()方法</li>
</ul>
<p><img src="/images/kafka/server/doSyncGroup%E6%93%8D%E4%BD%9C.png" alt="doSyncGroup操作"></p>
<ul>
<li>commitOffsetRequest()方法</li>
</ul>
<p><img src="/images/kafka/server/commitOffsetRequest.png" alt="commitOffsetRequest"></p>
<p><img src="/images/kafka/server/commitOffsetRequest2.png" alt="commitOffsetRequest2"></p>
<ul>
<li>leaveGroupRequest</li>
</ul>
<p><img src="/images/kafka/server/leaveGroupRequest.png" alt="leaveGroupRequest"></p>
<h1 id="kafkaController"><a href="#kafkaController" class="headerlink" title="kafkaController"></a>kafkaController</h1><h2 id="kafkaController简介"><a href="#kafkaController简介" class="headerlink" title="kafkaController简介"></a>kafkaController简介</h2><p><img src="/images/kafka/server/kafkaController%E7%AE%80%E4%BB%8B.png" alt="kafkaController简介"></p>
<p><img src="/images/kafka/server/broker%E5%9C%A8zookeeper%E4%B8%AD%E7%9A%84%E5%AD%98%E5%82%A8%E4%BF%A1%E6%81%AF.png" alt="broker在zookeeper中的存储信息"></p>
<p><img src="/images/kafka/server/kafkaController%E7%BB%84%E4%BB%B6.png" alt="kafkaController组件"></p>
<p>kafkaController是zookeeper与kafka集群交互的桥梁，他一方面对zookeeper进行监听，其中包括broker写入zookeeper中的数据，也包括管理员使用脚本写入的数据;另一方面根据zookeeper中数据的变化做出相应的处理，通过Request请求控制每个broker，kafkaControlle也通过zookeeper提高了高可用的机制。</p>
<h2 id="ControllerChannelManager"><a href="#ControllerChannelManager" class="headerlink" title="ControllerChannelManager"></a>ControllerChannelManager</h2><p>ControllerChannelManager主要管理broker之间的网络交互。controller只能发送leaderAndISRRequest、stopReplicaRequest、updateMetadataRequest三种请求；</p>
<p>ControllerChannelManager的核心字段是brokerStatInfo，主要用于管理集群中各个broker对应的brokerStatInfo对象。</p>
<p><img src="/images/kafka/server/ControllerChannelManager%E7%AE%A1%E7%90%86brokerStateInfo.png" alt="ControllerChannelManager管理brokerStateInfo"></p>
<h2 id="controllerContext"><a href="#controllerContext" class="headerlink" title="controllerContext"></a>controllerContext</h2><p>controllerContext中维护了controller使用到的上下文信息，从其构造函数可以猜到controllerContext与zookeeper有密切的关系，可以看做两个之间的缓存</p>
<h2 id="controllerBrokerRequestBatch"><a href="#controllerBrokerRequestBatch" class="headerlink" title="controllerBrokerRequestBatch"></a>controllerBrokerRequestBatch</h2><p>为了提高broker leader与集群中其它broker的通信效率，kafka controller使用controllerBrokerRequestBatch实现批量发送请求的功能。</p>
<p><img src="/images/kafka/server/controllerBrokerRequestBatch%E7%9A%84%E6%A0%B8%E5%BF%83%E5%AD%97%E6%AE%B5.png" alt="controllerBrokerRequestBatch的核心字段"></p>
<h2 id="partitionStateMachine"><a href="#partitionStateMachine" class="headerlink" title="partitionStateMachine"></a>partitionStateMachine</h2><p>partitionStateMachine是controller leader用于维护分区状态的状态机，分区的状态是通过partitionState接口定义的 </p>
<p><img src="/images/kafka/server/partitionState%E5%8F%8A%E8%BD%AC%E6%8D%A2.png" alt="partitionState及转换"></p>
<p><img src="/images/kafka/server/%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2%E6%97%B6%E5%AE%8C%E6%88%90%E7%9A%84%E6%93%8D%E4%BD%9C.png" alt="状态转换时完成的操作"></p>
<p>selectLeaderForPartition()方法</p>
<ul>
<li>使用指定的partitionLeaderSelector()为分区选举新的leader副本；</li>
<li>将leader副本和isr集合的信息写入zookeeper;</li>
<li>更新context.partitionLeadershipInfo集合中缓存的leader副本、isr集合等信息；</li>
<li>将上述确定的leader副本，isr集合，ar集合等信息添加到controllerBrokerRequestBatch，之后会封装成leaderAndIsrRequest发送相关的broker；</li>
</ul>
<h2 id="partitionLeaderSelector"><a href="#partitionLeaderSelector" class="headerlink" title="partitionLeaderSelector"></a>partitionLeaderSelector</h2><p>offlinePartitionLeaderSelector会根据currentLeaderAndIsr选举新的leader和isr集合；</p>
<p><img src="/images/kafka/server/offlinePartitionLeaderSelector.png" alt="offlinePartitionLeaderSelector"></p>
<ul>
<li>选举的代码实现</li>
</ul>
<p><img src="/images/kafka/server/SelectLeader1.png" alt="SelectLeader1"></p>
<p><img src="/images/kafka/server/SelectLeader2.png" alt="SelectLeader2"></p>
<h2 id="ReplicaStateMachine"><a href="#ReplicaStateMachine" class="headerlink" title="ReplicaStateMachine"></a>ReplicaStateMachine</h2><p>ReplicaStateMachine是controller leader 用于维护副本状态的状态机，副本状态由replicaState接口表示</p>
<p><img src="/images/kafka/server/replicaState%E7%8A%B6%E6%80%81.png" alt="replicaState状态"></p>
<p><img src="/images/kafka/server/replicaState%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E6%89%80%E5%81%9A%E6%93%8D%E4%BD%9C.png" alt="replicaState状态变化所做操作"></p>
<h2 id="zookeeperListener"><a href="#zookeeperListener" class="headerlink" title="zookeeperListener"></a>zookeeperListener</h2><p>I0Itec-zkClient 是zookeeper的客户端工具</p>
<h3 id="listener接口介绍"><a href="#listener接口介绍" class="headerlink" title="listener接口介绍"></a>listener接口介绍</h3><p>kafkaController 会通过zookeeper监控整个kafka集群的运行状态。具体实现是在zookeeper的指定节点添加listener，监听此节点中的数据变化或者其子节点的变化，从而触发响应的业务逻辑。</p>
<p>IZKDataListener监听指定节点的数据变化；IZKChildListener监听指定节点的子节点变化；IZKStateListener监听zookeeper连接状态的变化；</p>
<p><img src="/images/kafka/server/kafka%E5%AE%9E%E7%8E%B0%E7%9A%84zkListener%E6%8E%A5%E5%8F%A3.png" alt="kafka实现的zkListener接口"></p>
<p><img src="/images/kafka/server/topicChangeListener%E5%AE%9E%E7%8E%B0.png" alt="topicChangeListener实现"></p>
<p><img src="/images/kafka/server/deleteTopicChildChange.png" alt="deleteTopicChildChange"></p>
<p><img src="/images/kafka/server/deleteTopicChildChange2.png" alt="deleteTopicChildChange2"></p>
<p>partitionModificationListener 主要用于监听一个topic分区的变化</p>
<p><img src="/images/kafka/server/partitionModificationsListener.png" alt="partitionModificationsListener"></p>
<p>brokerChangeListener 主要负责处理broker的上线和故障下线，上线时会在“/brokers/ids”下创建临时节点，下线时会删除对应的临时节点。</p>
<p><img src="/images/kafka/server/brokerChildChange.png" alt="brokerChildChange"></p>
<p><img src="/images/kafka/server/onBrokerFailure.png" alt="onBrokerFailure"></p>
<p><img src="/images/kafka/server/onBrokerFailureDemo1.png" alt="onBrokerFailureDemo1"></p>
<p><img src="/images/kafka/server/onBrokerFailureDemo2.png" alt="onBrokerFailureDemo2"></p>
<p>副本重新分配的listener</p>
<p>partitionReassignedListener 监听zookeeper节点是 “/admin/reassign_partitions”,当管理人员通过ReassignPartitionsCommond名指定某些分区需要重新分配副本时，会将指定分区的信息写入改节点，从而触发partitionReassignedListener</p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E9%87%8D%E6%96%B0%E5%88%86%E9%85%8D%E7%9A%84%E6%AD%A5%E9%AA%A41.png" alt="副本重新分配的步骤1"></p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E9%87%8D%E6%96%B0%E5%88%86%E9%85%8D%E7%9A%84%E6%AD%A5%E9%AA%A42.png" alt="副本重新分配的步骤2"></p>
<p><img src="/images/kafka/server/%E5%89%AF%E6%9C%AC%E9%87%8D%E6%96%B0%E5%88%86%E9%85%8D%E7%9A%84%E6%AD%A5%E9%AA%A43.png" alt="副本重新分配的步骤3"></p>
<h2 id="kafkaController初始化与故障转移"><a href="#kafkaController初始化与故障转移" class="headerlink" title="kafkaController初始化与故障转移"></a>kafkaController初始化与故障转移</h2><p>kafkaController的启动和故障转移的过程与zookeeperLeaderElector有着密切的关系，</p>
<p>zookeeperLeaderElector中有两个比较重要的字段，leaderId以及leaderChangeListener</p>
<p><img src="/images/kafka/server/zookeeperLeaderElector.png" alt="zookeeperLeaderElector"></p>
<h3 id="触发选举"><a href="#触发选举" class="headerlink" title="触发选举"></a>触发选举</h3><ul>
<li>第一次启动的时候；</li>
<li>leaderChangeListener监听到”/controller”节点中的数据被删除；</li>
<li>zookeeper连接过期并重新连接之后；</li>
</ul>
<p><img src="/images/kafka/server/elect.png" alt="elect"></p>
<h3 id="onControllerFailover"><a href="#onControllerFailover" class="headerlink" title="onControllerFailover"></a>onControllerFailover</h3><p>elect方法中调用onBecomingLeader()方法实际上还是onControllerFailover方法。当选举成功后，会完成一系列初始化操作。</p>
<p><img src="/images/kafka/server/onControllerFailover1.png" alt="onControllerFailover1"></p>
<p><img src="/images/kafka/server/onControllerFailover2.png" alt="onControllerFailover2"></p>
<h3 id="ControllerContext-从zookeeper中获取的信息"><a href="#ControllerContext-从zookeeper中获取的信息" class="headerlink" title="ControllerContext 从zookeeper中获取的信息"></a>ControllerContext 从zookeeper中获取的信息</h3><p><img src="/images/kafka/server/ControllerContext%E4%BB%8Ezookeeper%E4%B8%AD%E8%8E%B7%E5%8F%96%E4%BF%A1%E6%81%AF.png" alt="ControllerContext从zookeeper中获取信息"></p>
<h3 id="partition-rebalance"><a href="#partition-rebalance" class="headerlink" title="partition rebalance"></a>partition rebalance</h3><p><img src="/images/kafka/server/%E4%BC%98%E5%85%88%E5%89%AF%E6%9C%AC.png" alt="优先副本"></p>
<h3 id="优先选举-checkAndTriggerPartitionRebalance"><a href="#优先选举-checkAndTriggerPartitionRebalance" class="headerlink" title="优先选举 checkAndTriggerPartitionRebalance"></a>优先选举 checkAndTriggerPartitionRebalance</h3><p><img src="/images/kafka/server/%E4%BC%98%E5%85%88%E9%80%89%E4%B8%BE1.png" alt="优先选举1"></p>
<p><img src="/images/kafka/server/%E4%BC%98%E5%85%88%E9%80%89%E4%B8%BE2.png" alt="优先选举2"></p>
<h2 id="处理controlledShutDownRequest"><a href="#处理controlledShutDownRequest" class="headerlink" title="处理controlledShutDownRequest"></a>处理controlledShutDownRequest</h2><p>更换硬件、系统升级可能需要管理broker，kafka提供了方法来管理,主动下线broker</p>
<p><img src="/images/kafka/server/controlledShutDownRequest.png" alt="controlledShutDownRequest"></p>
]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka server</tag>
      </tags>
  </entry>
  <entry>
    <title>maven实战-2</title>
    <url>/2018-09-19/maven%E5%AE%9E%E6%88%98-2/</url>
    <content><![CDATA[<h1 id="使用maven进行测试"><a href="#使用maven进行测试" class="headerlink" title="使用maven进行测试"></a>使用maven进行测试</h1><p>maven的重要职责就是自动运行单元测试，它通过maven-surefire-plugin与主流的单元测试框架junit4 以及testNG继承，并且能够自动生成丰富的结果报告。</p>
<h2 id="maven-surefire-plugin-插件简介"><a href="#maven-surefire-plugin-插件简介" class="headerlink" title="maven-surefire-plugin 插件简介"></a>maven-surefire-plugin 插件简介</h2><p>maven-surefire-plugin可以被称作测试运行器。生命周期阶段需要绑定到某个插件的目标才可以完成真正的工作。test阶段正是和maven-surefire-plugin的test目标绑定的。</p>
<p>在默认情况下，maven-surefire-plugin插件的test目标会自动执行测试源码路径（src/test/java）下符合一组命名模式的测试类。</p>
<p>1.<strong>/Test*.java 任何子目录下所有命名以Test开头的java类。<br>2.**/*Test.java 任何子目录下所有命名以Test结尾的Java类<br>3.</strong>/*TestCase.java 任何子目录下所有命名以testCase结尾的java类。</p>
<p>只要按照以上模式命名，maven就可以自动运行他们。当然可以自定义测试类的模式。</p>
<p>当然为了运行测试，maven需要自己引入测试框架的依赖。</p>
<h2 id="跳过测试"><a href="#跳过测试" class="headerlink" title="跳过测试"></a>跳过测试</h2><p>以下配置可以跳过测试类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maven package -Dmaven.test.skip &#x3D;true</span><br></pre></td></tr></table></figure>

<p>也可以采用配置的形式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&lt;!-- 编译插件 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-compiler-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;source&gt;1.7&lt;&#x2F;source&gt;</span><br><span class="line">        &lt;target&gt;1.7&lt;&#x2F;target&gt;</span><br><span class="line">        &lt;!-- 略过测试代码的编译，不推荐 --&gt;</span><br><span class="line">        &lt;skip&gt;true&lt;&#x2F;skip&gt;</span><br><span class="line">    &lt;&#x2F;configuration&gt;</span><br><span class="line">&lt;&#x2F;plugin&gt;</span><br><span class="line">&lt;!-- 单元测试插件 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-surefire-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;!-- 略过整个单元测试的执行，不推荐 --&gt;</span><br><span class="line">        &lt;skip&gt;true&lt;&#x2F;skip&gt;</span><br><span class="line">    &lt;&#x2F;configuration&gt;</span><br><span class="line">&lt;&#x2F;plugin&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="动态指定要运行的测试用例"><a href="#动态指定要运行的测试用例" class="headerlink" title="动态指定要运行的测试用例"></a>动态指定要运行的测试用例</h2><p>1.指定单个测试用例</p>
<p>mvn test -Dtest =Randm*Test</p>
<p>2.指定多个测试用例</p>
<p>mvn test -Dtest = ATest,BTest</p>
<h2 id="包含与排除测试用例"><a href="#包含与排除测试用例" class="headerlink" title="包含与排除测试用例"></a>包含与排除测试用例</h2><p>即使不符合测试类命名模式，即便如此，maven-surefire-plugin插件还是允许用户通过额外的配置自定义包含一些其它测试类，或者排除一些复合默认命名模式的测试类。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt; plugin &gt;   </span><br><span class="line">    &lt; groupId &gt; org.apache.maven.plugins &lt;&#x2F; groupId &gt;   </span><br><span class="line">    &lt; artifactId &gt; maven-surefire-plugin &lt;&#x2F; artifactId &gt;   </span><br><span class="line">    &lt; version &gt; 2.5 &lt;&#x2F; version &gt;   </span><br><span class="line">    &lt; configuration &gt;   </span><br><span class="line">        &lt; includes &gt;   </span><br><span class="line">            &lt; include &gt; **&#x2F;*Tests.java &lt;&#x2F; include &gt;   </span><br><span class="line">        &lt;&#x2F; includes &gt;   </span><br><span class="line">        &lt; excludes &gt;   </span><br><span class="line">            &lt; exclude &gt; **&#x2F;*ServiceTest.java &lt;&#x2F; exclude &gt;   </span><br><span class="line">            &lt; exclude &gt; **&#x2F;TempDaoTest.java &lt;&#x2F; exclude &gt;   </span><br><span class="line">        &lt;&#x2F; excludes &gt;   </span><br><span class="line">    &lt;&#x2F; configuration &gt;   </span><br><span class="line">&lt;&#x2F; plugin &gt;  </span><br></pre></td></tr></table></figure>
<h2 id="生成测试报告"><a href="#生成测试报告" class="headerlink" title="生成测试报告"></a>生成测试报告</h2><h3 id="基本测试报告"><a href="#基本测试报告" class="headerlink" title="基本测试报告"></a>基本测试报告</h3><p>默认情况下，maven-surefire-plugin会在项目的target/surefire-reports目录下生成两种格式的错误报告。</p>
<p>– 简单文本格式——内容十分简单，可以看出哪个测试项出错。<br>– 与JUnit兼容的XML格式——XML格式已经成为了Java单元测试报告的事实标准，这个文件可以用其他的工具如IDE来查看。</p>
<h3 id="测试覆盖率报告"><a href="#测试覆盖率报告" class="headerlink" title="测试覆盖率报告"></a>测试覆盖率报告</h3><p>测试覆盖率是衡量项目代码质量的一个重要的参考指标。Cobertura是一个优秀的开源 <a href="http://cobertura.sourceforge.net/">测试覆盖率统计工具</a> ，Maven通过cobertura-maven-plugin与之集成，用户可 以使用简单的命令为Maven项目生成测试覆盖率报告。运行下面命令生成报告：</p>
<p>mvn cobertura:cobertura </p>
<p>在target/site/cobertura下的index.xml文件可以看到覆盖率报告。</p>
<h3 id="重用测试代码"><a href="#重用测试代码" class="headerlink" title="重用测试代码"></a>重用测试代码</h3><p>当命令行运行mvn package的时候，Maven只会打包主代码及资源文件，并不会对测试代码打包。如果测试代码中有需要重用的代码，这时候就需要对测试代码打包了。<br>这时候需要配置maven-jar-plugin将测试类打包，如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt; plugin &gt;   </span><br><span class="line">    &lt; groupId &gt; org.apache.maven.plugins &lt;&#x2F; groupId &gt;   </span><br><span class="line">    &lt; artifactId &gt; maven-jar-plugin &lt;&#x2F; artifactId &gt;   </span><br><span class="line">    &lt; version &gt; 2.2 &lt;&#x2F; version &gt;   </span><br><span class="line">    &lt; executions &gt;   </span><br><span class="line">        &lt; execution &gt;   </span><br><span class="line">            &lt; goals &gt;   </span><br><span class="line">                &lt; goal &gt; test-jar &lt;&#x2F; goal &gt;   </span><br><span class="line">            &lt;&#x2F; goals &gt;   </span><br><span class="line">        &lt;&#x2F; execution &gt;   </span><br><span class="line">    &lt;&#x2F; executions &gt;   </span><br><span class="line">&lt;&#x2F; plugin &gt;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>maven-jar-plugin有两个目标，分别为jar和test-jar。这两个目标都默认绑定到default生命周期的package阶段运行，只是test-jar并没有在超级POM中配置，因此需要我们另外在pom中配置</p>
<h1 id="使用maven构建web应用"><a href="#使用maven构建web应用" class="headerlink" title="使用maven构建web应用"></a>使用maven构建web应用</h1><p>之前我们讨论的都是JAR或者POM的Maven项目，但在现今的互联网时代，我们创建的大部分应用程序都是Web应用，基于Java的Web应用，其标准的打开方式是war。<br>WAR与JAR相似，只不过他可以包含更多的内容，如JSP文件、Servlet、Java类、web.xml配置文件、依赖JAR包、静态web资源（如HTML、CSS、JavaScript文件）等。一个典型的WAR文件会有如下目录结构：</p>
<p><img src="/images/maven/war%E6%96%87%E4%BB%B6%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.png" alt="war文件的目录结构"></p>
<p><img src="/images/maven/maven%E7%9A%84web%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.png" alt="maven的web目录结构"></p>
<p>1.需要注意的时war文件的目录下有一个lib文件夹，而maven项目下没有，这是因为maven项目的所有依赖都在pom文件中，只有在打包的时候才会被下载到lib文件夹中。</p>
<p>2.web应用全部都是需要依赖servlet-api和jsp-api这两个几乎所有的web应用都要依赖的包。因为他们胡server和api的编写提供支持，但是他们的依赖范围是provided，表示他们不会被打包到war文件中，因为几乎所有的web容器都会提供这两个类库。</p>
<p>3.在一些web项目中，读者可能胡看到finalName元素的配置，该元素用来标识项目生成主构件的名称，该元素默认值已经在超级pom中配置，值为${project.artifactId}-${project.version}.例如<finalName>course</finalName></p>
<h2 id="使用jetty-maven-plugin-进行测试"><a href="#使用jetty-maven-plugin-进行测试" class="headerlink" title="使用jetty-maven-plugin 进行测试"></a>使用jetty-maven-plugin 进行测试</h2><p>传统的web测试要求我们编译/测试/打包及部署，这会消耗大量的时间，jetty-maven-plugin能够节约我们的时间，它可以周期性的减产项目内容，便跟后更新到内置的jetty web容器中，<br>jetty-maven-plugin默认就很好地支持了Maven的项目目录，通常情况下插件发现编译后的变化后，自动将其更新到Jetty容器，就可以直接测试Web页面了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;build&gt;  </span><br><span class="line">    &lt;finalName&gt;rop-sample&lt;&#x2F;finalName&gt;  </span><br><span class="line">    &lt;plugins&gt;  </span><br><span class="line">        &lt;!-- jetty插件 --&gt;  </span><br><span class="line">        &lt;plugin&gt;  </span><br><span class="line">            &lt;groupId&gt;org.mortbay.jetty&lt;&#x2F;groupId&gt;  </span><br><span class="line">            &lt;artifactId&gt;maven-jetty-plugin&lt;&#x2F;artifactId&gt;  </span><br><span class="line">            &lt;version&gt;6.1.5&lt;&#x2F;version&gt;  </span><br><span class="line">            &lt;configuration&gt;  </span><br><span class="line">                &lt;webAppSourceDirectory&gt;src&#x2F;main&#x2F;webapp&lt;&#x2F;webAppSourceDirectory&gt;  </span><br><span class="line">                &lt;scanIntervalSeconds&gt;3&lt;&#x2F;scanIntervalSeconds&gt;  </span><br><span class="line">                &lt;contextPath&gt;&#x2F;&lt;&#x2F;contextPath&gt;  </span><br><span class="line">                &lt;connectors&gt;  </span><br><span class="line">                    &lt;connector implementation&#x3D;&quot;org.mortbay.jetty.nio.SelectChannelConnector&quot;&gt;  </span><br><span class="line">                        &lt;port&gt;8088&lt;&#x2F;port&gt;  </span><br><span class="line">                    &lt;&#x2F;connector&gt;  </span><br><span class="line">                &lt;&#x2F;connectors&gt;  </span><br><span class="line">            &lt;&#x2F;configuration&gt;  </span><br><span class="line">        &lt;&#x2F;plugin&gt;  </span><br><span class="line">    &lt;&#x2F;plugins&gt;  </span><br><span class="line">&lt;&#x2F;build&gt; </span><br><span class="line"></span><br><span class="line">其中scanIntervalSecond表示扫描项目变更的时间间隔，默认为0，表示不扫描。</span><br><span class="line">ContextPath表示项目的访问路径，比如此：http:&#x2F;&#x2F;localhost:8787&#x2F;test&#x2F;</span><br><span class="line"></span><br><span class="line">port表示绑定的端口号，默认监听的端口是8080。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/machao0903/article/details/73481095">intellij idea使用配置jetty maven 插件</a></p>
<p><a href="http://stamen.iteye.com/blog/1933452">解决maven热部署webapp下的文件不生效的问题</a></p>
<p>下一步是启动jetty-maven-plugin，不过在此之前需要对settings.xml做个微小的改动，默认的只有org.apache.maven.plugins和org.codehaus.mojo两个groupId下的插件支持简化的命令行调用。</p>
<p>mvn help:system 可以运行是因为groupId是org.apache.maven.plugins。而jetty-maven-plugin的插件不是，为了可以运行，需要在settings.xml中配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;settings&gt;</span><br><span class="line">  &lt;pluginGroups&gt;</span><br><span class="line">  &lt;pluginGroup&gt;</span><br><span class="line">    org.mortbay.jetty</span><br><span class="line">  &lt;&#x2F;pluginGroup&gt;</span><br><span class="line">   &lt;pluginGroups&gt;</span><br><span class="line">&lt;&#x2F;settings&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>然后可以使用 mvn:jetty:run命令，默认监听的是8080端口。</p>
<h2 id="使用cargo实现自动化部署"><a href="#使用cargo实现自动化部署" class="headerlink" title="使用cargo实现自动化部署"></a>使用cargo实现自动化部署</h2><p>为了能在命令行中使用cargo，需要修改maven的settings.xml文件，修改如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;pluginGroup&gt;org.codehaus.cargo&lt;&#x2F;pluginGroup&gt;</span><br></pre></td></tr></table></figure>

<p>Cargo支持两种本地部署的方式：standalone模式和existing模式。</p>
<h3 id="standalone模式"><a href="#standalone模式" class="headerlink" title="standalone模式"></a>standalone模式</h3><p>Cargo会从web容器的安装目录中复制一份配置到用户指定的目录，然后在此基础上部署应用，每次重新构建的时候，这个目录会被清空，所有配置被重新 生成。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.codehaus.cargo&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;cargo-maven2-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;container&gt;</span><br><span class="line">            &lt;containerId&gt;tomcat6x&lt;&#x2F;containerId&gt;</span><br><span class="line">            &lt;home&gt;D:\Program Files\apache-tomcat-6.0.18&lt;&#x2F;home&gt;</span><br><span class="line">        &lt;&#x2F;container&gt;</span><br><span class="line">        &lt;configuration&gt;</span><br><span class="line">            &lt;type&gt;standalone&lt;&#x2F;type&gt;</span><br><span class="line">            &lt;home&gt;$&#123;project.build.directory&#125;&#x2F;tomcat6x&lt;&#x2F;home&gt;</span><br><span class="line">             &lt;properties&gt; &lt;cargo.servlet.port&gt;8181&lt;&#x2F;cargo.servlet.port&gt; &lt;&#x2F;properties&gt;</span><br><span class="line">        &lt;&#x2F;configuration&gt;</span><br><span class="line">    &lt;&#x2F;configuration&gt;</span><br><span class="line">&lt;&#x2F;plugin&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>对参数做如下说明：</p>
<p>containerId表示容器的类型。</p>
<p>home表示容器的安装目录。</p>
<p>configuration子元素type表示部署模式。</p>
<p>configuration子元素home表示复制容器配置到什么位置，其中${project.build.directory}表示target目录。</p>
<p>Cargo.servlet.port表示绑定的端口号，默认为8080。</p>
<p>打开命令提示符，执行如下命令：</p>
<p>mvn clean package 和 mvn cargo:run </p>
<p>或者 mvn clean package cargo:run</p>
<h3 id="existing模式"><a href="#existing模式" class="headerlink" title="existing模式"></a>existing模式</h3><p>在该模式中，指定现有的web容器配置目录，cargo会直接使用这些配置并将应用部署到对应的位置。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.codehaus.cargo&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;cargo-maven2-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;container&gt;</span><br><span class="line">                &lt;containerId&gt;tomcat6x&lt;&#x2F;containerId&gt;</span><br><span class="line">                &lt;home&gt;D:\Program Files\apache-tomcat-6.0.18&lt;&#x2F;home&gt;</span><br><span class="line">        &lt;&#x2F;container&gt;</span><br><span class="line">        &lt;configuration&gt;</span><br><span class="line">            &lt;type&gt;existing&lt;&#x2F;type&gt;</span><br><span class="line">            &lt;home&gt;D:\Program Files\apache-tomcat-6.0.18&lt;&#x2F;home&gt;</span><br><span class="line">        &lt;&#x2F;configuration&gt;    </span><br><span class="line">    &lt;&#x2F;configuration&gt;</span><br><span class="line">&lt;&#x2F;plugin&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>执行如下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn clean compile</span><br><span class="line"></span><br><span class="line">mvn clean package</span><br><span class="line"></span><br><span class="line">mvn cargo:run</span><br></pre></td></tr></table></figure>
<p>之后cargo会自动把war包部署到D:\Program Files\apache-tomcat-6.0.18\webapps中。</p>
<h3 id="部署至远程web容器"><a href="#部署至远程web容器" class="headerlink" title="部署至远程web容器"></a>部署至远程web容器</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.codehaus.cargo&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;cargo-maven2-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;container&gt;</span><br><span class="line">            &lt;containerId&gt;tomcat6x&lt;&#x2F;containerId&gt;</span><br><span class="line">            &lt;type&gt;remote&lt;&#x2F;type&gt;</span><br><span class="line">        &lt;&#x2F;container&gt;</span><br><span class="line">        &lt;configuration&gt;</span><br><span class="line">            &lt;type&gt;runtime&lt;&#x2F;type&gt;</span><br><span class="line">            &lt;properties&gt;</span><br><span class="line">                &lt;cargo.remote.uri&gt;http:&#x2F;&#x2F;10.64.204.188:8080&#x2F;manager&lt;&#x2F;cargo.remote.uri&gt;</span><br><span class="line">                &lt;cargo.remote.username&gt;admin&lt;&#x2F;cargo.remote.username&gt;</span><br><span class="line">                &lt;cargo.remote.password&gt;admin&lt;&#x2F;cargo.remote.password&gt;</span><br><span class="line">            &lt;&#x2F;properties&gt;</span><br><span class="line">        &lt;&#x2F;configuration&gt;</span><br><span class="line">    &lt;&#x2F;configuration&gt;</span><br><span class="line">&lt;&#x2F;plugin&gt;</span><br><span class="line"></span><br><span class="line"> mvn clean compile</span><br><span class="line"> mvn clean package</span><br><span class="line"> mvn cargo:redeploy</span><br><span class="line"></span><br><span class="line">执行上述命令后可以从远程tomcat的控制台中就可以看到部署的项目信息。</span><br></pre></td></tr></table></figure>

<h1 id="版本管理"><a href="#版本管理" class="headerlink" title="版本管理"></a>版本管理</h1><p>版本管理是指项目整体版本的演变过程管理，版本控制是指借助版本控制工具追踪代码的每一个变更。</p>
<p>快照版本和发布版本。快照版本对应了项目的开发过程，往往对应了很长的时间，而正式版本对应了项目的发布，因此仅仅代表某个时刻项目的状态。</p>
<p><img src="/images/maven/%E5%BF%AB%E7%85%A7%E7%89%88%E6%9C%AC%E5%92%8C%E5%8F%91%E5%B8%83%E7%89%88%E6%9C%AC%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2.png" alt="快照版本和发布版本之间的转换"></p>
<p>满足发布版本的条件：</p>
<p>1.所有自动化测试应当全部通过；<br>2.项目没有配置任何快照版本的依赖；<br>3.项目没有配置任何快照版本的插件；<br>4.项目所包含的代码已经全部提交到版本控制系统中。</p>
<h2 id="版本号的定义"><a href="#版本号的定义" class="headerlink" title="版本号的定义"></a>版本号的定义</h2><p>&lt;主版本&gt;.&lt;次版本&gt;.&lt;增量版本&gt;-&lt;里程碑版本&gt;</p>
<p>主版本表示项目的重大架构变更；</p>
<p>次版本表示较大范围的功能增加和变化以及bug修复；</p>
<p>增量版本表示重大bug的修复；（非必须）</p>
<p>里程碑版本 与正式版本相比表示不是非常稳定，需要很多测试；（非必须）</p>
<h2 id="主干-标签和分支"><a href="#主干-标签和分支" class="headerlink" title="主干 标签和分支"></a>主干 标签和分支</h2><p>主干表示项目开发代码的主体；分支表示从主干的某个点分离出来的代码拷贝；tag表示主干或者分支的某个点的状态，表示项目的稳定状态，通常时发布状态。</p>
<h2 id="自动化版本发布"><a href="#自动化版本发布" class="headerlink" title="自动化版本发布"></a>自动化版本发布</h2><p>流程自动化。maven release plugin提供了这样的功能。主要有三个目标</p>
<p>1.release：prepare 准备版本发布，一次执行下列操作：</p>
<ul>
<li>检查项目是否有未提交的代码；</li>
<li>检查项目是否有快照版本的依赖；</li>
<li>根据用户的输入将快照版本升级为发布版；</li>
<li>将pom中的scm信息更新为标签地址；</li>
<li>基于修改后的pom执行maven构建；</li>
<li>提交pom变更；</li>
<li>基于用户输入人为代码打标签；</li>
<li>将代码从发布版升级为新的快照版本；</li>
<li>提交pom变更；</li>
</ul>
<p>2.release：rollback 回退release：prepare所执行的操作，将pom回退至该操作之前的状态，并提交。需要注意的是不会删除标签，需要用户手动删除。</p>
<p>3.release: perform 执行版本发布，签出 release:prepare生成的标签中的源代码，并在此基础上执行mvn deploy 命令打包并部署构件至仓库；</p>
<p>要为项目发布版本，首先需要为其添加正确的版本控制信息，这是因为maven release plugin需要知道版本控制系统的主干，标签等地址信息才能执行相关的操作。<br>一般的scm信息如代码所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;scm&gt;</span><br><span class="line"> &lt;connection&gt;scm:svn:http:&#x2F;&#x2F;192.168.1.103&#x2F;app&#x2F;trunk&lt;&#x2F;connection&gt; --表示只读的scm地址</span><br><span class="line"> &lt;developerConnection&gt;scm:svn:https:&#x2F;&#x2F;192.168.1.103&#x2F;app&#x2F;trunk&lt;&#x2F;developerConnection&gt;--表示一个可写的scm地址</span><br><span class="line"> &lt;url&gt;http:&#x2F;&#x2F;192.168.1.103&#x2F;account&#x2F;trunk&lt;&#x2F;url&gt;--表示可在浏览器访问的url地址</span><br><span class="line">&lt;&#x2F;scm&gt;</span><br><span class="line"></span><br><span class="line">&lt;plugin&gt;</span><br><span class="line"> &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;&gt;</span><br><span class="line"> &lt;artifactId&gt;maven-release-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line"> &lt;version&gt;2.0&lt;&#x2F;version&gt;</span><br><span class="line"> &lt;configuration&gt;</span><br><span class="line">  &lt;tagBase&gt;https:&#x2F;&#x2F;192.168.1.103&#x2F;app&#x2F;tags&#x2F;&lt;&#x2F;tagBase&gt;</span><br><span class="line"> &lt;&#x2F;configuration&gt;</span><br><span class="line">&lt;&#x2F;plugin&gt;</span><br><span class="line">注意：</span><br><span class="line">1、本机必须安装命令行可用的svn </span><br><span class="line">2、pom必须配置了可用的部署仓库</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>一切就绪之后，在项目的根目录下运行如下命令：<br>mvn release:prepare 之后，maven release plugin开始准备发布版本，如果检查到项目有未提交的代码，或者有依赖快照版本的会提示出错；<br>如果没有问题，则会提示用户输入想要发布的版本号/标签的名称以及新的快照版本号。</p>
<p>如果标签等信息配置错误，则可以输入release：rollback命令回退发布，maven release plugin会将pom的配置回退到release：prepare之前的状态，但需要注意的是版本控制系统的标签并不会被删除。</p>
<p>如果是多模块的项目，则会提示分别输入每个模块的发布版本号。</p>
<p>运行如下的命令后，maven-release-plugin就会自动为所有子模块使用与父模块相同的发布版本和新的SNAPSHOT版本：</p>
<p>mvn release：prepare -DautoVersionSubModules=true</p>
<p>如果所有的没有问题执行 mvn release:perform。该命令将标签中的代码签出，执行mvn deploy 命令构建刚才准备的1.0.0版本，并部署到仓库中。至此版本1.0.0发布完成。</p>
<h1 id="灵活的构建"><a href="#灵活的构建" class="headerlink" title="灵活的构建"></a>灵活的构建</h1><p>Maven为了支持构建的灵活性，内置三大属性，即：属性   Profile  资源过滤</p>
<h2 id="六大属性"><a href="#六大属性" class="headerlink" title="六大属性"></a>六大属性</h2><p>1.内置属性 ${basedir} 项目根目录， ${version} 表示项目版本。<br>2.pom属性</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$&#123;project.build.sourceDirectory&#125;：项目的主源码目录，默认为src&#x2F;main&#x2F;java&#x2F;。</span><br><span class="line">$&#123;project.build.testSourceDirectory&#125;：项目的测试源码目录，默认为src&#x2F;test&#x2F;java&#x2F;。</span><br><span class="line">$&#123;project.build.directory&#125;：项目构建输出目录，默认为target&#x2F;。</span><br><span class="line">$&#123;project.outputDirectory&#125;：项目的主代码编译输出目录，默认为target&#x2F;classes&#x2F;。</span><br><span class="line">$&#123;project.testOutputDirectory&#125;：项目测试代码编译输出目录，默认为target&#x2F;test-classes&#x2F;。</span><br><span class="line">$&#123;project.groupId&#125;：项目的groupId。</span><br><span class="line">$&#123;project.artifactId&#125;：项目的artifactId。</span><br><span class="line">$&#123;project.version&#125;：项目的version。</span><br><span class="line">$&#123;project.build.finalName&#125;：项目打包输出文件的名称，默认为$&#123;project.artifactId&#125;-$&#123;project.version&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>3.自定义属性</p>
<properties> 
 <sys.version> test </sys.version>
</properties>


<p>4.settings属性</p>
<p>用户以settings来头的属性引用settings文件中的xml元素的值。如常使用的${settings.localRepository} 执行本地仓库的地址</p>
<p>5.java系统属性</p>
<p>所有java系统属性都可以使用maven属性引用，${user.home} 指向了用户目录。</p>
<p>6.环境变量属性</p>
<p>所有环境变量属性都可以使用env.开头的maven属性引用。例如：${env.JAVA_HOME}指代了JAVA_HOME环境变量。</p>
<h2 id="构建环境的差异"><a href="#构建环境的差异" class="headerlink" title="构建环境的差异"></a>构建环境的差异</h2><p>使用不同的profile</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;profiles&gt;</span><br><span class="line">    &lt;profile&gt;</span><br><span class="line">        &lt;id&gt;dev&lt;&#x2F;id&gt;</span><br><span class="line">        &lt;properties&gt;</span><br><span class="line">            &lt;env&gt;dev&lt;&#x2F;env&gt;</span><br><span class="line">        &lt;&#x2F;properties&gt;</span><br><span class="line">        &lt;activation&gt;</span><br><span class="line">            &lt;activeByDefault&gt;true&lt;&#x2F;activeByDefault&gt;</span><br><span class="line">        &lt;&#x2F;activation&gt;</span><br><span class="line">    &lt;&#x2F;profile&gt;</span><br><span class="line">    &lt;profile&gt;</span><br><span class="line">        &lt;id&gt;prd&lt;&#x2F;id&gt;</span><br><span class="line">        &lt;properties&gt;</span><br><span class="line">            &lt;env&gt;prd&lt;&#x2F;env&gt;</span><br><span class="line">        &lt;&#x2F;properties&gt;</span><br><span class="line">    &lt;&#x2F;profile&gt;</span><br><span class="line">&lt;&#x2F;profiles&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="生成项目站点"><a href="#生成项目站点" class="headerlink" title="生成项目站点"></a>生成项目站点</h1><p>使用 maven-site-plugin</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot;</span><br><span class="line">         xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line"></span><br><span class="line">    &lt;groupId&gt;cn.chenwj&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-config&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;!-- 问题解决信息 --&gt;</span><br><span class="line">    &lt;issueManagement&gt;</span><br><span class="line">        &lt;system&gt;Linux&lt;&#x2F;system&gt;</span><br><span class="line">        &lt;url&gt;http:&#x2F;&#x2F;www.baidu.com&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">    &lt;&#x2F;issueManagement&gt;</span><br><span class="line">    &lt;!-- 持续集成信息 --&gt;</span><br><span class="line">    &lt;ciManagement&gt;</span><br><span class="line">        &lt;url&gt;http:&#x2F;&#x2F;127.0.0.1:8080&#x2F;hudson&lt;&#x2F;url&gt;</span><br><span class="line">        &lt;system&gt;windows&lt;&#x2F;system&gt;</span><br><span class="line">    &lt;&#x2F;ciManagement&gt;</span><br><span class="line">    &lt;!-- 开发人员信息 --&gt;</span><br><span class="line">    &lt;developers&gt;</span><br><span class="line">        &lt;developer&gt;</span><br><span class="line">            &lt;id&gt;liuyan&lt;&#x2F;id&gt;</span><br><span class="line">            &lt;email&gt;suhuanzheng7784877@163.com&lt;&#x2F;email&gt;</span><br><span class="line">            &lt;name&gt;liuyan&lt;&#x2F;name&gt;</span><br><span class="line">            &lt;organization&gt;uxian99&lt;&#x2F;organization&gt;</span><br><span class="line">            &lt;roles&gt;</span><br><span class="line">                &lt;role&gt;softwareengineer&lt;&#x2F;role&gt;</span><br><span class="line">            &lt;&#x2F;roles&gt;</span><br><span class="line">            &lt;timezone&gt;8&lt;&#x2F;timezone&gt;</span><br><span class="line">        &lt;&#x2F;developer&gt;</span><br><span class="line">    &lt;&#x2F;developers&gt;</span><br><span class="line">    &lt;!--许可证 --&gt;</span><br><span class="line">    &lt;licenses&gt;</span><br><span class="line">        &lt;license&gt;</span><br><span class="line">            &lt;url&gt;http:&#x2F;&#x2F;127.0.0.1:8080&lt;&#x2F;url&gt;</span><br><span class="line">            &lt;comments&gt;评论&lt;&#x2F;comments&gt;</span><br><span class="line">            &lt;name&gt;完全开源&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;&#x2F;license&gt;</span><br><span class="line">    &lt;&#x2F;licenses&gt;</span><br><span class="line">    &lt;scm&gt;</span><br><span class="line">        &lt;connection&gt;</span><br><span class="line">            scm:svn:https:&#x2F;&#x2F;liuyan:111111@127.0.0.1:8443&#x2F;svn&#x2F;mysvn&#x2F;mysrc&#x2F;01-OpenSource&#x2F;maven&#x2F;MavenAccount-aggregator</span><br><span class="line">        &lt;&#x2F;connection&gt;</span><br><span class="line">        &lt;developerConnection&gt;</span><br><span class="line">            scm:svn:https:&#x2F;&#x2F;liuyan:111111@127.0.0.1:8443&#x2F;svn&#x2F;mysvn&#x2F;mysrc&#x2F;01-OpenSource&#x2F;maven&#x2F;MavenAccount-aggregator</span><br><span class="line">        &lt;&#x2F;developerConnection&gt;</span><br><span class="line">        &lt;url&gt;https:&#x2F;&#x2F;127.0.0.1:8443&#x2F;svn&#x2F;mysvn&#x2F;mysrc&#x2F;01-OpenSource&#x2F;maven&#x2F;MavenAccount-aggregator</span><br><span class="line">        &lt;&#x2F;url&gt;</span><br><span class="line">    &lt;&#x2F;scm&gt;</span><br><span class="line">    &lt;reporting&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;!-- 构建项目站点报告插件--&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;maven-site-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                &lt;version&gt;3.0-beta-3&lt;&#x2F;version&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;!-- 配置站点国际化 --&gt;</span><br><span class="line">                    &lt;locales&gt;zh_CN&lt;&#x2F;locales&gt;</span><br><span class="line">                    &lt;!-- 输出编码 --&gt;</span><br><span class="line">                    &lt;outputEncoding&gt;GBK&lt;&#x2F;outputEncoding&gt;</span><br><span class="line">                &lt;&#x2F;configuration&gt;</span><br><span class="line">            &lt;&#x2F;plugin&gt;</span><br><span class="line">            &lt;!-- 构建项目站点报告插件--&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;maven-site-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                &lt;version&gt;3.0-beta-3&lt;&#x2F;version&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;!-- 配置报告信息 --&gt;</span><br><span class="line">                    &lt;reportPlugins&gt;</span><br><span class="line">                        &lt;!-- 检查代码规范报告 --&gt;</span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;maven-checkstyle-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line">                        &lt;!-- 测试报告 --&gt;</span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;maven-surefire-report-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line">                        &lt;!-- 项目基本信息报告 --&gt;</span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;maven-project-info-reports-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                            &lt;version&gt;2.2&lt;&#x2F;version&gt;</span><br><span class="line">                            &lt;configuration&gt;</span><br><span class="line">                                &lt;dependencyDetailsEnabled&gt;true&lt;&#x2F;dependencyDetailsEnabled&gt;</span><br><span class="line">                                &lt;dependencyLocationsEnabled&gt;false&lt;&#x2F;dependencyLocationsEnabled&gt;</span><br><span class="line">                            &lt;&#x2F;configuration&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line">                        &lt;!-- 项目API doc报告 --&gt;</span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;maven-javadoc-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                            &lt;version&gt;2.7&lt;&#x2F;version&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line">                        &lt;!-- 项目源代码报告 --&gt;</span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.codehaus.mojo&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;jxr-maven-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line">                        &lt;!-- 项目还需要做的TODO报告 --&gt;</span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.codehaus.mojo&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;taglist-maven-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line">                        &lt;!-- 项目源代码分析报告 --&gt;</span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;maven-pmd-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                            &lt;version&gt;2.5&lt;&#x2F;version&gt;</span><br><span class="line">                            &lt;configuration&gt;</span><br><span class="line">                                &lt;linkXref&gt;true&lt;&#x2F;linkXref&gt;</span><br><span class="line">                                &lt;sourceEncoding&gt;GBK&lt;&#x2F;sourceEncoding&gt;</span><br><span class="line">                                &lt;minimumTokens&gt;100&lt;&#x2F;minimumTokens&gt;</span><br><span class="line">                                &lt;targetJdk&gt;1.5&lt;&#x2F;targetJdk&gt;</span><br><span class="line">                            &lt;&#x2F;configuration&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;maven-dependency-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                            &lt;version&gt;3.1.1&lt;&#x2F;version&gt;</span><br><span class="line">                            &lt;executions&gt;</span><br><span class="line">                                &lt;execution&gt;</span><br><span class="line">                                    &lt;id&gt;copy&lt;&#x2F;id&gt;</span><br><span class="line">                                    &lt;phase&gt;package&lt;&#x2F;phase&gt;</span><br><span class="line">                                    &lt;goals&gt;</span><br><span class="line">                                        &lt;goal&gt;copy&lt;&#x2F;goal&gt;</span><br><span class="line">                                    &lt;&#x2F;goals&gt;</span><br><span class="line">                                    &lt;configuration&gt;</span><br><span class="line">                                        &lt;artifactItems&gt;</span><br><span class="line">                                            &lt;artifactItem&gt;</span><br><span class="line">                                                &lt;groupId&gt;[ groupId ]&lt;&#x2F;groupId&gt;</span><br><span class="line">                                                &lt;artifactId&gt;[ artifactId ]&lt;&#x2F;artifactId&gt;</span><br><span class="line">                                                &lt;version&gt;[ version ]&lt;&#x2F;version&gt;</span><br><span class="line">                                                &lt;type&gt;[ packaging ]&lt;&#x2F;type&gt;</span><br><span class="line">                                                &lt;classifier&gt;[classifier - optional]&lt;&#x2F;classifier&gt;</span><br><span class="line">                                                &lt;overWrite&gt;[ true or false ]&lt;&#x2F;overWrite&gt;</span><br><span class="line">                                                &lt;outputDirectory&gt;[ output directory ]&lt;&#x2F;outputDirectory&gt;</span><br><span class="line">                                                &lt;destFileName&gt;[ filename ]&lt;&#x2F;destFileName&gt;</span><br><span class="line">                                            &lt;&#x2F;artifactItem&gt;</span><br><span class="line">                                        &lt;&#x2F;artifactItems&gt;</span><br><span class="line">                                        &lt;!-- other configurations here --&gt;</span><br><span class="line">                                    &lt;&#x2F;configuration&gt;</span><br><span class="line">                                &lt;&#x2F;execution&gt;</span><br><span class="line">                            &lt;&#x2F;executions&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line">                        &lt;!-- 生成站点文件具体信息报告 --&gt;</span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;maven-linkcheck-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                            &lt;version&gt;1.1&lt;&#x2F;version&gt;</span><br><span class="line">                            &lt;configuration&gt;</span><br><span class="line">                            &lt;&#x2F;configuration&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line">                        &lt;!-- 单元测试覆盖率报告 --&gt;</span><br><span class="line">                        &lt;plugin&gt;</span><br><span class="line">                            &lt;groupId&gt;org.codehaus.mojo&lt;&#x2F;groupId&gt;</span><br><span class="line">                            &lt;artifactId&gt;cobertura-maven-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                        &lt;&#x2F;plugin&gt;</span><br><span class="line">                    &lt;&#x2F;reportPlugins&gt;</span><br><span class="line">                &lt;&#x2F;configuration&gt;</span><br><span class="line">            &lt;&#x2F;plugin&gt;</span><br><span class="line">        &lt;&#x2F;plugins&gt;</span><br><span class="line">    &lt;&#x2F;reporting&gt;</span><br><span class="line">&lt;&#x2F;project&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>运行maven site命令后，可以生成站点文件target/site/</p>
<p><img src="/images/maven/site%E7%AB%99%E7%82%B9%E6%96%87%E4%BB%B6.png" alt="site站点文件"></p>
<p>要在浏览器中预览结果，你可以运行mvn site:run，Maven会构建站点并启动一个内嵌的Jetty容器。一旦Jetty启动并开始监听8080端口（默认情况下），你就可以通过在浏览器中输入<a href="http://localhost:8080/%E6%9F%A5%E7%9C%8B%E9%A1%B9%E7%9B%AE%E7%AB%99%E7%82%B9%E4%BA%86%E3%80%82">http://localhost:8080/查看项目站点了。</a></p>
<p><img src="/images/maven/%E4%B8%B0%E5%AF%8C%E7%9A%84%E9%A1%B9%E7%9B%AE%E4%BF%A1%E6%81%AF.png" alt="丰富的项目信息"></p>
<p>可以通过丰富的项目报告插件配置，生成内容丰富的报告。报告插件不同于普通的插件（<project><build><plugins>）它是配置在<project><reporting><plugins>节点下</p>
<h1 id="pom元素-settings元素以及常用插件"><a href="#pom元素-settings元素以及常用插件" class="headerlink" title="pom元素 settings元素以及常用插件"></a>pom元素 settings元素以及常用插件</h1><p><img src="/images/maven/pom%E5%85%83%E7%B4%A01.png" alt="pom元素1"><br><img src="/images/maven/pom%E5%85%83%E7%B4%A02.png" alt="pom元素2"><br><img src="/images/maven/setting%E5%85%83%E7%B4%A0.png" alt="setting元素"><br><img src="/images/maven/%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B61.png" alt="常用插件1"><br><img src="/images/maven/%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B62.png" alt="常用插件2"></p>
<h1 id="Archetype的使用"><a href="#Archetype的使用" class="headerlink" title="Archetype的使用"></a>Archetype的使用</h1><p>archetype 可以快速生产项目骨架，可以理解archetype是maven项目的模板，例如maven-archetype-quickstart就是最简单的maven项目模板。</p>
<p>archetype是通过maven-archetype-plugin插件来实现的。</p>
<h2 id="使用archetype的一般步骤"><a href="#使用archetype的一般步骤" class="headerlink" title="使用archetype的一般步骤"></a>使用archetype的一般步骤</h2><p>1.执行命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maven3 :mvn archetype:generate</span><br><span class="line"></span><br><span class="line">maven2 :mvn org.apache.maven.plugins:maven-archetype-plugin:2.0-alpha-5:generate</span><br></pre></td></tr></table></figure>
<p>2.输入基本的参数</p>
<p>groupId artifactId version package </p>
<h2 id="常用archetype介绍"><a href="#常用archetype介绍" class="headerlink" title="常用archetype介绍"></a>常用archetype介绍</h2><ol>
<li><p>maven-archetype-quickstart 最简单的maven项目</p>
</li>
<li><p>maven-archetype-webapp 最简单的web项目</p>
</li>
</ol>
]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title>python2.7高级教程入门</title>
    <url>/2018-07-11/python2-7%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h1><h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><p>实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">class Employee:</span><br><span class="line">    &#39; 所有员工的基类 &#39;</span><br><span class="line">    empCount &#x3D; 0</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, salary):</span><br><span class="line">        self.name &#x3D; name</span><br><span class="line">        self.salary &#x3D; salary</span><br><span class="line">        Employee.empCount +&#x3D; 1</span><br><span class="line"></span><br><span class="line">    def displayCount(self):</span><br><span class="line">        print &quot;total employee %d&quot; % Employee.empCount</span><br><span class="line"></span><br><span class="line">    def displayEmployee(self):</span><br><span class="line">        print &quot;name:&quot;, self.name, &quot;,salary:&quot;, self.salary</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># empCount 变量是一个类变量，它的值将在这个类的所有实例之间共享。你可以在内部类或外部类使用 Employee.empCount 访问。</span><br><span class="line"># 第一种方法__init__()方法是一种特殊的方法，被称为类的构造函数或初始化方法，当创建了这个类的实例时就会调用该方法</span><br><span class="line"># self 代表类的实例，self 在定义类的方法时是必须有的，虽然在调用时不必传入相应的参数。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="创建实例对象和访问属性与调用方法"><a href="#创建实例对象和访问属性与调用方法" class="headerlink" title="创建实例对象和访问属性与调用方法"></a>创建实例对象和访问属性与调用方法</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">emp1 &#x3D; Employee(&quot;lee&quot;, 2000)</span><br><span class="line">emp2 &#x3D; Employee(&quot;zhang&quot;, 4000)</span><br><span class="line"></span><br><span class="line">emp1.displayCount()</span><br><span class="line">emp2.displayEmployee()</span><br><span class="line"></span><br><span class="line">print &quot;total employee %d&quot; % Employee.empCount</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="对属性的操作"><a href="#对属性的操作" class="headerlink" title="对属性的操作"></a>对属性的操作</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">emp1.age &#x3D; 7  # 添加一个 &#39;age&#39; 属性</span><br><span class="line">emp1.age &#x3D; 8  # 修改 &#39;age&#39; 属性</span><br><span class="line">del emp1.age  # 删除 &#39;age&#39; 属性</span><br><span class="line"></span><br><span class="line">hasattr(emp1, &#39;age&#39;)    # 如果存在 &#39;age&#39; 属性返回 True。</span><br><span class="line">getattr(emp1, &#39;age&#39;)    # 返回 &#39;age&#39; 属性的值</span><br><span class="line">setattr(emp1, &#39;age&#39;, 8) # 添加属性 &#39;age&#39; 值为 8</span><br><span class="line">delattr(emp1, &#39;age&#39;)    # 删除属性 &#39;age&#39;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="python内置类属性"><a href="#python内置类属性" class="headerlink" title="python内置类属性"></a>python内置类属性</h2><ul>
<li><strong>dict</strong> : 类的属性（包含一个字典，由类的数据属性组成）</li>
<li><strong>doc</strong> :类的文档字符串</li>
<li><strong>name</strong>: 类名</li>
<li><strong>module</strong>: 类定义所在的模块（类的全名是’<strong>main</strong>.className’，如果类位于一个导入模块mymod中，那么className.<strong>module</strong> 等于 mymod）</li>
<li><strong>bases</strong> : 类的所有父类构成元素（包含了一个由所有父类组成的元组）</li>
</ul>
<h2 id="python对象销毁-垃圾回收"><a href="#python对象销毁-垃圾回收" class="headerlink" title="python对象销毁(垃圾回收)"></a>python对象销毁(垃圾回收)</h2><p>Python 使用了引用计数这一简单技术来跟踪和回收垃圾。在 Python 内部记录着所有使用中的对象各有多少引用。<br>一个内部跟踪变量，称为一个引用计数器。<br>当对象被创建时， 就创建了一个引用计数， 当这个对象不再需要时， 也就是说， 这个对象的引用计数变为0 时， 它被垃圾回收。但是回收不是”立即”的， 由解释器在适当的时机，将垃圾对象占用的内存空间回收。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"> </span><br><span class="line">class Point:</span><br><span class="line">   def __init__( self, x&#x3D;0, y&#x3D;0):</span><br><span class="line">      self.x &#x3D; x</span><br><span class="line">      self.y &#x3D; y</span><br><span class="line">   def __del__(self):</span><br><span class="line">      class_name &#x3D; self.__class__.__name__</span><br><span class="line">      print class_name, &quot;销毁&quot;</span><br><span class="line"> </span><br><span class="line">pt1 &#x3D; Point()</span><br><span class="line">pt2 &#x3D; pt1</span><br><span class="line">pt3 &#x3D; pt1</span><br><span class="line">print id(pt1), id(pt2), id(pt3) # 打印对象的id</span><br><span class="line">del pt1</span><br><span class="line">del pt2</span><br><span class="line">del pt3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="类的继承"><a href="#类的继承" class="headerlink" title="类的继承"></a>类的继承</h2><p>通过继承创建的新类称为子类或派生类，被继承的类称为基类、父类或超类。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class SubClassName (ParentClass1[, ParentClass2, ...]):</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="方法重写"><a href="#方法重写" class="headerlink" title="方法重写"></a>方法重写</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"> </span><br><span class="line">class Parent:        # 定义父类</span><br><span class="line">   def myMethod(self):</span><br><span class="line">      print &#39;调用父类方法&#39;</span><br><span class="line"> </span><br><span class="line">class Child(Parent): # 定义子类</span><br><span class="line">   def myMethod(self):</span><br><span class="line">      print &#39;调用子类方法&#39;</span><br><span class="line"> </span><br><span class="line">c &#x3D; Child()          # 子类实例</span><br><span class="line">c.myMethod()         # 子类调用重写方法</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="类属性与方法"><a href="#类属性与方法" class="headerlink" title="类属性与方法"></a>类属性与方法</h2><h3 id="类的私有属性"><a href="#类的私有属性" class="headerlink" title="类的私有属性"></a>类的私有属性</h3><p>__private_attrs：两个下划线开头，声明该属性为私有，不能在类的外部被使用或直接访问。在类内部的方法中使用时 self.__private_attrs。</p>
<h3 id="类的方法"><a href="#类的方法" class="headerlink" title="类的方法"></a>类的方法</h3><p>在类的内部，使用 def 关键字可以为类定义一个方法，与一般函数定义不同，类方法必须包含参数 self,且为第一个参数</p>
<h3 id="类的私有方法"><a href="#类的私有方法" class="headerlink" title="类的私有方法"></a>类的私有方法</h3><p>__private_method：两个下划线开头，声明该方法为私有方法，不能在类的外部调用。在类的内部调用 self.__private_methods</p>
<p>Python不允许实例化的类访问私有数据，但你可以使用 object._className__attrName（ 对象名._类名__私有属性名 ）访问属性</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">class Runoob:</span><br><span class="line">    __site &#x3D; &quot;www.runoob.com&quot;</span><br><span class="line"></span><br><span class="line">runoob &#x3D; Runoob()</span><br><span class="line">print runoob._Runoob__site</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="单下划线、双下划线、头尾双下划线说明："><a href="#单下划线、双下划线、头尾双下划线说明：" class="headerlink" title="单下划线、双下划线、头尾双下划线说明："></a>单下划线、双下划线、头尾双下划线说明：</h2><ul>
<li><strong>foo</strong>: 定义的是特殊方法，一般是系统定义名字 ，类似 <strong>init</strong>() 之类的。</li>
<li>_foo: 以单下划线开头的表示的是 protected 类型的变量，即保护类型只能允许其本身与子类进行访问，不能用于 from module import *</li>
<li>__foo: 双下划线的表示的是私有类型(private)的变量, 只能是允许这个类本身进行访问了。</li>
</ul>
<h1 id="python正则表达式"><a href="#python正则表达式" class="headerlink" title="python正则表达式"></a>python正则表达式</h1><p>Python 自1.5版本起增加了re 模块，它提供 Perl 风格的正则表达式模式。</p>
<h2 id="re-match函数"><a href="#re-match函数" class="headerlink" title="re.match函数"></a>re.match函数</h2><p>re.match 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。</p>
<p>re.match(pattern, string, flags=0)</p>
<ul>
<li><p>pattern    匹配的正则表达式</p>
</li>
<li><p>string    要匹配的字符串。</p>
</li>
<li><p>flags    标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。</p>
</li>
</ul>
<h2 id="group"><a href="#group" class="headerlink" title="group"></a>group</h2><p>我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。</p>
<ul>
<li>group(num=0)    匹配的整个表达式的字符串，group() 可以一次输入多个组号，在这种情况下它将返回一个包含那些组所对应值的元组。</li>
<li>groups()    返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。</li>
</ul>
<h2 id="re-search方法"><a href="#re-search方法" class="headerlink" title="re.search方法"></a>re.search方法</h2><p>re.search  扫描整个字符串并返回第一个成功的匹配。</p>
<h2 id="re-match与re-search的区别"><a href="#re-match与re-search的区别" class="headerlink" title="re.match与re.search的区别"></a>re.match与re.search的区别</h2><p>re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。</p>
<h2 id="检索和替换-re-sub"><a href="#检索和替换-re-sub" class="headerlink" title="检索和替换 re.sub"></a>检索和替换 re.sub</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">re.sub(pattern, repl, string, count&#x3D;0, flags&#x3D;0)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>pattern : 正则中的模式字符串。</li>
<li>repl : 替换的字符串，也可为一个函数。</li>
<li>string : 要被查找替换的原始字符串。</li>
<li>count : 模式匹配后替换的最大次数，默认 0 表示替换所有的匹配。</li>
</ul>
<h2 id="re-compile-函数"><a href="#re-compile-函数" class="headerlink" title="re.compile 函数"></a>re.compile 函数</h2><p>compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用。<br>语法格式为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">re.compile(pattern[, flags])</span><br><span class="line"></span><br><span class="line">pattern : 一个字符串形式的正则表达式</span><br><span class="line">flags : 可选，表示匹配模式，比如忽略大小写，多行模式等，具体参数为：</span><br><span class="line">re.I 忽略大小写</span><br><span class="line">re.L 表示特殊字符集 \w, \W, \b, \B, \s, \S 依赖于当前环境</span><br><span class="line">re.M 多行模式</span><br><span class="line">re.S 即为 . 并且包括换行符在内的任意字符（. 不包括换行符）</span><br><span class="line">re.U 表示特殊字符集 \w, \W, \b, \B, \d, \D, \s, \S 依赖于 Unicode 字符属性数据库</span><br><span class="line">re.X 为了增加可读性，忽略空格和 # 后面的注释</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pattern &#x3D; re.compile(r&#39;\d+&#39;)                    # 用于匹配至少一个数字</span><br><span class="line">m &#x3D; pattern.match(&#39;one12twothree34four&#39;)        # 查找头部，没有匹配</span><br><span class="line">print m</span><br><span class="line">m &#x3D; pattern.match(&#39;one12twothree34four&#39;, 2, 10) # 从&#39;e&#39;的位置开始匹配，没有匹配</span><br><span class="line">print m</span><br><span class="line">m &#x3D; pattern.match(&#39;one12twothree34four&#39;, 3, 10) # 从&#39;1&#39;的位置开始匹配，正好匹配</span><br><span class="line">print m                                         # 返回一个 Match 对象</span><br><span class="line">print m.group(0)   # 可省略 0</span><br><span class="line">print m.start(0)   # 可省略 0</span><br><span class="line">print m.end(0)     # 可省略 0</span><br><span class="line">print m.span(0)    # 可省略 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在上面，当匹配成功时返回一个 Match 对象，其中：</p>
<ul>
<li>group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)；</li>
<li>start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0；</li>
<li>end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0；</li>
<li>span([group]) 方法返回 (start(group), end(group))。</li>
</ul>
<h2 id="findall"><a href="#findall" class="headerlink" title="findall"></a>findall</h2><p>在字符串中找到正则表达式所匹配的所有子串，并返回一个列表，如果没有找到匹配的，则返回空列表。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">findall(string[, pos[, endpos]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>string : 待匹配的字符串。</li>
<li>pos : 可选参数，指定字符串的起始位置，默认为 0。</li>
<li>endpos : 可选参数，指定字符串的结束位置，默认为字符串的长度。</li>
</ul>
<h2 id="re-finditer"><a href="#re-finditer" class="headerlink" title="re.finditer"></a>re.finditer</h2><p>和 findall 类似，在字符串中找到正则表达式所匹配的所有子串，并把它们作为一个迭代器返回。</p>
<p>re.finditer(pattern, string, flags=0)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">it &#x3D; re.finditer(r&quot;\d+&quot;,&quot;12a32bc43jf3&quot;)</span><br><span class="line">for match in it:</span><br><span class="line">    print (match.group() )</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="re-split"><a href="#re-split" class="headerlink" title="re.split"></a>re.split</h2><p>split 方法按照能够匹配的子串将字符串分割后返回列表</p>
<h2 id="正则表达式对象"><a href="#正则表达式对象" class="headerlink" title="正则表达式对象"></a>正则表达式对象</h2><h3 id="re-RegexObject"><a href="#re-RegexObject" class="headerlink" title="re.RegexObject"></a>re.RegexObject</h3><p>re.compile() 返回 RegexObject 对象。</p>
<h3 id="re-MatchObject"><a href="#re-MatchObject" class="headerlink" title="re.MatchObject"></a>re.MatchObject</h3><ul>
<li>group() 返回被 RE 匹配的字符串。</li>
<li>start() 返回匹配开始的位置</li>
<li>end() 返回匹配结束的位置</li>
<li>span() 返回一个元组包含匹配 (开始,结束) 的位置</li>
</ul>
<h2 id="正则表达式模式"><a href="#正则表达式模式" class="headerlink" title="正则表达式模式"></a>正则表达式模式</h2><ul>
<li>字母和数字表示他们自身。一个正则表达式模式中的字母和数字匹配同样的字符串。</li>
<li>多数字母和数字前加一个反斜杠时会拥有不同的含义。</li>
<li>标点符号只有被转义时才匹配自身，否则它们表示特殊的含义。</li>
<li>反斜杠本身需要使用反斜杠转义。</li>
<li>由于正则表达式通常都包含反斜杠，所以你最好使用原始字符串来表示它们。模式元素(如 r’\t’，等价于 ‘\t’)匹配相应的特殊字符。</li>
</ul>
<h1 id="CGI编程"><a href="#CGI编程" class="headerlink" title="CGI编程"></a>CGI编程</h1><p>Python 提供了两个级别访问的网络服务。：</p>
<ol>
<li>低级别的网络服务支持基本的 Socket，它提供了标准的 BSD Sockets API，可以访问底层操作系统Socket接口的全部方法。</li>
<li>高级别的网络服务模块 SocketServer， 它提供了服务器中心类，可以简化网络服务器的开发。</li>
</ol>
<h2 id="socket-函数"><a href="#socket-函数" class="headerlink" title="socket()函数"></a>socket()函数</h2><p>socket.socket([family[, type[, proto]]])</p>
<p>family: 套接字家族可以使AF_UNIX或者AF_INET</p>
<p>type: 套接字类型可以根据是面向连接的还是非连接分为SOCK_STREAM或SOCK_DGRAM</p>
<p>protocol: 一般不填默认为0.</p>
<h2 id="Socket-对象-内建-方法"><a href="#Socket-对象-内建-方法" class="headerlink" title="Socket 对象(内建)方法"></a>Socket 对象(内建)方法</h2><h3 id="服务器端套接字"><a href="#服务器端套接字" class="headerlink" title="服务器端套接字"></a>服务器端套接字</h3><p>s.bind() 绑定地址（host,port）到套接字， 在AF_INET下,以元组（host,port）的形式表示地址。</p>
<p>s.listen() 开始TCP监听</p>
<p>s.accept() 被动接受TCP客户端连接,(阻塞式)等待连接的到来</p>
<h3 id="客户端套接字"><a href="#客户端套接字" class="headerlink" title="客户端套接字"></a>客户端套接字</h3><p>s.connect()    主动初始化TCP服务器连接，。一般address的格式为元组（hostname,port），如果连接出错，返回socket.error错误。</p>
<h3 id="公共用途的套接字函数"><a href="#公共用途的套接字函数" class="headerlink" title="公共用途的套接字函数"></a>公共用途的套接字函数</h3><p>s.recv() 接收TCP数据，数据以字符串形式返回，bufsize指定要接收的最大数据量。flag提供有关消息的其他信息，通常可以忽略。</p>
<p>s.send() 发送TCP数据，将string中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于string的字节大小。</p>
<p>s.close() 关闭套接字</p>
<p>客户端示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"># 文件名：client.py</span><br><span class="line"></span><br><span class="line">import socket               # 导入 socket 模块</span><br><span class="line"></span><br><span class="line">s &#x3D; socket.socket()         # 创建 socket 对象</span><br><span class="line">host &#x3D; socket.gethostname() # 获取本地主机名</span><br><span class="line">port &#x3D; 12345                # 设置端口号</span><br><span class="line"></span><br><span class="line">s.connect((host, port))</span><br><span class="line">print s.recv(1024)</span><br><span class="line">s.close() </span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="Python-Internet-模块"><a href="#Python-Internet-模块" class="headerlink" title="Python Internet 模块"></a>Python Internet 模块</h3><p><img src="/images/python/2.7/PythonInternet%E6%A8%A1%E5%9D%97.png" alt="Python Internet 模块"></p>
<h1 id="python多线程"><a href="#python多线程" class="headerlink" title="python多线程"></a>python多线程</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">thread.start_new_thread ( function, args[, kwargs] </span><br><span class="line"></span><br><span class="line">function - 线程函数。</span><br><span class="line"></span><br><span class="line">args - 传递给线程函数的参数,他必须是个tuple类型。</span><br><span class="line"></span><br><span class="line">kwargs - 可选参数。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="python多线程的例子"><a href="#python多线程的例子" class="headerlink" title="python多线程的例子"></a>python多线程的例子</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import thread</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 为线程定义一个函数</span><br><span class="line">def print_time(threadName, delay):</span><br><span class="line">    count &#x3D; 0</span><br><span class="line">    while (count &lt; 5):</span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        count &#x3D; +1</span><br><span class="line">        print &quot;%s: %s&quot; % (threadName, time.ctime(time.time()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建两个线程</span><br><span class="line">try:</span><br><span class="line">    thread.start_new_thread(print_time, (&quot;Thread-1&quot;, 2), )</span><br><span class="line">    thread.start_new_thread(print_time, (&quot;Thread-2&quot;, 4), )</span><br><span class="line">except:</span><br><span class="line">    print &quot;Error: unable to start thread&quot;</span><br><span class="line"></span><br><span class="line">while 1:</span><br><span class="line">    pass</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="线程模块"><a href="#线程模块" class="headerlink" title="线程模块"></a>线程模块</h2><p>Python通过两个标准库thread和threading提供对线程的支持。thread提供了低级别的、原始的线程以及一个简单的锁</p>
<p>threading.currentThread(): 返回当前的线程变量。</p>
<p>threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。</p>
<p>threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。</p>
<p>线程模块同样提供了Thread类来处理线程，Thread类提供了以下方法:</p>
<p>run(): 用以表示线程活动的方法。</p>
<p>start():启动线程活动。</p>
<p>join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。</p>
<p>isAlive(): 返回线程是否活动的。</p>
<p>getName(): 返回线程名。</p>
<p>setName(): 设置线程名。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"> </span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line">exitFlag &#x3D; 0</span><br><span class="line"> </span><br><span class="line">class myThread (threading.Thread):   #继承父类threading.Thread</span><br><span class="line">    def __init__(self, threadID, name, counter):</span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.threadID &#x3D; threadID</span><br><span class="line">        self.name &#x3D; name</span><br><span class="line">        self.counter &#x3D; counter</span><br><span class="line">    def run(self):                   #把要执行的代码写到run函数里面 线程在创建后会直接运行run函数 </span><br><span class="line">        print &quot;Starting &quot; + self.name</span><br><span class="line">        print_time(self.name, self.counter, 5)</span><br><span class="line">        print &quot;Exiting &quot; + self.name</span><br><span class="line"> </span><br><span class="line">def print_time(threadName, delay, counter):</span><br><span class="line">    while counter:</span><br><span class="line">        if exitFlag:</span><br><span class="line">            (threading.Thread).exit()</span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        print &quot;%s: %s&quot; % (threadName, time.ctime(time.time()))</span><br><span class="line">        counter -&#x3D; 1</span><br><span class="line"> </span><br><span class="line"># 创建新线程</span><br><span class="line">thread1 &#x3D; myThread(1, &quot;Thread-1&quot;, 1)</span><br><span class="line">thread2 &#x3D; myThread(2, &quot;Thread-2&quot;, 2)</span><br><span class="line"> </span><br><span class="line"># 开启线程</span><br><span class="line">thread1.start()</span><br><span class="line">thread2.start()</span><br><span class="line"> </span><br><span class="line">print &quot;Exiting Main Thread&quot;</span><br></pre></td></tr></table></figure>

<h2 id="线程同步"><a href="#线程同步" class="headerlink" title="线程同步"></a>线程同步</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"> </span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line">class myThread (threading.Thread):</span><br><span class="line">    def __init__(self, threadID, name, counter):</span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.threadID &#x3D; threadID</span><br><span class="line">        self.name &#x3D; name</span><br><span class="line">        self.counter &#x3D; counter</span><br><span class="line">    def run(self):</span><br><span class="line">        print &quot;Starting &quot; + self.name</span><br><span class="line">       # 获得锁，成功获得锁定后返回True</span><br><span class="line">       # 可选的timeout参数不填时将一直阻塞直到获得锁定</span><br><span class="line">       # 否则超时后将返回False</span><br><span class="line">        threadLock.acquire()</span><br><span class="line">        print_time(self.name, self.counter, 3)</span><br><span class="line">        # 释放锁</span><br><span class="line">        threadLock.release()</span><br><span class="line"> </span><br><span class="line">def print_time(threadName, delay, counter):</span><br><span class="line">    while counter:</span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        print &quot;%s: %s&quot; % (threadName, time.ctime(time.time()))</span><br><span class="line">        counter -&#x3D; 1</span><br><span class="line"> </span><br><span class="line">threadLock &#x3D; threading.Lock()</span><br><span class="line">threads &#x3D; []</span><br><span class="line"> </span><br><span class="line"># 创建新线程</span><br><span class="line">thread1 &#x3D; myThread(1, &quot;Thread-1&quot;, 1)</span><br><span class="line">thread2 &#x3D; myThread(2, &quot;Thread-2&quot;, 2)</span><br><span class="line"> </span><br><span class="line"># 开启新线程</span><br><span class="line">thread1.start()</span><br><span class="line">thread2.start()</span><br><span class="line"> </span><br><span class="line"># 添加线程到线程列表</span><br><span class="line">threads.append(thread1)</span><br><span class="line">threads.append(thread2)</span><br><span class="line"> </span><br><span class="line"># 等待所有线程完成</span><br><span class="line">for t in threads:</span><br><span class="line">    t.join()</span><br><span class="line">print &quot;Exiting Main Thread&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="python-JSON"><a href="#python-JSON" class="headerlink" title="python JSON"></a>python JSON</h1><p>使用 Python 语言来编码和解码 JSON 对象。</p>
<ol>
<li><p>json.dumps    将 Python 对象编码成 JSON 字符串</p>
</li>
<li><p>json.loads    将已编码的 JSON 字符串解码为 Python 对象</p>
</li>
</ol>
<p><strong>json类型转换到python的类型对照表</strong></p>
<p><img src="/images/python/2.7/json%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E5%88%B0python%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%AF%B9%E7%85%A7%E8%A1%A8.png" alt="json类型转换到python的类型对照表"></p>
<p><a href="https://github.com/dmeranda/demjson">Demjson</a> 是python的第三方JSON类库。</p>
<p>1.encode    将 Python 对象编码成 JSON 字符串</p>
<p>2.decode    将已编码的 JSON 字符串解码为 Python 对象</p>
<h1 id="python2-0和python3的区别"><a href="#python2-0和python3的区别" class="headerlink" title="python2.0和python3的区别"></a>python2.0和python3的区别</h1><ol>
<li><p>print语句没有了，取而代之的是print()函数</p>
</li>
<li><p>Python3.X 源码文件默认使用utf-8编码</p>
</li>
<li><p>除法运算：</p>
<p>在python 2.x中/除法就跟我们熟悉的大多数语言，比如Java啊C啊差不多，整数相除的结果是一个整数，把小数部分完全忽略掉，浮点数除法会保留小数点的部分得到一个浮点数的结果。</p>
<p>在python 3.x中/除法不再这么做了，对于整数之间的相除，结果也会是浮点数</p>
</li>
</ol>
<p>等等。。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python2.7高级教程</tag>
      </tags>
  </entry>
  <entry>
    <title>python2.7入门笔记</title>
    <url>/2018-06-29/python2.7%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="python介绍"><a href="#python介绍" class="headerlink" title="python介绍"></a>python介绍</h1><p>python是一种解释型、面向对象、动态数据类型高级程序设计语言、脚本语言。由荷兰人发明。</p>
<h1 id="基础语法"><a href="#基础语法" class="headerlink" title="基础语法"></a>基础语法</h1><h2 id="Python-标识符"><a href="#Python-标识符" class="headerlink" title="Python 标识符"></a>Python 标识符</h2><ol>
<li>在 Python 里，标识符由字母、数字、下划线组成。</li>
<li>在 Python 中，所有标识符可以包括英文、数字以及下划线(_)，<strong>但不能以数字开头</strong>。</li>
<li>Python 中的标识符是区分大小写的。</li>
<li>以<strong>下划线开头</strong>的标识符是有特殊意义的。以单下划线开头 _foo 的代表<strong>不能直接访问的类属性</strong>，需通过类提供的接口进行访问，不能用 *<em>from xxx import * 而导入*</em></li>
<li>以<strong>双下划线开头</strong>的 <strong>foo 代表类的私有成员；以<strong>双下划线开头和结尾</strong>的 __foo</strong> 代表 Python 里特殊方法专用的标识，如 <strong>init</strong>() 代表类的构造函数</li>
<li>Python 可以同一行显示多条语句，方法是用分号 ; 分开</li>
</ol>
<h2 id="Python保留字"><a href="#Python保留字" class="headerlink" title="Python保留字"></a>Python保留字</h2><p>包括 and <strong>exec</strong> <strong>not</strong> assert finally or break for <strong>pass</strong> class <strong>from</strong> print continue <strong>global</strong> <strong>raise</strong> def if return <strong>del</strong></p>
<p>import try <strong>elif</strong> in while else <strong>is</strong> <strong>with</strong> <strong>except</strong> <strong>lambda</strong> yield</p>
<h2 id="行和缩进"><a href="#行和缩进" class="headerlink" title="行和缩进"></a>行和缩进</h2><p>Python 的代码块不使用大括号 {} 来控制类，函数以及其他逻辑判断。python 最具特色的就是用缩进来写模块。</p>
<p><strong>常见的错误：</strong> IndentationError: unindent does not match any outer indentation level错误表明，你使用的缩进方式不一致，有的是 tab 键缩进，有的是空格缩进，改为一致即可。</p>
<h2 id="多行语句"><a href="#多行语句" class="headerlink" title="多行语句"></a>多行语句</h2><p>Python语句中一般以新行作为语句的结束符。</p>
<p>但是我们可以使用斜杠（ \）将一行的语句分为多行显示。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">total &#x3D;item_one + \</span><br><span class="line">       item_two + \</span><br><span class="line">       item_three</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>语句中包含 [], {} 或 () 括号就不需要使用多行连接符。如下实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">days &#x3D; [&#39;Monday&#39;, &#39;Tuesday&#39;, &#39;Wednesday&#39;,</span><br><span class="line">        &#39;Thursday&#39;, &#39;Friday&#39;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Python-引号"><a href="#Python-引号" class="headerlink" title="Python 引号"></a>Python 引号</h2><p>Python 可以使用引号( ‘ )、双引号( “ )、三引号( ‘’’ 或 “”” ) 来表示字符串，引号的开始与结束必须的相同类型的。</p>
<p>其中三引号可以由多行组成，编写多行文本的快捷语法，常用于文档字符串，在文件的特定地点，被当做注释。</p>
<h2 id="Python-注释"><a href="#Python-注释" class="headerlink" title="Python 注释"></a>Python 注释</h2><p>python中单行注释采用 # 开头。可以在语句或者表达式行末；</p>
<p>多行使用三引号表示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#39;&#39;&#39;</span><br><span class="line">这是多行注释，使用单引号。</span><br><span class="line">这是多行注释，使用单引号。</span><br><span class="line">这是多行注释，使用单引号。</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">这是多行注释，使用双引号。</span><br><span class="line">这是多行注释，使用双引号。</span><br><span class="line">这是多行注释，使用双引号。</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Python空行"><a href="#Python空行" class="headerlink" title="Python空行"></a>Python空行</h2><p>函数之间或类的方法之间用空行分隔，表示一段新的代码的开始。类和函数入口之间也用一行空行分隔，以突出函数入口的开始。</p>
<p>空行与代码缩进不同，空行并不是Python语法的一部分。书写时不插入空行，Python解释器运行也不会出错。但是空行的作用在于分隔两段不同功能或含义的代码，便于日后代码的维护或重构。</p>
<p>记住：空行也是程序代码的一部分。</p>
<h2 id="等待用户输入"><a href="#等待用户输入" class="headerlink" title="等待用户输入"></a>等待用户输入</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">raw_input(&quot;按下 enter键退出，其他任意键显示。。。\n&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="同一行显示多条语句"><a href="#同一行显示多条语句" class="headerlink" title="同一行显示多条语句"></a>同一行显示多条语句</h2><p>同一行显示多条语句使用;分割</p>
<h2 id="Print输出"><a href="#Print输出" class="headerlink" title="Print输出"></a>Print输出</h2><p>print 默认输出是换行的，如果要实现不换行需要在变量末尾加上逗号 ,</p>
<h1 id="变量类型"><a href="#变量类型" class="headerlink" title="变量类型"></a>变量类型</h1><p>有五个标准的数据类型：Numbers（数字）/  String（字符串） /List（列表）/Tuple（元组）/Dictionary（字典）</p>
<p>python中变量类型不需要声明，每个变量在内存中创建都包括变量的标识，名称和数据这些信息。</p>
<p>每个变量在使用前都会被赋值，变量赋值后才会被创建。</p>
<h2 id="多个变量赋值"><a href="#多个变量赋值" class="headerlink" title="多个变量赋值"></a>多个变量赋值</h2><p>a =b =c =1</p>
<p>或者 a, b ,c =1,2,”hohn”</p>
<h2 id="python数字"><a href="#python数字" class="headerlink" title="python数字"></a>python数字</h2><p>当你指定一个值时，Number对象就会被创建，使用del语句删除单个或多个对象的引用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var1 &#x3D; 1</span><br><span class="line"></span><br><span class="line">var2 &#x3D;10</span><br><span class="line"></span><br><span class="line">del var1,var2</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>python支持4种不同的数据类型 int long float complex（复数）</p>
<h3 id="Python-math-模块、cmath-模块"><a href="#Python-math-模块、cmath-模块" class="headerlink" title="Python math 模块、cmath 模块"></a>Python math 模块、cmath 模块</h3><p>Python 中数学运算常用的函数基本都在 math 模块、cmath 模块中。</p>
<p>Python math 模块提供了许多对浮点数的数学运算函数。</p>
<p>Python cmath 模块包含了一些用于复数运算的函数。</p>
<p>cmath 模块的函数跟 math 模块函数基本一致，区别是 cmath 模块运算的是复数，math 模块运算的是数学运算。</p>
<h3 id="python数学函数"><a href="#python数学函数" class="headerlink" title="python数学函数"></a>python数学函数</h3><p>abs(x)    返回数字的绝对值，如abs(-10) 返回 10</p>
<p>ceil(x)    返回数字的上入整数，如math.ceil(4.1) 返回 5</p>
<p>cmp(x, y)    如果 x &lt; y 返回 -1, 如果 x == y 返回 0, 如果 x &gt; y 返回 1</p>
<p>exp(x)    返回e的x次幂(ex),如math.exp(1) 返回2.718281828459045</p>
<p>fabs(x)    返回数字的绝对值，如math.fabs(-10) 返回10.0</p>
<p>floor(x)    返回数字的下舍整数，如math.floor(4.9)返回 4</p>
<p>log(x)    如math.log(math.e)返回1.0,math.log(100,10)返回2.0</p>
<p>log10(x)    返回以10为基数的x的对数，如math.log10(100)返回 2.0</p>
<p>max(x1, x2,…)    返回给定参数的最大值，参数可以为序列。</p>
<p>min(x1, x2,…)    返回给定参数的最小值，参数可以为序列。</p>
<p>modf(x)    返回x的整数部分与小数部分，两部分的数值符号与x相同，整数部分以浮点型表示。</p>
<p>pow(x, y)    x**y 运算后的值。</p>
<p>round(x [,n])    返回浮点数x的四舍五入值，如给出n值，则代表舍入到小数点后的位数。</p>
<p>sqrt(x)    返回数字x的平方根</p>
<h2 id="python字符串"><a href="#python字符串" class="headerlink" title="python字符串"></a>python字符串</h2><p>字符串的取值顺序： 从左到右索引默认0开始的，最大范围是字符串长度少1。</p>
<p>如果你要实现从字符串中获取一段子字符串的话，可以使用变量 [头下标:尾下标]，就可以截取相应的字符串(包括头下标，不包括尾下标)</p>
<p>加号（+）是字符串连接运算符，星号（*）是重复操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">print str  # 输出完整字符串</span><br><span class="line">print str[0]  # 输出字符串中的第一个字符</span><br><span class="line">print str[2:5]  # 输出字符串中第三个至第五个之间的字符串</span><br><span class="line">print str[2:]  # 输出从第三个字符开始的字符串</span><br><span class="line">print str * 2  # 输出字符串两次</span><br><span class="line">print str + &quot;TEST&quot;  # 输出连接的字符串</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="python字符串操作符"><a href="#python字符串操作符" class="headerlink" title="python字符串操作符"></a>python字符串操作符</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a值为：hello  b值为：world</span><br><span class="line"></span><br><span class="line">+    字符串连接   </span><br><span class="line">&gt;&gt;&gt;a + b</span><br><span class="line">&#39;HelloPython&#39;</span><br><span class="line"></span><br><span class="line">*    重复输出字符串</span><br><span class="line">&gt;&gt;&gt;a * 2</span><br><span class="line">&#39;HelloHello&#39;</span><br><span class="line"></span><br><span class="line">[]    通过索引获取字符串中字符</span><br><span class="line">&gt;&gt;&gt;a[1]</span><br><span class="line">&#39;e&#39;</span><br><span class="line"></span><br><span class="line">[ : ]    截取字符串中的一部分</span><br><span class="line">&gt;&gt;&gt;a[1:4]</span><br><span class="line">&#39;ell&#39;</span><br><span class="line"></span><br><span class="line">in    成员运算符 - 如果字符串中包含给定的字符返回 True</span><br><span class="line">&gt;&gt;&gt;&quot;H&quot; in a</span><br><span class="line">True</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>实例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"> </span><br><span class="line">a &#x3D; &quot;Hello&quot;</span><br><span class="line">b &#x3D; &quot;Python&quot;</span><br><span class="line"> </span><br><span class="line">print &quot;a + b 输出结果：&quot;, a + b </span><br><span class="line">print &quot;a * 2 输出结果：&quot;, a * 2 </span><br><span class="line">print &quot;a[1] 输出结果：&quot;, a[1] </span><br><span class="line">print &quot;a[1:4] 输出结果：&quot;, a[1:4] </span><br><span class="line"> </span><br><span class="line">if( &quot;H&quot; in a) :</span><br><span class="line">    print &quot;H 在变量 a 中&quot; </span><br><span class="line">else :</span><br><span class="line">    print &quot;H 不在变量 a 中&quot; </span><br><span class="line"> </span><br><span class="line">if( &quot;M&quot; not in a) :</span><br><span class="line">    print &quot;M 不在变量 a 中&quot; </span><br><span class="line">else :</span><br><span class="line">    print &quot;M 在变量 a 中&quot;</span><br><span class="line"> </span><br><span class="line">print r&#39;\n&#39;</span><br><span class="line">print R&#39;\n&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Python-字符串格式化"><a href="#Python-字符串格式化" class="headerlink" title="Python 字符串格式化"></a>Python 字符串格式化</h3><p>%s是字符串占位符，%d是数字占位符。  注意字符串和值之间的连接符%</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">print &quot;My name is %s and weight is %d kg!&quot; % (&#39;Zara&#39;, 21) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Python三引号"><a href="#Python三引号" class="headerlink" title="Python三引号"></a>Python三引号</h3><p>python三引号允许一个字符串跨多行，字符串中可以包含换行符、制表符以及其他特殊字符。三引号的语法是一对连续的单引号或者双引号。</p>
<h3 id="python的字符串内建函数"><a href="#python的字符串内建函数" class="headerlink" title="python的字符串内建函数"></a>python的字符串内建函数</h3><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><p>列表中值的切割也可以用到变量 [头下标:尾下标] ，就可以截取相应的列表，从左到右索引默认 0 开始，从右到左索引默认 -1 开始，下标可以为空表示取到头或尾。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">list &#x3D; [&#39;runoob&#39;, 786, 2.23, &#39;john&#39;, 70.2]</span><br><span class="line">tinylist &#x3D; [123, &#39;john&#39;]</span><br><span class="line"></span><br><span class="line">print list  # 输出完整列表</span><br><span class="line">print list[0]  # 输出列表的第一个元素</span><br><span class="line">print list[1:3]  # 输出第二个至第三个元素</span><br><span class="line">print list[2:]  # 输出从第三个开始至列表末尾的所有元素</span><br><span class="line">print tinylist * 2  # 输出列表两次</span><br><span class="line">print list + tinylist  # 打印组合的列表</span><br><span class="line"></span><br><span class="line">list.append(5)  # 添加元素</span><br><span class="line">list.append(&#39;test&#39;)</span><br><span class="line"></span><br><span class="line">del list[4]  # 删除元素</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="list更新列表"><a href="#list更新列表" class="headerlink" title="list更新列表"></a>list更新列表</h3><p>添加元素：</p>
<p>list.append(5)</p>
<p>删除元素:</p>
<p>del list[4] </p>
<h3 id="列表脚本操作符"><a href="#列表脚本操作符" class="headerlink" title="列表脚本操作符"></a>列表脚本操作符</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">print &#39;列表长度：&#39;,len(list)  # 长度</span><br><span class="line">print &#39;列表组合：&#39;,list +tinylist  # 组合</span><br><span class="line">print &#39;列表重复：&#39;, list * 3</span><br><span class="line">print &#39;某个元素是否在列表中：&#39;,5 in list</span><br><span class="line">for x in list :</span><br><span class="line">    print &#39;循环元素：&#39;,x</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="列表的函数"><a href="#列表的函数" class="headerlink" title="列表的函数"></a>列表的函数</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lenList &#x3D; [4, 6, 7, 8, 9]</span><br><span class="line"># 获取列表的长度</span><br><span class="line">print len(lenList)</span><br><span class="line"># 获取列表元素的最大值</span><br><span class="line">print max(lenList)</span><br><span class="line"># 将元祖转化为列表</span><br><span class="line">tup &#x3D; (5, 7, 9, 0)</span><br><span class="line">print tup</span><br><span class="line">tupList &#x3D; list(tup)</span><br><span class="line">print tupList</span><br><span class="line"># 添加元素</span><br><span class="line">tupList.append(5)</span><br><span class="line"># 统计某个元素在列表中出现的次数</span><br><span class="line">n &#x3D; tupList.count(5)</span><br><span class="line">print &#39;元素在列表中出现的次数：&#39;, n</span><br><span class="line"></span><br><span class="line"># 一次性扩展多个值</span><br><span class="line">aList &#x3D; [123, &#39;xyz&#39;, &#39;zara&#39;, &#39;abc&#39;, 123]</span><br><span class="line">bList &#x3D; [2009, &#39;manni&#39;]</span><br><span class="line">aList.extend(bList)</span><br><span class="line"></span><br><span class="line"># 列出某个元素在列表中的位置</span><br><span class="line">bList.index(123)</span><br><span class="line"></span><br><span class="line"># 在某个位置插入某个元素</span><br><span class="line">list.insert(3, &#39;dddd&#39;)</span><br><span class="line"></span><br><span class="line"># 移除列表中的一个元素（默认最后一个元素），并且返回该元素的值</span><br><span class="line">bList.pop(-1)</span><br><span class="line"></span><br><span class="line"># 移除列表中某个值的第一个匹配项</span><br><span class="line">bList.remove(5)</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">cmp -- 可选参数, 如果指定了该参数会使用该参数的方法进行排序。</span><br><span class="line">key -- 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。</span><br><span class="line">reverse -- 排序规则，reverse &#x3D; True 降序， reverse &#x3D; False 升序（默认）。</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"># 排序</span><br><span class="line">list.sort(cmp&#x3D;None, key&#x3D;None, reverse&#x3D;False)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="Python元组"><a href="#Python元组" class="headerlink" title="Python元组"></a>Python元组</h2><p>元组是另一个数据类型，类似于List（列表）。<strong>元组用”()”标识</strong>。内部元素用逗号隔开。但是元组不<strong>能二次赋值</strong>，<strong>相当于只读列表</strong>。</p>
<p>其它和list一样</p>
<h2 id="Python-字典"><a href="#Python-字典" class="headerlink" title="Python 字典"></a>Python 字典</h2><p>字典的每个键值 key=&gt;value 对用冒号 : 分割，每个键值对之间用逗号 , 分割，整个字典包括在花括号 {} 中 ,格式如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line">dict =&#123;&#125;</span><br><span class="line">dict[<span class="string">&#x27;one&#x27;</span>] = <span class="string">&quot;this is one&quot;</span></span><br><span class="line">dict[<span class="number">2</span>] = <span class="string">&quot;this is two&quot;</span></span><br><span class="line"></span><br><span class="line">tinydict =&#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;john&#x27;</span>,<span class="string">&#x27;code&#x27;</span>:<span class="string">&#x27;123&#x27;</span>,<span class="string">&#x27;dept&#x27;</span>:<span class="string">&#x27;sales&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> dict[<span class="string">&#x27;one&#x27;</span>]</span><br><span class="line"><span class="keyword">print</span> dict[<span class="number">2</span>]</span><br><span class="line"><span class="keyword">print</span> tinydict</span><br><span class="line"><span class="keyword">print</span> dict</span><br><span class="line"><span class="keyword">print</span> tinydict.viewkeys()</span><br><span class="line"><span class="keyword">print</span> tinydict.viewvalues()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>字典值可以没有限制地取任何python对象，既可以是标准的对象，也可以是用户定义的，但键不行。键必须不可变，所以可以用数字，字符串或元组充当，所以用列表就不行。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tinydict &#x3D; &#123;&#39;name&#39;: &#39;john&#39;, &#39;code&#39;: &#39;123&#39;, &#39;dept&#39;: &#39;sales&#39;&#125;</span><br><span class="line">tinySet &#x3D; &#123;&#39;a&#39;, 6, 7&#125;</span><br><span class="line">tinyList &#x3D; [&#39;f&#39;, 7, 9]</span><br><span class="line">tinyTup &#x3D; (6, 8, 9)</span><br><span class="line">print &#39;tinydict type:&#39;, type(tinydict)</span><br><span class="line">print &#39;tinySet type:&#39;, type(tinySet)</span><br><span class="line">print &#39;tinyList type:&#39;, type(tinyList)</span><br><span class="line">print &#39;tinyTup type:&#39;, type(tinyTup) # 类型</span><br><span class="line"></span><br><span class="line">print &quot;after del:&quot;, dict</span><br><span class="line">dict.clear() # 删除字典的所有元素</span><br><span class="line">print &quot;after clear:&quot;, dict</span><br><span class="line"></span><br><span class="line"># 直接引用</span><br><span class="line">tinydict1 &#x3D; tinydict</span><br><span class="line"></span><br><span class="line"># 浅copy 深拷贝父对象（一级目录），子对象（二级目录）不拷贝，还是引用</span><br><span class="line">tinydict2 &#x3D; tinydict.copy()</span><br><span class="line">tinydict[&#39;name&#39;] &#x3D; &#39;张三&#39;</span><br><span class="line">del tinydict[&#39;name&#39;]</span><br><span class="line"></span><br><span class="line">print &#39;tinydict1：&#39;, tinydict1</span><br><span class="line">print &#39;tinydict2：&#39;, tinydict2</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>不存在则返回默认值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 如果键在字典dict里返回true，否则返回false</span><br><span class="line">dict.has_key(key)</span><br><span class="line"></span><br><span class="line"># 以列表返回可遍历的(键, 值) 元组数组</span><br><span class="line">dict.items()</span><br><span class="line"></span><br><span class="line"># 以列表返回一个字典所有的键</span><br><span class="line">dict.keys()</span><br><span class="line"></span><br><span class="line"># 和get()类似, 但如果键不存在于字典中，将会添加键并将值设为default</span><br><span class="line">dict.setdefault(key,&quot;&quot;)</span><br><span class="line"></span><br><span class="line"># 把字典dict2的键&#x2F;值对更新到dict里</span><br><span class="line">dict.update(dict2)</span><br><span class="line"># 以列表返回字典中的所有值</span><br><span class="line">dict.values()</span><br><span class="line"># 删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。 否则，返回default值。</span><br><span class="line">pop(key[,default])</span><br><span class="line"></span><br><span class="line"># 随机返回并删除字典中的一对键和值。</span><br><span class="line">popitem()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="日期和时间"><a href="#日期和时间" class="headerlink" title="日期和时间"></a>日期和时间</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line"># 引入time模块</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"># 时间戳</span><br><span class="line">ticks &#x3D; time.time()</span><br><span class="line">print &#39;ticks:&#39;, ticks</span><br><span class="line"></span><br><span class="line"># 获取当前时间,元组形式</span><br><span class="line">localTime &#x3D; time.localtime(time.time())</span><br><span class="line">print &#39;localTime:&#39;, localTime</span><br><span class="line"></span><br><span class="line"># 获取格式化日期</span><br><span class="line"># 格式化成2016-03-20 11:45:39形式</span><br><span class="line">print time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime())</span><br><span class="line"></span><br><span class="line"># 格式化成Sat Mar 28 22:24:24 2016形式</span><br><span class="line">print time.strftime(&quot;%a %b %d %H:%M:%S %Y&quot;, time.localtime())</span><br><span class="line"></span><br><span class="line"># 将格式字符串转换为时间戳</span><br><span class="line">a &#x3D; &quot;Sat Mar 28 22:24:24 2016&quot;</span><br><span class="line">print time.mktime(time.strptime(a, &quot;%a %b %d %H:%M:%S %Y&quot;))</span><br><span class="line"></span><br><span class="line"># 输出日历</span><br><span class="line">cal &#x3D; calendar.month(2016, 1)</span><br><span class="line">print &quot;以下输出2016年1月份的日历:&quot;</span><br><span class="line">print cal</span><br><span class="line"></span><br><span class="line"># 用以浮点数计算的秒数返回当前的CPU时间。用来衡量不同程序的耗时，比time.time()更有用。</span><br><span class="line">time.clock( )</span><br><span class="line"></span><br><span class="line">i &#x3D; datetime.datetime.now()</span><br><span class="line">print (&quot;当前的日期和时间是 %s&quot; % i)</span><br><span class="line">print (&quot;ISO格式的日期和时间是 %s&quot; % i.isoformat())</span><br><span class="line">print (&quot;当前的年份是 %s&quot; % i.year)</span><br><span class="line">print (&quot;当前的月份是 %s&quot; % i.month)</span><br><span class="line">print (&quot;当前的日期是  %s&quot; % i.day)</span><br><span class="line">print (&quot;dd&#x2F;mm&#x2F;yyyy 格式是  %s&#x2F;%s&#x2F;%s&quot; % (i.day, i.month, i.year))</span><br><span class="line">print (&quot;当前小时是 %s&quot; % i.hour)</span><br><span class="line">print (&quot;当前分钟是 %s&quot; % i.minute)</span><br><span class="line">print (&quot;当前秒是  %s&quot; % i.second)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h1><h2 id="Python算术运算符"><a href="#Python算术运算符" class="headerlink" title="Python算术运算符"></a>Python算术运算符</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+ - * &#x2F; % 之外 </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>** 幂-返回x的y次幂  4**2 =16</p>
<p>//    取整除 - 返回商的整数部分   9//2 =4</p>
<p>Python2.x 里，整数除整数，只能得出整数。如果要得到小数部分，把其中一个数改成浮点数即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a &#x3D; 10</span><br><span class="line">b &#x3D; 20</span><br><span class="line">c &#x3D; a + b</span><br><span class="line">print &quot;1---c的值为：&quot;, c</span><br><span class="line"></span><br><span class="line">c &#x3D; b - a</span><br><span class="line">print &quot;2---c的值为：&quot;,c</span><br><span class="line"></span><br><span class="line">c &#x3D; a * b</span><br><span class="line">print &quot;3---c的值为：&quot;,c</span><br><span class="line"></span><br><span class="line">c &#x3D; b &#x2F; a</span><br><span class="line">print &#39;4----c的值为：&#39;,c</span><br><span class="line"></span><br><span class="line">c &#x3D; b ** a</span><br><span class="line">print &#39;5----c的值为：&#39;,c</span><br><span class="line"></span><br><span class="line">c &#x3D; b &#x2F;&#x2F; a</span><br><span class="line">print &#39;6----c的值为：&#39;,c</span><br><span class="line"></span><br><span class="line">c &#x3D; b % a</span><br><span class="line">print &#39;7----c的值为：&#39;,c</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Python比较运算符"><a href="#Python比较运算符" class="headerlink" title="Python比较运算符"></a>Python比较运算符</h2><p>==  !=  &lt;&gt;  &gt;  &lt;  &gt;=  &lt;=</p>
<h2 id="Python赋值运算符"><a href="#Python赋值运算符" class="headerlink" title="Python赋值运算符"></a>Python赋值运算符</h2><p>= += -= *= 等等</p>
<h2 id="Python位运算符"><a href="#Python位运算符" class="headerlink" title="Python位运算符"></a>Python位运算符</h2><p>按位运算符是把数字看作二进制来进行计算的</p>
<p>&amp; 与运算符：参与运算的两个值,如果两个相应位都为1,则该位的结果为1,否则为0</p>
<p>| 或运算符：只要对应的二个二进位有一个为1时，结果位就为1。</p>
<p>^ 异或运算符：当两对应的二进位相异时，结果为1; </p>
<p>~ 取反运算符：对数据的每个二进制位取反,即把1变为0,把0变为1 。~x 类似于 -x-1</p>
<p>&lt;&lt; 左移动运算符：运算数的各二进位全部左移若干位，由 &lt;&lt; 右边的数字指定了移动的位数，高位丢弃，低位补0。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">a &#x3D; 60 # 60 &#x3D; 0011 1100</span><br><span class="line">b &#x3D; 13 # 13 &#x3D; 0000 1101</span><br><span class="line">c &#x3D; 0</span><br><span class="line"></span><br><span class="line">c &#x3D; a &amp; b</span><br><span class="line">print &#39;c&#x3D;&#x3D;&#x3D;&#39;,c</span><br><span class="line"></span><br><span class="line">c &#x3D; a | b</span><br><span class="line">print &#39;c&#x3D;&#x3D;&#x3D;&#x3D;&#39;,c</span><br><span class="line"></span><br><span class="line">c &#x3D; a ^ b</span><br><span class="line">print &#39;c&#x3D;&#x3D;&#x3D;&#x3D;&#39;,c</span><br><span class="line"></span><br><span class="line">c &#x3D; - a</span><br><span class="line">print &#39;c&#x3D;&#x3D;&#x3D;&#x3D;&#39;,c</span><br><span class="line"></span><br><span class="line">c &#x3D; ~a</span><br><span class="line">print &quot;4 - c 的值为：&quot;, c # ~x 类似于 -x-1</span><br><span class="line"></span><br><span class="line">c &#x3D; a &lt;&lt; 2</span><br><span class="line">print &quot;5 - c 的值为：&quot;, c</span><br><span class="line"></span><br><span class="line">c &#x3D; a &gt;&gt; 2</span><br><span class="line">print &quot;6 - c 的值为：&quot;, c</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Python逻辑运算符"><a href="#Python逻辑运算符" class="headerlink" title="Python逻辑运算符"></a>Python逻辑运算符</h2><p>and or not</p>
<h1 id="python条件语句"><a href="#python条件语句" class="headerlink" title="python条件语句"></a>python条件语句</h1><p>Python程序语言指定任何非0和非空（null）值为true，0 或者 null为false。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">flag &#x3D; False</span><br><span class="line">name &#x3D; &#39;luren&#39;</span><br><span class="line">if name &#x3D;&#x3D; &#39;python&#39;:</span><br><span class="line">    flag &#x3D; True</span><br><span class="line">    print &#39;welcome python&#39;</span><br><span class="line">elif name &#x3D;&#x3D; &#39;luren&#39;:</span><br><span class="line">    print &#39;welcome luren&#39;</span><br><span class="line">else:</span><br><span class="line">    print name</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="循环语句"><a href="#循环语句" class="headerlink" title="循环语句"></a>循环语句</h1><p>包括 while for 嵌套循环</p>
<h2 id="while循环-break和continue"><a href="#while循环-break和continue" class="headerlink" title="while循环 break和continue"></a>while循环 break和continue</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">i &#x3D; 1</span><br><span class="line">while i &lt; 10:</span><br><span class="line">    i +&#x3D; 1</span><br><span class="line">    print i</span><br><span class="line">else:</span><br><span class="line">    print &quot;end！&quot;</span><br><span class="line"></span><br><span class="line">print &quot;----------&quot;</span><br><span class="line"></span><br><span class="line">i &#x3D; 2</span><br><span class="line">while i &lt; 20:</span><br><span class="line">    i +&#x3D; 1</span><br><span class="line">    if i % 2 &#x3D;&#x3D; 0:</span><br><span class="line">        break # continue</span><br><span class="line">    print &quot;i&#x3D;&#x3D;&quot;,i</span><br><span class="line">else:</span><br><span class="line">    print &#39;end&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>break只能跳出一层循环，如果你的循环是嵌套循环，那么你需要按照你嵌套的层次，逐步使用break来跳出。</p>
<p>continue 语句用来告诉Python跳过当前循环的剩余语句，然后继续进行下一轮循环。</p>
<h2 id="for-循环语句"><a href="#for-循环语句" class="headerlink" title="for 循环语句"></a>for 循环语句</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line"># 遍历字符串</span><br><span class="line">for letter in &quot;python&quot;:</span><br><span class="line">    print &#39;当前字母：&#39;,letter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 遍历list</span><br><span class="line">fruits &#x3D; [&#39;apple&#39;, &#39;banana&#39;, &#39;peer&#39;]</span><br><span class="line">for fruit in fruits:</span><br><span class="line">    print &#39;当前水果为：&#39;, fruit</span><br><span class="line"></span><br><span class="line"># 通过下标遍历list</span><br><span class="line">for index in range(len(fruits)):</span><br><span class="line">    print &#39;通过下标获取的水果的名字为：&#39;, fruits[index]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="循环嵌套"><a href="#循环嵌套" class="headerlink" title="循环嵌套"></a>循环嵌套</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">i &#x3D; 2</span><br><span class="line">while i &lt; 100:</span><br><span class="line">    j &#x3D; 2</span><br><span class="line">    while j &lt;&#x3D; (i &#x2F; j):</span><br><span class="line">        if not (i % j): break</span><br><span class="line">        j +&#x3D; 1</span><br><span class="line">    if j &gt; (i &#x2F; j): print i, &quot;是素数&quot;</span><br><span class="line">    i +&#x3D; 1</span><br><span class="line">print &#39;good bye&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="pass-语句"><a href="#pass-语句" class="headerlink" title="pass 语句"></a>pass 语句</h2><p>Python pass是空语句，是为了保持程序结构的完整性。</p>
<p>pass 不做任何事情，一般用做占位语句。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*- </span><br><span class="line"></span><br><span class="line"># 输出 Python 的每个字母</span><br><span class="line">for letter in &#39;Python&#39;:</span><br><span class="line">   if letter &#x3D;&#x3D; &#39;h&#39;:</span><br><span class="line">      pass</span><br><span class="line">      print &#39;这是 pass 块&#39;</span><br><span class="line">   print &#39;当前字母 :&#39;, letter</span><br><span class="line"></span><br><span class="line">print &quot;Good bye!&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>执行结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">当前字母 : P</span><br><span class="line">当前字母 : y</span><br><span class="line">当前字母 : t</span><br><span class="line">这是 pass 块</span><br><span class="line">当前字母 : h</span><br><span class="line">当前字母 : o</span><br><span class="line">当前字母 : n</span><br><span class="line">Good bye!</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="python函数"><a href="#python函数" class="headerlink" title="python函数"></a>python函数</h2><h3 id="定义一个函数"><a href="#定义一个函数" class="headerlink" title="定义一个函数"></a>定义一个函数</h3><p>你可以定义一个由自己想要功能的函数，以下是简单的规则：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">函数代码块以 def 关键词开头，后接函数标识符名称和圆括号()。</span><br><span class="line"></span><br><span class="line">任何传入参数和自变量必须放在圆括号中间。圆括号之间可以用于定义参数。</span><br><span class="line"></span><br><span class="line">函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明。</span><br><span class="line"></span><br><span class="line">函数内容以冒号起始，并且缩进。</span><br><span class="line"></span><br><span class="line">return [表达式] 结束函数，选择性地返回一个值给调用方。不带表达式的return相当于返回 None。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="在python中，类型属于对象，变量是没有对象的。"><a href="#在python中，类型属于对象，变量是没有对象的。" class="headerlink" title="在python中，类型属于对象，变量是没有对象的。"></a>在python中，类型属于对象，变量是没有对象的。</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a&#x3D;[1,2,3]</span><br><span class="line"></span><br><span class="line">a&#x3D;&quot;Runoob&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以上代码中，[1,2,3] 是 List 类型，”Runoob” 是 String 类型，而变量 a 是没有类型，她仅仅是一个对象的引用（一个指针），可以是 List 类型对象，也可以指向 String 类型对象。</p>
<h3 id="可更改-mutable-与不可更改-immutable-对象"><a href="#可更改-mutable-与不可更改-immutable-对象" class="headerlink" title="可更改(mutable)与不可更改(immutable)对象"></a>可更改(mutable)与不可更改(immutable)对象</h3><p><strong>不可变类型</strong>：变量赋值 a=5 后再赋值 a=10，这里实际是新生成一个 int 值对象 10，再让 a 指向它，而 5 被丢弃，不是改变a的值，相当于新生成了a。</p>
<p><strong>可变类型</strong>：变量赋值 la=[1,2,3,4] 后再赋值 la[2]=5 则是将 list la 的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了。</p>
<h4 id="python-函数的参数传递："><a href="#python-函数的参数传递：" class="headerlink" title="python 函数的参数传递："></a>python 函数的参数传递：</h4><p><strong>不可变类型</strong>：类似 c++ 的值传递，如 整数、字符串、元组。如fun（a），传递的只是a的值，没有影响a对象本身。比如在 fun（a）内部修改 a 的值，只是修改另一个复制的对象，不会影响 a 本身。</p>
<p><strong>可变类型</strong>：类似 c++ 的引用传递，如 列表，字典。如 fun（la），则是将 la 真正的传过去，修改后fun外部的la也会受影响</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 传递不可变对象</span><br><span class="line">def changeInt(a):</span><br><span class="line">    b &#x3D; a</span><br><span class="line">    a &#x3D; 10</span><br><span class="line">    print a</span><br><span class="line">    print b</span><br><span class="line">    return</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">b &#x3D; 120</span><br><span class="line">changeInt(b)</span><br><span class="line">print b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 传可变对象实例</span><br><span class="line">def changeMe(myList):</span><br><span class="line">    &#39;&#39;&#39;修改传入的列表：&#39;&#39;&#39;</span><br><span class="line">    myList.append([1, 4, 6, 8])</span><br><span class="line">    return</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myList &#x3D; [10, 40, 60]</span><br><span class="line">changeMe(myList)</span><br><span class="line">print &#39;myList&#39;, myList</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><h4 id="必备参数"><a href="#必备参数" class="headerlink" title="必备参数"></a>必备参数</h4><p>必备参数须以正确的顺序传入函数。调用时的数量必须和声明时的一样。无需指定参数的名字</p>
<h4 id="关键字参数"><a href="#关键字参数" class="headerlink" title="关键字参数"></a>关键字参数</h4><p>关键字参数和函数调用关系紧密，函数调用使用关键字参数来确定传入的参数值。</p>
<p>使用关键字参数允许函数调用时参数的顺序与声明时不一致，因为 Python 解释器能够用参数名匹配参数值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def printinfo( name, age ):</span><br><span class="line">   &quot;打印任何传入的字符串&quot;</span><br><span class="line">   print &quot;Name: &quot;, name;</span><br><span class="line">   print &quot;Age &quot;, age;</span><br><span class="line">   return;</span><br><span class="line"> </span><br><span class="line">#调用printinfo函数</span><br><span class="line">printinfo( age&#x3D;50, name&#x3D;&quot;miki&quot; );</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="缺省参数"><a href="#缺省参数" class="headerlink" title="缺省参数"></a>缺省参数</h4><p>调用函数时，缺省参数的值如果没有传入，则被认为是默认值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#可写函数说明</span><br><span class="line">def printinfo( name, age &#x3D; 35 ):</span><br><span class="line">   &quot;打印任何传入的字符串&quot;</span><br><span class="line">   print &quot;Name: &quot;, name;</span><br><span class="line">   print &quot;Age &quot;, age;</span><br><span class="line">   return;</span><br><span class="line"> </span><br><span class="line">#调用printinfo函数</span><br><span class="line">printinfo( age&#x3D;50, name&#x3D;&quot;miki&quot; );</span><br><span class="line">printinfo( name&#x3D;&quot;miki&quot; );</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="不定长参数"><a href="#不定长参数" class="headerlink" title="不定长参数"></a>不定长参数</h4><p>你可能需要一个函数能处理比当初声明时更多的参数。这些参数叫做不定长参数，和上述2种参数不同，声明时不会命名</p>
<p>加了星号（*）的变量名会存放所有未命名的变量参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def printinfo(arg1, *vartuple):</span><br><span class="line">    &quot;打印任何传入的参数&quot;</span><br><span class="line">    print &quot;输出: &quot;</span><br><span class="line">    print arg1</span><br><span class="line">    for var in vartuple:</span><br><span class="line">        print &#39;var:&#39;, var</span><br><span class="line">    return</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 调用printinfo 函数</span><br><span class="line">printinfo(10)</span><br><span class="line">printinfo(70, 60, 50)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h3><p>python 使用 lambda 来创建匿名函数。</p>
<p>1.lambda只是一个表达式，函数体比def简单很多。</p>
<p>2.lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。</p>
<p>3.lambda函数拥有自己的命名空间，且不能访问自有参数列表之外或全局命名空间里的参数。</p>
<p>4.虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。</p>
<p>语法：</p>
<p>lambda [arg1 [,arg2,…..argn]]:expression</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"> </span><br><span class="line"># 可写函数说明</span><br><span class="line">sum &#x3D; lambda arg1, arg2: arg1 + arg2;</span><br><span class="line"> </span><br><span class="line"># 调用sum函数</span><br><span class="line">print &quot;相加后的值为 : &quot;, sum( 10, 20 )</span><br><span class="line">print &quot;相加后的值为 : &quot;, sum( 20, 20 )</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="全局变量和局部变量"><a href="#全局变量和局部变量" class="headerlink" title="全局变量和局部变量"></a>全局变量和局部变量</h2><p>局部变量只能在其被声明的函数内部访问，而全局变量可以在整个程序范围内访问。调用函数时，所有在函数内声明的变量名称都将被加入到作用域中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*-coding: UTF-8-*-</span><br><span class="line"></span><br><span class="line">total &#x3D; 0  # 这是一个全局变量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 可写函数说明</span><br><span class="line">def sum(arg1, arg2):</span><br><span class="line">    # 返回2个参数的和.&quot;</span><br><span class="line">    total &#x3D; arg1 + arg2  # total在这里是局部变量.</span><br><span class="line">    print &quot;函数内是局部变量 : &quot;, total</span><br><span class="line">    return total;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 调用sum函数</span><br><span class="line">sum(10, 20)</span><br><span class="line"># total &#x3D; sum(30, 50)</span><br><span class="line">print &quot;函数外是全局变量 : &quot;, total</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="python-模块"><a href="#python-模块" class="headerlink" title="python 模块"></a>python 模块</h1><p>Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句</p>
<p>import语句 引入模块</p>
<p>from…import语句 Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中</p>
<h2 id="搜索路径"><a href="#搜索路径" class="headerlink" title="搜索路径"></a>搜索路径</h2><p>当你导入一个模块，Python 解析器对模块位置的搜索顺序是：</p>
<ol>
<li>当前目录</li>
<li>如果不在当前目录，Python 则搜索在 shell 变量 PYTHONPATH 下的每个目录。</li>
<li>如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/。</li>
</ol>
<p>模块搜索路径存储在 system 模块的 sys.path 变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录。</p>
<h2 id="命名空间和作用域"><a href="#命名空间和作用域" class="headerlink" title="命名空间和作用域"></a>命名空间和作用域</h2><p>变量是拥有匹配对象的名字（标识符）。命名空间是一个包含了变量名称们（键）和它们各自相应的对象们（值）的字典。</p>
<p>如果一个局部变量和一个全局变量重名，则局部变量会覆盖全局变量。</p>
<p>Python 会智能地猜测一个变量是局部的还是全局的，它假设任何在函数内赋值的变量都是局部的。因此，如果要给函数内的全局变量赋值，必须使用 global 语句。</p>
<p>global VarName 的表达式会告诉 Python， VarName 是一个全局变量，这样 Python 就不会在局部命名空间里寻找这个变量了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*-coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">money &#x3D; 3000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def AddMoney():</span><br><span class="line">    # 全局变量的使用</span><br><span class="line">    global money</span><br><span class="line">    money &#x3D; money + 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print &#39;money:&#39;, money</span><br><span class="line">AddMoney()</span><br><span class="line">print &#39;money:&#39;, money</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="dir-函数"><a href="#dir-函数" class="headerlink" title="dir()函数"></a>dir()函数</h3><p>dir() 函数一个排好序的字符串列表，内容是一个模块里定义过的名字。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*-coding: UTF-8 -*-</span><br><span class="line">import math</span><br><span class="line">from math import floor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># dir函数</span><br><span class="line">content &#x3D; dir(math)</span><br><span class="line">print &#39;content:&#39;, content</span><br><span class="line"></span><br><span class="line">print floor(5.8)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="globals-和-locals-函数"><a href="#globals-和-locals-函数" class="headerlink" title="globals() 和 locals() 函数"></a>globals() 和 locals() 函数</h3><p>根据调用地方的不同，globals() 和 locals() 函数可被用来返回全局和局部命名空间里的名字。</p>
<p>如果在函数内部调用 locals()，返回的是所有能在该函数里访问的命名。</p>
<p>如果在函数内部调用 globals()，返回的是所有在该函数里能访问的全局名字。</p>
<h3 id="Python中的包"><a href="#Python中的包" class="headerlink" title="Python中的包"></a>Python中的包</h3><p>简单来说，包就是文件夹，但该文件夹下必须存在 <strong>init</strong>.py 文件, 该文件的内容可以为空。<strong>init</strong>.py 用于标识当前文件夹是一个包。</p>
<h2 id="Python-文件I-O"><a href="#Python-文件I-O" class="headerlink" title="Python 文件I/O"></a>Python 文件I/O</h2><p>raw_input函数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">str &#x3D; raw_input(&quot;按下 enter键退出，其他任意键显示。。。\n&quot;)</span><br><span class="line">print &#39;str:&#39;, str</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>input函数</p>
<p>input([prompt]) 函数和 raw_input([prompt]) 函数基本类似，但是 input 可以接收一个Python表达式作为输入，并将运算结果返回。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">str &#x3D; input(&quot;请输入：&quot;)  # 输入[x*5 for x in range(2,10,2)]</span><br><span class="line">print &quot;你输入的内容是: &quot;, str</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="文件IO"><a href="#文件IO" class="headerlink" title="文件IO"></a>文件IO</h1><h2 id="open-函数"><a href="#open-函数" class="headerlink" title="open 函数"></a>open 函数</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">file object &#x3D; open(file_name [, access_mode][, buffering])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>各个参数的细节如下：</p>
<p>file_name：file_name变量是一个包含了你要访问的文件名称的字符串值。</p>
<p>access_mode：access_mode决定了打开文件的模式：只读，写入，追加等。所有可取值见如下的完全列表。这个参数是非强制的，默认文件访问模式为只读(r)。</p>
<p>buffering:如果buffering的值被设为0，就不会有寄存。如果buffering的值取1，访问文件时会寄存行。如果将buffering的值设为大于1的整数，表明了这就是的寄存区的缓冲大小。如果取负值，寄存区的缓冲大小则为系统默认。</p>
<p><img src="/images/python/2.7/python%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90.png" alt="python文件访问权限"></p>
<h2 id="文件定位"><a href="#文件定位" class="headerlink" title="文件定位"></a>文件定位</h2><p>tell() 该方法告诉你文件内的当前位置, 换句话说，下一次的读写会发生在文件开头这么多字节之后。</p>
<p>seek（offset [,from]）方法改变当前文件的位置。Offset变量表示要移动的字节数。From变量指定开始移动字节的参考位置。</p>
<h2 id="重命名和删除文件"><a href="#重命名和删除文件" class="headerlink" title="重命名和删除文件"></a>重命名和删除文件</h2><p>Python的os模块提供了帮你执行文件处理操作的方法，比如重命名和删除文件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">os.rename(current_file_name, new_file_name)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="文件和目录操作的例子"><a href="#文件和目录操作的例子" class="headerlink" title="文件和目录操作的例子"></a>文件和目录操作的例子</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*-coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">fo &#x3D; open(&quot;foo.txt&quot;, &quot;w+&quot;)</span><br><span class="line">print &quot;文件名字：&quot;, fo.name</span><br><span class="line">print &quot;是否已经关闭1：&quot;, fo.closed</span><br><span class="line">print &quot;打开文件的访问模式：&quot;, fo.mode</span><br><span class="line"># 文件写入内容 write()方法不会在字符串的结尾添加换行符(&#39;\n&#39;)：</span><br><span class="line">fo.write(&quot;i&#39;m writing something.....\n 第二行文本  \n \n 第四行文本&quot;)</span><br><span class="line"># 关闭打开的文件</span><br><span class="line">fo.close()</span><br><span class="line">print &quot;是否已经关闭2：&quot;, fo.closed</span><br><span class="line"></span><br><span class="line">fo1 &#x3D; open(&quot;foo.txt&quot;, &quot;r+&quot;)</span><br><span class="line"># read（）方法从一个打开的文件中读取一个字符串。需要重点注意的是，Python字符串可以是二进制数据，而不是仅仅是文字。  fileObject.read([count])</span><br><span class="line">str &#x3D; fo1.read(10)</span><br><span class="line">print &quot;str:&quot;, str</span><br><span class="line"></span><br><span class="line">print &quot;分隔符1：&quot;, &quot;--------------------------------&quot;</span><br><span class="line"></span><br><span class="line"># 打开一个文件</span><br><span class="line">fo2 &#x3D; open(&quot;foo.txt&quot;, &quot;r+&quot;)</span><br><span class="line">str &#x3D; fo2.read(10)</span><br><span class="line">print &quot;读取的字符串是 : &quot;, str</span><br><span class="line"></span><br><span class="line"># 查找当前位置</span><br><span class="line">position &#x3D; fo2.tell()</span><br><span class="line">print &quot;当前文件位置 : &quot;, position</span><br><span class="line"></span><br><span class="line"># 把指针再次重新定位到文件开头</span><br><span class="line">position &#x3D; fo2.seek(0, 0)</span><br><span class="line">str &#x3D; fo2.read(10)</span><br><span class="line">print &quot;重新读取字符串 : &quot;, str</span><br><span class="line"># 关闭打开的文件</span><br><span class="line">fo2.close()</span><br><span class="line"></span><br><span class="line">print &quot;分隔符2：&quot;, &quot;--------------------------------&quot;</span><br><span class="line"></span><br><span class="line"># 重命名和删除文件</span><br><span class="line">os.rename(&quot;foo.txt&quot;, &quot;fool2.txt&quot;)</span><br><span class="line"></span><br><span class="line"># 删除一个已经存在的文件</span><br><span class="line"># os.remove(&quot;fool2.txt&quot;)</span><br><span class="line"></span><br><span class="line"># 创建目录</span><br><span class="line"># os.mkdir(&quot;test&quot;)</span><br><span class="line"></span><br><span class="line"># 改变当前目录</span><br><span class="line"># 将当前目录改为&quot;&#x2F;home&#x2F;newdir&quot;</span><br><span class="line"># os.chdir(&quot;&#x2F;home&#x2F;zhuningning&#x2F;PycharmProjects&#x2F;pythonBase&#x2F;base&#x2F;test&quot;)</span><br><span class="line"></span><br><span class="line"># 显示当前目录</span><br><span class="line">print os.getcwd()</span><br><span class="line"></span><br><span class="line"># 删除目录</span><br><span class="line"># os.rmdir(&quot;&#x2F;home&#x2F;zhuningning&#x2F;PycharmProjects&#x2F;pythonBase&#x2F;base&#x2F;test&quot;)</span><br><span class="line"></span><br><span class="line">print &quot;分隔符3：&quot;, &quot;--------------------------------&quot;</span><br><span class="line"></span><br><span class="line"># 每行读取文件</span><br><span class="line">fo &#x3D; open(&quot;fool2.txt&quot;, &quot;rw+&quot;)</span><br><span class="line">print &quot;文件名为: &quot;, fo.name</span><br><span class="line"></span><br><span class="line">for index in range(4):</span><br><span class="line">    line &#x3D; fo.next()</span><br><span class="line">    print &quot;第 %d 行 - %s&quot; % (index+1, line)</span><br><span class="line"></span><br><span class="line"># 关闭文件</span><br><span class="line">fo.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h1><p>python提供了两个非常重要的功能来处理python程序在运行中出现的异常和错误：异常处理 和 断言(Assertions)</p>
<p>捕捉异常可以使用try/except语句。</p>
<p>try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。</p>
<p>语法如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">try:</span><br><span class="line">&lt;语句&gt;        #运行别的代码</span><br><span class="line">except &lt;名字&gt;：</span><br><span class="line">&lt;语句&gt;        #如果在try部份引发了&#39;name&#39;异常</span><br><span class="line">except &lt;名字&gt;，&lt;数据&gt;:</span><br><span class="line">&lt;语句&gt;        #如果引发了&#39;name&#39;异常，获得附加的数据</span><br><span class="line">else:</span><br><span class="line">&lt;语句&gt;        #如果没有异常发生</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">try的工作原理是，当开始一个try语句后，python就在当前程序的上下文中作标记，这样当异常出现时就可以回到这里，try子句先执行，接下来会发生什么依赖于执行时是否出现异常。</span><br><span class="line"></span><br><span class="line">如果当try后的语句执行时发生异常，python就跳回到try并执行第一个匹配该异常的except子句，异常处理完毕，控制流就通过整个try语句（除非在处理异常时又引发新的异常）。</span><br><span class="line"></span><br><span class="line">如果在try后的语句里发生了异常，却没有匹配的except子句，异常将被递交到上层的try，或者到程序的最上层（这样将结束程序，并打印缺省的出错信息）。</span><br><span class="line"></span><br><span class="line">如果在try子句执行时没有发生异常，python将执行else语句后的语句（如果有else的话），然后控制流通过整个try语句。</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>异常的demo</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    fh &#x3D; open(&quot;testfile.txt&quot;, &quot;w&quot;)</span><br><span class="line">    fh.write(&quot;write someting...&quot;)</span><br><span class="line">except IOError:</span><br><span class="line">    print &quot;error: 没有找到文件或者读取文件失败&quot;</span><br><span class="line">else:</span><br><span class="line">    print &quot;内容写入成功！&quot;</span><br><span class="line">    fh.close()</span><br><span class="line"></span><br><span class="line"># try finally语句</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    fh &#x3D; open(&quot;testfile&quot;, &quot;w&quot;)</span><br><span class="line">    fh.write(&quot;这是一个测试文件1，用于测试异常!&quot;)</span><br><span class="line">finally:</span><br><span class="line">    print &quot;Error: 没有找到文件或读取文件失败&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 用户自定义异常</span><br><span class="line"></span><br><span class="line">class Networkerror(RuntimeError):</span><br><span class="line">    def __init__(self, arg):</span><br><span class="line">        self.args &#x3D; arg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    raise Networkerror(&quot;Bad hostname&quot;)</span><br><span class="line">except Networkerror, e:</span><br><span class="line">    print e.args</span><br><span class="line"></span><br><span class="line"># 使用except而带多种异常类型</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    print &quot;正常执行！&quot;</span><br><span class="line">except(IOError, BaseException, IndentationError):</span><br><span class="line">    print &quot;发生异常！&quot;</span><br><span class="line">else:</span><br><span class="line">    print &quot;如果没有异常执行这块代码&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><strong>print语句默认的会在后面加上 换行  加了逗号之后 换行 就变成了 空格</strong>  </p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python2.7入门</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-cluster</title>
    <url>/2018-01-28/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-cluster/</url>
    <content><![CDATA[<p>Redis集群时redis提供的分布式数据库方案.</p>
<h1 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h1><p>一个 Redis 集群通常由多个节点（node）组成， 在刚开始的时候， 每个节点都是相互独立的， 它们都处于一个只包含自己的集群当中， 要组建一个真正可工作的集群， 我们必须将各个独立的节点连接起来， 构成一个包含多个节点的集群。</p>
<p>当一个节点使用下面的命令时,使得ip和port制定的节点进行握手,当捂手成功后,node节点就会将该ip和port所在的节点添加到自己的集群中.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CLUSTER MEET &lt;ip&gt; &lt;port&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>假设我们当前有三个节点:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root     21254  9329  0 01:35 pts&#x2F;2    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root     21255 21254  0 01:35 pts&#x2F;2    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:6002 [cluster]</span><br><span class="line">root     21263  9329  0 01:36 pts&#x2F;2    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root     21264 21263  0 01:36 pts&#x2F;2    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:6001 [cluster]</span><br><span class="line">root     21283  9329  0 01:36 pts&#x2F;2    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root     21284 21283  0 01:36 pts&#x2F;2    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:6000 [cluster]</span><br><span class="line">zhuning+ 21466  9329  0 01:37 pts&#x2F;2    00:00:00 grep --color&#x3D;auto redis</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>将节点加入集群</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisClusterTest&#x2F;6000&#x2F;src$ .&#x2F;redis-cli -p 127.0.0.1 -p 6000</span><br><span class="line">127.0.0.1:6000&gt; cluster nodes</span><br><span class="line">e6f7de12f623d0a92da8aa307a7ee224da73b92e :6000 myself,master - 0 0 0 connected</span><br><span class="line">127.0.0.1:6000&gt; cluster meet 127.0.0.1 6001</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6000&gt; 21264:M 29 Jan 01:39:45.936 # IP address for this node updated to 127.0.0.1</span><br><span class="line">                                                                                           21284:M 29 Jan 01:39:45.975 # IP address for this node updated to 127.0.0.1 </span><br><span class="line">127.0.0.1:6000&gt; cluster nodes</span><br><span class="line">5e57d9227987c64486ec791217b64712ad201016 127.0.0.1:6001 master - 0 1517161211620 1 connected</span><br><span class="line">e6f7de12f623d0a92da8aa307a7ee224da73b92e 127.0.0.1:6000 myself,master - 0 0 0 connected</span><br><span class="line">127.0.0.1:6000&gt; cluster meet 127.0.0.1 6002</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6000&gt; 21255:M 29 Jan 01:41:29.250 # IP address for this node updated to 127.0.0.1</span><br><span class="line">127.0.0.1:6000&gt; </span><br><span class="line">127.0.0.1:6000&gt; clsuter nodes</span><br><span class="line">(error) ERR unknown command &#39;clsuter&#39;</span><br><span class="line">127.0.0.1:6000&gt; cluster nodes</span><br><span class="line">94a98e405ec368ad45469b9d5fb0e019bdf2d796 127.0.0.1:6002 master - 0 1517161300885 2 connected</span><br><span class="line">5e57d9227987c64486ec791217b64712ad201016 127.0.0.1:6001 master - 0 1517161299882 1 connected</span><br><span class="line">e6f7de12f623d0a92da8aa307a7ee224da73b92e 127.0.0.1:6000 myself,master - 0 0 0 connected</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以上是建立集群的过程</p>
<h2 id="启动节点"><a href="#启动节点" class="headerlink" title="启动节点"></a>启动节点</h2><p>启动的时候redis会根据参数cluster-enabled参数来决定是否启动集群模式.</p>
<p>node在集群模式下仍然会使用单机集群的功能,比如运行serverCron函数,而serverCron函数又会调用clusterCron函数.</p>
<p>除此之外节点会继续使用 redisServer 结构来保存服务器的状态， 使用 redisClient 结构来保存客户端的状态， 至于那些只有在集群模式下才会用到的数据， 节点将它们保存到了 cluster.h/clusterNode 结构， cluster.h/clusterLink 结构， 以及 cluster.h/clusterState 结构里面</p>
<h2 id="集群数据结构"><a href="#集群数据结构" class="headerlink" title="集群数据结构"></a>集群数据结构</h2><p>每个节点都会使用一个 clusterNode 结构来记录自己的状态， 并为集群中的所有其他节点（包括主节点和从节点）都创建一个相应的 clusterNode 结构</p>
<p>结构如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct clusterNode &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 创建节点的时间</span><br><span class="line">    mstime_t ctime;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 节点的名字，由 40 个十六进制字符组成</span><br><span class="line">    &#x2F;&#x2F; 例如 68eef66df23420a5862208ef5b1a7005b806f2ff</span><br><span class="line">    char name[REDIS_CLUSTER_NAMELEN];</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 节点标识</span><br><span class="line">    &#x2F;&#x2F; 使用各种不同的标识值记录节点的角色（比如主节点或者从节点），</span><br><span class="line">    &#x2F;&#x2F; 以及节点目前所处的状态（比如在线或者下线）。</span><br><span class="line">    int flags;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 节点当前的配置纪元，用于实现故障转移</span><br><span class="line">    uint64_t configEpoch;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 节点的 IP 地址</span><br><span class="line">    char ip[REDIS_IP_STR_LEN];</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 节点的端口号</span><br><span class="line">    int port;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 保存连接节点所需的有关信息</span><br><span class="line">    clusterLink *link;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>clusterNode 结构的 link 属性是一个 clusterLink 结构， 该结构保存了连接节点所需的有关信息， 比如套接字描述符， 输入缓冲区和输出缓冲区：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct clusterLink &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 连接的创建时间</span><br><span class="line">    mstime_t ctime;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; TCP 套接字描述符</span><br><span class="line">    int fd;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 输出缓冲区，保存着等待发送给其他节点的消息（message）。</span><br><span class="line">    sds sndbuf;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 输入缓冲区，保存着从其他节点接收到的消息。</span><br><span class="line">    sds rcvbuf;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 与这个连接相关联的节点，如果没有的话就为 NULL</span><br><span class="line">    struct clusterNode *node;</span><br><span class="line"></span><br><span class="line">&#125; clusterLink;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>redisClient 结构和 clusterLink 结构的相同和不同之处</li>
</ul>
<p>redisClient 结构和 clusterLink 结构都有自己的套接字描述符和输入、输出缓冲区， 这两个结构的区别在于， redisClient 结构中的套接字和缓冲区是用于连接客户端的， 而 clusterLink 结构中的套接字和缓冲区则是用于连接节点的。</p>
<p>每个节点都保存着一个 clusterState 结构， 这个结构记录了在当前节点的视角下， 集群目前所处的状态 —— 比如集群是在线还是下线， 集群包含多少个节点， 集群当前的配置纪元</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct clusterState &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 指向当前节点的指针</span><br><span class="line">    clusterNode *myself;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群当前的配置纪元，用于实现故障转移</span><br><span class="line">    uint64_t currentEpoch;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群当前的状态：是在线还是下线</span><br><span class="line">    int state;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群中至少处理着一个槽的节点的数量</span><br><span class="line">    int size;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集群节点名单（包括 myself 节点）</span><br><span class="line">    &#x2F;&#x2F; 字典的键为节点的名字，字典的值为节点对应的 clusterNode 结构</span><br><span class="line">    dict *nodes;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">&#125; clusterState;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>创建了三个节点的集群结构如下图:</p>
<p><img src="/images/redis/cluster/%E5%88%9B%E5%BB%BA%E4%BA%86%E4%B8%89%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E9%9B%86%E7%BE%A4%E7%BB%93%E6%9E%84.png" alt="创建了三个节点的集群结构"></p>
<p>结构的 currentEpoch 属性的值为 0 ， 表示集群当前的配置纪元为 0 。</p>
<p>结构的 size 属性的值为 0 ， 表示集群目前没有任何节点在处理槽： 因此结构的 state 属性的值为 REDIS_CLUSTER_FAIL —— 这表示集群目前处于下线状态。</p>
<p>结构的 nodes 字典记录了集群目前包含的三个节点， 这三个节点分别由三个 clusterNode 结构表示： 其中 myself 指针指向代表节点 7000 的 clusterNode 结构， 而字典中的另外两个指针则分别指向代表节点 7001 和代表节点 7002 的 clusterNode 结构， 这两个节点是节点 7000 已知的在集群中的其他节点。</p>
<p>三个节点的 clusterNode 结构的 flags 属性都是 REDIS_NODE_MASTER ，说明三个节点都是主节点。</p>
<h2 id="CLUSTER-MEET-命令的实现¶"><a href="#CLUSTER-MEET-命令的实现¶" class="headerlink" title="CLUSTER MEET 命令的实现¶"></a>CLUSTER MEET 命令的实现¶</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CLUSTER MEET &lt;ip&gt; &lt;port&gt;</span><br></pre></td></tr></table></figure>
<p>节点A发送以上的命令给B.A节点与B节点进行握手:</p>
<ol>
<li>节点 A 会为节点 B 创建一个 clusterNode 结构， 并将该结构添加到自己的 clusterState.nodes 字典里面。</li>
<li>之后， 节点 A 将根据 CLUSTER MEET 命令给定的 IP 地址和端口号， 向节点 B 发送一条 MEET 消息（message）。</li>
<li>如果一切顺利， 节点 B 将接收到节点 A 发送的 MEET 消息， 节点 B 会为节点 A 创建一个 clusterNode 结构， 并将该结构添加到自己的 clusterState.nodes 字典里面。</li>
<li>之后， 节点 B 将向节点 A 返回一条 PONG 消息。</li>
<li>如果一切顺利， 节点 A 将接收到节点 B 返回的 PONG 消息， 通过这条 PONG 消息节点 A 可以知道节点 B 已经成功地接收到了自己发送的 MEET 消息。</li>
<li>之后， 节点 A 将向节点 B 返回一条 PING 消息。</li>
<li>如果一切顺利， 节点 B 将接收到节点 A 返回的 PING 消息， 通过这条 PING 消息节点 B 可以知道节点 A 已经成功地接收到了自己返回的 PONG 消息， 握手完成。</li>
</ol>
<h1 id="槽指派"><a href="#槽指派" class="headerlink" title="槽指派"></a>槽指派</h1><p>数据库中的每个键都属于16384个槽位中的其中一个,集群中的每个及诶点都可以处理0个最多16384个槽位.之后全部的槽为被处理后,那么这个集群才处于上线状态,否则处于下线状态.</p>
<p>上一节中,cluster meet命令将三个节点加到一个集群中,但是没有进行槽位指派,所以集群处于fail状态.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisClusterTest&#x2F;6002$ .&#x2F;src&#x2F;redis-cli -h 127.0.0.1 -p 6002</span><br><span class="line">127.0.0.1:6002&gt; </span><br><span class="line">127.0.0.1:6002&gt; </span><br><span class="line">127.0.0.1:6002&gt; cluster info</span><br><span class="line">cluster_state:fail</span><br><span class="line">cluster_slots_assigned:0</span><br><span class="line">cluster_slots_ok:0</span><br><span class="line">cluster_slots_pfail:0</span><br><span class="line">cluster_slots_fail:0</span><br><span class="line">cluster_known_nodes:3</span><br><span class="line">cluster_size:0</span><br><span class="line">cluster_current_epoch:2</span><br><span class="line">cluster_my_epoch:2</span><br><span class="line">cluster_stats_messages_sent:1858</span><br><span class="line">cluster_stats_messages_received:0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这样启动后,查看集群状态,处于fail状态.</p>
<p>可以连接上连接上node节点使用 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6000&gt; cluster addslots 0 1 2 3 ... 5000</span><br><span class="line">127.0.0.1:6001&gt; cluster addslots 5001 5002 2 3 ... 10000</span><br><span class="line">127.0.0.1:6002&gt; cluster addslots 10001 10002 10003 ... 16383 </span><br></pre></td></tr></table></figure>
<p>分配槽位.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6000&gt; cluster nodes</span><br><span class="line">5e57d9227987c64486ec791217b64712ad201016 127.0.0.1:6001 master - 0 1517243097362 1 connected</span><br><span class="line">94a98e405ec368ad45469b9d5fb0e019bdf2d796 127.0.0.1:6002 master - 0 1517243098365 2 connected</span><br><span class="line">e6f7de12f623d0a92da8aa307a7ee224da73b92e 127.0.0.1:6000 myself,master - 0 0 0 connected</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="记录节点的槽指派信息"><a href="#记录节点的槽指派信息" class="headerlink" title="记录节点的槽指派信息"></a>记录节点的槽指派信息</h2><p>clusterNode结构的slots和numslot属性记录了节点负责处理哪些槽.</p>
<p><img src="/images/redis/cluster/clusterMode%E7%BB%93%E6%9E%84.png" alt="clusterMode结构"></p>
<p>slots属性时一个二进制位数组.这个数组的长度时16384/8=2048个字节,共包含16384个二进制位.</p>
<p><img src="/images/redis/cluster/slots%E6%95%B0%E7%BB%84%E7%A4%BA%E4%BE%8B.png" alt="slots数组示例"></p>
<p>值是1表示该节点处理该槽位.</p>
<p>由于取出和设置slots数组中的任意一个二进制位的值的复杂度仅为O(1),所以对于一个制定节点的slots数组来说,检查该节点是否处理某个槽,时间复杂度都为O(1).</p>
<h2 id="传播节点的槽指派信息"><a href="#传播节点的槽指派信息" class="headerlink" title="传播节点的槽指派信息"></a>传播节点的槽指派信息</h2><p>一个节点除了会将自己负责的槽记录在clusterNode结构的slots属性和numslots属性中,还会将自己的slots数组通过消息发送到集群中的其他节点,以此来告知其他节点自己目前处理的哪些槽.</p>
<p><img src="/images/redis/cluster/node%E5%91%8A%E7%9F%A5%E5%88%AB%E7%9A%84%E8%8A%82%E7%82%B9%E8%87%AA%E5%B7%B1%E5%A4%84%E7%90%86%E7%9A%84%E6%A7%BD%E4%BD%8D.png" alt="node告知别的节点自己处理的槽位"></p>
<p>这样,某个节点会将别的节点处理的槽位记录在其记录的该节点的clusterNode结构中.</p>
<h2 id="记录集群所有槽的指派信息"><a href="#记录集群所有槽的指派信息" class="headerlink" title="记录集群所有槽的指派信息"></a>记录集群所有槽的指派信息</h2><p>clusterState结构的slots数组记录了集群中所有的槽位的指派信息.如果只将槽位的指派信息记录到clusterNode节点中,则查找某个槽位在哪个节点还要遍历各个节点,时间复杂度为O(N)</p>
<p>有了clusterState结构,则时间复杂度为O(1)</p>
<p><img src="/images/redis/cluster/clusterState%E7%BB%93%E6%9E%84%E7%9A%84slots%E6%95%B0%E7%BB%84.png" alt="clusterState结构的slots数组"></p>
<p>clusterState结构的slots数组包含16384个项,存储的是指向某一个clusterNode节点的指针.</p>
<p>clusterNode.slots数组记录了节点的指派信息,clusterState.slots数组记录了所有的槽位指派信息.前者是便于发送槽位指派信息,后者是便于查找某一个槽位在哪个节点.</p>
<h2 id="CLUSTER-ADDSLOTS命令的实现"><a href="#CLUSTER-ADDSLOTS命令的实现" class="headerlink" title="CLUSTER ADDSLOTS命令的实现"></a>CLUSTER ADDSLOTS命令的实现</h2><p>cluster addslots<slot>[slot …] ,将槽位指派给接收该命令的节点负责</p>
<p><img src="/images/redis/cluster/clusteraddslots%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="cluster addslots 的伪代码实现"></p>
<p>未指派的cluster结构:</p>
<p><img src="/images/redis/cluster/%E6%9C%AA%E6%8C%87%E6%B4%BE%E7%9A%84cluster%E7%BB%93%E6%9E%84.png" alt="未指派的cluster结构"></p>
<p>执行命令后</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cluster addslots 1 2</span><br></pre></td></tr></table></figure>
<p>![执行cluster addSlots命令后](/images/redis/cluster/执行cluster addSlots命令后.png)</p>
<p>之后,节点会通过发送命令发送消息告知集群中的其它节点,自己正在处理的哪些槽.</p>
<h1 id="在集群中执行命令"><a href="#在集群中执行命令" class="headerlink" title="在集群中执行命令"></a>在集群中执行命令</h1><p>槽位指派完后,集群进入上线状态.这时客户端就可以向集群发送数据命令了.</p>
<p><img src="/images/redis/cluster/%E5%88%A4%E6%96%AD%E5%AE%A2%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%98%AF%E5%90%A6%E9%9C%80%E8%A6%81%E8%BD%AC%E5%90%91%E5%85%B6%E5%AE%83%E6%B5%81%E7%A8%8B.png" alt="判断客客户端是否需要转向其它流程"></p>
<h2 id="计算键属于哪个槽"><a href="#计算键属于哪个槽" class="headerlink" title="计算键属于哪个槽"></a>计算键属于哪个槽</h2><p>计算键属于哪个槽位</p>
<p><img src="/images/redis/cluster/%E8%AE%A1%E7%AE%97%E9%94%AE%E7%9A%84%E6%A7%BD%E4%BD%8D.png" alt="计算键的槽位"></p>
<p>cluster keyslot <key> 查看给定的键属于哪个槽.</p>
<h2 id="判断槽位是否由当前节点处理"><a href="#判断槽位是否由当前节点处理" class="headerlink" title="判断槽位是否由当前节点处理"></a>判断槽位是否由当前节点处理</h2><p>当节点计算出键所属的槽i后,接待节点检查自己在clusterState.slots数组的项i,看槽是否由自己负责.</p>
<p>如果自己负责,则执行命令,否则返回负责该槽位的节点ip和端口号.并向客户端返回 moved错误.</p>
<h2 id="moved错误"><a href="#moved错误" class="headerlink" title="moved错误"></a>moved错误</h2><p>MOVED错误的格式:</p>
<p>moved<slot><ip>:<port> ,其中slot是键所在的槽,ip和por是处理该键的节点.</p>
<p>一个集群客户端通常会与集群中的多个节点建立套接字连接.而所谓的节点转向其实就是换一个节点自来发送命令.</p>
<p>单机模式的客户端会打印moved信息,而集群客户端不会打印,只是自动进行节点转向.</p>
<h2 id="节点数据库的实现"><a href="#节点数据库的实现" class="headerlink" title="节点数据库的实现"></a>节点数据库的实现</h2><p>节点数据库只可以使用0号数据库.<strong>节点使用clusterState结构中的slots_to_keys跳跃表来保存槽和键之间的关系.</strong></p>
<p>slots_to_keys跳跃表每个节点的分之都是一个槽号,每个节点的成员都是一个数据库键.</p>
<p>当往数据库中添加一个新的键值对时,节点都会将这个键及键的槽号关联到slots_to_keys跳跃表.</p>
<p><img src="/images/redis/cluster/%E8%8A%82%E7%82%B97000%E7%9A%84%E8%B7%B3%E8%B7%83%E8%A1%A8.png" alt="节点7000的跳跃表"></p>
<h1 id="重新分片"><a href="#重新分片" class="headerlink" title="重新分片"></a>重新分片</h1><p>redis集群的重新分片操作可以将任意数量已经指派给某个几点的槽改为指派给另一个节点,并且想过槽所属的键值对也会从源节点移动到目标节点.</p>
<p>重新分片可以在线进行,在重新分片的过程中,集群不需要下线,并且源节点和目标节点都可以继续处理命令请求.</p>
<h2 id="重新分片的实现原理"><a href="#重新分片的实现原理" class="headerlink" title="重新分片的实现原理:"></a>重新分片的实现原理:</h2><p>redis集群的重新分片操作是有redis的集群管理软件redis-trib负责执行的.redis-trib通过向源节点和目标节点发送命令来实现的.</p>
<p><img src="/images/redis/cluster/%E9%87%8D%E6%96%B0%E5%88%86%E7%89%87%E7%9A%84%E6%93%8D%E4%BD%9C.png" alt="重新分片的操作"></p>
<p><img src="/images/redis/cluster/%E8%BF%81%E7%A7%BB%E9%94%AE%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="迁移键的过程"></p>
<p><img src="/images/redis/cluster/%E5%AF%B9%E6%A7%BD%E8%BF%9B%E8%A1%8C%E9%87%8D%E6%96%B0%E5%88%86%E7%89%87%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="对槽进行重新分片的过程"></p>
<h1 id="ASK错误"><a href="#ASK错误" class="headerlink" title="ASK错误"></a>ASK错误</h1><p>在进行重新分片期间,源节点向目标节点迁移一个槽的过程中.可能出现:属于被迁移槽的一部分键值对保存在源节点里面,而另一部分键值对保存在目标节点里面.</p>
<p>当客户端向源节点发送一个与数据库键有关的命令,并且命令要处理的数据恰好属于被迁移的槽时:</p>
<p>源节点会先在自己的数据库里面查找制定的键,如果找到的话,就直接执行客户端发送的命令.源节点没能在自己的数据库里面找到制定的键,那么键有可能被迁移到目标节点,源节点向客户端返回一个ASK错误,指引客户端转向正在导入槽的目标节点,并再次发送之前要执行的命令.</p>
<p><img src="/images/redis/cluster/%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E5%8F%91%E9%80%81ASK%E9%94%99%E8%AF%AF%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="判断是否发送ASK错误的过程"></p>
<p>和moved错误情况类似,集群模式的客户端会自动根据错误提供的ip和端口进行转向动作.</p>
<h2 id="cluster-setslot-importing命令的实现"><a href="#cluster-setslot-importing命令的实现" class="headerlink" title="cluster setslot importing命令的实现"></a>cluster setslot importing命令的实现</h2><p>clusterState结构的importing_slots_from数组记录了当前节点正在从其他节点导入的槽</p>
<p><img src="/images/redis/cluster/importing_slots_from%E6%95%B0%E7%BB%84.png" alt="importing_slots_from数组"></p>
<p>如果importing_slots_from[i]不为null,而是指向一个clusterNode结构,那么表示当前节点正在从clusterNode所代表的节点导入槽.</p>
<p>在对集群重新进行分片的时候,向目标节点发送命令:</p>
<p>cluster setslot<i> importing <source_id> ,可以将目标节点的clusterState.importing_slots_from[i] 的值设置为source_id所代表的cluster_node结构</p>
<p><img src="/images/redis/cluster/%E5%8F%91%E9%80%81setslot%E5%91%BD%E4%BB%A4.png" alt="发送setslot命令"></p>
<h2 id="cluster-setslot-migrating命令的实现"><a href="#cluster-setslot-migrating命令的实现" class="headerlink" title="cluster setslot migrating命令的实现"></a>cluster setslot migrating命令的实现</h2><p>clusterState结构的migrating_slots_to数组记录了当前节点正在迁移至其他节点的槽.</p>
<p>如果migrating_slots_to[i]不为null,而是指向一个clusterNode结构,那么表示当前节点正在将槽i迁移至clusterNode所代表的节点.</p>
<p>节点7002的migrating_slots_to数组:</p>
<p><img src="/images/redis/cluster/%E8%8A%82%E7%82%B97002%E7%9A%84migrating_slots_to%E6%95%B0%E7%BB%84.png" alt="节点7002的migrating_slots_to数组"></p>
<h2 id="ASK错误-1"><a href="#ASK错误-1" class="headerlink" title="ASK错误"></a>ASK错误</h2><p>如果节点收到一个关于键key的命令请求,并且键key所属的槽i正好指派给该节点,则该节点处理该命令.否则节点会检查migrating_slots_to[i],看键key所属的槽i是否正在进行迁移,如果槽i的确正在迁移,那么节点会向客户端返回一个ASK错误.</p>
<p>比如返回 ASK 16198 127.0.0.1:7003 表示客户端可以尝试到ip为127.0.0.1,端口号为7003的节点去执行和槽16198有关的操作.</p>
<p>接收到ASK错误的客户端会根据错误提供的ip和端口号,转向正在导入槽的目标及节点,然后首先向目标节点发送一个ASKING命令,之后重新发送原本想要执行的命令.</p>
<h2 id="ASKING命令"><a href="#ASKING命令" class="headerlink" title="ASKING命令"></a>ASKING命令</h2><p>ASKING命令唯一要做的就是打开发送该命令的客户端redis_asking标示.</p>
<p><img src="/images/redis/cluster/%E8%8A%82%E7%82%B9%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%89%A7%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%91%BD%E4%BB%A4%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="节点判断是否执行客户端命令的过程"></p>
<p>当客户端接收到ASK错误并转向至正在导入槽的节点时,客户端会首先发送ASKING命令,然后才重新发送需要执行的命令.如果不发送ASKING命令,直接发送要执行的命令,客户端会拒绝执行,返回moved错误.</p>
<p>客户端redis_asking标示是一次性的.当节点执行了一个带有该标识的命令后,该标示就会被移除.</p>
<h2 id="ASK错误和MOVED错误的区别"><a href="#ASK错误和MOVED错误的区别" class="headerlink" title="ASK错误和MOVED错误的区别"></a>ASK错误和MOVED错误的区别</h2><p><img src="/images/redis/cluster/ASK%E9%94%99%E8%AF%AF%E5%92%8CMOVED%E9%94%99%E8%AF%AF%E7%9A%84%E5%8C%BA%E5%88%AB.png" alt="ASK错误和MOVED错误的区别"></p>
<h1 id="复制和故障转移"><a href="#复制和故障转移" class="headerlink" title="复制和故障转移"></a>复制和故障转移</h1><p>redis集群中的节点分为主节点和从节点,主节点用于处理槽,从节点用于复制某个主节点,并在被复制的主节点下线时,代替下线朱及诶点继续处理命令请求.</p>
<h2 id="设置从节点"><a href="#设置从节点" class="headerlink" title="设置从节点"></a>设置从节点</h2><p>向一个节点发送</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cluster replicate&lt;node_id&gt;</span><br></pre></td></tr></table></figure>
<p>可以让接收命令的节点成为node_id所指定节点的从节点,并开始对主节点进行复制.</p>
<ol>
<li>接收到命令的节点首先从clusterState.nodes字典中找到node_id所对应节点的clusterNode结构,,并将自己的clusterState.mysql.slaveof指针指向这个结构,以此来记录这个节点正在复制主节点.</li>
<li>然后节点会修改自己在clusterState.myself.flags中的属性.关闭原本的REDIS_NODE_MASTER属性.打开redis_node_slave属性.</li>
<li>最后,节点会调用复制代码,并根据clusterState.myself.slaveof指向的clusterNode结构保存的ip地址和端口号.</li>
</ol>
<p><img src="/images/redis/cluster/7004%E4%BB%8E%E8%8A%82%E7%82%B9%E7%9A%84clusterState%E7%BB%93%E6%9E%84.png" alt="7004从节点的clusterState结构"></p>
<h2 id="故障检测"><a href="#故障检测" class="headerlink" title="故障检测"></a>故障检测</h2><p>集群中的每个节点都会定时的向集群中的其它节点发送ping消息,以此来检测对方是否在线;如果接收ping消息的节点在规定的时间内,回复pong消息,那么发送ping消息的及诶点就会向接收ping消息的节点标记为疑似下线状态(PFAIL);</p>
<p>集群中的各个节点都会通过互相发送消息的方式来交换集群中各个节点的状态消息,例如某个节点处于下线状态还是疑似下线状态.</p>
<p>当一个主节点A通过消息得知主节点B认为主节点C进入了疑似下线状态时,主节点A会在自己的clusterState.nodes字典中找到主节点C对应的clusterNode结构,并将主节点B的下线报告添加到clusterNode结构的fail_repoorts链表里面.</p>
<p>当主节点7001在收到主节点7002/主节点7003发送的消息后得知,主节点7002和主节点7003都认为主节点7000进入了疑似下线状态,那么主节点7001将为主节点7000创建如下的下线报告</p>
<p><img src="/images/redis/cluster/%E8%8A%82%E7%82%B97000%E7%9A%84%E4%B8%8B%E7%BA%BF%E6%8A%A5%E5%91%8A.png" alt="节点7000的下线报告"></p>
<p>如果一个集群里面,半数以上的负责处理槽的主节点将某个主节点X报告为疑似下线,那么主节点X将被将被标记为下线状态,将主节点X标记为下线状态的节点会向集群广播一条关于主节点X的fail消息,那么收到这条Fail消息的节点将会立即将主节点X标记为已下线.</p>
<h2 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h2><p>当从节点发现主节点进入下线状态,从节点开始对主节点进行故障转移:</p>
<p><img src="/images/redis/cluster/%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E7%9A%84%E6%AD%A5%E9%AA%A4.png" alt="故障转移的步骤"></p>
<h2 id="选举新的主节点"><a href="#选举新的主节点" class="headerlink" title="选举新的主节点"></a>选举新的主节点</h2><p>基于Raft算法:</p>
<p><img src="/images/redis/cluster/%E9%80%89%E5%8F%96%E6%96%B0%E7%9A%84%E4%B8%BB%E8%8A%82%E7%82%B91.png" alt="选取新的主节点1"></p>
<p><img src="/images/redis/cluster/%E9%80%89%E5%8F%96%E6%96%B0%E7%9A%84%E4%B8%BB%E8%8A%82%E7%82%B92.png" alt="选取新的主节点2"></p>
<h1 id="消息"><a href="#消息" class="headerlink" title="消息"></a>消息</h1><ul>
<li>meet消息</li>
</ul>
<p>发送者请求接收该消息者加入到当前所在的集群里面</p>
<ul>
<li>ping消息</li>
</ul>
<p>集群中每个节点默认每隔一秒钟都会从已知节点列表中随机选出5隔节点发送ping消息,一次来检验被选中的节点是否在线.</p>
<ul>
<li>pong消息</li>
</ul>
<p>接收ping或者meet消息的接受者会发送pong来回复发送者.还有在故障转移后,新的主节点会向集群广播一条pong消息,以此让集群知道该节点成为主节点,并接管了已经下线节点负责的槽.</p>
<ul>
<li>fail消息</li>
</ul>
<p>当A节点判断B节点进入Fail状态,它会向集群广播一条关于节点B的Fail消息,所有收到消息的节点会将B标记为下线状态.</p>
<ul>
<li>publish消息</li>
</ul>
<p>当节点接收到一个PUBLISH命令时,节点会向集群广播一条PUBLISH消息,所有接收到这条PUBLISH消息的节点都会执行相同的PUBLISH命令.</p>
<h2 id="消息头"><a href="#消息头" class="headerlink" title="消息头"></a>消息头</h2><p>节点发送的消息都由一个消息头包裹,消息头除了包含消息正文之外,还记录了消息发送者自身的一些信息.</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis cluster</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-客户端和服务端</title>
    <url>/2018-01-16/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E7%AB%AF/</url>
    <content><![CDATA[<h1 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h1><p>redis服务器与客户端是一对多的关系,使用由I/O多路复用技术实现的文件事件处理器,redis服务器单线程和单进程的方式来处理命令请求,并与多个客户端进行网络通信.</p>
<p>redisClient结构保存了客户端当前的状态信息:</p>
<ol>
<li>客户端的套接字描述</li>
<li>客户端的名字</li>
<li>客户端的标志值 flag</li>
<li>执行客户端正在使用的数据库的指针,以及数据库的号码</li>
<li>客户端当前要执行的命令/命令的参数/命令参数的个数/指向命令实现函数的指针</li>
<li>客户端输入和输出缓冲区</li>
<li>客户端复制状态信息以及进行复制所需要的数据结构</li>
<li>客户端执行BRPOP BLPOP等等列表阻塞命令时使用的数据结构</li>
<li>客户端的事务状态以及watch命令用到的数据结构</li>
<li>身份验证标志</li>
<li>客户端的创建时间,客户端和服务端最后的通信时间等</li>
</ol>
<p>Redis服务器状态结构的<strong>clients属性是一个链表</strong>,这个链表保存了所有连接的客户端的状态结构</p>
<p><img src="/images/redis/serverClient/redisServer%E7%9A%84clients.png" alt="redisServer的clients"></p>
<p><img src="/images/redis/serverClient/clients%E9%93%BE%E8%A1%A8.png" alt="clients链表"></p>
<h2 id="客户端属性"><a href="#客户端属性" class="headerlink" title="客户端属性"></a>客户端属性</h2><p>一种是通用的属性,另一种是特定功能的属性</p>
<h3 id="套接字描述"><a href="#套接字描述" class="headerlink" title="套接字描述"></a>套接字描述</h3><p>td属性 fd属性的值可以是-1或者大于-1的整数:</p>
<p>伪客户端的fd属性的值为-1,它处理的命令来自AOF文件或者Lua脚本,而不是网络.</p>
<p>普通客户端的fd属性值为大于-1的整数,它使用套接字来与服务器进行通讯,所以服务器使用fd属性来记录客户端套接字的描述符.</p>
<p>客户端的描述信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">27.0.0.1:6379&gt; CLIENT LIST</span><br><span class="line">id&#x3D;2 addr&#x3D;127.0.0.1:53958 fd&#x3D;5 name&#x3D; age&#x3D;25 idle&#x3D;0 flags&#x3D;N db&#x3D;0 sub&#x3D;0 psub&#x3D;0 multi&#x3D;-1 qbuf&#x3D;0 qbuf-free&#x3D;32768 obl&#x3D;0 oll&#x3D;0 omem&#x3D;0 events&#x3D;r cmd&#x3D;client</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="名字"><a href="#名字" class="headerlink" title="名字"></a>名字</h3><p>默认的客户端时没有名字的,可以使用client setname来设置名字</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; CLIENT SETNAME testName</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; CLIENT GETNAME</span><br><span class="line">&quot;testName&quot;</span><br><span class="line">127.0.0.1:6379&gt; CLIENT LIST</span><br><span class="line">id&#x3D;2 addr&#x3D;127.0.0.1:53958 fd&#x3D;5 name&#x3D;testName age&#x3D;198 idle&#x3D;0 flags&#x3D;N db&#x3D;0 sub&#x3D;0 psub&#x3D;0 multi&#x3D;-1 qbuf&#x3D;0 qbuf-free&#x3D;32768 obl&#x3D;0 oll&#x3D;0 omem&#x3D;0 events&#x3D;r cmd&#x3D;client</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="标志"><a href="#标志" class="headerlink" title="标志"></a>标志</h3><p>flags记录客户端的角色,可以是一个或者多个</p>
<p>flags=<flag1>|<flag2> </p>
<p><img src="/images/redis/serverClient/client%E7%9A%84flags1.png" alt="client的flags1"></p>
<p><img src="/images/redis/serverClient/client%E7%9A%84flags2.png" alt="client的flags2"></p>
<h3 id="输入缓冲区"><a href="#输入缓冲区" class="headerlink" title="输入缓冲区"></a>输入缓冲区</h3><p>在客户端输入以下命令:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set key value</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以下展示SDS的值以及querybuf属性的样子</p>
<p><img src="/images/redis/serverClient/querybuf%E5%B1%9E%E6%80%A7%E7%9A%84%E6%A0%B7%E5%AD%90.png" alt="querybuf属性的样子"></p>
<h3 id="命令与命令参数"><a href="#命令与命令参数" class="headerlink" title="命令与命令参数"></a>命令与命令参数</h3><p>服务器将客户端端发送的请求保存到客户端状态的querybuf属性之后,服务器将对命令请求的状态进行分析,并将得出的命令和参数的格式分别保存到客户端状态的argv属性和argc属性</p>
<p>argv属性是一个数组,数组中的每个项都是一个字符串对象,其中arg[0]时要执行的命令,而后的其它项都是传给命令的参数</p>
<p>argc属性则负责记录argv数组的长度</p>
<p><img src="/images/redis/serverClient/argv%E5%92%8Cargc%E5%B1%9E%E6%80%A7%E7%9A%84%E7%A4%BA%E4%BE%8B.png" alt="argv和argc属性的示例"></p>
<h3 id="命令的实现函数"><a href="#命令的实现函数" class="headerlink" title="命令的实现函数"></a>命令的实现函数</h3><p>服务器会根据argv[0]去命令表中查找命令所对应的命令实现函数.</p>
<p>命令表如下所示,它时一个字典,字典的键时一个SDS结构,保存了命令的名字,字典的值是命令所对应的redisCommand结构,这个结构保存了命令的实现函数.命令的标志.命令应该给定的参数个数.命令的执行次数以及总消耗时长等信息</p>
<p><img src="/images/redis/serverClient/%E6%9F%A5%E6%89%BE%E5%91%BD%E4%BB%A4%E5%B9%B6%E8%AE%BE%E7%BD%AEcmd%E5%B1%9E%E6%80%A7.png" alt="查找命令并设置cmd属性"></p>
<p>当程序在命令表中成功的找到argv[0]结构时,它会将客户端状态的cmd指针指向redisClient结构,之后服务器就使用cmd属性指向的redisCommand结构,以及其它一些参数来执行制定的命令.</p>
<h3 id="输出缓冲区"><a href="#输出缓冲区" class="headerlink" title="输出缓冲区"></a>输出缓冲区</h3><p>执行命令所得的命令的回复会被保存到客户端状态的输出缓冲区中,每个客户端都有2个输出缓冲区</p>
<h4 id="固定大小"><a href="#固定大小" class="headerlink" title="固定大小"></a>固定大小</h4><p>固定大小的缓冲区用于保存那些长度比较小的回复,ok,简短的字符串值等</p>
<p><img src="/images/redis/serverClient/%E5%9B%BA%E5%AE%9A%E5%A4%A7%E5%B0%8F%E7%9A%84%E7%BC%93%E5%86%B2%E5%8C%BA.png" alt="固定大小的缓冲区"></p>
<h4 id="可变大小"><a href="#可变大小" class="headerlink" title="可变大小"></a>可变大小</h4><p>可变大小的缓冲区用于保存那些长度比较大的回复</p>
<p>可变大小缓冲区由reply链表和一个或者多个字符串对象组成</p>
<p><img src="/images/redis/serverClient/%E5%8F%AF%E5%8F%98%E5%A4%A7%E5%B0%8F%E7%BC%93%E5%86%B2%E5%8C%BA%E7%A4%BA%E4%BE%8B.png" alt="可变大小缓冲区示例"></p>
<h3 id="身份验证"><a href="#身份验证" class="headerlink" title="身份验证"></a>身份验证</h3><p>客户端状态的authenticated属性用于记录客户端是否通过了身份验证: 值为0表示未通过身份验证,1表示已经通过身份验证,使用auth命令进行验证</p>
<h3 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h3><p>ctime属性记录了创建客户端的时间,client list命令的age域记录了这个秒数</p>
<p>lastinteraction记录了与客户端最后互动的时间,client list命令的idle记录了空闲了多久</p>
<h2 id="客户端的创建和关闭"><a href="#客户端的创建和关闭" class="headerlink" title="客户端的创建和关闭"></a>客户端的创建和关闭</h2><h3 id="创建客户端"><a href="#创建客户端" class="headerlink" title="创建客户端"></a>创建客户端</h3><p>如果客户端是通过网络连接与服务器进行连接的普通客户端,那么connect函数连接到服务器时,服务器就会调用连接事件处理器为客户端创建相应的客户端状态,并将这个新的客户端状态添加到服务器链表的末尾</p>
<p><img src="/images/redis/serverClient/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8A%B6%E6%80%81%E7%BB%93%E6%9E%84%E7%9A%84clients%E9%93%BE%E8%A1%A8.png" alt="服务器状态结构的clients链表"></p>
<h3 id="关闭普通客户端"><a href="#关闭普通客户端" class="headerlink" title="关闭普通客户端"></a>关闭普通客户端</h3><p>关闭的原因如下:</p>
<p><img src="/images/redis/serverClient/%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%85%B3%E9%97%AD%E7%9A%84%E5%8E%9F%E5%9B%A0%E5%A6%82%E4%B8%8B.png" alt="客户端关闭的原因如下"></p>
<h3 id="Lua脚本的伪客户端"><a href="#Lua脚本的伪客户端" class="headerlink" title="Lua脚本的伪客户端"></a>Lua脚本的伪客户端</h3><p>服务器会在初始化时创建负责执行Lua脚本中包含的Redis命令的伪客户端.伪客户端在服务器运行的整个生命周期都会一直存在,只有服务器被关闭时,这个客户端才会被关闭</p>
<h3 id="AOF伪客户端"><a href="#AOF伪客户端" class="headerlink" title="AOF伪客户端"></a>AOF伪客户端</h3><p>载入AOF文件时,会创建用于执行AOF文件中包含的redis命令的伪客户端,载入完成则关闭这个伪客户端.</p>
<h1 id="服务器"><a href="#服务器" class="headerlink" title="服务器"></a>服务器</h1><p>redis服务器负责与多个客户端建立网络连接,处理客户端发送的命令请求,在数据库中保存客户端执行命令所产生的数据,并通过资源管理来维持服务器自身的运转.</p>
<h2 id="命令请求的执行过程"><a href="#命令请求的执行过程" class="headerlink" title="命令请求的执行过程"></a>命令请求的执行过程</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set key value </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>客户端向服务器发送命令请求 SET KEY VALUE 。</li>
<li>服务器接收并处理客户端发来的命令请求 SET KEY VALUE ， 在数据库中进行设置操作， 并产生命令回复 OK 。</li>
<li>服务器将命令回复 OK 发送给客户端。</li>
<li>客户端接收服务器返回的命令回复 OK ， 并将这个回复打印给用户观看。</li>
</ol>
<h3 id="发送命令请求"><a href="#发送命令请求" class="headerlink" title="发送命令请求"></a>发送命令请求</h3><p>Redis 服务器的命令请求来自 Redis 客户端， 当用户在客户端中键入一个命令请求时， 客户端会将这个命令请求转换成协议格式， 然后通过连接到服务器的套接字， 将协议格式的命令请求发送给服务器</p>
<p><img src="/images/redis/serverClient/%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%8E%A5%E6%94%B6%E5%B9%B6%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82%E5%91%BD%E4%BB%A4%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="客户端接收并发送请求命令的过程"></p>
<h3 id="读取命令请求"><a href="#读取命令请求" class="headerlink" title="读取命令请求"></a>读取命令请求</h3><p>服务器读取命令的过程</p>
<ol>
<li>读取套接字中协议格式的命令请求， 并将其保存到客户端状态的输入缓冲区里面。</li>
<li>对输入缓冲区中的命令请求进行分析， 提取出命令请求中包含的命令参数， 以及命令参数的个数， 然后分别将参数和参数个数保存到客户端状态的 argv 属性和 argc 属性里面。</li>
<li>调用命令执行器， 执行客户端指定的命令。</li>
</ol>
<p><img src="/images/redis/serverClient/%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%8A%B6%E6%80%81%E4%B8%AD%E7%9A%84%E5%91%BD%E4%BB%A4%E8%AF%B7%E6%B1%82.png" alt="客户端状态中的命令请求"></p>
<p><img src="/images/redis/serverClient/%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%8A%B6%E6%80%81%E4%B8%AD%E7%9A%84argv%E5%92%8Cargc%E5%8F%82%E6%95%B0.png" alt="客户端状态中的argv和argc参数"></p>
<h2 id="命令执行器"><a href="#命令执行器" class="headerlink" title="命令执行器"></a>命令执行器</h2><p>命令执行器要做的第一件事就是根据客户端状态的 argv[0] 参数， 在命令表（command table）中查找参数所指定的命令， 并将找到的命令保存到客户端状态的 cmd 属性里面。</p>
<h3 id="查找命令的实现"><a href="#查找命令的实现" class="headerlink" title="查找命令的实现"></a>查找命令的实现</h3><p>redisCommand 结构的主要属性</p>
<p><img src="/images/redis/serverClient/redisCommand%E7%BB%93%E6%9E%84%E7%9A%84%E4%B8%BB%E8%A6%81%E5%B1%9E%E6%80%A7.png" alt="redisCommand结构的主要属性"></p>
<p>sflags属性的标识</p>
<p><img src="/images/redis/serverClient/sflags%E5%B1%9E%E6%80%A7%E7%9A%84%E6%A0%87%E8%AF%86.png" alt="sflags属性的标识"></p>
<p>SET 命令的名字为 “set” ， 实现函数为 setCommand ； 命令的参数个数为 -3 ， 表示命令接受三个或以上数量的参数； 命令的标识为 “wm” ， 表示 SET 命令是一个写入命令， 并且在执行这个命令之前， 服务器应该对占用内存状况进行检查， 因为这个命令可能会占用大量内存。</p>
<p>GET 命令的名字为 “get” ， 实现函数为 getCommand 函数； 命令的参数个数为 2 ， 表示命令只接受两个参数； 命令的标识为 “r” ， 表示这是一个只读命令。</p>
<p><img src="/images/redis/serverClient/%E5%91%BD%E4%BB%A4%E8%A1%A8.png" alt="命令表"></p>
<p>继续之前 SET 命令的例子， 当程序以图 14-3 中的 argv[0] 作为输入， 在命令表中进行查找时， 命令表将返回 “set” 键所对应的 redisCommand 结构， 客户端状态的 cmd 指针会指向这个 redisCommand 结构， 如图 14-5 所示。</p>
<p><img src="/images/redis/serverClient/%E8%AE%BE%E7%BD%AE%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%8A%B6%E6%80%81%E7%9A%84cmd%E6%8C%87%E9%92%88.png" alt="设置客户端状态的cmd指针"></p>
<h3 id="进行预备操作"><a href="#进行预备操作" class="headerlink" title="进行预备操作"></a>进行预备操作</h3><p>在以上操作之后,在真正执行命令之前还要进行一些预备操作</p>
<ol>
<li>检查客户端状态的 cmd 指针是否指向 NULL ， 如果是的话， 那么说明用户输入的命令名字找不到相应的命令实现， 服务器不再执行后续步骤， 并向客户端返回一个错误。</li>
<li>根据客户端 cmd 属性指向的 redisCommand 结构的 arity 属性， 检查命令请求所给定的参数个数是否正确， 当参数个数不正确时， 不再执行后续步骤， 直接向客户端返回一个错误。 比如说， 如果 redisCommand 结构的 arity 属性的值为 -3 ， 那么用户输入的命令参数个数必须大于等于 3 个才行。</li>
<li>检查客户端是否已经通过了身份验证， 未通过身份验证的客户端只能执行 AUTH 命令， 如果未通过身份验证的客户端试图执行除 AUTH 命令之外的其他命令， 那么服务器将向客户端返回一个错误。</li>
<li>如果服务器打开了 maxmemory 功能， 那么在执行命令之前， 先检查服务器的内存占用情况， 并在有需要时进行内存回收， 从而使得接下来的命令可以顺利执行。 如果内存回收失败， 那么不再执行后续步骤， 向客户端返回一个错误。</li>
<li>如果服务器上一次执行 BGSAVE 命令时出错， 并且服务器打开了 stop-writes-on-bgsave-error 功能， 而且服务器即将要执行的命令是一个写命令， 那么服务器将拒绝执行这个命令， 并向客户端返回一个错误。</li>
<li>如果客户端当前正在用 SUBSCRIBE 命令订阅频道， 或者正在用 PSUBSCRIBE 命令订阅模式， 那么服务器只会执行客户端发来的 SUBSCRIBE 、 PSUBSCRIBE 、 UNSUBSCRIBE 、 PUNSUBSCRIBE 四个命令， 其他别的命令都会被服务器拒绝。</li>
<li>如果服务器正在进行数据载入， 那么客户端发送的命令必须带有 l 标识（比如 INFO 、 SHUTDOWN 、 PUBLISH ，等等）才会被服务器执行， 其他别的命令都会被服务器拒绝。</li>
<li>如果服务器因为执行 Lua 脚本而超时并进入阻塞状态， 那么服务器只会执行客户端发来的 SHUTDOWN nosave 命令和 SCRIPT KILL 命令， 其他别的命令都会被服务器拒绝。</li>
<li>如果客户端正在执行事务， 那么服务器只会执行客户端发来的 EXEC 、 DISCARD 、 MULTI 、 WATCH 四个命令， 其他命令都会被放进事务队列中。</li>
<li>如果服务器打开了监视器功能， 那么服务器会将要执行的命令和参数等信息发送给监视器。</li>
</ol>
<h3 id="调用命令的实现函数"><a href="#调用命令的实现函数" class="headerlink" title="调用命令的实现函数"></a>调用命令的实现函数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; client 是指向客户端状态的指针</span><br><span class="line"></span><br><span class="line">client-&gt;cmd-&gt;proc(client);</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>以上代码相当于执行setCommand(client)</p>
<p><img src="/images/redis/serverClient/%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%8A%B6%E6%80%81.png" alt="客户端状态"></p>
<p>被调用的命令实现函数会执行指定的操作， 并产生相应的命令回复， 这些回复会被保存在客户端状态的输出缓冲区里面（buf 属性和 reply 属性）， 之后实现函数还会为客户端的套接字关联命令回复处理器， 这个处理器负责将命令回复返回给客户端。</p>
<h3 id="执行后续操作"><a href="#执行后续操作" class="headerlink" title="执行后续操作"></a>执行后续操作</h3><ol>
<li>如果服务器开启了慢查询日志功能， 那么慢查询日志模块会检查是否需要为刚刚执行完的命令请求添加一条新的慢查询日志。</li>
<li>根据刚刚执行命令所耗费的时长， 更新被执行命令的 redisCommand 结构的 milliseconds 属性， 并将命令的 redisCommand 结构的 calls 计数器的值增一。</li>
<li>如果服务器开启了 AOF 持久化功能， 那么 AOF 持久化模块会将刚刚执行的命令请求写入到 AOF 缓冲区里面。</li>
<li>如果有其他从服务器正在复制当前这个服务器， 那么服务器会将刚刚执行的命令传播给所有从服务器。</li>
</ol>
<h3 id="将命令回复给客户端"><a href="#将命令回复给客户端" class="headerlink" title="将命令回复给客户端"></a>将命令回复给客户端</h3><p>服务器命令实现函数为套接字关联命令回复处理器,将客户端buf属性中回复信息以协议格式的命令回复给客户端.</p>
<h3 id="客户端接收并打印命令回复"><a href="#客户端接收并打印命令回复" class="headerlink" title="客户端接收并打印命令回复"></a>客户端接收并打印命令回复</h3><p><img src="/images/redis/serverClient/%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%8E%A5%E6%94%B6%E5%B9%B6%E6%89%93%E5%8D%B0%E5%91%BD%E4%BB%A4%E5%9B%9E%E5%A4%8D.png" alt="客户端接收并打印命令回复"></p>
<h2 id="serverCron-函数"><a href="#serverCron-函数" class="headerlink" title="serverCron 函数"></a>serverCron 函数</h2><p>serverCron函数默认每100毫秒执行一次,这个函数负责管理服务器资源</p>
<h3 id="更新服务器的时间缓存"><a href="#更新服务器的时间缓存" class="headerlink" title="更新服务器的时间缓存"></a>更新服务器的时间缓存</h3><p>服务器中有好多命令需要获取当前时间,为了减少系统调用的执行次数.服务器状态中的unixtime和mstime属性被作为当前时间的缓存</p>
<p><img src="/images/redis/serverClient/redisServer%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4%E5%B1%9E%E6%80%A7.png" alt="redisServer中的时间属性"></p>
<p>serverCron函数默认会100毫秒一次的频率更新unixtime属性和mstime属性.所以这两个属性记录的时间精度不高,</p>
<p>对于打印日志,更新服务器的LRU时钟,决定是否执行持久化任务,计算服务器上线时间这类对时间精度不高的功能上使用以上时间属性.对键设置过期时间 添加慢查询日志这种需要搞定的时间功能来说还是需要获取最准确的系统当前时间</p>
<h3 id="更新LRU时钟"><a href="#更新LRU时钟" class="headerlink" title="更新LRU时钟"></a>更新LRU时钟</h3><p>服务器状态中的lruclock属性保存了服务器的LRU时钟,这个服务器时间缓存的一种,默认每10秒更新一次时钟缓存.用于计算键的idle</p>
<p>每个redis对象都有一个lru属性,保存了对象最后一次被访问的时间</p>
<p>当服务器计算一个数据库键的空转时间,可以使用服务器的lruclock减去键的lru属性</p>
<p>因为serverCron函数会以每10秒一次的频率更新lruClock的值,所以计算的idle不是非常精确的</p>
<h3 id="更新服务器美妙执行命令的次数"><a href="#更新服务器美妙执行命令的次数" class="headerlink" title="更新服务器美妙执行命令的次数"></a>更新服务器美妙执行命令的次数</h3><p>serverCron函数中的trackOperationPerSecond函数会以每100毫秒一次的频率执行,这个函数以抽样的方式计算服务器在最近一秒钟处理的命令请求数量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; info stats</span><br><span class="line"># Stats</span><br><span class="line">total_connections_received:1</span><br><span class="line">total_commands_processed:5</span><br><span class="line">instantaneous_ops_per_sec:0</span><br><span class="line">total_net_input_bytes:145</span><br><span class="line">total_net_output_bytes:11352</span><br><span class="line">instantaneous_input_kbps:0.00</span><br><span class="line">instantaneous_output_kbps:0.00</span><br><span class="line">rejected_connections:0</span><br><span class="line">sync_full:0</span><br><span class="line">sync_partial_ok:0</span><br><span class="line">sync_partial_err:0</span><br><span class="line">expired_keys:0</span><br><span class="line">evicted_keys:0</span><br><span class="line">keyspace_hits:0</span><br><span class="line">keyspace_misses:0</span><br><span class="line">pubsub_channels:0</span><br><span class="line">pubsub_patterns:0</span><br><span class="line">latest_fork_usec:0</span><br><span class="line">migrate_cached_sockets:0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="更新服务器内存峰值记录"><a href="#更新服务器内存峰值记录" class="headerlink" title="更新服务器内存峰值记录"></a>更新服务器内存峰值记录</h3><p>used_memory_peak和used_memory_peak_human参数分别以两种形式记录服务器内存峰值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; info memory</span><br><span class="line"># Memory</span><br><span class="line">used_memory:821744</span><br><span class="line">used_memory_human:802.48K</span><br><span class="line">used_memory_rss:9351168</span><br><span class="line">used_memory_rss_human:8.92M</span><br><span class="line">used_memory_peak:821744</span><br><span class="line">used_memory_peak_human:802.48K</span><br><span class="line">total_system_memory:8053633024</span><br><span class="line">total_system_memory_human:7.50G</span><br><span class="line">used_memory_lua:37888</span><br><span class="line">used_memory_lua_human:37.00K</span><br><span class="line">maxmemory:0</span><br><span class="line">maxmemory_human:0B</span><br><span class="line">maxmemory_policy:noeviction</span><br><span class="line">mem_fragmentation_ratio:11.38</span><br><span class="line">mem_allocator:jemalloc-4.0.3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="处理sigterm信号"><a href="#处理sigterm信号" class="headerlink" title="处理sigterm信号"></a>处理sigterm信号</h3><p>在启动服务器时,redis会为服务器进程的sigterm信号关联处理器sigtermHandler函数,这个信号处理器负责在服务器接收到sigterm信号时打开关标识</p>
<p><img src="/images/redis/serverClient/sigtermHandler%E5%87%BD%E6%95%B0.png" alt="sigtermHandler函数"></p>
<p>服务器一接收到sigterm信号就会关闭服务器,服务器要拦截sigterm信号,在关闭服务器之前进行RDB操作</p>
<h3 id="管理客户端资源"><a href="#管理客户端资源" class="headerlink" title="管理客户端资源"></a>管理客户端资源</h3><p>serverCron函数每次执行都会调用clientsCron函数,该clientsCron函数会对客户端进行检查</p>
<ol>
<li><p>如果客户端与服务器连接已经超时(客户端与服务器很长时间都没有互动),那么程序释放这个客户端</p>
</li>
<li><p>如果客户端在上一次执行命令之后,输入缓冲区的大小超过了一定的长度,那么程序会释放客户端的当前的缓冲区,并重新创建一个默认的缓冲区</p>
</li>
</ol>
<h3 id="管理数据库资源"><a href="#管理数据库资源" class="headerlink" title="管理数据库资源"></a>管理数据库资源</h3><p>serverCron函数每次执行都会调用databaseCron函数,该databaseCron函数会对数据库进行检查,删除其中的过期键.</p>
<h3 id="执行被延迟的BGREWRITEAOF"><a href="#执行被延迟的BGREWRITEAOF" class="headerlink" title="执行被延迟的BGREWRITEAOF"></a>执行被延迟的BGREWRITEAOF</h3><p>在服务器执行BGSAVE命令的期间,如果客户端向服务器发来BGREWRITEAOF命令,那么服务器会将BGREWRITEAOF延迟到BGSAVE命令之后执行 </p>
<p>redisServer的aof_rewrite_scheduled标识记录了服务器是否延迟了BGREWRITEAOF命令,如果被延迟,则将该标识置为1</p>
<p>每次调用serverCron函数执行,函数都检查bgsave和BGREWRITEAOF命令是否在执行,如果都没有执行,并且aof_rewrite_scheduled属性的值为1,那么服务器就会执行之前被推延的BGREWRITEAOF命令</p>
<h3 id="检查持久化操作的运行状态"><a href="#检查持久化操作的运行状态" class="headerlink" title="检查持久化操作的运行状态"></a>检查持久化操作的运行状态</h3><p>服务器使用rdb_child_pid属性和aof_child_pid属性记录执行bgsave命令和BGREWRITEAOF命令的子进程的ID,这两个属性也可以检查bgsave命令或者BGREWRITEAOF是否正在执行</p>
<p><img src="/images/redis/serverClient/%E6%8C%81%E4%B9%85%E5%8C%96%E6%93%8D%E4%BD%9C%E7%9A%84%E8%BF%90%E8%A1%8C%E7%8A%B6%E6%80%81%E7%9A%84%E5%8F%82%E6%95%B0.png" alt="持久化操作的运行状态的参数"></p>
<ul>
<li><p>每次serverCron函数执行都会检查这两个pid属性的值是否为-1,</p>
<pre><code>只有其中一个不为-1,程序就会执行wait3函数,检查子进程是否有信号发来服务器进程 如果有信号到达,表示新的RDB文件生成完成或者新的AOF文件重写完毕.服务器需要进行后续操作,比如新的RDB文件替换现有的RDB文件,新的AOF文件替换现有的AOF文件

如果2个进程id都不是-1则要进行以下检查:检查是否有BGREWRITEAOF命令被延迟;是否满足自动保存条件(bgsave执行的条件);AOF重写的条件是否满足</code></pre>
</li>
</ul>
<h3 id="AOF缓冲区的内容写到AOF文件"><a href="#AOF缓冲区的内容写到AOF文件" class="headerlink" title="AOF缓冲区的内容写到AOF文件"></a>AOF缓冲区的内容写到AOF文件</h3><p>如果服务器开启了AOF功能,并且AOF文件中还有待写入的数据,那么serverCron函数会调用相应的函数将数据写入到AOF文件</p>
<h3 id="关闭异步客户端"><a href="#关闭异步客户端" class="headerlink" title="关闭异步客户端"></a>关闭异步客户端</h3><p>关闭那些输入缓冲区超出大小限制的客户端</p>
<h3 id="增加cronloops计数器的值"><a href="#增加cronloops计数器的值" class="headerlink" title="增加cronloops计数器的值"></a>增加cronloops计数器的值</h3><p>服务器状态的cronloops记录了serverCron函数执行的次数(唯一的功能是,实现每执行N次就执行一次制定的代码)</p>
<h2 id="初始化服务器"><a href="#初始化服务器" class="headerlink" title="初始化服务器"></a>初始化服务器</h2><h3 id="初始化服务器状态结构"><a href="#初始化服务器状态结构" class="headerlink" title="初始化服务器状态结构"></a>初始化服务器状态结构</h3><p>即将redisServer类型的实例变量server作为服务器的状态,并为结构中的各个属性设置默认值,调用initServerConfig函数做以下工作,为服务器赋默认值</p>
<ol>
<li>设计服务器的运行id</li>
<li>设计服务器的默认运行频率</li>
<li>设置服务器的默认配置文件路径</li>
<li>设置服务器的运行架构</li>
<li>设置服务器的默认端口号</li>
<li>设置服务器的默认RDB持久化条件和AOF持久化条件</li>
<li>初始化服务器的LRU时钟</li>
<li>创建命令表</li>
</ol>
<h3 id="载入配置文件"><a href="#载入配置文件" class="headerlink" title="载入配置文件"></a>载入配置文件</h3><p>用户可以制定参数或者制定配置文件,对服务器的默认配置进行修改,是对初始化服务器结构的参数进行修改.这是第二步操作.</p>
<p>直接指定参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redis-3.2.10&#x2F;src$ .&#x2F;redis-server -- port 10086 &amp;</span><br><span class="line">[1] 11639</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redis-3.2.10&#x2F;src$ 11639:M 18 Jan 02:09:01.264 * Increased maximum number of open files to 10032 (it was originally set to 1024).</span><br><span class="line">                _._                                                  </span><br><span class="line">           _.-&#96;&#96;__ &#39;&#39;-._                                             </span><br><span class="line">      _.-&#96;&#96;    &#96;.  &#96;_.  &#39;&#39;-._           Redis 3.2.10 (00000000&#x2F;0) 64 bit</span><br><span class="line">  .-&#96;&#96; .-&#96;&#96;&#96;.  &#96;&#96;&#96;\&#x2F;    _.,_ &#39;&#39;-._                                   </span><br><span class="line"> (    &#39;      ,       .-&#96;  | &#96;,    )     Running in standalone mode</span><br><span class="line"> |&#96;-._&#96;-...-&#96; __...-.&#96;&#96;-._|&#39;&#96; _.-&#39;|     Port: 10086</span><br><span class="line"> |    &#96;-._   &#96;._    &#x2F;     _.-&#39;    |     PID: 11639</span><br><span class="line">  &#96;-._    &#96;-._  &#96;-.&#x2F;  _.-&#39;    _.-&#39;                                   </span><br><span class="line"> |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  </span><br><span class="line"> |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |           http:&#x2F;&#x2F;redis.io        </span><br><span class="line">  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   </span><br><span class="line"> |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  </span><br><span class="line"> |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |                                  </span><br><span class="line">  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   </span><br><span class="line">      &#96;-._    &#96;-.__.-&#39;    _.-&#39;                                       </span><br><span class="line">          &#96;-._        _.-&#39;                                           </span><br><span class="line">              &#96;-.__.-&#39;                                               </span><br><span class="line"></span><br><span class="line">11639:M 18 Jan 02:09:01.266 # WARNING: The TCP backlog setting of 511 cannot be enforced because &#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;somaxconn is set to the lower value of 128.</span><br><span class="line">11639:M 18 Jan 02:09:01.266 # Server started, Redis version 3.2.10</span><br><span class="line">11639:M 18 Jan 02:09:01.267 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &#39;vm.overcommit_memory &#x3D; 1&#39; to &#x2F;etc&#x2F;sysctl.conf and then reboot or run the command &#39;sysctl vm.overcommit_memory&#x3D;1&#39; for this to take effect.</span><br><span class="line">11639:M 18 Jan 02:09:01.267 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &#39;echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled&#39; as root, and add it to your &#x2F;etc&#x2F;rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.</span><br><span class="line">11639:M 18 Jan 02:09:01.267 * DB loaded from disk: 0.000 seconds</span><br><span class="line">11639:M 18 Jan 02:09:01.267 * The server is now ready to accept connections on port 10086</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>或者指定配置文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redis-3.2.10&#x2F;src$ .&#x2F;redis-server ..&#x2F;redis.conf &amp;</span><br><span class="line">[1] 11765</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redis-3.2.10&#x2F;src$ 11765:M 18 Jan 02:10:21.493 * Increased maximum number of open files to 10032 (it was originally set to 1024).</span><br><span class="line">                _._                                                  </span><br><span class="line">           _.-&#96;&#96;__ &#39;&#39;-._                                             </span><br><span class="line">      _.-&#96;&#96;    &#96;.  &#96;_.  &#39;&#39;-._           Redis 3.2.10 (00000000&#x2F;0) 64 bit</span><br><span class="line">  .-&#96;&#96; .-&#96;&#96;&#96;.  &#96;&#96;&#96;\&#x2F;    _.,_ &#39;&#39;-._                                   </span><br><span class="line"> (    &#39;      ,       .-&#96;  | &#96;,    )     Running in standalone mode</span><br><span class="line"> |&#96;-._&#96;-...-&#96; __...-.&#96;&#96;-._|&#39;&#96; _.-&#39;|     Port: 6379</span><br><span class="line"> |    &#96;-._   &#96;._    &#x2F;     _.-&#39;    |     PID: 11765</span><br><span class="line">  &#96;-._    &#96;-._  &#96;-.&#x2F;  _.-&#39;    _.-&#39;                                   </span><br><span class="line"> |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  </span><br><span class="line"> |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |           http:&#x2F;&#x2F;redis.io        </span><br><span class="line">  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   </span><br><span class="line"> |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  </span><br><span class="line"> |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |                                  </span><br><span class="line">  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   </span><br><span class="line">      &#96;-._    &#96;-.__.-&#39;    _.-&#39;                                       </span><br><span class="line">          &#96;-._        _.-&#39;                                           </span><br><span class="line">              &#96;-.__.-&#39;                                               </span><br><span class="line"></span><br><span class="line">11765:M 18 Jan 02:10:21.495 # WARNING: The TCP backlog setting of 511 cannot be enforced because &#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;somaxconn is set to the lower value of 128.</span><br><span class="line">11765:M 18 Jan 02:10:21.495 # Server started, Redis version 3.2.10</span><br><span class="line">11765:M 18 Jan 02:10:21.495 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &#39;vm.overcommit_memory &#x3D; 1&#39; to &#x2F;etc&#x2F;sysctl.conf and then reboot or run the command &#39;sysctl vm.overcommit_memory&#x3D;1&#39; for this to take effect.</span><br><span class="line">11765:M 18 Jan 02:10:21.495 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &#39;echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled&#39; as root, and add it to your &#x2F;etc&#x2F;rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.</span><br><span class="line">11765:M 18 Jan 02:10:21.495 * DB loaded from disk: 0.000 seconds</span><br><span class="line">11765:M 18 Jan 02:10:21.495 * The server is now ready to accept connections on port 6379</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="初始化服务器数据结构"><a href="#初始化服务器数据结构" class="headerlink" title="初始化服务器数据结构"></a>初始化服务器数据结构</h3><p>第三步 就是调用initServer初始化数据结构,包括:</p>
<p>server.clients链表,这个链表包含了所有与服务器连接的客户端redisClient,结构实例</p>
<p>server.db数组,包含了服务器的所有数据库</p>
<p>server.pubsub_channelszidian关于频道订阅信息的</p>
<p>用于执行lua脚本的环境server.lua</p>
<p>用于保存慢查询日志的server.slowlog属性</p>
<p>为以上的数据机构分配内存,除此之外还包括以下:</p>
<p><img src="/images/redis/serverClient/initServer%E5%87%BD%E6%95%B0%E7%9A%84%E5%85%B6%E5%AE%83%E6%93%8D%E4%BD%9C.png" alt="initServer函数的其它操作"></p>
<h3 id="还原数据库状态"><a href="#还原数据库状态" class="headerlink" title="还原数据库状态"></a>还原数据库状态</h3><p>如果开启了AOF持久化功能,则使用AOF文件还原数据库,否则使用RDB文件还原数据库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">11765:M 18 Jan 02:10:21.495 * DB loaded from disk: 0.000 seconds</span><br></pre></td></tr></table></figure>

<h3 id="执行时间循环"><a href="#执行时间循环" class="headerlink" title="执行时间循环"></a>执行时间循环</h3><p>初始化的最后异步打印</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">11765:M 18 Jan 02:10:21.495 * The server is now ready to accept connections on port 6379</span><br></pre></td></tr></table></figure>

<p>之后开始执行时间循环.</p>
<p>这样服务器这样就可以接收客户端的连接请求,以及接收客户端的命令了.</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis客户端,redis服务端</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-慢查询日志和事务以及二进制数组</title>
    <url>/2018-01-21/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%E5%92%8C%E4%BA%8B%E5%8A%A1%E4%BB%A5%E5%8F%8A%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<h1 id="慢查询日志"><a href="#慢查询日志" class="headerlink" title="慢查询日志"></a>慢查询日志</h1><p>Redis 的慢查询日志功能用于记录执行时间超过给定时长的命令请求， 用户可以通过这个功能产生的日志来监视和优化查询速度。</p>
<ol>
<li>slowlog-log-slower-than 选项指定执行时间超过多少微秒（1 秒等于 1,000,000 微秒）的命令请求会被记录到日志上。</li>
<li>slowlog-max-len 选项指定服务器最多保存多少条慢查询日志。( 当服务器储存的慢查询日志数量等于 slowlog-max-len 选项的值时， 服务器在添加一条新的慢查询日志之前， 会先将最旧的一条慢查询日志删除。)</li>
</ol>
<p>代码demo:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;先将时间设置为0 以使得所有的命令都会记录到慢查询日志里</span><br><span class="line">127.0.0.1:6379&gt; config get slowlog-log-slower-than</span><br><span class="line">1) &quot;slowlog-log-slower-than&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;记录慢查询日志的条数</span><br><span class="line">127.0.0.1:6379&gt; config get slowlog-max-len</span><br><span class="line">1) &quot;slowlog-max-len&quot;</span><br><span class="line">2) &quot;10&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;查询慢日志</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; slowlog get</span><br><span class="line"> 1) 1) (integer) 9           # 日志的唯一标识符（uid）</span><br><span class="line">    2) (integer) 1516475717  # 命令执行时的 UNIX 时间戳</span><br><span class="line">    3) (integer) 5           # 命令执行的时长，以微秒计算</span><br><span class="line">    4) 1) &quot;slowlog&quot;          # 命令以及命令参数</span><br><span class="line">       2) &quot;ge&quot;</span><br><span class="line"> 2) 1) (integer) 8</span><br><span class="line">    2) (integer) 1516475638</span><br><span class="line">    3) (integer) 49</span><br><span class="line">    4) 1) &quot;config&quot;</span><br><span class="line">       2) &quot;get&quot;</span><br><span class="line">       3) &quot;slowlog-log-slower-than&quot;</span><br><span class="line"> 3) 1) (integer) 7</span><br><span class="line">    2) (integer) 1516475500</span><br><span class="line">    3) (integer) 61</span><br><span class="line">    4) 1) &quot;config&quot;</span><br><span class="line">       2) &quot;get&quot;</span><br><span class="line">       3) &quot;slowlog-max-len&quot;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="慢查询记录的保存"><a href="#慢查询记录的保存" class="headerlink" title="慢查询记录的保存"></a>慢查询记录的保存</h2><p>服务器状态中包含了几个和慢查询日志功能有关的属性：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct redisServer &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 下一条慢查询日志的 ID</span><br><span class="line">    long long slowlog_entry_id;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 保存了所有慢查询日志的链表</span><br><span class="line">    list *slowlog;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 服务器配置 slowlog-log-slower-than 选项的值</span><br><span class="line">    long long slowlog_log_slower_than;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 服务器配置 slowlog-max-len 选项的值</span><br><span class="line">    unsigned long slowlog_max_len;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>slowlog 链表保存了服务器中的所有慢查询日志， 链表中的每个节点都保存了一个 slowlogEntry 结构， 每个 slowlogEntry 结构代表一条慢查询日志：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct slowlogEntry &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 唯一标识符</span><br><span class="line">    long long id;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 命令执行时的时间，格式为 UNIX 时间戳</span><br><span class="line">    time_t time;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 执行命令消耗的时间，以微秒为单位</span><br><span class="line">    long long duration;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 命令与命令参数</span><br><span class="line">    robj **argv;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 命令与命令参数的数量</span><br><span class="line">    int argc;</span><br><span class="line"></span><br><span class="line">&#125; slowlogEntry;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="慢查询日志的阅览和删除"><a href="#慢查询日志的阅览和删除" class="headerlink" title="慢查询日志的阅览和删除"></a>慢查询日志的阅览和删除</h2><p>伪代码实现</p>
<p>SLOWLOG GET 伪代码实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">def SLOWLOG_GET(number&#x3D;None):</span><br><span class="line"></span><br><span class="line">    # 用户没有给定 number 参数</span><br><span class="line">    # 那么打印服务器包含的全部慢查询日志</span><br><span class="line">    if number is None:</span><br><span class="line">        number &#x3D; SLOWLOG_LEN()</span><br><span class="line"></span><br><span class="line">    # 遍历服务器中的慢查询日志</span><br><span class="line">    for log in redisServer.slowlog:</span><br><span class="line"></span><br><span class="line">        if number &lt;&#x3D; 0:</span><br><span class="line">            # 打印的日志数量已经足够，跳出循环</span><br><span class="line">            break</span><br><span class="line">        else:</span><br><span class="line">            # 继续打印，将计数器的值减一</span><br><span class="line">            number -&#x3D; 1</span><br><span class="line"></span><br><span class="line">        # 打印日志</span><br><span class="line">        printLog(log)</span><br></pre></td></tr></table></figure>

<p>SLOWLOG LEN伪代码实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def SLOWLOG_LEN():</span><br><span class="line"></span><br><span class="line">    # slowlog 链表的长度就是慢查询日志的条目数量</span><br><span class="line">    return len(redisServer.slowlog)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>SLOWLOG RESET 伪代码实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def SLOWLOG_RESET():</span><br><span class="line"></span><br><span class="line">    # 遍历服务器中的所有慢查询日志</span><br><span class="line">    for log in redisServer.slowlog:</span><br><span class="line"></span><br><span class="line">        # 删除日志</span><br><span class="line">        deleteLog(log)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>例子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;get</span><br><span class="line">127.0.0.1:6379&gt; slowlog get</span><br><span class="line"> 1) 1) (integer) 14</span><br><span class="line">    2) (integer) 1516476187</span><br><span class="line">    3) (integer) 6</span><br><span class="line">    4) 1) &quot;slowlog&quot;</span><br><span class="line">       2) &quot;restt&quot;</span><br><span class="line"> 2) 1) (integer) 13</span><br><span class="line">    2) (integer) 1516476173</span><br><span class="line">    3) (integer) 5</span><br><span class="line">    4) 1) &quot;slowlog&quot;</span><br><span class="line">       2) &quot;len&quot;</span><br><span class="line"> 3) 1) (integer) 12</span><br><span class="line">    2) (integer) 1516476169</span><br><span class="line">    3) (integer) 4</span><br><span class="line">    4) 1) &quot;slowlog&quot;</span><br><span class="line">       2) &quot;len&quot;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; len</span><br><span class="line">127.0.0.1:6379&gt; slowlog len</span><br><span class="line">(integer) 10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; reset</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; slowlog reset</span><br><span class="line">OK</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="添加新日志"><a href="#添加新日志" class="headerlink" title="添加新日志"></a>添加新日志</h2><p>在每次执行命令的之前和之后， 程序都会记录微秒格式的当前 UNIX 时间戳， 这两个时间戳之间的差就是服务器执行命令所耗费的时长， 服务器会将这个时长作为参数之一传给 slowlogPushEntryIfNeeded 函数， 而 slowlogPushEntryIfNeeded 函数则负责检查是否需要为这次执行的命令创建慢查询日志， 以下伪代码展示了这一过程：</p>
<p>伪代码实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 记录执行命令前的时间</span><br><span class="line">before &#x3D; unixtime_now_in_us()</span><br><span class="line"></span><br><span class="line"># 执行命令</span><br><span class="line">execute_command(argv, argc, client)</span><br><span class="line"></span><br><span class="line"># 记录执行命令后的时间</span><br><span class="line">after &#x3D; unixtime_now_in_us()</span><br><span class="line"></span><br><span class="line"># 检查是否需要创建新的慢查询日志</span><br><span class="line">slowlogPushEntryIfNeeded(argv, argc, before-after)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>slowlogPushEntryIfNeeded函数检查slowlog-log-slower-than和slowlog-max-len这两个参数及做出相应的操作.</p>
<h1 id="监视器"><a href="#监视器" class="headerlink" title="监视器"></a>监视器</h1><p>通过执行 MONITOR 命令， 客户端可以将自己变为一个监视器， 实时地接收并打印出服务器当前处理的命令请求的相关信息：</p>
<p>每当一个客户端向服务器发送一条命令请求时， 服务器除了会处理这条命令请求之外， 还会将关于这条命令请求的信息发送给所有监视器</p>
<p>实例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;监视器对象客户端</span><br><span class="line">127.0.0.1:6379&gt; MONITOR</span><br><span class="line">OK</span><br><span class="line">1516477049.121659 [0 127.0.0.1:58004] &quot;ping&quot;  &#x2F;&#x2F;在1516477049.121659个时间点,根据 IP 为 127.0.0.1 、端口号为 56604 的客户端发送的命令请求， 对 0 号数据库执行命令ping</span><br><span class="line">1516477085.685457 [0 127.0.0.1:58004] &quot;set&quot; &quot;testkey&quot; &quot;test&quot;</span><br><span class="line">1516477099.400328 [0 127.0.0.1:58004] &quot;get&quot; &quot;testkey&quot;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;执行命令的客户端</span><br><span class="line">127.0.0.1:6379&gt; ping</span><br><span class="line">PONG</span><br><span class="line">127.0.0.1:6379&gt; set testkey test</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get testkey</span><br><span class="line">&quot;test&quot;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="成为监视器"><a href="#成为监视器" class="headerlink" title="成为监视器"></a>成为监视器</h2><p>伪代码实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def MONITOR():</span><br><span class="line"></span><br><span class="line">    # 打开客户端的监视器标志</span><br><span class="line">    client.flags |&#x3D; REDIS_MONITOR</span><br><span class="line"></span><br><span class="line">    # 将客户端添加到服务器状态的 monitors 链表的末尾</span><br><span class="line">    server.monitors.append(client)</span><br><span class="line"></span><br><span class="line">    # 向客户端返回 OK</span><br><span class="line">    send_reply(&quot;OK&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="向监视器发送命令信息"><a href="#向监视器发送命令信息" class="headerlink" title="向监视器发送命令信息"></a>向监视器发送命令信息</h2><p>服务器在每次处理命令请求之前， 都会调用 replicationFeedMonitors 函数， 由这个函数将被处理命令请求的相关信息发送给各个监视器。</p>
<p>replicationFeedMonitors 函数的伪代码:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def replicationFeedMonitors(client, monitors, dbid, argv, argc):</span><br><span class="line"></span><br><span class="line">    # 根据执行命令的客户端、当前数据库的号码、命令参数、命令参数个数等参数</span><br><span class="line">    # 创建要发送给各个监视器的信息</span><br><span class="line">    msg &#x3D; create_message(client, dbid, argv, argc)</span><br><span class="line"></span><br><span class="line">    # 遍历所有监视器</span><br><span class="line">    for monitor in monitors:</span><br><span class="line"></span><br><span class="line">        # 将信息发送给监视器</span><br><span class="line">        send_message(monitor, msg)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><p>redis通过multi/exec/watch等命令来实现事务(transaction)功能.</p>
<p>实例demo:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set name &quot;practical common listp&quot;</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set author &quot;peter seibel&quot;</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; get author</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">1) OK</span><br><span class="line">2) &quot;practical common listp&quot;</span><br><span class="line">3) OK</span><br><span class="line">4) &quot;peter seibel&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="事务的实现"><a href="#事务的实现" class="headerlink" title="事务的实现"></a>事务的实现</h2><p>事务的实现会经历三个阶段:</p>
<ol>
<li>事务开始;</li>
<li>命令入队;</li>
<li>事务执行</li>
</ol>
<h3 id="事务开始"><a href="#事务开始" class="headerlink" title="事务开始"></a>事务开始</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>MULTI 命令可以将执行该命令的客户端从非事务状态切换至事务状态， 这一切换是通过在客户端状态的 flags 属性中打开 REDIS_MULTI 标识来完成的</p>
<p>伪代码实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def MULTI():</span><br><span class="line"></span><br><span class="line">    # 打开事务标识</span><br><span class="line">    client.flags |&#x3D; REDIS_MULTI</span><br><span class="line"></span><br><span class="line">    # 返回 OK 回复</span><br><span class="line">    replyOK()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="命令入队"><a href="#命令入队" class="headerlink" title="命令入队"></a>命令入队</h3><p>当一个客户端处于非事务状态时， 这个客户端发送的命令会立即被服务器执行,</p>
<p>当一个客户端切换到事务状态之后， 服务器会根据这个客户端发来的不同命令执行不同的操作:</p>
<ol>
<li>如果客户端发送的命令为 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令的其中一个， 那么服务器立即执行这个命令。</li>
<li>如果客户端发送的命令是 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令以外的其他命令， 那么服务器并不立即执行这个命令， 而是将这个命令放入一个事务队列里面， 然后向客户端返回 QUEUED 回复。</li>
</ol>
<h3 id="事务队列"><a href="#事务队列" class="headerlink" title="事务队列"></a>事务队列</h3><p>Redis 客户端都有自己的事务状态， 这个事务状态保存在客户端状态的 mstate 属性里面</p>
<p>事务状态的状态结构:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct redisClient &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 事务状态</span><br><span class="line">    multiState mstate;      &#x2F;* MULTI&#x2F;EXEC state *&#x2F;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">&#125; redisClient;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>事务队列的结构:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct multiState &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 事务队列，FIFO 顺序</span><br><span class="line">    multiCmd *commands;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 已入队命令计数</span><br><span class="line">    int count;</span><br><span class="line"></span><br><span class="line">&#125; multiState;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>事务队列是一个 multiCmd 类型的数组， 数组中的每个 multiCmd 结构都保存了一个已入队命令的相关信息:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct multiCmd &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 参数</span><br><span class="line">    robj **argv;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 参数数量</span><br><span class="line">    int argc;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 命令指针</span><br><span class="line">    struct redisCommand *cmd;</span><br><span class="line"></span><br><span class="line">&#125; multiCmd;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/images/redis/transactionbitmap/IMAGE_TRANSACTION_STATE%E4%BA%8B%E5%8A%A1%E7%8A%B6%E6%80%81.png" alt="IMAGE_TRANSACTION_STATE事务状态"></p>
<h3 id="执行事务"><a href="#执行事务" class="headerlink" title="执行事务"></a>执行事务</h3><p>当一个处于事务状态的客户端向服务器发送 EXEC 命令时， 这个 EXEC 命令将立即被服务器执行： 服务器会遍历这个客户端的事务队列， 执行队列中保存的所有命令， 最后将执行命令所得的结果全部返回给客户端。</p>
<p>EXEC 命令的实现原理可以用以下伪代码来描述：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def EXEC():</span><br><span class="line"></span><br><span class="line">    # 创建空白的回复队列</span><br><span class="line">    reply_queue &#x3D; []</span><br><span class="line"></span><br><span class="line">    # 遍历事务队列中的每个项</span><br><span class="line">    # 读取命令的参数，参数的个数，以及要执行的命令</span><br><span class="line">    for argv, argc, cmd in client.mstate.commands:</span><br><span class="line"></span><br><span class="line">        # 执行命令，并取得命令的返回值</span><br><span class="line">        reply &#x3D; execute_command(cmd, argv, argc)</span><br><span class="line"></span><br><span class="line">        # 将返回值追加到回复队列末尾</span><br><span class="line">        reply_queue.append(reply)</span><br><span class="line"></span><br><span class="line">    # 移除 REDIS_MULTI 标识，让客户端回到非事务状态</span><br><span class="line">    client.flags &amp;&#x3D; ~REDIS_MULTI</span><br><span class="line"></span><br><span class="line">    # 清空客户端的事务状态，包括：</span><br><span class="line">    # 1）清零入队命令计数器</span><br><span class="line">    # 2）释放事务队列</span><br><span class="line">    client.mstate.count &#x3D; 0</span><br><span class="line">    release_transaction_queue(client.mstate.commands)</span><br><span class="line"></span><br><span class="line">    # 将事务的执行结果返回给客户端</span><br><span class="line">    send_reply_to_client(client, reply_queue)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="WATCH-命令的实现"><a href="#WATCH-命令的实现" class="headerlink" title="WATCH 命令的实现"></a>WATCH 命令的实现</h2><p>WATCH 命令是一个乐观锁,它可以在exec命令执行之前.监视任意数量的数据库键,并在exec命令执行时,检查被监视的键是否至少有一个已经被修改过了,如果是的话,服务器拒绝执行事务,并向服务器端返回代表事务执行失败的空回复.</p>
<p><img src="/images/redis/transactionbitmap/watch%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E5%A4%B1%E8%B4%A5%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt="watch命令执行失败的例子"></p>
<p>在T5时执行exec,服务器会发现watch监视的键”name” 已经发生了变化,则拒绝执行A的事务.</p>
<h3 id="使用watch命令监听数据库键"><a href="#使用watch命令监听数据库键" class="headerlink" title="使用watch命令监听数据库键"></a>使用watch命令监听数据库键</h3><p>每个redis数据库保存着一个watched_keys字典,这个字典的键是某个被watch命令监视的数据库键,值则是一个链表,链表记录了所监视的相应数据库键的客户端.</p>
<p>以下是watched_keys字典的实例.通过watch关键字可以使得key和客户端在watched_keys字典中进行关联.</p>
<p><img src="/images/redis/transactionbitmap/%E4%B8%80%E4%B8%AAwatched_keys%E5%AD%97%E5%85%B8.png" alt="一个watched_keys字典"></p>
<h3 id="监视机制的触发"><a href="#监视机制的触发" class="headerlink" title="监视机制的触发"></a>监视机制的触发</h3><p>对数据库进行写操作的时候,都会调用touchWatchKey函数进行检查,检查是否客户端正在监视刚刚被命令修改过的数据库键.如果有的话,那么该函数会将监视被修改键的客户端的REDIS_DIRTY_CAS 标示打开,标示客户端的事务的安全性被破坏.</p>
<h3 id="判断事务是否安全"><a href="#判断事务是否安全" class="headerlink" title="判断事务是否安全"></a>判断事务是否安全</h3><p>在服务器收到一个客户端发过来的exec命令时,服务器检查这个客户端是否打开 REDIS_DIRTY_CAS.打开了则放弃执行,没打开则执行.</p>
<h3 id="一个完整事务的执行过程"><a href="#一个完整事务的执行过程" class="headerlink" title="一个完整事务的执行过程"></a>一个完整事务的执行过程</h3><p>一个C1的客户端在执行watch name命令后,watch_keys字典的当前状态为name–C1;接下来客户端C1执行如下命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C1&gt;multi</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">C1&gt;set name &quot;peter&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这时,C2客户端执行set name “test” 命令,C2执行这个set命令会导致那些正在监视name键的客户端的REDIS_DIRTY_CAS标示被打开,其中包括C1客户端</p>
<p>之后,C1执行exec操作,发现REDIS_DIRTY_CAS处于打开的状态,则服务器拒绝它提交事务.</p>
<h2 id="事务的-ACID-性质"><a href="#事务的-ACID-性质" class="headerlink" title="事务的 ACID 性质"></a>事务的 ACID 性质</h2><p>事务的原子性,一致性,隔离性和持久性简称ACID可以检查事务的可靠性和安全性.</p>
<h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>要么全部执行,要么不执行.下面的例子中事务有错误的命令,所以事务中的所有命令不可以执行.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi </span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; get</span><br><span class="line">(error) ERR wrong number of arguments for &#39;get&#39; command</span><br><span class="line">127.0.0.1:6379&gt; get message</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br><span class="line">127.0.0.1:6379&gt; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>redis的事务和传统的关系型数据库最大区别在于不支持事务的回滚机制.</p>
<h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>事务的一致性是指,数据库的状态在事务执行之前和执行之后(无论是否成功)都是一致的.</p>
<h4 id="入队错误"><a href="#入队错误" class="headerlink" title="入队错误"></a>入队错误</h4><p>在入队的过程中出现错误,则redis拒绝执行该事务.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set name test</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; ddd</span><br><span class="line">(error) ERR unknown command &#39;ddd&#39;</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br><span class="line">127.0.0.1:6379&gt; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="执行错误"><a href="#执行错误" class="headerlink" title="执行错误"></a>执行错误</h4><p>比如一个type为String类型的键,执行了lpush操作.在入队时是发现不了的.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; type name</span><br><span class="line">string</span><br><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lpush name 1 2 3</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">1) (error) WRONGTYPE Operation against a key holding the wrong kind of value</span><br><span class="line">2) &quot;test&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>出错的命令会被服务器识别出来,不去执行,所以不会对数据库造成影响.</p>
<h3 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h3><p>事务的隔离性是指,即使数据库中有多个事务并发的执行,各个事务之间也不会互相的影响.并且并发状态下执行的事务和串行执行的事务产生的结果完全相同.</p>
<p>由于redis是单线程的,所以事务的执行都是串行的,所以事务是具有隔离性的.</p>
<h3 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h3><p>事务的持久性是指,当一个事务执行完毕时,执行这个事务的结果已经被永久的保存到数据库中了,即使服务器停机,结果也不会丢失.</p>
<p>redis事务只是简单的将命令包裹在一起,并没有提供持久化的功能.具体是否持久化到硬盘是有redis的持久化机制决定的.所以redis是否持久化是与redis事务没有关系的.</p>
<h1 id="二进制位数组"><a href="#二进制位数组" class="headerlink" title="二进制位数组"></a>二进制位数组</h1><p>redis提供了SETBIT GETBIT BITCOUNT BITOP四个命令用于处理二进制输入(位数组)</p>
<p>setbit命令用于为位数组指定偏移量上的二进制位设置值,位数组的<strong>偏移量从0开始计数</strong>,而<strong>二进制位的值则可以是0或者1</strong>.返回该位置原先的值.</p>
<p>例子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setbit bit 0 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit bit 3 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit bit 0 0</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>

<p>getbit则用于获取位数组指定偏移量上的二进制位的值.</p>
<p>例子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; getbit bit 100</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; getbit bit 0</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; getbit bit 3</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>

<p>bitcount 用于统计位数组里面,值为1的二进制位的数量.</p>
<p>例子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bitcount bit 0 -1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; </span><br></pre></td></tr></table></figure>

<p>bitcount 命令可以对多个位数组进行按位与(and) 或(or) 异或(xor)运算</p>
<p>与运算：0&amp;0=0;  0&amp;1=0;   1&amp;0=0;    1&amp;1=1;(两位同时为“1”，结果才为“1”，否则为0)<br>或运算: 0|0=0；  0|1=1；  1|0=1；   1|1=1；(参加运算的两个对象只要有一个为1，其值为1。)<br>异或运算:0^0=0；  0^1=1；  1^0=1；   1^1=0；(参加运算的两个对象，如果两个相应位为“异”（值不同），则该位结果为1，否则为0。)</p>
<p>例子:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setbit x 3 1   x &#x3D;0000 1011</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit x 1 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit x 0 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit y 2 1   y &#x3D;0000 0110</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit y 1 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit z 2 1   z &#x3D;0000 0101</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit z 0 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; bitop and resultand x y z   0000 0000</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bitcount resultand 0  -1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; bitop or resultor x y z     0000 1111</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bitcount resultor 0 -1</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; bitop xor resultxor x y z  0000 1000</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bitcount resultxor 0 -1</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="位数组的表示"><a href="#位数组的表示" class="headerlink" title="位数组的表示"></a>位数组的表示</h2><p>位数组采用字符串对象表示.</p>
<p><img src="/images/redis/transactionbitmap/SDS%E8%A1%A8%E7%A4%BA%E7%9A%84%E4%BD%8D%E6%95%B0%E7%BB%84.png" alt="SDS表示的位数组"></p>
<p>redisObject.type的值为REDIS_STRING</p>
<p>sdshdr.len的值为1</p>
<p>buf数组中的buf[0]表示存了一字节畅的位数组.</p>
<p>buf数组中的buf[1]字节保存了SDS程序自动追加到值末尾的空字符串’\0’</p>
<p><img src="/images/redis/transactionbitmap/%E4%B8%80%E5%AD%97%E8%8A%82%E9%95%BF%E7%9A%84%E4%BD%8D%E6%95%B0%E7%BB%84%E7%9A%84SDS%E8%A1%A8%E7%A4%BA.png" alt="一字节长的位数组的SDS表示"></p>
<h2 id="GETBIT命令的实现"><a href="#GETBIT命令的实现" class="headerlink" title="GETBIT命令的实现"></a>GETBIT命令的实现</h2><p>getbit <bitarray> <offset></p>
<ol>
<li>计算byte=(offset/8) byte值记录了offset偏移量指定的二进制位保存在数组的哪个字节;</li>
<li>计算bit=(offset mod 8) +1 ,bit位记录了offset偏移量指定的二进制位是byte字节的第几个二进制位;</li>
<li>根据byte值和bit值.在位数组bitarray中定位offset偏移量制定的二进制位.并返回这个位的值;</li>
</ol>
<p>例子:</p>
<p>GETBIT <bitarray> 3</p>
<ol>
<li><p>3/8 的值为0.</p>
</li>
<li><p>(3 mod 8) +1的值为4</p>
</li>
<li><p>定位到buf[0]字节上面.人后去除第四个二进制位的值为1 返回给客户端</p>
</li>
</ol>
<p>以上操作都在常数时间内完成,时间复杂度为O(1)</p>
<h2 id="SETBIT命令的实现"><a href="#SETBIT命令的实现" class="headerlink" title="SETBIT命令的实现"></a>SETBIT命令的实现</h2><p>SET <bitarray> <offset> <value></p>
<ol>
<li>len =(offset/8)+1 计算出需要多少字节;</li>
<li>检查bitarray键保存的长度是否小于len,如果是的话则扩展空间为len字节,并将所有的新空间的二进制位设置为0</li>
<li>计算byte=(offset/8) byte值记录了offset偏移量指定的二进制位保存的位数在哪个字节上</li>
<li>bit= (offset mod 8)+1 bit记录了偏移量指定的二进制位是byte字节的第几个二进制位;</li>
<li>byte值和bit值,在bitarray键保存的位数组中定位offset偏移量指定的二进制位,先将保存新值,然后返回旧值给客户端.</li>
</ol>
<h2 id="BITCOUNT命令的实现"><a href="#BITCOUNT命令的实现" class="headerlink" title="BITCOUNT命令的实现"></a>BITCOUNT命令的实现</h2><p>bitcount <bitarray></p>
<p>计算二进制数组中1的个数</p>
<p>算法:</p>
<p>采用的是查表和variable-precisionSWAR两种算法.具体细节可自行查阅资料.</p>
<h2 id="BITOP命令"><a href="#BITOP命令" class="headerlink" title="BITOP命令"></a>BITOP命令</h2><p>采用的是计算机的位运算符操作,将结果放到给定的键上</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis事务,二进制数组,慢查询日志</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-数据结构与对象1</title>
    <url>/2017-12-26/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A11/</url>
    <content><![CDATA[<h1 id="简单动态字符串"><a href="#简单动态字符串" class="headerlink" title="简单动态字符串"></a>简单动态字符串</h1><ul>
<li><p>概要</p>
<p>redis没有直接使用C语言传统的字符串表示(以空字符结尾的字符数组),自己构建了一种SDS的抽象类型,即redis的默认字符串类型表示.</p>
</li>
</ul>
<h2 id="SDS的定义"><a href="#SDS的定义" class="headerlink" title="SDS的定义"></a>SDS的定义</h2><ul>
<li><p>如图所示:</p>
<p><img src="/images/redis/struct1/SDS%E7%A4%BA%E4%BE%8B.png" alt="SDS示例"></p>
</li>
</ul>
<p>1.free 属性的值为 0 ， 表示这个 SDS 没有分配任何未使用空间。</p>
<p>2.len 属性的值为 5 ， 表示这个 SDS 保存了一个五字节长的字符串。</p>
<p>3.buf 属性是一个 char 类型的数组， 数组的前五个字节分别保存了 ‘R’ 、 ‘e’ 、 ‘d’ 、 ‘i’ 、 ‘s’ 五个字符， 而最后一个字节则保存了空字符 ‘\0’ 。</p>
<p><code>说明</code></p>
<p>SDS 遵循 C 字符串以空字符结尾的惯例， 保存空字符的 1 字节空间不计算在 SDS 的 len 属性里面， 并且为空字符分配额外的 1 字节空间， 以及添加空字符到字符串末尾等操作都是由 SDS 函数自动完成的， 所以这个空字符对于 SDS 的使用者来说是完全透明的。</p>
<ul>
<li><p>下图中与上图不同的是,free属性的值为5</p>
<p><img src="/images/redis/struct1/%E5%B8%A6%E6%9C%89%E6%9C%AA%E4%BD%BF%E7%94%A8%E7%A9%BA%E9%97%B4%E7%9A%84SDS%E7%A4%BA%E4%BE%8B.png" alt="SDS示例"></p>
</li>
</ul>
<h2 id="SDS与C字符串的区别"><a href="#SDS与C字符串的区别" class="headerlink" title="SDS与C字符串的区别"></a>SDS与C字符串的区别</h2><p>C语言使用N+1长度的字符数组来表示长度为N的字符串.</p>
<h3 id="常数复杂度获取字符串长度"><a href="#常数复杂度获取字符串长度" class="headerlink" title="常数复杂度获取字符串长度"></a>常数复杂度获取字符串长度</h3><ol>
<li><p>因为 C 字符串并不记录自身的长度信息， 所以为了获取一个 C 字符串的长度， 程序必须遍历整个字符串， 对遇到的每个字符进行计数， 直到遇到代表字符串结尾的空字符为止， 这个操作的复杂度为 O(N) 。</p>
</li>
<li><p>和 C 字符串不同， 因为 SDS 在 len 属性中记录了 SDS 本身的长度， 所以获取一个 SDS 长度的复杂度仅为 O(1) 。</p>
</li>
</ol>
<h3 id="杜绝缓冲区溢出"><a href="#杜绝缓冲区溢出" class="headerlink" title="杜绝缓冲区溢出"></a>杜绝缓冲区溢出</h3><p> 当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求， 如果不满足的话， API 会自动将 SDS 的空间扩展至执行修改所需的大小， 然后才执行实际的修改操作， 所以使用 SDS 既不需要手动修改 SDS 的空间大小， 也不会出现前面所说的缓冲区溢出问题。</p>
<h3 id="减少修改字符串时带来的内存重分配次数"><a href="#减少修改字符串时带来的内存重分配次数" class="headerlink" title="减少修改字符串时带来的内存重分配次数"></a>减少修改字符串时带来的内存重分配次数</h3><p>c字符串内存再次分配:</p>
<p>如果程序执行的是增长字符串的操作， 比如拼接操作（append）， 那么在执行这个操作之前， 程序需要先通过内存重分配来扩展底层数组的空间大小 —— 如果忘了这一步就会产生缓冲区溢出。</p>
<p>如果程序执行的是缩短字符串的操作， 比如截断操作（trim）， 那么在执行这个操作之后， 程序需要通过内存重分配来释放字符串不再使用的那部分空间 —— 如果忘了这一步就会产生内存泄漏。</p>
<p>SDS内存再次分配:</p>
<p>为了避免 C 字符串的这种缺陷， SDS 通过未使用空间解除了字符串长度和底层数组长度之间的关联： 在 SDS 中， buf 数组的长度不一定就是字符数量加一， 数组里面可以包含未使用的字节， 而这些字节的数量就由 SDS 的 free 属性记录。</p>
<p>策略如:空间预分配 惰性空间释放</p>
<h3 id="二进制安全"><a href="#二进制安全" class="headerlink" title="二进制安全"></a>二进制安全</h3><p>  所有 SDS API 都会以处理二进制的方式来处理 SDS 存放在 buf 数组里的数据， 程序不会对其中的数据做任何限制、过滤、或者假设 —— 数据在写入时是什么样的， 它被读取时就是什么样。</p>
<h3 id="兼容部分-C-字符串函数"><a href="#兼容部分-C-字符串函数" class="headerlink" title="兼容部分 C 字符串函数"></a>兼容部分 C 字符串函数</h3><p>虽然 SDS 的 API 都是二进制安全的， 但它们一样遵循 C 字符串以空字符结尾的惯例： 这些 API 总会将 SDS 保存的数据的末尾设置为空字符， 并且总会在为 buf 数组分配空间时多分配一个字节来容纳这个空字符， 这是为了让那些保存文本数据的 SDS 可以重用一部分 </p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p> <img src="/images/redis/struct1/SDS%E4%B8%8EC%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%8C%BA%E5%88%AB.jpg" alt="SDS与C字符串的区别"></p>
<h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><p> 链表提供了高效的节点重排能力， 以及顺序性的节点访问方式， 并且可以通过增删节点来灵活地调整链表的长度。列表键的底层实现之一就是链表： 当一个列表键包含了数量比较多的元素， 又或者列表中包含的元素都是比较长的字符串时， Redis 就会使用链表作为列表键的底层实现。</p>
<h2 id="链表和链表节点的实现"><a href="#链表和链表节点的实现" class="headerlink" title="链表和链表节点的实现"></a>链表和链表节点的实现</h2><p>链表节点的结构</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct listNode &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 前置节点</span><br><span class="line">    struct listNode *prev;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 后置节点</span><br><span class="line">    struct listNode *next;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 节点的值</span><br><span class="line">    void *value;</span><br><span class="line"></span><br><span class="line">&#125; listNode;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>多个 listNode 可以通过 prev 和 next 指针组成双端链表</p>
<p> <img src="/images/redis/struct1/%E5%8F%8C%E7%AB%AF%E9%93%BE%E8%A1%A8.png" alt="双端链表"></p>
<p>虽然仅仅使用多个 listNode 结构就可以组成链表， 但使用 adlist.h/list 来持有链表的话,即redis进行了封装,结构如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct list &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 表头节点</span><br><span class="line">    listNode *head;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 表尾节点</span><br><span class="line">    listNode *tail;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 链表所包含的节点数量</span><br><span class="line">    unsigned long len;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 节点值复制函数</span><br><span class="line">    void *(*dup)(void *ptr);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 节点值释放函数</span><br><span class="line">    void (*free)(void *ptr);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 节点值对比函数</span><br><span class="line">    int (*match)(void *ptr, void *key);</span><br><span class="line"></span><br><span class="line">&#125; list;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>如下图是是一个list结构和三个listNode结构组成的链表</p>
<p> <img src="/images/redis/struct1/list%E7%BB%93%E6%9E%84%E5%92%8C%E5%8F%8C%E7%AB%AF%E9%93%BE%E8%A1%A8.png" alt="list结构和双端链表"></p>
<ul>
<li>Redis 的链表实现的特性可以总结如下：</li>
</ul>
<ol>
<li>双端： 链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。</li>
<li>无环： 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。</li>
<li>带表头指针和表尾指针： 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。</li>
<li>带链表长度计数器： 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1) 。</li>
<li>多态： 链表节点使用 void* 指针来保存节点值， 并且可以通过 list 结构的 dup 、 free 、 match 三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。</li>
</ol>
<ul>
<li>总结</li>
</ul>
<ol>
<li>链表被广泛用于实现 Redis 的各种功能， 比如列表键， 发布与订阅， 慢查询， 监视器， 等等。</li>
<li>每个链表节点由一个 listNode 结构来表示， 每个节点都有一个指向前置节点和后置节点的指针， 所以 Redis 的链表实现是双端链表。</li>
<li>每个链表使用一个 list 结构来表示， 这个结构带有表头节点指针、表尾节点指针、以及链表长度等信息。</li>
<li>因为链表表头节点的前置节点和表尾节点的后置节点都指向 NULL ， 所以 Redis 的链表实现是无环链表。</li>
<li>通过为链表设置不同的类型特定函数， Redis 的链表可以用于保存各种不同类型的值。</li>
</ol>
<h1 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h1><p> 字典可以表示数据库， 字典还是哈希键的底层实现之一.</p>
<h2 id="字典的实现"><a href="#字典的实现" class="headerlink" title="字典的实现"></a>字典的实现</h2><p>Redis 的字典使用哈希表作为底层实现， 一个<strong>哈希表</strong>里面可以有多个<strong>哈希表节点</strong>， 而每个哈希表节点就保存了字典中的一个<strong>键值对</strong>。</p>
<h3 id="hash表"><a href="#hash表" class="headerlink" title="hash表"></a>hash表</h3><p> hash表的结构如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">typedef struct dictht &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 哈希表数组</span><br><span class="line">    dictEntry **table;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 哈希表大小</span><br><span class="line">    unsigned long size;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 哈希表大小掩码，用于计算索引值</span><br><span class="line">    &#x2F;&#x2F; 总是等于 size - 1</span><br><span class="line">    unsigned long sizemask;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 该哈希表已有节点的数量</span><br><span class="line">    unsigned long used;</span><br><span class="line"></span><br><span class="line">&#125; dictht;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li><p><strong>table 属性是一个数组</strong>， 数组中的每个元素都是一个指向 dict.h/dictEntry 结构的指针， 每个 dictEntry 结构保存着一个键值对。</p>
</li>
<li><p>size 属性记录了哈希表的大小， 也即是 table 数组的大小， 而 used 属性则记录了哈希表目前已有节点（键值对）的数量。</p>
</li>
<li><p>sizemask 属性的值总是等于 size - 1 ， 这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上面。</p>
</li>
</ol>
<p>如下为一个空的hash表</p>
<p> <img src="/images/redis/struct1/%E7%A9%BAhash%E8%A1%A8.png" alt="空hash表"></p>
<h3 id="hash表节点"><a href="#hash表节点" class="headerlink" title="hash表节点"></a>hash表节点</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">typedef struct dictEntry &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 键</span><br><span class="line">    void *key;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 值</span><br><span class="line">    union &#123;</span><br><span class="line">        void *val;</span><br><span class="line">        uint64_t u64;</span><br><span class="line">        int64_t s64;</span><br><span class="line">    &#125; v;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 指向下个哈希表节点，形成链表</span><br><span class="line">    struct dictEntry *next;</span><br><span class="line"></span><br><span class="line">&#125; dictEntry;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中next 属性是指向另一个哈希表节点的指针， 这个指针可以将多个哈希值相同的键值对连接在一次， 以此来解决键冲突（collision）的问题。</p>
<p> <img src="/images/redis/struct1/next%E6%8C%87%E9%92%88%E5%B0%86%E4%B8%A4%E4%B8%AA%E7%B4%A2%E5%BC%95%E5%80%BC%E7%9B%B8%E5%90%8C%E7%9A%84%E9%94%AE%E8%BF%9E%E6%8E%A5%E5%9C%A8%E4%B8%80%E8%B5%B7.png" alt="next指针将两个索引值相同的键连接在一起"></p>
<h3 id="字典-1"><a href="#字典-1" class="headerlink" title="字典"></a>字典</h3><p>结构如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct dict &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 类型特定函数</span><br><span class="line">    dictType *type;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 私有数据</span><br><span class="line">    void *privdata;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 哈希表</span><br><span class="line">    dictht ht[2];</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; rehash 索引</span><br><span class="line">    &#x2F;&#x2F; 当 rehash 不在进行时，值为 -1</span><br><span class="line">    int rehashidx; &#x2F;* rehashing not in progress if rehashidx &#x3D;&#x3D; -1 *&#x2F;</span><br><span class="line"></span><br><span class="line">&#125; dict;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>type 属性和 privdata 属性是针对不同类型的键值对， 为创建多态字典而设置的：</p>
<p>type 属性是一个指向 dictType 结构的指针， 每个 dictType 结构保存了一簇用于操作特定类型键值对的函数， Redis 会为用途不同的字典设置不同的类型特定函数。<br>而 privdata 属性则保存了需要传给那些类型特定函数的可选参数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">typedef struct dictType &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 计算哈希值的函数</span><br><span class="line">    unsigned int (*hashFunction)(const void *key);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 复制键的函数</span><br><span class="line">    void *(*keyDup)(void *privdata, const void *key);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 复制值的函数</span><br><span class="line">    void *(*valDup)(void *privdata, const void *obj);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 对比键的函数</span><br><span class="line">    int (*keyCompare)(void *privdata, const void *key1, const void *key2);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 销毁键的函数</span><br><span class="line">    void (*keyDestructor)(void *privdata, void *key);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 销毁值的函数</span><br><span class="line">    void (*valDestructor)(void *privdata, void *obj);</span><br><span class="line"></span><br><span class="line">&#125; dictType;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>ht 属性是一个包含两个项的数组， 数组中的每个项都是一个 dictht 哈希表， 一般情况下， 字典只使用 ht[0] 哈希表， ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用。<br>除了 ht[1] 之外， 另一个和 rehash 有关的属性就是 rehashidx ： 它记录了 rehash 目前的进度， 如果目前没有在进行 rehash ， 那么它的值为 -1 。</p>
<p>普通状态下的字典.</p>
<p> <img src="/images/redis/struct1/%E5%B1%95%E7%A4%BA%E4%BA%86%E4%B8%80%E4%B8%AA%E6%99%AE%E9%80%9A%E7%8A%B6%E6%80%81%E4%B8%8B%E7%9A%84%E5%AD%97%E5%85%B8.png" alt="展示了一个普通状态下的字典"></p>
<h2 id="hash算法"><a href="#hash算法" class="headerlink" title="hash算法"></a>hash算法</h2><p>当要将一个新的键值对添加到字典里面时， 程序需要先根据键值对的键计算出哈希值和索引值， 然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面。</p>
<p>使用字典设置的哈希函数，计算键 key 的哈希值</p>
<p>hash = dict-&gt;type-&gt;hashFunction(key);</p>
<p>使用哈希表的 sizemask 属性和哈希值，计算出索引值,根据情况不同， ht[x] 可以是 ht[0] 或者 ht[1]</p>
<p>index = hash &amp; dict-&gt;ht[x].sizemask;</p>
<p> <img src="/images/redis/struct1/hash%E7%AE%97%E6%B3%95.png" alt="hash算法"></p>
<p>当字典被用作数据库的底层实现， 或者哈希键的底层实现时， Redis 使用 MurmurHash2 算法来计算键的哈希值。</p>
<h2 id="解决键冲突"><a href="#解决键冲突" class="headerlink" title="解决键冲突"></a>解决键冲突</h2><h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><p>当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面时， 我们称这些键发生了冲突（collision）。</p>
<h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法:"></a>解决办法:</h3><p>Redis 的哈希表使用链地址法（separate chaining）来解决键冲突： 每个哈希表节点都有一个 next 指针， 多个哈希表节点可以用 next 指针构成一个单向链表， 被分配到同一个索引上的多个节点可以用这个单向链表连接起来， 这就解决了键冲突的问题。</p>
<p> <img src="/images/redis/struct1/%E8%A7%A3%E5%86%B3%E9%94%AE%E5%86%B2%E7%AA%81.png" alt="解决键冲突"></p>
<h2 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h2><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>随着操作的不断执行， 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子（load factor）维持在一个合理的范围之内， 当哈希表保存的键值对数量太多或者太少时， 程序需要对哈希表的大小进行相应的扩展或者收缩。</p>
<h3 id="Redis-对字典的哈希表执行-rehash-的步骤如下"><a href="#Redis-对字典的哈希表执行-rehash-的步骤如下" class="headerlink" title="Redis 对字典的哈希表执行 rehash 的步骤如下"></a>Redis 对字典的哈希表执行 rehash 的步骤如下</h3><p>1.为字典的 ht[1] 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是 ht[0].used 属性的值）：</p>
<p>  如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n （2 的 n 次方幂）；</p>
<p>  如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n 。</p>
<p>2.将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。</p>
<p>3.当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。</p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>对图 4-8 所示字典的 ht[0] 进行<code>扩展</code>操作</p>
<p>1.ht[0].used 当前的值为 4 ， 4 * 2 = 8 ， 而 8 （2^3）恰好是第一个大于等于 4 的 2 的 n 次方， 所以程序会将 ht[1] 哈希表的大小设置为 8 </p>
<p> <img src="/images/redis/struct1/rehash%E4%B9%8B%E5%89%8D%E7%9A%84%E5%AD%97%E5%85%B8.png" alt="rehash之前的字典"></p>
<p> <img src="/images/redis/struct1/%E4%B8%BA%E5%AD%97%E5%85%B8%E7%9A%84ht%5B1%5D%E5%88%86%E9%85%8D%E8%A1%A8%E7%A9%BA%E9%97%B4.png" alt="为字典的ht[1]分配表空间"></p>
<p>2.将 ht[0] 包含的四个键值对都 rehash 到 ht[1] ， 如图 4-10 所示。 </p>
<p><img src="/images/redis/struct1/%E7%A7%BB%E5%8A%A8%E9%94%AE%E5%80%BC%E5%AF%B9.png" alt="移动键值对"></p>
<p>3.释放 ht[0] ，并将 ht[1] 设置为 ht[0] ，然后为 ht[1] 分配一个空白哈希表，如图 4-11 所示。</p>
<p><img src="/images/redis/struct1/rehash%E4%B9%8B%E5%90%8E%E7%9A%84%E5%AD%97%E5%85%B8.png" alt="rehash之后的字典"></p>
<h3 id="哈希表的扩展与收缩"><a href="#哈希表的扩展与收缩" class="headerlink" title="哈希表的扩展与收缩"></a>哈希表的扩展与收缩</h3><p><strong>当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作</strong></p>
<p>1.服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 ；<br>2.服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5 ；</p>
<p><code>负载因子的计算公式</code>:</p>
<p>负载因子 = 哈希表已保存节点数量 / 哈希表大小</p>
<p>load_factor = ht[0].used / ht[0].size</p>
<p><strong>当哈希表的负载因子小于 0.1 时， 程序自动开始对哈希表执行收缩操作。</strong></p>
<h2 id="渐进式-rehash"><a href="#渐进式-rehash" class="headerlink" title="渐进式 rehash"></a>渐进式 rehash</h2><h3 id="名词解释-1"><a href="#名词解释-1" class="headerlink" title="名词解释"></a>名词解释</h3><p>扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面， 但是， 这个 rehash 动作并不是一次性、集中式地完成的， 而是分多次、渐进式地完成的。</p>
<h3 id="渐进式rehash的步骤"><a href="#渐进式rehash的步骤" class="headerlink" title="渐进式rehash的步骤"></a>渐进式rehash的步骤</h3><p>1.为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。<br>2.在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 <code>0</code> ， 表示 rehash 工作正式开始。<strong>rehashidx代表当前rehash的索引</strong><br>3.在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， <code>程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1]</code> ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。<br>4.随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为<code> -1</code> ， 表示 rehash 操作已完成。</p>
<h3 id="渐进式-rehash-执行期间的哈希表操作"><a href="#渐进式-rehash-执行期间的哈希表操作" class="headerlink" title="渐进式 rehash 执行期间的哈希表操作"></a>渐进式 rehash 执行期间的哈希表操作</h3><p>因为在进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0] 里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找， 诸如此类。</p>
<p>另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis数据结构与对象</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-数据结构与对象2</title>
    <url>/2018-01-03/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A12/</url>
    <content><![CDATA[<h1 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a>跳跃表</h1><ul>
<li>概念</li>
</ul>
<p>跳跃表（skiplist）是一种有序数据结构， 它通过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的。</p>
<p>跳跃表支持平均 O(log N) 最坏 O(N) 复杂度的节点查找</p>
<p>Redis 只在两个地方用到了跳跃表， 一个是实现有序集合键， 另一个是在集群节点中用作内部数据结构， 除此之外， 跳跃表在 Redis 里面没有其他用途。</p>
<h2 id="跳跃表的实现"><a href="#跳跃表的实现" class="headerlink" title="跳跃表的实现"></a>跳跃表的实现</h2><p>Redis 的跳跃表由 redis.h/zskiplistNode 和 redis.h/zskiplist 两个结构定义， 其中 zskiplistNode 结构用于表示跳跃表节点， 而 zskiplist 结构则用于保存跳跃表节点的相关信息， 比如节点的数量， 以及指向表头节点和表尾节点的指针， 等等</p>
<p> <img src="/images/redis/struct1/%E8%B7%B3%E8%B7%83%E8%A1%A8%E7%9A%84%E7%BB%93%E6%9E%84.png" alt="跳跃表的结构"></p>
<ul>
<li>展示了一个跳跃表示例， 位于图片最左边的是 <strong>zskiplist</strong> 结构</li>
</ul>
<p><code>header</code> ：指向跳跃表的表头节点。</p>
<p><code>tail</code> ：指向跳跃表的表尾节点。</p>
<p><code>level</code> ：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。</p>
<p><code>length</code> ：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。</p>
<ul>
<li>位于 zskiplist 结构右方的是四个 <strong>zskiplistNode</strong> 结构， 该结构包含以下属性：</li>
</ul>
<p><code>层（level）</code>：节点中用 L1 、 L2 、 L3 等字样标记节点的各个层， L1 代表第一层， L2 代表第二层，以此类推。每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。在上面的图片中，连线上带有数字的箭头就代表前进指针，而那个数字就是跨度。当程序从表头向表尾进行遍历时，访问会沿着层的前进指针进行。</p>
<p><code>后退（backward）指针</code>：节点中用 BW 字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。</p>
<p><code>分值（score）</code>：各个节点中的 1.0 、 2.0 和 3.0 是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。</p>
<h2 id="跳跃表节点"><a href="#跳跃表节点" class="headerlink" title="跳跃表节点"></a>跳跃表节点</h2><ul>
<li>zskiplistNode 结构定义：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct zskiplistNode &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 后退指针</span><br><span class="line">    struct zskiplistNode *backward;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 分值</span><br><span class="line">    double score;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 成员对象</span><br><span class="line">    robj *obj;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 层</span><br><span class="line">    struct zskiplistLevel &#123;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 前进指针</span><br><span class="line">        struct zskiplistNode *forward;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 跨度</span><br><span class="line">        unsigned int span;</span><br><span class="line"></span><br><span class="line">    &#125; level[];</span><br><span class="line"></span><br><span class="line">&#125; zskiplistNode;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="层"><a href="#层" class="headerlink" title="层"></a>层</h3><p>跳跃表节点的 level 数组可以包含多个元素， 每个元素都包含一个指向其他节点的指针， 程序可以通过这些层来加快访问其他节点的速度， 一般来说， 层的数量越多， 访问其他节点的速度就越快。</p>
<p>每次创建一个新跳跃表节点的时候， 程序都根据幂次定律 （power law，越大的数出现的概率越小） 随机生成一个<strong>介于 1 和 32 之间的值</strong>作为 level 数组的大小， 这个大小就是层的“高度”。</p>
<p>图 5-2 分别展示了三个高度为 1 层、 3 层和 5 层的节点， 因为 C 语言的数组索引总是从 0 开始的， 所以节点的第一层是 level[0] ， 而第二层是 level[1] ， 以此类推。</p>
<p> <img src="/images/redis/struct1/%E4%B8%8D%E5%90%8C%E5%B1%82%E9%AB%98%E7%9A%84%E8%8A%82%E7%82%B9.png" alt="不同层高的节点"></p>
<h3 id="前进指针"><a href="#前进指针" class="headerlink" title="前进指针"></a>前进指针</h3><p>每个层都有一个指向表尾方向的前进指针（level[i].forward 属性）， 用于从表头向表尾方向访问节点。</p>
<p>图 5-3 用虚线表示出了程序从表头向表尾方向， <strong>遍历跳跃表</strong>中所有节点的路径：</p>
<p>1.迭代程序首先访问跳跃表的第一个节点（表头）， 然后从第四层的前进指针移动到表中的第二个节点。</p>
<p>2.在第二个节点时， 程序沿着第二层的前进指针移动到表中的第三个节点。</p>
<p>3.在第三个节点时， 程序同样沿着第二层的前进指针移动到表中的第四个节点。</p>
<p>4.当程序再次沿着第四个节点的前进指针移动时， 它碰到一个 NULL ， 程序知道这时已经到达了跳跃表的表尾， 于是结束这次遍历。</p>
<p> <img src="/images/redis/struct1/%E9%81%8D%E5%8E%86%E8%B7%B3%E8%B7%83%E8%A1%A8.png" alt="遍历跳跃表"></p>
<h3 id="跨度"><a href="#跨度" class="headerlink" title="跨度"></a>跨度</h3><p>层的跨度（level[i].span 属性）用于记录两个节点之间的距离：</p>
<p>1.两个节点之间的跨度越大， 它们相距得就越远。</p>
<p>2.指向 NULL 的所有前进指针的跨度都为 0 ， 因为它们没有连向任何节点。</p>
<ul>
<li>跨度的作用</li>
</ul>
<p>跨度实际上是用来计算排位（rank）的： 在查找某个节点的过程中， 将沿途访问过的所有层的跨度累计起来， 得到的结果就是目标节点在跳跃表中的排位。</p>
<p>例子:</p>
<p>图 5-4 用虚线标记了在跳跃表中查找分值为 3.0 、 成员对象为 o3 的节点时， 沿途经历的层： 查找的过程只经过了一个层， 并且层的跨度为 3 ， 所以目标节点在跳跃表中的排位为 3 。</p>
<p> <img src="/images/redis/struct1/%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E7%9A%84%E6%8E%92%E4%BD%8D.png" alt="计算节点的排位"></p>
<h3 id="后退指针"><a href="#后退指针" class="headerlink" title="后退指针"></a>后退指针</h3><p>节点的后退指针（backward 属性）用于从表尾向表头方向访问节点： 跟可以一次跳过多个节点的前进指针不同， 因为每个节点只有一个后退指针， 所以每次只能后退至前一个节点。</p>
<p>图 5-6 用虚线展示了如果从表尾向表头遍历跳跃表中的所有节点： 程序首先通过跳跃表的 tail 指针访问表尾节点， 然后通过后退指针访问倒数第二个节点， 之后再沿着后退指针访问倒数第三个节点， 再之后遇到指向 NULL 的后退指针， 于是访问结束。</p>
<p> <img src="/images/redis/struct1/%E4%BB%8E%E8%A1%A8%E5%B0%BE%E9%83%A8%E5%90%91%E8%A1%A8%E5%A4%B4%E7%9A%84%E9%81%8D%E5%8E%86.png" alt="从表尾部向表头的遍历"></p>
<h3 id="分值和成员"><a href="#分值和成员" class="headerlink" title="分值和成员"></a>分值和成员</h3><p>节点的分值（score 属性）是一个 double 类型的浮点数， 跳跃表中的所有节点都按分值从小到大来排序。</p>
<p>节点的成员对象（obj 属性）是一个指针， 它指向一个字符串对象， 而字符串对象则保存着一个 SDS 值。</p>
<p>在同一个跳跃表中， <strong>各个节点保存的成员对象必须是唯一的</strong>， <strong>但是多个节点保存的分值却可以是相同的</strong>： 分值相同的节点将按照成员对象在字典序中的大小来进行排序， 成员对象较小的节点会排在前面（靠近表头的方向）， 而成员对象较大的节点则会排在后面（靠近表尾的方向）。</p>
<h2 id="跳跃表-1"><a href="#跳跃表-1" class="headerlink" title="跳跃表"></a>跳跃表</h2><p>虽然仅靠多个跳跃表节点就可以组成一个跳跃表如图 5-8 所示。<br>但通过使用一个 zskiplist 结构来持有这些节点， 程序可以更方便地对整个跳跃表进行处理， 比如快速访问跳跃表的表头节点和表尾节点， 又或者快速地获取跳跃表节点的数量（也即是跳跃表的长度）等信息， 如图 5-9 所示</p>
<p> <img src="/images/redis/struct1/%E5%A4%9A%E4%B8%AA%E8%B7%B3%E8%B7%83%E8%8A%82%E7%82%B9%E7%BB%84%E6%88%90%E7%9A%84%E8%B7%B3%E8%B7%83%E8%A1%A8.png" alt="多个跳跃节点组成的跳跃表"></p>
<p> <img src="/images/redis/struct1/%E5%B8%A6%E6%9C%89skiplist%E7%BB%93%E6%9E%84%E7%9A%84%E8%B7%B3%E8%B7%83%E8%A1%A8.png" alt="带有skiplist结构的跳跃表"></p>
<p>zskiplist结构定义</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct zskiplist &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 表头节点和表尾节点</span><br><span class="line">    struct zskiplistNode *header, *tail;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 表中节点的数量</span><br><span class="line">    unsigned long length;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 表中层数最大的节点的层数</span><br><span class="line">    int level;</span><br><span class="line"></span><br><span class="line">&#125; zskiplist;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>header 和 tail 指针分别指向跳跃表的表头和表尾节点， 通过这两个指针， 程序定位表头节点和表尾节点的复杂度为 O(1) 。</p>
<p>通过使用 length 属性来记录节点的数量， 程序可以在 O(1) 复杂度内返回跳跃表的长度。</p>
<p>level 属性则用于在 O(1) 复杂度内获取跳跃表中层高最大的那个节点的层数量， 注意<strong>表头节点的层高并不计算在内</strong>。</p>
<h1 id="整数集合"><a href="#整数集合" class="headerlink" title="整数集合"></a>整数集合</h1><p>整数集合（intset）是集合键的底层实现之一： 当一个集合只包含整数值元素， 并且这个集合的元素数量不多时， Redis 就会使用整数集合作为集合键的底层实现。</p>
<h2 id="整数集合的实现"><a href="#整数集合的实现" class="headerlink" title="整数集合的实现"></a>整数集合的实现</h2><p>整数集合（intset）是 Redis 用于保存整数值的集合抽象数据结构， 它可以保存类型为 int16_t 、 int32_t 或者 int64_t 的整数值， 并且保证集合中不会出现重复元素。</p>
<p>结构如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct intset &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 编码方式</span><br><span class="line">    uint32_t encoding;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 集合包含的元素数量</span><br><span class="line">    uint32_t length;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 保存元素的数组</span><br><span class="line">    int8_t contents[];</span><br><span class="line"></span><br><span class="line">&#125; intset;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>contents</strong> 数组是整数集合的底层实现： 整数集合的每个元素都是 contents 数组的一个数组项（item）， 各个项在数组中按值的大小从小到大<code>有序地排列</code>， 并且数组中<code>不包含任何重复项</code>。</p>
<p><strong>length</strong> 属性记录了整数集合包含的元素数量， 也即是 contents 数组的长度。</p>
<p><strong>encoding</strong></p>
<p> 如果 encoding 属性的值为 INTSET_ENC_INT16 ， 那么 contents 就是一个 int16_t 类型的数组， 数组里的每个项都是一个 int16_t 类型的整数值 （最小值为 -32,768 ，最大值为 32,767 ）。</p>
<p> 如果 encoding 属性的值为 INTSET_ENC_INT32 ， 那么 contents 就是一个 int32_t 类型的数组， 数组里的每个项都是一个 int32_t 类型的整数值 （最小值为 -2,147,483,648 ，最大值为 2,147,483,647 ）。</p>
<p> 如果 encoding 属性的值为 INTSET_ENC_INT64 ， 那么 contents 就是一个 int64_t 类型的数组， 数组里的每个项都是一个 int64_t 类型的整数值 （最小值为 -9,223,372,036,854,775,808 ，最大值为 9,223,372,036,854,775,807 ）。</p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>图 6-1 展示了一个整数集合示例：</p>
<p>encoding 属性的值为 INTSET_ENC_INT16 ， 表示整数集合的底层实现为 int16_t 类型的数组， 而集合保存的都是 int16_t 类型的整数值。</p>
<p>length 属性的值为 5 ， 表示整数集合包含五个元素。</p>
<p>contents 数组按从小到大的顺序保存着集合中的五个元素。</p>
<p>因为每个集合元素都是 int16_t 类型的整数值， 所以 contents 数组的大小等于 sizeof(int16_t) * 5 = 16 * 5 = 80 位。</p>
<p> <img src="/images/redis/struct1/16bit%E7%9A%84%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88.png" alt="16bit的整数集合"></p>
<ul>
<li>注意</li>
</ul>
<p>当向一个底层为 int16_t 数组的整数集合添加一个 int64_t 类型的整数值时， 整数集合已有的所有元素都会被转换成 int64_t 类型， 所以 contents 数组保存的四个整数值都是 int64_t 类型的， 不仅仅是 -2675256175807981027 。</p>
<h2 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h2><p>每当我们要将一个新元素添加到整数集合里面， 并且<strong>新元素的类型比整数集合现有所有元素的类型都要长时</strong>， 整数集合需要先进行升级（upgrade）， 然后才能将新元素添加到整数集合里面。</p>
<ul>
<li>升级整数集合并添加新元素共分为三步进行：</li>
</ul>
<p>1.根据新元素的类型， 扩展整数集合底层数组的空间大小， 并为新元素分配空间。</p>
<p>2.将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中， 需要继续维持底层数组的有序性质不变。</p>
<p>3.将新元素添加到底层数组里面。</p>
<h3 id="升级例子"><a href="#升级例子" class="headerlink" title="升级例子"></a>升级例子</h3><p>假设现在有一个 INTSET_ENC_INT16 编码的整数集合， 集合中包含三个 int16_t 类型的元素， 如图 6-3 所示。</p>
<p> <img src="/images/redis/struct1/int16%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88.png" alt="int16整数集合"></p>
<p>因为每个元素都占用 16 位空间， 所以整数集合底层数组的大小为 3 * 16 = 48 位， 图 6-4 展示了整数集合的三个元素在这 48 位里的位置。</p>
<p> <img src="/images/redis/struct1/contents%E6%95%B0%E7%BB%84%E4%B8%AD%E5%90%84%E4%B8%AA%E5%85%83%E7%B4%A0%E6%89%80%E5%9C%A8%E7%9A%84%E4%BD%8D%E7%BD%AE.png" alt="contents数组中各个元素所在的位置"></p>
<p>现在， 假设我们要将类型为 int32_t 的整数值 65535 添加到整数集合里面， 因为 65535 的类型 int32_t 比整数集合当前所有元素的类型都要长， 所以在将 65535 添加到整数集合之前， 程序需要先对整数集合进行升级。</p>
<p>整数集合目前有三个元素， 再加上新元素 65535 ， 整数集合需要分配四个元素的空间， 因为每个 int32_t 整数值需要占用 32 位空间， 所以在空间重分配之后， 底层数组的大小将是 32 * 4 = 128 位， 如图 6-5 所示。</p>
<p> <img src="/images/redis/struct1/%E7%A9%BA%E9%97%B4%E9%87%8D%E6%96%B0%E5%88%86%E9%85%8D%E5%90%8E%E7%9A%84%E6%95%B0%E7%BB%84.png" alt="空间重新分配后的数组"></p>
<p>虽然程序对底层数组进行了空间重分配， 但数组原有的三个元素 1 、 2 、 3 仍然是 int16_t 类型， 这些元素还保存在数组的前 48 位里面， 所以程序接下来要做的就是将这三个元素转换成 int32_t 类型， 并将转换后的元素放置到正确的位上面， 而且在放置元素的过程中， 需要维持底层数组的有序性质不变。</p>
<p>首先， 因为元素 3 在 1 、 2 、 3 、 65535 四个元素中排名第三， 所以它将被移动到 contents 数组的索引 2 位置上， 也即是数组 64 位至 95 位的空间内， 如图 6-6 所示。</p>
<p> <img src="/images/redis/struct1/%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E5%85%83%E7%B4%A03%E7%9A%84%E6%93%8D%E4%BD%9C.png" alt="类型转换元素3的操作"></p>
<p> 接着， 因为元素 2 在 1 、 2 、 3 、 65535 四个元素中排名第二， 所以它将被移动到 contents 数组的索引 1 位置上， 也即是数组的 32 位至 63 位的空间内， 如图 6-7 所示。</p>
<p> <img src="/images/redis/struct1/%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E5%85%83%E7%B4%A02%E7%9A%84%E6%93%8D%E4%BD%9C.png" alt="类型转换元素2的操作"></p>
<p> 然后， 因为元素 65535 在 1 、 2 、 3 、 65535 四个元素中排名第四， 所以它将被添加到 contents 数组的索引 3 位置上， 也即是数组的 96 位至 127 位的空间内， 如图 6-9 所示。<br> <img src="/images/redis/struct1/%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E6%96%B0%E6%B7%BB%E5%8A%A0%E5%85%83%E7%B4%A0%E7%9A%84%E6%93%8D%E4%BD%9C.png" alt="类型转换新添加元素的操作"></p>
<p> 最后， 程序将整数集合 encoding 属性的值从 INTSET_ENC_INT16 改为 INTSET_ENC_INT32 ， 并将 length 属性的值从 3 改为 4 ， 设置完成之后的整数集合如图 6-10 所示。</p>
<p> <img src="/images/redis/struct1/%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E5%90%8E%E7%9A%84%E5%AF%B9%E8%B1%A1.png" alt="类型转换后的对象"></p>
<h2 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h2><p>整数集合不支持降级操作， 一旦对数组进行了升级， 编码就会一直保持升级后的状态。</p>
<p>举个例子，即使我们将集合里唯一一个真正需要使用 int64_t 类型来保存的元素 4294967295 删除了， 整数集合的编码仍然会维持 INTSET_ENC_INT64 ， 底层数组也仍然会是 int64_t 类型的</p>
<h1 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h1><p>压缩列表（ziplist）是列表键和哈希键的底层实现之一。</p>
<p>当一个列表键只包含少量列表项， 并且每个列表项要么就是小整数值， 要么就是长度比较短的字符串， 那么 Redis 就会使用压缩列表来做列表键的底层实现。</p>
<h2 id="压缩列表的构成"><a href="#压缩列表的构成" class="headerlink" title="压缩列表的构成"></a>压缩列表的构成</h2><p>压缩列表是 Redis 为了节约内存而开发的， 由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。</p>
<p>一个压缩列表可以包含任意多个节点（entry）， 每个节点可以保存一个字节数组或者一个整数值。</p>
<p> <img src="/images/redis/struct1/%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8%E7%9A%84%E5%90%84%E4%B8%AA%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86.png" alt="压缩列表的各个组成部分"></p>
<p> <strong>lbytes</strong>    uint32_t    4 字节    记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配， 或者计算 zlend 的位置时使用。</p>
<p> <strong>zltail</strong>    uint32_t    4 字节    记录压缩列表表尾节点距离压缩列表的起始地址有多少字节： 通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址。</p>
<p> <strong>zllen</strong>    uint16_t    2 字节    记录了压缩列表包含的节点数量： 当这个属性的值小于 UINT16_MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量； 当这个值等于 UINT16_MAX 时， 节点的真实数量需要遍历整个压缩列表才能计算得出。</p>
<p> <strong>entryX</strong>    列表节点    不定    压缩列表包含的各个节点，节点的长度由节点保存的内容决定。</p>
<p> <strong>zlend</strong>    uint8_t    1 字节    特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。</p>
<p>三个节点的压缩列表</p>
<p> <img src="/images/redis/struct1/%E4%B8%89%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8.png" alt="三个节点的压缩列表"></p>
<p>列表 zlbytes 属性的值为 0x50 （十进制 80）， 表示压缩列表的总长为 80 字节。</p>
<p>列表 zltail 属性的值为 0x3c （十进制 60）， 这表示如果我们有一个指向压缩列表起始地址的指针 p ， 那么只要用指针 p 加上偏移量 60 ， 就可以计算出表尾节点 entry3 的地址。</p>
<p>列表 zllen 属性的值为 0x3 （十进制 3）， 表示压缩列表包含三个节点。</p>
<h2 id="压缩列表节点的构成"><a href="#压缩列表节点的构成" class="headerlink" title="压缩列表节点的构成"></a>压缩列表节点的构成</h2><ul>
<li>每个压缩列表节点可以保存一个字节数组或者一个整数值， </li>
</ul>
<p>其中， 字节数组可以是以下三种长度的其中一种：</p>
<ol>
<li><p>长度小于等于 63 （2^{6}-1）字节的字节数组； </p>
</li>
<li><p>长度小于等于 16383 （2^{14}-1） 字节的字节数组；</p>
</li>
<li><p>长度小于等于 4294967295 （2^{32}-1）字节的字节数组；</p>
</li>
</ol>
<p>而整数值则可以是以下六种长度的其中一种：</p>
<ol>
<li><p>4 位长，介于 0 至 12 之间的无符号整数；</p>
</li>
<li><p>1 字节长的有符号整数；</p>
</li>
<li><p>3 字节长的有符号整数；</p>
</li>
<li><p>int16_t 类型整数；</p>
</li>
<li><p>int32_t 类型整数；</p>
</li>
<li><p>int64_t 类型整数。</p>
</li>
</ol>
<p>每个压缩列表节点都由 previous_entry_length 、 encoding 、 content 三个部分组成， 如图 7-4 所示。</p>
<p> <img src="/images/redis/struct1/%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8%E8%8A%82%E7%82%B9%E7%9A%84%E5%90%84%E4%B8%AA%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86.png" alt="压缩列表节点的各个组成部分"></p>
<h3 id="previous-entry-length"><a href="#previous-entry-length" class="headerlink" title="previous_entry_length"></a>previous_entry_length</h3><p>节点的 previous_entry_length 属性以字节为单位， 记录了压缩列表中前一个节点的长度。</p>
<p>previous_entry_length 属性的长度可以是 1 字节或者 5 字节：</p>
<ol>
<li><p>如果前一节点的长度小于 254 字节， 那么 previous_entry_length 属性的长度为 1 字节： 前一节点的长度就保存在这一个字节里面。</p>
</li>
<li><p>如果前一节点的长度大于等于 254 字节， 那么 previous_entry_length 属性的长度为 5 字节： 其中属性的第一字节会被设置为 0xFE （十进制值 254）， 而之后的四个字节则用于保存前一节点的长度。</p>
</li>
</ol>
<p>图 7-5 展示了一个包含一字节长 previous_entry_length 属性的压缩列表节点， 属性的值为 0x05 ， 表示前一节点的长度为 5 字节。</p>
<p> <img src="/images/redis/struct1/%E5%89%8D%E4%B8%80%E8%8A%82%E7%82%B9%E7%9A%84%E9%95%BF%E5%BA%A6%E4%B8%BA1%E5%AD%97%E8%8A%82.png" alt="前一节点的长度为1字节"></p>
<p>图 7-6 展示了一个包含五字节长 previous_entry_length 属性的压缩节点， 属性的值为 0xFE00002766 ， 其中值的最高位字节 0xFE 表示这是一个五字节长的 previous_entry_length 属性， 而之后的四字节 0x00002766 （十进制值 10086 ）才是前一节点的实际长度。</p>
<p> <img src="/images/redis/struct1/%E5%89%8D%E4%B8%80%E8%8A%82%E7%82%B9%E7%9A%84%E9%95%BF%E5%BA%A6%E4%B8%BA5%E5%AD%97%E8%8A%82.png" alt="前一节点的长度为5字节"></p>
<p>因为节点的 previous_entry_length 属性记录了前一个节点的长度， 所以程序可以通过指针运算， 根据当前节点的起始地址来计算出前一个节点的起始地址。</p>
<p>举个例子， 如果我们有一个指向当前节点起始地址的指针 c ， 那么我们只要用指针 c 减去当前节点 previous_entry_length 属性的值， 就可以得出一个指向前一个节点起始地址的指针 p ， 如图 7-7 所示。<br><img src="/images/redis/struct1/%E8%AE%A1%E7%AE%97%E5%89%8D%E4%B8%80%E8%8A%82%E7%82%B9%E7%9A%84%E4%BD%8D%E7%BD%AE.png" alt="计算前一节点的位置"></p>
<h4 id="一个从表尾节点向表头节点进行遍历的完整过程"><a href="#一个从表尾节点向表头节点进行遍历的完整过程" class="headerlink" title="一个从表尾节点向表头节点进行遍历的完整过程"></a>一个从表尾节点向表头节点进行遍历的完整过程</h4><p>首先，我们拥有指向压缩列表表尾节点 entry4 起始地址的指针 p1 （指向表尾节点的指针可以通过指向压缩列表起始地址的指针加上 zltail 属性的值得出）；</p>
<p>通过用 p1 减去 entry4 节点 previous_entry_length 属性的值， 我们得到一个指向 entry4 前一节点 entry3 起始地址的指针 p2 ；</p>
<p>通过用 p2 减去 entry3 节点 previous_entry_length 属性的值， 我们得到一个指向 entry3 前一节点 entry2 起始地址的指针 p3 ；</p>
<p>通过用 p3 减去 entry2 节点 previous_entry_length 属性的值， 我们得到一个指向 entry2 前一节点 entry1 起始地址的指针 p4 ， entry1 为压缩列表的表头节点；</p>
<p>最终， 我们从表尾节点向表头节点遍历了整个列表。</p>
<p><img src="/images/redis/struct1/%E8%A1%A8%E5%B0%BE%E5%90%91%E8%A1%A8%E5%A4%B4%E9%81%8D%E5%8E%86%E7%9A%841.png" alt="表尾向表头遍历的1"></p>
<p><img src="/images/redis/struct1/%E8%A1%A8%E5%B0%BE%E5%90%91%E8%A1%A8%E5%A4%B4%E9%81%8D%E5%8E%86%E7%9A%842.png" alt="表尾向表头遍历的2"></p>
<p><img src="/images/redis/struct1/%E8%A1%A8%E5%B0%BE%E5%90%91%E8%A1%A8%E5%A4%B4%E9%81%8D%E5%8E%86%E7%9A%843.png" alt="表尾向表头遍历的3"></p>
<p><img src="/images/redis/struct1/%E8%A1%A8%E5%B0%BE%E5%90%91%E8%A1%A8%E5%A4%B4%E9%81%8D%E5%8E%86%E7%9A%844.png" alt="表尾向表头遍历的4"></p>
<h3 id="encoding"><a href="#encoding" class="headerlink" title="encoding"></a>encoding</h3><p>节点的 encoding 属性记录了节点的 content 属性所保存数据的类型以及长度：</p>
<p>一字节、两字节或者五字节长， 值的最高位为 00 、 01 或者 10 的是<strong>字节数组</strong>编码： 这种编码表示节点的 content 属性保存着字节数组， 数组的长度由编码除去最高两位之后的其他位记录；</p>
<p>一字节长， 值的最高位以 11 开头的是整数编码： 这种编码表示节点的 content 属性保存着<strong>整数值</strong>， 整数值的类型和长度由编码除去最高两位之后的其他位记录；</p>
<h3 id="content"><a href="#content" class="headerlink" title="content"></a>content</h3><p>节点的 content 属性负责保存节点的值， 节点值可以是一个字节数组或者整数， 值的类型和长度由节点的 encoding 属性决定</p>
<ul>
<li>图 7-9 展示了一个保存字节数组的节点示例：</li>
</ul>
<p><img src="/images/redis/struct1/%E4%BF%9D%E5%AD%98%E5%AD%97%E8%8A%82%E6%95%B0%E7%BB%84%E7%9A%84%E8%8A%82%E7%82%B9.png" alt="保存字节数组的节点"></p>
<p>编码的最高两位 00 表示节点保存的是一个字节数组；</p>
<p>编码的后六位 001011 记录了字节数组的长度 11 ；</p>
<p>content 属性保存着节点的值 “hello world” 。</p>
<ul>
<li>图 7-10 展示了一个保存整数值的节点示例：</li>
</ul>
<p><img src="/images/redis/struct1/%E4%BF%9D%E5%AD%98%E6%95%B4%E6%95%B0%E5%80%BC%E7%9A%84%E8%8A%82%E7%82%B9.png" alt="保存整数值的节点"></p>
<p>编码 11000000 表示节点保存的是一个 int16_t 类型的整数值；</p>
<p>content 属性保存着节点的值 10086 。</p>
<h3 id="连锁更新"><a href="#连锁更新" class="headerlink" title="连锁更新"></a>连锁更新</h3><p>添加新节点到压缩列表， 或者从压缩列表中删除节点， 可能会引发连锁更新操作， 但这种操作出现的几率并不高。</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis数据结构与对象</tag>
      </tags>
  </entry>
  <entry>
    <title>redis设计与实现-数据结构与对象3</title>
    <url>/2018-01-08/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A13/</url>
    <content><![CDATA[<ul>
<li><p>redis的数据对象</p>
<p>redis不是使用前面介绍的数据结构来实现键值对数据库,而是基于这些数据结构创建了一个对象系统.包括字符串对象.列表对象.hash对象,集合对象和有序集合对象.</p>
</li>
</ul>
<h1 id="对象的类型与编码"><a href="#对象的类型与编码" class="headerlink" title="对象的类型与编码"></a>对象的类型与编码</h1><p>Redis 使用对象来表示数据库中的键和值， 每次当我们在 Redis 的数据库中新创建一个键值对时， 我们至少会创建两个对象， 一个对象用作键值对的键<strong>（键对象）</strong>， 另一个对象用作键值对的值<strong>（值对象）</strong></p>
<p>Redis 中的每个对象都由一个 redisObject 结构表示， 该结构中和保存数据有关的三个属性分别是 type 属性、 encoding 属性和 ptr 属性：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct redisObject &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 类型</span><br><span class="line">    unsigned type:4;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 编码</span><br><span class="line">    unsigned encoding:4;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 指向底层实现数据结构的指针</span><br><span class="line">    void *ptr;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">&#125; robj;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h2><p>对象的 type 属性记录了对象的类型</p>
<table>
<thead>
<tr>
<th>类型常量</th>
<th>对象的名称</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>REDIS_STRING</td>
<td>字符串对象</td>
<td></td>
</tr>
<tr>
<td>REDIS_LIST</td>
<td>列表对象</td>
<td></td>
</tr>
<tr>
<td>REDIS_HASH</td>
<td>哈希对象</td>
<td></td>
</tr>
<tr>
<td>REDIS_SET</td>
<td>集合对象</td>
<td></td>
</tr>
<tr>
<td>REDIS_ZSET</td>
<td>有序集合对象</td>
<td></td>
</tr>
</tbody></table>
<p>Redis 数据库保存的键值对来说， <strong>键总是一个字符串对象</strong>， 而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种.</p>
<p>TYPE 命令的实现方式也与此类似， 当我们对一个数据库键执行 TYPE 命令时， 命令返回的结果为数据库键对应的值对象的类型</p>
<p>如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 键为字符串对象，值为字符串对象</span><br><span class="line"></span><br><span class="line">redis&gt; SET msg &quot;hello world&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; TYPE msg</span><br><span class="line">string</span><br><span class="line"></span><br><span class="line"># 键为字符串对象，值为列表对象</span><br><span class="line"></span><br><span class="line">redis&gt; RPUSH numbers 1 3 5</span><br><span class="line">(integer) 6</span><br><span class="line"></span><br><span class="line">redis&gt; TYPE numbers</span><br><span class="line">list</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="编码和底层实现"><a href="#编码和底层实现" class="headerlink" title="编码和底层实现"></a>编码和底层实现</h2><p>对象的 ptr 指针指向对象的底层实现数据结构， 而这些数据结构由对象的 encoding 属性决定。</p>
<ul>
<li>encoding 属性记录了对象所使用的编码如下所示:</li>
</ul>
<table>
<thead>
<tr>
<th>编码常量</th>
<th>编码所对应的底层数据结构</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>REDIS_ENCODING_INT</td>
<td>long 类型的整数</td>
<td></td>
</tr>
<tr>
<td>REDIS_ENCODING_EMBSTR</td>
<td>embstr 编码的简单动态字符串</td>
<td></td>
</tr>
<tr>
<td>REDIS_ENCODING_RAW</td>
<td>简单动态字符串</td>
<td></td>
</tr>
<tr>
<td>REDIS_SET</td>
<td>集合对象</td>
<td></td>
</tr>
<tr>
<td>REDIS_ENCODING_HT</td>
<td>字典</td>
<td></td>
</tr>
<tr>
<td>REDIS_ENCODING_LINKEDLIST</td>
<td>双端链表</td>
<td></td>
</tr>
<tr>
<td>REDIS_ENCODING_ZIPLIST</td>
<td>压缩列表</td>
<td></td>
</tr>
<tr>
<td>REDIS_ENCODING_INTSET</td>
<td>整数集合</td>
<td></td>
</tr>
<tr>
<td>REDIS_ENCODING_SKIPLIST</td>
<td>跳跃表和字典</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>每种类型的对象都至少使用了两种不同的编码， 表 8-4 列出了每种类型的对象可以使用的编码。</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>编码</th>
<th>对象</th>
</tr>
</thead>
<tbody><tr>
<td>REDIS_STRING</td>
<td>REDIS_ENCODING_INT</td>
<td>使用整数值实现的字符串对象。</td>
</tr>
<tr>
<td>REDIS_STRING</td>
<td>REDIS_ENCODING_EMBSTR</td>
<td>使用 embstr 编码的简单动态字符串实现的字符串对象。</td>
</tr>
<tr>
<td>REDIS_STRING</td>
<td>REDIS_ENCODING_RAW</td>
<td>使用简单动态字符串实现的字符串对象。</td>
</tr>
<tr>
<td>REDIS_LIST</td>
<td>REDIS_ENCODING_ZIPLIST</td>
<td>使用压缩列表实现的列表对象。</td>
</tr>
<tr>
<td>REDIS_LIST</td>
<td>REDIS_ENCODING_LINKEDLIST</td>
<td>使用双端链表实现的列表对象。</td>
</tr>
<tr>
<td>REDIS_HASH</td>
<td>REDIS_ENCODING_ZIPLIST</td>
<td>使用压缩列表实现的哈希对象。</td>
</tr>
<tr>
<td>REDIS_HASH</td>
<td>REDIS_ENCODING_HT</td>
<td>使用字典实现的哈希对象。</td>
</tr>
<tr>
<td>REDIS_SET</td>
<td>REDIS_ENCODING_INTSET</td>
<td>使用整数集合实现的集合对象。</td>
</tr>
<tr>
<td>REDIS_SET</td>
<td>REDIS_ENCODING_HT</td>
<td>使用字典实现的集合对象。</td>
</tr>
<tr>
<td>REDIS_ZSET</td>
<td>REDIS_ENCODING_ZIPLIST</td>
<td>使用压缩列表实现的有序集合对象。</td>
</tr>
<tr>
<td>REDIS_ZSET</td>
<td>REDIS_ENCODING_SKIPLIST</td>
<td>使用跳跃表和字典实现的有序集合对象。</td>
</tr>
</tbody></table>
<ul>
<li>使用 OBJECT ENCODING 命令可以查看一个数据库键的值对象的编码：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SET msg &quot;hello wrold&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING msg</span><br><span class="line">&quot;embstr&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; SET story &quot;long long long long long long ago ...&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING story</span><br><span class="line">&quot;raw&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="字符串对象"><a href="#字符串对象" class="headerlink" title="字符串对象"></a>字符串对象</h1><p>字符串对象的编码可以是 int 、 raw 或者 embstr 。</p>
<h2 id="int"><a href="#int" class="headerlink" title="int"></a>int</h2><p>如果一个字符串对象保存的是<strong>整数值</strong>， 并且这个整数值可以<strong>用 long 类型来表示</strong>， 那么字符串对象会将整数值保存在字符串对象结构的 ptr 属性里面*<em>（将 void</em> 转换成 long ）<strong>， 并将字符串对象的</strong>编码设置为 int** 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SET number 10086</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING number</span><br><span class="line">&quot;int&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/images/redis/struct2/int%E7%BC%96%E7%A0%81%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AF%B9%E8%B1%A1.png" alt="int编码的字符串对象"></p>
<h2 id="raw"><a href="#raw" class="headerlink" title="raw"></a>raw</h2><p>如果字符串对象保存的是一个<strong>字符串值</strong>， 并且这个字符串值的<strong>长度大于 39 字节</strong>， 那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值， 并将对象的编码设置为 raw 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SET story &quot;Long, long, long ago there lived a king ...&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; STRLEN story</span><br><span class="line">(integer) 43</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING story</span><br><span class="line">&quot;raw&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/images/redis/struct2/raw%E7%BC%96%E7%A0%81%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AF%B9%E8%B1%A1.png" alt="raw编码的字符串对象"></p>
<h2 id="embstr"><a href="#embstr" class="headerlink" title="embstr"></a>embstr</h2><p>如果字符串对象保存的是一个<strong>字符串值</strong>， 并且这个字符串值的长度<strong>小于等于 39 字节</strong>， 那么字符串对象将使用 embstr 编码的方式来保存这个字符串值。</p>
<ul>
<li>embstr和raw的区别:</li>
</ul>
<p>embstr 编码是专门用于保存短字符串的一种优化编码方式， 这种编码和 raw 编码一样， 都使用 redisObject 结构和 sdshdr 结构来表示字符串对象， 但 <strong>raw 编码会调用两次内存分配函数</strong>来分别创建 redisObject 结构和 sdshdr 结构， 而 embstr <strong>编码则通过调用一次内存分配函数来分配一块连续的空间</strong>， 空间中依次包含 redisObject 和 sdshdr 两个结构， 如图 8-3 所示。</p>
<p><img src="/images/redis/struct2/embstr%E7%BC%96%E7%A0%81%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AF%B9%E8%B1%A1.png" alt="embstr编码的字符串对象"></p>
<ul>
<li>embstr存储的好处</li>
</ul>
<ol>
<li>e**mbstr 编码将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次。</li>
<li>释放 embstr 编码的字符串对象只需要调用一次内存释放函数， 而释放 raw 编码的字符串对象需要调用两次内存释放函数。</li>
<li>因为 embstr 编码的字符串对象的所有数据都保存在一块连续的内存里面， 所以这种编码的字符串对象比起 raw 编码的字符串对象能够更好地利用缓存带来的优势。</li>
</ol>
<h2 id="编码的转换"><a href="#编码的转换" class="headerlink" title="编码的转换"></a>编码的转换</h2><p>int 编码的字符串对象和 embstr 编码的字符串对象在条件满足的情况下， 会被转换为 raw 编码的字符串对象。</p>
<ul>
<li>例子</li>
</ul>
<p>对于 int 编码的字符串对象来说， 如果我们向对象执行了一些命令， 使得这个对象保存的不再是整数值， 而是一个字符串值， 那么字符串对象的编码将从 int 变为 raw </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SET number 10086</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING number</span><br><span class="line">&quot;int&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; APPEND number &quot; is a good number!&quot;</span><br><span class="line">(integer) 23</span><br><span class="line"></span><br><span class="line">redis&gt; GET number</span><br><span class="line">&quot;10086 is a good number!&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING number</span><br><span class="line">&quot;raw&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p><em>注意</em></p>
<p>因为 Redis 没有为 embstr 编码的字符串对象编写任何相应的修改程序 （只有 int 编码的字符串对象和 raw 编码的字符串对象有这些程序）， <strong>所以 embstr 编码的字符串对象实际上是只读的</strong>： 当我们对 embstr 编码的字符串对象执行任何修改命令时， 程序会先将对象的编码从 embstr 转换成 raw ， 然后再执行修改命令； 因为这个原因， embstr 编码的字符串对象在执行修改命令之后， 总会变成一个 raw 编码的字符串对象。</p>
</li>
</ul>
<p><em>以下例子中执行append操作后,字符串的长度没有超过39,但由于embstr的只读特性.</em></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SET msg &quot;hello world&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING msg</span><br><span class="line">&quot;embstr&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; APPEND msg &quot; again!&quot;</span><br><span class="line">(integer) 18</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING msg</span><br><span class="line">&quot;raw&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="列表对象"><a href="#列表对象" class="headerlink" title="列表对象"></a>列表对象</h1><p>列表对象的编码可以是 ziplist 或者 linkedlist 。</p>
<h2 id="ziplist编码"><a href="#ziplist编码" class="headerlink" title="ziplist编码"></a>ziplist编码</h2><p>ziplist 编码的列表对象使用压缩列表作为底层实现， 每个压缩列表节点（entry）保存了一个列表元素。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; RPUSH numbers 1 &quot;three&quot; 5</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以上的numbers对象使用的是ziplist编码,则对象将会是如下的样子.</p>
<p><img src="/images/redis/struct2/ziplist%E7%BC%96%E7%A0%81%E7%9A%84list%E5%AF%B9%E8%B1%A1.png" alt="ziplist编码的list对象"></p>
<h2 id="linkedlist编码"><a href="#linkedlist编码" class="headerlink" title="linkedlist编码"></a>linkedlist编码</h2><p>linkedlist 编码的列表对象使用双端链表作为底层实现， 每个双端链表节点（node）都保存了一个字符串对象， 而每个字符串对象都保存了一个列表元素。</p>
<p>如果numbers对象使用的是linklist编码,则对象将会时如下的样子.</p>
<p><img src="/images/redis/struct2/linklist%E7%BC%96%E7%A0%81%E7%9A%84list%E5%AF%B9%E8%B1%A1.png" alt="linklist编码的list对象"></p>
<p>linkedlist 编码的列表对象在底层的双端链表结构中包含了多个字符串对象， 这种嵌套字符串对象的行为在稍后介绍的哈希对象、集合对象和有序集合对象中都会出现， 字符串对象是 Redis 五种类型的对象中唯一一种会被其他四种类型对象嵌套的对象。</p>
<p><img src="/images/redis/struct2/%E5%AE%8C%E6%95%B4%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AF%B9%E8%B1%A1%E8%A1%A8%E7%A4%BA.png" alt="完整的字符串对象表示"> </p>
<p>以上linklist中的字符串对象只是简单的表示.</p>
<h2 id="编码转化"><a href="#编码转化" class="headerlink" title="编码转化"></a>编码转化</h2><p>当列表对象可以同时满足以下两个条件时， 列表对象使用 ziplist 编码：</p>
<ol>
<li>列表对象保存的所有字符串元素的长度都小于 64 字节；</li>
<li>列表对象保存的元素数量小于 512 个；</li>
</ol>
<p>以下代码展示了列表对象因为保存了长度太大的元素而进行编码转换的情况：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 所有元素的长度都小于 64 字节</span><br><span class="line">redis&gt; RPUSH blah &quot;hello&quot; &quot;world&quot; &quot;again&quot;</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING blah</span><br><span class="line">&quot;ziplist&quot;</span><br><span class="line"></span><br><span class="line"># 将一个 65 字节长的元素推入列表对象中</span><br><span class="line">redis&gt; RPUSH blah &quot;wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww&quot;</span><br><span class="line">(integer) 4</span><br><span class="line"></span><br><span class="line"># 编码已改变</span><br><span class="line">redis&gt; OBJECT ENCODING blah</span><br><span class="line">&quot;linkedlist&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>除此之外， 以下代码展示了列表对象因为保存的元素数量过多而进行编码转换的情况：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 列表对象包含 512 个元素</span><br><span class="line">redis&gt; EVAL &quot;for i&#x3D;1,512 do redis.call(&#39;RPUSH&#39;, KEYS[1], i) end&quot; 1 &quot;integers&quot;</span><br><span class="line">(nil)</span><br><span class="line"></span><br><span class="line">redis&gt; LLEN integers</span><br><span class="line">(integer) 512</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING integers</span><br><span class="line">&quot;ziplist&quot;</span><br><span class="line"></span><br><span class="line"># 再向列表对象推入一个新元素，使得对象保存的元素数量达到 513 个</span><br><span class="line">redis&gt; RPUSH integers 513</span><br><span class="line">(integer) 513</span><br><span class="line"></span><br><span class="line"># 编码已改变</span><br><span class="line">redis&gt; OBJECT ENCODING integers</span><br><span class="line">&quot;linkedlist&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="哈希对象"><a href="#哈希对象" class="headerlink" title="哈希对象"></a>哈希对象</h1><p>哈希对象的编码可以是 ziplist 或者 hashtable 。</p>
<h2 id="ziplist编码-1"><a href="#ziplist编码-1" class="headerlink" title="ziplist编码"></a>ziplist编码</h2><p>ziplist 编码的哈希对象使用压缩列表作为底层实现， 每当有新的键值对要加入到哈希对象时， 程序会先将保存了键的压缩列表节点推入到压缩列表表尾， 然后再将保存了值的压缩列表节点推入到压缩列表表尾， 因此：</p>
<ol>
<li>保存了同一键值对的两个节点总是紧挨在一起， 保存键的节点在前， 保存值的节点在后；</li>
<li>先添加到哈希对象中的键值对会被放在压缩列表的表头方向， 而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; HSET profile name &quot;Tom&quot;</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line">redis&gt; HSET profile age 25</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line">redis&gt; HSET profile career &quot;Programmer&quot;</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以上代码如果编码是zipist,则如下表示:</p>
<p><img src="/images/redis/struct2/ziplist%E7%BC%96%E7%A0%81%E7%9A%84hash%E5%AF%B9%E8%B1%A1.png" alt="ziplist编码的hash对象"></p>
<p><img src="/images/redis/struct2/hash%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0.png" alt="hash对象的压缩列表的底层实现"></p>
<p>另一方面， hashtable 编码的哈希对象使用字典作为底层实现， 哈希对象中的每个键值对都使用一个字典键值对来保存：</p>
<ol>
<li>字典的每个键都是一个字符串对象， 对象中保存了键值对的键；</li>
<li>字典的每个值都是一个字符串对象， 对象中保存了键值对的值。</li>
</ol>
<p><img src="/images/redis/struct2/hashtable%E7%BC%96%E7%A0%81%E7%9A%84hash%E5%AF%B9%E8%B1%A1.png" alt="hashtable编码的hash对象"></p>
<h2 id="编码转换"><a href="#编码转换" class="headerlink" title="编码转换"></a>编码转换</h2><p>当哈希对象可以同时满足以下两个条件时， 哈希对象使用 ziplist 编码：</p>
<ol>
<li>哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节；</li>
<li>哈希对象保存的键值对数量小于 512 个；</li>
</ol>
<p>不能同时满足这两个条件的哈希对象需要使用 hashtable 编码。</p>
<p>以下代码展示了哈希对象因为键值对的键长度太大而引起编码转换的情况：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 哈希对象只包含一个键和值都不超过 64 个字节的键值对</span><br><span class="line">redis&gt; HSET book name &quot;Mastering C++ in 21 days&quot;</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING book</span><br><span class="line">&quot;ziplist&quot;</span><br><span class="line"></span><br><span class="line"># 向哈希对象添加一个新的键值对，键的长度为 66 字节</span><br><span class="line">redis&gt; HSET book long_long_long_long_long_long_long_long_long_long_long_description &quot;content&quot;</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"># 编码已改变</span><br><span class="line">redis&gt; OBJECT ENCODING book</span><br><span class="line">&quot;hashtable&quot;</span><br></pre></td></tr></table></figure>

<p>除了键的长度太大会引起编码转换之外， 值的长度太大也会引起编码转换， 以下代码展示了这种情况的一个示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 哈希对象只包含一个键和值都不超过 64 个字节的键值对</span><br><span class="line">redis&gt; HSET blah greeting &quot;hello world&quot;</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING blah</span><br><span class="line">&quot;ziplist&quot;</span><br><span class="line"></span><br><span class="line"># 向哈希对象添加一个新的键值对，值的长度为 68 字节</span><br><span class="line">redis&gt; HSET blah story &quot;many string ... many string ... many string ... many string ... many&quot;</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"># 编码已改变</span><br><span class="line">redis&gt; OBJECT ENCODING blah</span><br><span class="line">&quot;hashtable&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>最后， 以下代码展示了哈希对象因为包含的键值对数量过多而引起编码转换的情况：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建一个包含 512 个键值对的哈希对象</span><br><span class="line">redis&gt; EVAL &quot;for i&#x3D;1, 512 do redis.call(&#39;HSET&#39;, KEYS[1], i, i) end&quot; 1 &quot;numbers&quot;</span><br><span class="line">(nil)</span><br><span class="line"></span><br><span class="line">redis&gt; HLEN numbers</span><br><span class="line">(integer) 512</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING numbers</span><br><span class="line">&quot;ziplist&quot;</span><br><span class="line"></span><br><span class="line"># 再向哈希对象添加一个新的键值对，使得键值对的数量变成 513 个</span><br><span class="line">redis&gt; HMSET numbers &quot;key&quot; &quot;value&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; HLEN numbers</span><br><span class="line">(integer) 513</span><br><span class="line"></span><br><span class="line"># 编码改变</span><br><span class="line">redis&gt; OBJECT ENCODING numbers</span><br><span class="line">&quot;hashtable&quot;</span><br></pre></td></tr></table></figure>


<h1 id="集合对象"><a href="#集合对象" class="headerlink" title="集合对象"></a>集合对象</h1><p>集合对象的编码可以是 intset 或者 hashtable 。</p>
<h2 id="inset编码"><a href="#inset编码" class="headerlink" title="inset编码"></a>inset编码</h2><p>intset 编码的集合对象使用整数集合作为底层实现， 集合对象包含的所有元素都被保存在<strong>整数集合</strong>里面。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SADD numbers 1 3 5</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/images/redis/struct2/inset%E7%BC%96%E7%A0%81%E7%9A%84%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88%E5%AF%B9%E8%B1%A1.png" alt="inset编码的整数集合对象"></p>
<p> hashtable 编码的集合对象使用字典作为底层实现， 字典的每个键都是一个字符串对象， 每个字符串对象包含了一个集合元素， 而字典的值则全部被设置为 NULL 。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SADD fruits &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/images/redis/struct2/hashtable%E7%BC%96%E7%A0%81%E7%9A%84%E9%9B%86%E5%90%88%E5%AF%B9%E8%B1%A1.png" alt="hashtable编码的集合对象"></p>
<h2 id="编码的转换-1"><a href="#编码的转换-1" class="headerlink" title="编码的转换"></a>编码的转换</h2><p>当集合对象可以同时满足以下两个条件时， 对象使用 intset 编码：</p>
<ol>
<li>集合对象保存的所有元素都是整数值；</li>
<li>集合对象保存的元素数量不超过 512 个；</li>
</ol>
<p>不能满足这两个条件的集合对象需要使用 hashtable 编码。</p>
<p>举个例子， 以下代码创建了一个只包含整数元素的集合对象， 该对象的编码为 intset ：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SADD numbers 1 3 5</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING numbers</span><br><span class="line">&quot;intset&quot;</span><br><span class="line">不过， 只要我们向这个只包含整数元素的集合对象添加一个字符串元素， 集合对象的编码转移操作就会被执行：</span><br><span class="line"></span><br><span class="line">redis&gt; SADD numbers &quot;seven&quot;</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING numbers</span><br><span class="line">&quot;hashtable&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>除此之外， 如果我们创建一个包含 512 个整数元素的集合对象， 那么对象的编码应该会是 intset ：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; EVAL &quot;for i&#x3D;1, 512 do redis.call(&#39;SADD&#39;, KEYS[1], i) end&quot; 1 integers</span><br><span class="line">(nil)</span><br><span class="line"></span><br><span class="line">redis&gt; SCARD integers</span><br><span class="line">(integer) 512</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING integers</span><br><span class="line">&quot;intset&quot;</span><br></pre></td></tr></table></figure>

<p>但是， 只要我们再向集合添加一个新的整数元素， 使得这个集合的元素数量变成 513 ， 那么对象的编码转换操作就会被执行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SADD integers 10086</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line">redis&gt; SCARD integers</span><br><span class="line">(integer) 513</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING integers</span><br><span class="line">&quot;hashtable&quot;</span><br></pre></td></tr></table></figure>

<h1 id="有序集合对象"><a href="#有序集合对象" class="headerlink" title="有序集合对象"></a>有序集合对象</h1><p>有序集合的编码可以是 ziplist 或者 skiplist 。</p>
<h2 id="ziplist编码-2"><a href="#ziplist编码-2" class="headerlink" title="ziplist编码"></a>ziplist编码</h2><p>ziplist 编码的有序集合对象使用压缩列表作为底层实现， 每个集合元素使用两个紧挨在一起的压缩列表节点来保存， 第一个节点保存元素的成员（member）， 而第二个元素则保存元素的分值（score）。</p>
<p>压缩列表内的集合元素按分值从小到大进行排序， 分值较小的元素被放置在靠近表头的方向， 而分值较大的元素则被放置在靠近表尾的方向。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; ZADD price 8.5 apple 5.0 banana 6.0 cherry</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>ziplist编码</p>
<p><img src="/images/redis/struct2/hashtable%E7%BC%96%E7%A0%81%E7%9A%84%E9%9B%86%E5%90%88%E5%AF%B9%E8%B1%A1.png" alt="ziplist编码的有序集合对象"></p>
<p><img src="/images/redis/struct2/%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%E5%9C%A8%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0.png" alt="有序集合在压缩列表中的实现"></p>
<h2 id="skiplist"><a href="#skiplist" class="headerlink" title="skiplist"></a>skiplist</h2><p>skiplist 编码的有序集合对象使用 zset 结构作为底层实现， 一个 zset 结构同时包含一个字典和一个跳跃表：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct zset &#123;</span><br><span class="line"></span><br><span class="line">    zskiplist *zsl;</span><br><span class="line"></span><br><span class="line">    dict *dict;</span><br><span class="line"></span><br><span class="line">&#125; zset;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>zset 结构中的 zsl 跳跃表按分值从小到大保存了所有集合元素， 每个跳跃表节点都保存了一个集合元素： 跳跃表节点的 object 属性保存了元素的成员， 而跳跃表节点的 score 属性则保存了元素的分值。 通过这个跳跃表， <strong>程序可以对有序集合进行范围型操作</strong>， 比如 ZRANK 、 ZRANGE 等命令就是基于跳跃表 API 来实现的。</p>
<p>zset 结构中的 dict 字典为有序集合创建了一个从成员到分值的映射， 字典中的每个键值对都保存了一个集合元素： 字典的键保存了元素的成员， 而字典的值则保存了元素的分值。 通过这个字典， <strong>程序可以用 O(1) 复杂度查找给定成员的分值， ZSCORE 命令就是根据这一特性实现的</strong></p>
<p><strong>注意</strong></p>
<p>值得一提的是， 虽然 zset 结构同时使用跳跃表和字典来保存有序集合元素， 但这两种数据结构都会通过指针来共享相同元素的成员和分值</p>
<p><img src="/images/redis/struct2/skiplist%E7%BC%96%E7%A0%81%E7%9A%84%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88.png" alt="skiplist编码的有序集合"></p>
<p><img src="/images/redis/struct2/%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%E5%90%8C%E6%97%B6%E8%A2%AB%E4%BF%9D%E5%AD%98%E5%9C%A8%E5%AD%97%E5%85%B8%E5%92%8Cskiplist%E4%B8%AD.png" alt="有序集合同时被保存在字典和skiplist中"></p>
<h2 id="编码的转换-2"><a href="#编码的转换-2" class="headerlink" title="编码的转换"></a>编码的转换</h2><p>当有序集合对象可以同时满足以下两个条件时， 对象使用 ziplist 编码：</p>
<ol>
<li>有序集合保存的元素数量小于 128 个；</li>
<li>有序集合保存的所有元素成员的长度都小于 64 字节；</li>
</ol>
<p>不能满足以上两个条件的有序集合对象将使用 skiplist 编码。</p>
<p>以下代码展示了有序集合对象因为包含了过多元素而引发编码转换的情况：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 对象包含了 128 个元素</span><br><span class="line">redis&gt; EVAL &quot;for i&#x3D;1, 128 do redis.call(&#39;ZADD&#39;, KEYS[1], i, i) end&quot; 1 numbers</span><br><span class="line">(nil)</span><br><span class="line"></span><br><span class="line">redis&gt; ZCARD numbers</span><br><span class="line">(integer) 128</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING numbers</span><br><span class="line">&quot;ziplist&quot;</span><br><span class="line"></span><br><span class="line"># 再添加一个新元素</span><br><span class="line">redis&gt; ZADD numbers 3.14 pi</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"># 对象包含的元素数量变为 129 个</span><br><span class="line">redis&gt; ZCARD numbers</span><br><span class="line">(integer) 129</span><br><span class="line"></span><br><span class="line"># 编码已改变</span><br><span class="line">redis&gt; OBJECT ENCODING numbers</span><br><span class="line">&quot;skiplist&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以下代码则展示了有序集合对象因为元素的成员过长而引发编码转换的情况：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 向有序集合添加一个成员只有三字节长的元素</span><br><span class="line">redis&gt; ZADD blah 1.0 www</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT ENCODING blah</span><br><span class="line">&quot;ziplist&quot;</span><br><span class="line"></span><br><span class="line"># 向有序集合添加一个成员为 66 字节长的元素</span><br><span class="line">redis&gt; ZADD blah 2.0 oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"># 编码已改变</span><br><span class="line">redis&gt; OBJECT ENCODING blah</span><br><span class="line">&quot;skiplist&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="类型检查与命令多态"><a href="#类型检查与命令多态" class="headerlink" title="类型检查与命令多态"></a>类型检查与命令多态</h1><h2 id="命令的类型"><a href="#命令的类型" class="headerlink" title="命令的类型"></a>命令的类型</h2><p>一种命令可以对任何类型的键执行， 比如说 DEL 命令、 EXPIRE 命令、 RENAME 命令、 TYPE 命令、 OBJECT 命令， 等等。</p>
<p>另一种命令只能对特定类型的键执行</p>
<p>SET 、 GET 、 APPEND 、 STRLEN 等命令只能对字符串键执行；</p>
<p>HDEL 、 HSET 、 HGET 、 HLEN 等命令只能对哈希键执行；</p>
<p>RPUSH 、 LPOP 、 LINSERT 、 LLEN 等命令只能对列表键执行；</p>
<p>SADD 、 SPOP 、 SINTER 、 SCARD 等命令只能对集合键执行；</p>
<p>ZADD 、 ZCARD 、 ZRANK 、 ZSCORE 等命令只能对有序集合键执行；</p>
<h2 id="类型检查的实现"><a href="#类型检查的实现" class="headerlink" title="类型检查的实现"></a>类型检查的实现</h2><p><img src="/images/redis/struct2/%E7%B1%BB%E5%9E%8B%E6%A3%80%E6%9F%A5%E7%9A%84%E5%AE%9E%E7%8E%B0.png" alt="类型检查的实现"></p>
<h2 id="多态命令的实现"><a href="#多态命令的实现" class="headerlink" title="多态命令的实现"></a>多态命令的实现</h2><p>Redis 除了会根据值对象的类型来判断键是否能够执行指定命令之外， 还会根据值对象的编码方式， 选择正确的命令实现代码来执行命令。</p>
<p>例如对一个list对象的建执行llen命令</p>
<ol>
<li>如果列表对象的编码为 ziplist ， 那么说明列表对象的实现为压缩列表， 程序将使用 ziplistLen 函数来返回列表的长度；</li>
<li>如果列表对象的编码为 linkedlist ， 那么说明列表对象的实现为双端链表， 程序将使用 listLength 函数来返回双端链表的长度；</li>
</ol>
<p><img src="/images/redis/struct2/LLEN%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B.png" alt="LLEN命令执行过程"></p>
<h1 id="内存回收"><a href="#内存回收" class="headerlink" title="内存回收"></a>内存回收</h1><p>Redis 在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制， 通过这一机制， 程序可以通过跟踪对象的引用计数信息， 在适当的时候自动释放对象并进行内存回收。</p>
<p>每个对象的引用计数信息由 redisObject 结构的 refcount 属性记录：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct redisObject &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 引用计数</span><br><span class="line">    int refcount;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ...</span><br><span class="line"></span><br><span class="line">&#125; robj;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>对象的引用计数信息会随着对象的使用状态而不断变化：</p>
<ol>
<li>在创建一个新对象时， 引用计数的值会被初始化为 1 ；</li>
<li>当对象被一个新程序使用时， 它的引用计数值会被增一；</li>
<li>当对象不再被一个程序使用时， 它的引用计数值会被减一；</li>
<li>当对象的引用计数值变为 0 时， 对象所占用的内存会被释放。</li>
</ol>
<h1 id="对象共享"><a href="#对象共享" class="headerlink" title="对象共享"></a>对象共享</h1><p>除了用于实现引用计数内存回收机制之外， 对象的引用计数属性还带有对象共享的作用。</p>
<p>键A创建了一个保存整数值100的字符串对象.如果创建一个键B同样保存一个整数值100的字符串对象,则数据库键会执行以下操作</p>
<ol>
<li>将数据库键的值指针指向一个现有的值对象；</li>
<li>将被共享的值对象的引用计数增一。</li>
</ol>
<p><img src="/images/redis/struct2/%E8%A2%AB%E5%85%B1%E4%BA%AB%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AF%B9%E8%B1%A1.png" alt="被共享的字符串对象"></p>
<p>共享对象机制对于节约内存非常有帮助， 数据库中保存的相同值对象越多， 对象共享机制就能节约越多的内存。</p>
<p><strong>注意</strong></p>
<p>Redis 会在初始化服务器时， 创建一万个字符串对象， 这些对象包含了从 0 到 9999 的所有整数值， 当服务器需要用到值为 0 到 9999 的字符串对象时， 服务器就会使用这些共享对象， 而不是新创建对象。</p>
<p>举个例子， 如果我们创建一个值为 100 的键 A ， 并使用 OBJECT REFCOUNT 命令查看键 A 的值对象的引用计数， 我们会发现值对象的引用计数为 2 ：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SET A 100</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; OBJECT REFCOUNT A</span><br><span class="line">(integer) 2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>引用这个值对象的两个程序分别是持有这个值对象的服务器程序， 以及共享这个值对象的键 A ， 如图 8-22 所示。</p>
<p><img src="/images/redis/struct2/%E5%BC%95%E7%94%A8%E8%AE%A1%E6%95%B0%E4%B8%BA2%E7%9A%84%E5%85%B1%E4%BA%AB%E5%AF%B9%E8%B1%A1.png" alt="引用计数为2的共享对象"></p>
<h1 id="对象的空转时长"><a href="#对象的空转时长" class="headerlink" title="对象的空转时长"></a>对象的空转时长</h1><p>除了前面介绍过的 type 、 encoding 、 ptr 和 refcount 四个属性之外， redisObject 结构包含的最后一个属性为 lru 属性， 该属性记录了对象最后一次被命令程序访问的时间：</p>
<p>OBJECT IDLETIME 命令可以打印出给定键的空转时长， 这一空转时长就是通过将当前时间减去键的值对象的 lru 时间计算得出的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis&gt; SET msg &quot;hello world&quot;</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"># 等待一小段时间</span><br><span class="line">redis&gt; OBJECT IDLETIME msg</span><br><span class="line">(integer) 20</span><br><span class="line"></span><br><span class="line"># 等待一阵子</span><br><span class="line">redis&gt; OBJECT IDLETIME msg</span><br><span class="line">(integer) 180</span><br><span class="line"></span><br><span class="line"># 访问 msg 键的值</span><br><span class="line">redis&gt; GET msg</span><br><span class="line">&quot;hello world&quot;</span><br><span class="line"></span><br><span class="line"># 键处于活跃状态，空转时长为 0</span><br><span class="line">redis&gt; OBJECT IDLETIME msg</span><br><span class="line">(integer) 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>


























]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis,数据结构与对象</tag>
      </tags>
  </entry>
  <entry>
    <title>tomcat学习-结构和基本配置</title>
    <url>/2017-11-06/tomcat%E5%AD%A6%E4%B9%A0-%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<ul>
<li>Tomcat的安装目录结构</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin: 启动和关闭Tomcat脚本文件。</span><br><span class="line">conf: Tomcat服务器的各种配置文件，包括：server.xml、web.xml、catalina.policy等。</span><br><span class="line">lib: Tomcat服务器和所有web应用可以访问的jar包。</span><br><span class="line">logs: Tomcat的日志文件。</span><br><span class="line">webapps: Tomcat自带的两个web应用：admin和manager，用来管理Tomcat的Web服务。</span><br><span class="line">work: JSP经过Tomcat编译后生成的Servlet。</span><br><span class="line">temp: Tomcat运行时的临时文件。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>Tomcat常用配置文件</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server.xml：Tomcat中最重要的配置文件，定义了tomcat的体系结构，包括连接器端口、连接数、集群、虚拟目录、访问日志等的设置。</span><br><span class="line">context.xml：全局context的配置文件，包括JNDI等信息的配置。</span><br><span class="line">tocmat-users.xml：Tocmat管理员身份的配置文件，关键是设置管理员账号的密码。</span><br><span class="line">logging.properties：Tocmat日志配置文件，可以修改默认的Tocmat日志路径和名称。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>Tomcat JVM参数调整</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">根据系统物理内存大小合理设置下列五个参数catalina.sh&#x2F;catalina.bat</span><br><span class="line"></span><br><span class="line">-server </span><br><span class="line">-Xms512m </span><br><span class="line">-Xmx512m</span><br><span class="line">-XX:PermSize&#x3D;128m</span><br><span class="line">-XX:MaxPermSize&#x3D;128m</span><br><span class="line"></span><br><span class="line">   一般情况下，设置-Xms&#x3D;-Xmx、-XX:PermSize&#x3D;-XX:MaxPermSize，正式服务器必须设置以上参数，以尽可能压榨服务器性能。</span><br><span class="line">相关参数取值需要根据实际情况考虑，不要超过(物理内存-其他程序内存)的80%即可。</span><br><span class="line"></span><br><span class="line">没有特殊理由，尽量不要对上述五个参数外的其他JVM参数进行设置;</span><br><span class="line">无法保证各种操作系统平台的可移植性;</span><br><span class="line">过度干涉JVM内存管理会导致无法预料的后果;</span><br><span class="line">如果在Windows平台上将解压版的Tomcat安装为服务，可以通过修改批处理文件$CATALINA_HOME&#x2F;bin&#x2F;service.bat对JVM参数进行调整。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>Tomcat日志配置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Tomcat日志信息包括访问日志和运行日志。</span><br><span class="line"></span><br><span class="line">访问日志用于对用户访问系统的行为进行跟踪记录，主要记录用户访问的时间、对应的IP</span><br><span class="line">地址、访问的资料等信息。记录访问日志主要是基于对系统安全的考虑，对系统中一些重</span><br><span class="line">要、敏感信息的资料访问历史进行记录，便于对资源的访问历史进行追踪，对于敏感信息</span><br><span class="line">未经授权访问等进行事后追查有一定帮助。但记录访问日志会对服务器性能产生一定的影</span><br><span class="line">响，在生产系统中需要慎用。</span><br><span class="line"></span><br><span class="line">运行日志主要记录程序运行的一些信息，其中的异常错误信息可以为我们定位错误。</span><br><span class="line">从6.0版本开始，Tomcat的日志接口采用是对Apache Commons Logging日志接口进行独</span><br><span class="line">立封装，缺省配置下，该日志接口采用硬编码使用java.util.logging日志框架。</span><br><span class="line"></span><br><span class="line">由于Tomcat发布版本中独立封装的Apache Commons Logging接口并没有对接口完全实</span><br><span class="line">现，如果要选择不同的日志框架就需要将该日志接口替换为完全实现的版本。</span><br><span class="line"></span><br><span class="line">缺省配置下，Tomcat是不记录访问日志的，可以通过如下配置允许Tomcat记录访问日志：</span><br><span class="line"></span><br><span class="line">修改$CATALINA_HOME&#x2F;server.xml，在Host标签下，找到如下配置信息，去掉两端的注释</span><br><span class="line">就会启用访问日志记录功能：</span><br><span class="line"></span><br><span class="line">&lt;Valve className&#x3D;&quot;org.apache.catalina.valves.AccessLogValve&quot; directory&#x3D;&quot;logs&quot;</span><br><span class="line"></span><br><span class="line">prefix&#x3D;&quot;localhost_access_log.&quot; suffix&#x3D;&quot;.txt&quot; pattern&#x3D;&quot;common&quot; resolveHosts&#x3D;&quot;false&quot;&#x2F;&gt;</span><br><span class="line"></span><br><span class="line">通过对pattern项的修改，可以改变日志输出的内容。该项值可以为： common 与 combined，对应的日志输出内容如下所示：</span><br><span class="line"></span><br><span class="line">common: %h %l %u %t %r %s %b</span><br><span class="line"></span><br><span class="line">combined: %h %l %u %t %r %s %b %&#123;Referer&#125;i %&#123;User-Agent&#125;i</span><br><span class="line"></span><br><span class="line">pattern 也可以根据需要自由组合, 例如 pattern&#x3D;&quot;%h %l&quot;，对 于各 fields 字段的含义请参照Tomcat官方文档。</span><br><span class="line"></span><br><span class="line">在不同的环境下，需要设置不同的日志级别，在生产环境中，为了提高效率和稳定性，一般</span><br><span class="line">会将日志级别设置为相对较高的级别，而开发环境中为了跟踪程序流程，可以将日志级别</span><br><span class="line">调整为较低的级别。不同日志框架有不同的日志级别，常用的日志框架对应级别如下：</span><br><span class="line"></span><br><span class="line">Java.util.logging对应的日志级别由高到低分别为：</span><br><span class="line"></span><br><span class="line">severe &gt; warning &gt; info &gt; config &gt; fine &gt; finer &gt; finest</span><br><span class="line"></span><br><span class="line">org.apache.log4j对应的日志级别由高到低分别为：</span><br><span class="line"></span><br><span class="line">fatal &gt; error &gt; warn &gt; info &gt; debug &gt; trace</span><br><span class="line"></span><br><span class="line">在缺省配置下，Tomcat采用Java.util.logging日志框架，对应的配置文件</span><br><span class="line">为$CATALINA_HOME&#x2F; logging.properties，常用的日志级别设定方法如下：</span><br><span class="line"></span><br><span class="line">设置catalina日志的级别为：FINE</span><br><span class="line"></span><br><span class="line">1catalina.org.apache.juli.FileHandler.level &#x3D; FINE</span><br><span class="line"></span><br><span class="line">禁用catalina日志的输出：</span><br><span class="line"></span><br><span class="line">1catalina.org.apache.juli.FileHandler.level &#x3D; OFF</span><br><span class="line"></span><br><span class="line">设置catalina所有的日志消息均输出：</span><br><span class="line"></span><br><span class="line">1catalina.org.apache.juli.FileHandler.level &#x3D; ALL</span><br><span class="line"></span><br><span class="line">Log4j是目前应用最广的日志框架，可以使用Log4j替换Tomcat缺省采用的</span><br><span class="line">java.util.logging</span><br><span class="line">日志框架，步骤如下：</span><br><span class="line"></span><br><span class="line">创建log4j配置文件log4j.properties ，保存在$CATALINA_HOME&#x2F;lib 下。</span><br><span class="line"></span><br><span class="line">从Apache官网Log4J项目下载Log4J（1.2版本以后）。</span><br><span class="line"></span><br><span class="line">从Apache官网Tomcat项目下载tomcat-juli.jar和tomcat-juli-adapters.jar。</span><br><span class="line"></span><br><span class="line">复制log4j.jar、tomcat-juli-adapters.jar到$CATALINA_HOME&#x2F;lib下。</span><br><span class="line"></span><br><span class="line">用tomcat-juli.jar覆盖$CATALINA_HOME&#x2F;bin下的同名文件。</span><br><span class="line"></span><br><span class="line">删除Tomcat的缺省日志配置文件$CATALINA_HOME&#x2F;conf&#x2F; logging.properties，以避免生成一些冗余的空日志文件。</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ul>
<li>Tomcat URL编码格式设置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">缺省情况下，如果URL当中包含有非英文字符，需要通过在程序对URL进行转码处理，否</span><br><span class="line">则URL中的非英文字符无法保证正确解析。在无特殊要求的情况下，需要将URL编码设置为</span><br><span class="line">和项目统一的编码格式，目前公司大部分项目都统一采用UTF-8字符编码方式，示例如下：</span><br><span class="line"></span><br><span class="line">&lt;Connector port&#x3D;&quot;8087&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot; connectionTimeout&#x3D;&quot;20000&quot;</span><br><span class="line">redirectPort&#x3D;&quot;8443&quot; URIEncoding&#x3D;&quot;utf-8&quot; &#x2F;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>Tomcat 常见问题总结</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JVM内存溢出(OOM)，分为堆内存溢出和PermGen区内存溢出：</span><br><span class="line"></span><br><span class="line">java.lang.OutOfMemoryError: PermGen space</span><br><span class="line"></span><br><span class="line">PermGen space(Permanent Generation space)，是指内存的永久保存区域，主要用于存</span><br><span class="line">放Class和Meta信息的，Class在被Loader时就会被放到PermGen space中, 它和存放类实</span><br><span class="line">例(Instance)的Heap区域不同，GC(Garbage Collection)不会在主程序运行期对其进行清</span><br><span class="line">理，所以如果应用中有很多CLASS的话，就很可能出现PermGen space错误。如果加载的Class超过MaxPermSize，就会抛出该异常，可以通过调整MaxPermSize进行解决。</span><br><span class="line"></span><br><span class="line">java.lang.OutOfMemoryError: Java heap space</span><br><span class="line"></span><br><span class="line">JVM堆是指java程序运行过程中JVM可以调配使用的内存空间。JVM在启动的时候会自动</span><br><span class="line">设置Heap size的值，其初始空间(-Xms)是物理内存的1&#x2F;64，最大空间(-Xmx)是物理内存</span><br><span class="line">的1&#x2F;4。可以利用JVM提供的-Xmn -Xms -Xmx等选项可进行设置。Heap size 的大小是</span><br><span class="line">Young Generation 和Tenured Generaion 之和。在JVM中如果98％的时间是用于GC且</span><br><span class="line">可用的Heap size 不足2％的时候将抛出此异常信息。</span><br><span class="line"></span><br><span class="line">大量用户访问时浏览器没有响应</span><br><span class="line">并发线程数设置太小，调整$CATALINA&#x2F;conf&#x2F;server.xml中连接器对应的请求处理线程数。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>tomcat的并发介绍</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">对web应用开发者来说，我们很关心应用可同时处理的请求数，以及响应时间。</span><br><span class="line"></span><br><span class="line">对tomcat来说，每一个进来的请求(request)都需要一个线程，直到该请求结束。如果同时</span><br><span class="line">进来的请求多于当前可用的请求处理线程数，额外的线程就会被创建，直到到达配置的最大</span><br><span class="line">线程数(maxThreads属性值)。如果仍就同时接收到更多请求，这些来不及处理的请求就会</span><br><span class="line">在Connector创建的ServerSocket中堆积起来，直到到达最大的配置值(acceptCount属性</span><br><span class="line">值)。至此，任何再来的请求将会收到connection refused错误，直到有可用的资源来处理</span><br><span class="line">它们。</span><br><span class="line"></span><br><span class="line">这里我们关心的是tomcat能同时处理的请求数和请求响应时间，显然Connector元素</span><br><span class="line">的maxThreads和acceptCount属性对其有直接的影响。无论acceptCount值为多</span><br><span class="line">少，maxThreads直接决定了实际可同时处理的请求数。而不管maxThreads如何acceptCount</span><br><span class="line">则决定了有多少请求可等待处理。然而，不管是可立即处理请求还是需要放入等待区，都</span><br><span class="line">需要tomcat先接受该请求(即接受client的连接请求，建立socketchannel)，那么tomcat</span><br><span class="line">同时可建立的连接数(maxConnections属性值)也会影响可同时处理的请求数。</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li>tomcat并发配置１</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tomcat的http connector有三种：bio、nio、apr。从上面的属性描述中可以看出对于不同</span><br><span class="line">的connector实现，相同的属性可能会有不同的默认值和不同的处理策略，所以在调整配</span><br><span class="line">置前，要先弄清楚各种实现之间的不同，以及当前部署容器使用的是哪种connector。</span><br><span class="line">查阅Tomcat7 http connector 配置文档Connector Comparison部分便可获知各种connector实现间的差异。</span><br><span class="line">怎样才能知道容器使用的是何种connector实现？启动tomcat后，访问Server Status Page，看到如下信息即可知道使用的是何种connector：</span><br><span class="line"></span><br><span class="line">我的OS是windows，所以tomcat默认使用的是aprconnector。在linux上，默认使用的是bio connector。与nio相比，bio性能较低。将&lt;TOMCAT_HOME&gt;&#x2F;conf&#x2F;server.xml中的如下配置片段：</span><br><span class="line"></span><br><span class="line">&lt;Connectorport&#x3D;&quot;8080&quot;protocol&#x3D;&quot;HTTP&#x2F;1.1&quot;</span><br><span class="line">               connectionTimeout&#x3D;&quot;20000&quot;</span><br><span class="line">               redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt;</span><br><span class="line">修改为：</span><br><span class="line"></span><br><span class="line">&lt;Connectorport&#x3D;&quot;8080&quot;protocol&#x3D;&quot;org.apache.coyote.http11.Http11NioProtocol&quot;</span><br><span class="line">               connectionTimeout&#x3D;&quot;20000&quot;</span><br><span class="line">               redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt;</span><br><span class="line">就可将http connector切换至nio了。</span><br><span class="line"></span><br><span class="line">　tomcat的最大线程数设置：</span><br><span class="line"></span><br><span class="line">Tomcat的server.xml中连接器设置如下</span><br><span class="line"></span><br><span class="line">   &lt;Connectorport&#x3D;&quot;8080&quot;  maxThreads&#x3D;&quot;150&quot;minSpareThreads&#x3D;&quot;25&quot; maxSpareThreads&#x3D;&quot;75&quot;  enableLookups&#x3D;&quot;false&quot;redirectPort&#x3D;&quot;8443&quot; acceptCount&#x3D;&quot;100&quot;  debug&#x3D;&quot;0&quot;connectionTimeout&#x3D;&quot;20000&quot;  disableUploadTimeout&#x3D;&quot;true&quot;&#x2F;&gt; </span><br><span class="line"> tomcat在配置时设置最大线程数，当前线程数超过这个数值时会出错</span><br><span class="line"></span><br><span class="line">minProcessors：最小空闲连接线程数，用于提高系统处理性能，默认值为10</span><br><span class="line">maxProcessors：最大连接线程数，即：并发处理的最大请求数，默认值为75</span><br><span class="line">acceptCount：允许的最大连接数，应大于等于maxProcessors，默认值为100</span><br><span class="line">enableLookups：是否反查域名，取值为：true或false。为了提高处理能力，</span><br><span class="line">应设置为false  </span><br><span class="line">connectionTimeout：网络连接超时，单位：毫秒。设置为0表示永不超时，这样设置有隐患的。通常可设置为30000毫秒。</span><br><span class="line">其中和最大连接数相关的参数为maxProcessors和acceptCount。如果要加大并发连接数，应同时加大这两个参数。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>如何加大tomcat可以使用的内存</li>
</ul>
<p>tomcat默认可以使用的内存为128MB，在较大型的应用项目中，这点内存是不够的，需要调大。<br>Unix下，在文件{tomcat_home}/bin/catalina.sh的前面，增加如下设置：<br>JAVA_OPTS=’-Xms【初始化内存大小】 -Xmx【可以使用的最大内存】’<br>需要把这个两个参数值调大。例如：<br>JAVA_OPTS=’-Xms256m -Xmx512m’<br>表示初始化内存为256MB，可以使用的最大内存为512MB</p>
<ul>
<li>Tomcat中的并发配置２</li>
</ul>
<p><a href="http://tomcat.apache.org/tomcat-7.0-doc/config/http.html">官网关于线程数的配置</a></p>
<p><a href="http://www.365mini.com/page/tomcat-connector-mode.htm">修改Tomcat Connector运行模式</a></p>
<p>tomcat的线程配置有两种：可以在connector中配置，也可以配置executor。</p>
<p>连接器中的线程配置是私有的，连接器自己的配置只能自己使用；而线程池可以被共享，<br>多个连接器通过executor属性关联到连接池的name完成配置（见下图）；<br>一旦连接器中配置了一个存在的executor，那么线程池的配置将会覆盖连接器的线程配置。<br><img src="/images/tomcat/tomcat3.png" alt="连接器和线程池"></p>
<p>线程池覆盖连接器中的线程配置，主要是覆盖maxThreads和minSpareThreads两个参数，这两个参数在线程池标签和连接器标签中都存在。<br>    a. 对于线程池而言：最主要的配置项是maxThreads和minSpareThreads（参看3.1表格，官网全部配置项参看4.1链接），前者代表线程池中可以创建的最大线程数，后者代表当线程池空闲的时候保留的线程数量，当线程池覆盖连接器的线程配置的时候，最主要的是覆盖这两个参数，连接器如何关联线程池，参看上文截图。<br>    b. 对于连接器而言：线程相关的主要参数有四个——maxThreads、minSpareThreads、maxConnections、acceptCount，如果连接器关联了线程池，那么maxThreads和minSpareThreads会被覆盖（重要的事情反复说），acceptCount和maxConnections继续生效；<br>    maxThreads：一个请求分配一个线程处理，其实就是serversocket.accept之后，新建了一个线程去处理这个接受的socket，然后这个连接器可以建立的最大线程数量即为maxThreads配置的值，如果是多个连接器关联了同一个线程池，那么多个连接器允许建立的线程数量之和即为maxThreads的值；<br>    minSpareThreads：如果请求少或者没有请求，那么tomcat就会主动关闭一些不用的线程，但是至少会保留minSpareThreads配置的线程数；<br>    maxConnections：表示可以同时被当前连接器处理的请求数量，这个配置项需要和maxThreads进行对比，一个请求一旦被接受处理就会分配给一个线程，这时候能够同时处理多少个请求取决于maxConnections和maxThreads两个配置项中的较小者，如果连接器是BIO则maxConnections默认等于maxThreads（连接器的maxThreads，如果关联了线程池，则为线程池中的maxThreads），NIO2默认是10000，APR默认是8192（BIO/NIO/NIO2/APR主要是根据connector的protocol属性，这个属性可以配置小表中的类）；<br>    举个例子，连接器中maxThreads=200，maxConnections=100，这时候因为线程池最多只允许创建100个线程，因此能被同时处理的请求数量是100，取决于两者中的较小者；但是如果连接器关联了线程池maxThreads=200，连接器A的maxConnections=120，连接器B的maxConnections=100，这时候对于连接器A而言，处理请求的最大的线程数是120，不会超过120，但是能不能达到120还需要看线程池中的可用的线程数，如果这时候连接器B已经拿了100个线程，那么此时A只能拿到100个线程；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Java Blocking Connector BIO    Java Nio Connector NIO     Java Nio2 Connector NIO2    APRnative Connector</span><br><span class="line">APR</span><br><span class="line">Classname    Http11Protocol    Http11NioProtocol    Http11Nio2Protocol    Http11AprProtocol</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>acceptCount：相当于建立ServerSocket的时候构造函数中传入的backlog参数，表</code></pre>
<p>示serversocket中完成三次握手后（成功建立TCP连接）允许等待被accept的socket数量，<br>已经建立好了TCP连接，但是socket还没有被accept取出来处理；</p>
<ul>
<li><p>Tomcat结构<br>Tomcat是一个基于组件的服务器，它的构成组件都是可配置的，其中最外层的组件是Catalina Servlet容器，其他的组件按照一定的格式要求配置在这个顶层容器中。Tomcat的各个组件是在<TOMCAT_HOME>\conf\server.xml文件中配置的，Tomcat服务器默认情况下对各种组件都有默认的实现，下面通过分析server.xml文件来理解Tomcat的各个组件是如何组织的。server.xml文件的基本组成结构如下。</p>
<p><img src="/images/tomcat/tomcat1.jpg"></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">XML配置文件结构</span><br><span class="line">&lt;Server&gt;                     顶层类元素：一个配置文件中只能有一个&lt;Server&gt;元素，可包含多个Service。</span><br><span class="line">    &lt;Service&gt;                顶层类元素：本身不是容器，可包含一个Engine，多个Connector。</span><br><span class="line">        &lt;Connector&#x2F;&gt;         连接器类元素：代表通信接口。</span><br><span class="line">           &lt;Engine&gt;   容器类元素：为特定的Service组件处理所有客户请求，可包含多个Host。</span><br><span class="line">              &lt;Host&gt;    容器类元素：为特定的虚拟主机处理所有客户请求，可包含多个Context。</span><br><span class="line">                 &lt;Context&gt;   容器类元素：为特定的Web应用处理所有客户请求。</span><br><span class="line">                 &lt;&#x2F;Context&gt;</span><br><span class="line">               &lt;&#x2F;Host&gt;</span><br><span class="line">              &lt;&#x2F;Engine&gt;</span><br><span class="line">     &lt;&#x2F;Service&gt;</span><br><span class="line">&lt;&#x2F;Server&gt;</span><br><span class="line"></span><br><span class="line">1)Service</span><br><span class="line">Service组件是一些Connector组件的集合，它本身不是一个容器，所以在这里不能定义日志</span><br><span class="line">等组件。一个Service组件中只能有一个Engine组件，可以包含多个Connector组件。</span><br><span class="line"></span><br><span class="line">2)Connector组件</span><br><span class="line">Connector组件表示一个接口，通过这个接口接收客户的请求，然户发送给其他的容器组件，最后再把服务器的响应结果传递给客户。</span><br><span class="line"></span><br><span class="line">3) Engine, Host和context</span><br><span class="line">上面介绍的3个组件本身并不能处理客户请求，也不能生成响应。在Tomcat中只有3个组件是</span><br><span class="line">可以处理客户请求并生成响应的，这3个组件分别是 Engine、Host和Context组件。这3个组</span><br><span class="line">件分别代表了不同的服务范围，通过嵌套关系可以知道3个组件的范围有如下的关系：Engine&gt;Host&gt;Context。</span><br><span class="line">a.Engine组件下可以包含多个Host组件，它为特定的Service组件处理所有客户请求。</span><br><span class="line">b.一个Host组件代表一个虚拟主机，一个虚拟主机中可以包含多个Web应用（Context组件）。</span><br><span class="line">c.Context组件代表一个Web应用。</span><br><span class="line">Tomcat的各个组件关系，可以用下图描述。</span><br></pre></td></tr></table></figure>
<p> <img src="/images/tomcat/tomcat2.jpg"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2. Tomcat处理一个HTTP请求的过程</span><br><span class="line">假设来自客户的请求为： http:&#x2F;&#x2F;localhost:8080&#x2F;wsota&#x2F;wsota_index.jsp </span><br><span class="line">1) 请求被发送到本机端口8080，被在那里侦听的Coyote HTTP&#x2F;1.1 Connector获得 </span><br><span class="line">2) Connector把该请求交给它所在的Service的Engine来处理，并等待来自Engine的回应 </span><br><span class="line">3) Engine获得请求localhost&#x2F;wsota&#x2F;wsota_index.jsp，匹配它所拥有的所有虚拟主机Host </span><br><span class="line">4) Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机） </span><br><span class="line">5) localhost Host获得请求&#x2F;wsota&#x2F;wsota_index.jsp，匹配它所拥有的所有Context </span><br><span class="line">6) Host匹配到路径为&#x2F;wsota的Context（如果匹配不到就把该请求交给路径名为&quot;&quot;的Context去处理） </span><br><span class="line">7) path&#x3D;&quot;&#x2F;wsota&quot;的Context获得请求&#x2F;wsota_index.jsp，在它的mapping table中寻找对应的servlet </span><br><span class="line">8) Context匹配到URL PATTERN为*.jsp的servlet，对应于JspServlet类 </span><br><span class="line">9) 构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet或doPost方法 </span><br><span class="line">10)Context把执行完了之后的HttpServletResponse对象返回给Host </span><br><span class="line">11)Host把HttpServletResponse对象返回给Engine </span><br><span class="line">12)Engine把HttpServletResponse对象返回给Connector </span><br><span class="line">13)Connector把HttpServletResponse对象返回给客户browser</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="http://www.cnblogs.com/xzpp/archive/2012/06/15/2550473.html">tomcat的结构</a></p>
<p><a href="http://tomcat.apache.org/tomcat-8.0-doc/config/http.html">官网connector配置</a></p>
<p><a href="http://tomcat.apache.org/tomcat-8.0-doc/config/executor.html">官网executor配置</a></p>
<p><a href="http://www.cnblogs.com/doit8791/archive/2012/10/27/2742768.html">参考资料１</a></p>
<p><a href="http://www.cnblogs.com/softidea/p/5750791.html">参考资料２</a></p>
<p><a href="http://www.cnblogs.com/softidea/p/5750791.html">参考资料３</a></p>
<p><a href="https://blog.csdn.net/w1992wishes/article/details/79242797">tomcat源码解析</a></p>
]]></content>
      <categories>
        <category>web容器</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解java虚拟机-java内存区域和内存溢出异常</title>
    <url>/2018-09-29/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%92%8C%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>对于C和C++程序员，他们负责这每一个对象开始到结束的维护责任，需要为对象分配和释放内存。而java程序员在虚拟机自动内存管理机制的帮助下，不再需要为每一个对象写配对的delete/free代码，不容易出现内存泄露和内存溢出的问题，但是一旦你出现内存泄露和溢出的问题，不了解java虚拟机时不容易解决此类问题的。</p>
<h2 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h2><p><img src="/images/jvm/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA.png" alt="java虚拟机运行时数据区"></p>
<p>1.程序计数器</p>
<p>   程序计数器（Program Counter Register） 是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条执行字节码指令。</p>
<p>   每条线程都有一个独立的程序计数器。多线程是通过线程轮流切换并分配处理器执行的时间方式来实现的，为了线程切换后可以恢复到正确的执行位置，每条线程都需要一个独立的程序计数器。</p>
<p>   如果执行的是java方法，这个计数器记录的是正在执行的虚拟机字节码指令地址。如果是native方法，计数器为空。此内存区域是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。</p>
<p>2.Java虚拟机栈</p>
<p>   同样是线程私有，描述Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。一个方法对应一个栈帧。</p>
<p>   局部变量表存放了各种基本类型、对象引用和returnAddress类型（指向了一条字节码指令地址）。其中64位长度long 和 double占两个局部变量空间，其他只占一个。</p>
<p>   规定的异常情况有两种：1.线程请求的栈的深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；2.如果虚拟机可以动态扩展，如果扩展时无法申请到足够的内存，就抛出OutOfMemoryError异常。</p>
<p>3.本地方法栈</p>
<p>   和Java虚拟机栈很类似，不同的是本地方法栈为Native方法服务。</p>
<p>4.Java堆</p>
<p>   是Java虚拟机所管理的内存中最大的一块。由所有线程共享，在虚拟机启动时创建。堆区唯一目的就是存放对象实例。虚拟机规范中描述：所有的对象实例以及数组都在java堆中分配内存。</p>
<p>   堆中可细分为新生代和老年代，再细分可分为Eden空间、From Survivor空间、To Survivor空间。</p>
<p>   堆无法扩展时，抛出OutOfMemoryError异常</p>
<p>5.方法区</p>
<p>   所有线程共享，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。</p>
<p>   当方法区无法满足内存分配需求时，抛出OutOfMemoryError</p>
<p>6.运行时常量池</p>
<p>   它是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项是常量池（Const Pool Table），用于存放编译期生成的各种字面量和符号引用。并非预置入Class文件中常量池的内容才进入方法运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。</p>
<p>   当方法区无法满足内存分配需求时，抛出OutOfMemoryError</p>
<p>7.直接内存</p>
<p>   并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。</p>
<p>   JDK1.4加入了NIO，引入一种基于通道与缓冲区的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。因为避免了在Java堆和Native堆中来回复制数据，提高了性能。</p>
<p>   当各个内存区域总和大于物理内存限制，抛出OutOfMemoryError异常。</p>
<h2 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h2><p>创建对象（克隆/反序列化）通常仅仅是一个new关键字而已。虚拟机遇到一条new指令的时候，首先去检查这个指令的参数是否在常量池找那个定位到一个类的符号引用，并检查这个符号引用代表的类是否在内存中已经被加载、解析和初始化。</p>
<ul>
<li>分配内存的方式：</li>
</ul>
<ol>
<li><p>指针碰撞：假设java堆中的内存是绝对规整的，所有用过的内存放到一边，所有没有用过的内存放到另一边，中间放着一个指针作为分界点的指示器，那么内存分配仅仅是把那个指针向空闲内存那的那一边移动与对象大小相等的距离。</p>
</li>
<li><p>空闲列表：如果java堆中的内存并不是规整的，已使用的和未使用的是相互交错的，这样虚拟机必须维护一个记录表，记录哪些内存是可以使用的，在分配内存的时候从列表中找到一块足够打的空间划分给实例，并更新列表上的记录。</p>
</li>
</ol>
<p>而选择哪种方式是由java堆是否规整决定的，而java堆是否规整是由java的垃圾回收器决定的。使用serial、parNew等代用compact过程的收集器时，通常采用的是指针碰撞，而使用CMS这种使用MARK——Sweep算法的收集器时通常采用空闲列表的算法。</p>
<ul>
<li>内存分配的线程安全问题</li>
</ul>
<p>如果仅仅修改一个指针的指向分配内存，并发情况下的分配会出现问题，解决问题的方案：</p>
<ol>
<li>对分配内存空间的动作进行同步，实际上是采用CAS配上失败重试的方式保证更新操作的原子性；</li>
<li>另一种是把内存分配的动作按照线程规划在不同的空间中进行，内个线程在java杜仲预先分配一小块内存，称为本地线程分配缓冲(Thread Local Allocation Buffer TLAB),哪个线程需要分配内存就在其对应的TLAB上分配，只用TLAB用完需要分配新的TLAB的时候菜户同步锁定，虚拟机是否使用TLAB可以使用-XX:+UseTLAB参数来决定；</li>
</ol>
<ul>
<li><p>分配完之后，虚拟机需要将分配到内存空间都初始化为零值。</p>
</li>
<li><p>接下来虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例，如何才能找到对象的元数据信息，对象的hash码，对象的GC分代年龄等信息。</p>
</li>
</ul>
<h2 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h2><p>在HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头、实例数据、对齐填充。</p>
<h3 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h3><p>对象头包括2部分信息：</p>
<ol>
<li>第一部分存储对象自身的运行时数据，如hash码，GC分代年龄，锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等；</li>
<li>对象头的另一部分是类型指针，即对象指向它的类数据的指针，虚拟机通过这个指针能够确定对象属于哪个类的实例；</li>
</ol>
<h3 id="实例数据"><a href="#实例数据" class="headerlink" title="实例数据"></a>实例数据</h3><p>主要存储的是对象真正的有效信息，也就是在程序代码中定义的各种类型的字段内容，无论是从父类继承下来的，还是在子类中定义的都要记录下来。</p>
<h3 id="对齐填充"><a href="#对齐填充" class="headerlink" title="对齐填充"></a>对齐填充</h3><p>这部分不是必须存在的，也没有特别的含义。它仅仅起占位符的作用，对于HotSpot VM的自动内存管理系统要求对象必须是8字节的整数倍，而对象头的大小正好是8字节的整数倍，因此对象头不需要填充来补全。</p>
<h2 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h2><p>对象是通过栈上的reference数据来操作堆上的具体对象。目前主流的访问方式有句柄和直接指针两种。</p>
<h3 id="句柄访问方式"><a href="#句柄访问方式" class="headerlink" title="句柄访问方式"></a>句柄访问方式</h3><p>使用句柄访问的话，java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，句柄中保函了对象实例数据与类型数据各自的具体地址信息。</p>
<p><img src="/images/jvm/%E9%80%9A%E8%BF%87%E5%8F%A5%E6%9F%84%E8%AE%BF%E9%97%AE%E5%AF%B9%E8%B1%A1.jpeg" alt="通过句柄访问对象"></p>
<h3 id="通过指针访问"><a href="#通过指针访问" class="headerlink" title="通过指针访问"></a>通过指针访问</h3><p>如果通过指针访问，那么java堆对象的布局就必须考虑如何放置访问类型数据的相关信息。而reference中存储的直接就是对象地址。</p>
<p><img src="/images/jvm/%E9%80%9A%E8%BF%87%E6%8C%87%E9%92%88%E8%AE%BF%E9%97%AE%E5%AF%B9%E8%B1%A1.jpeg" alt="通过指针访问对象"></p>
<h3 id="对象访问方式的对比"><a href="#对象访问方式的对比" class="headerlink" title="对象访问方式的对比"></a>对象访问方式的对比</h3><p>使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾回收时移动对象是非常普遍的数据）时改变句柄中的实例数据指针，而reference并不会被改变，</p>
<p>使用直接指针访问的最大好处就是速度快，它节省了一次指针丁文的时间开销。</p>
<h2 id="实战OutOfMemoryError异常"><a href="#实战OutOfMemoryError异常" class="headerlink" title="实战OutOfMemoryError异常"></a>实战OutOfMemoryError异常</h2><p>虚拟机内存的其他几个运行区域都除了程序计数器都有发生异常OOM的可能。</p>
<p>java 堆用于存储对象实例，只要不断的创建，并且保证GC ROOTs到对象之间有可达路径来避免垃圾回收机制清楚这些对象，那么对象达到最大堆的容量限制后就会产生内存溢出异常。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio&#x3D;8 -XX:+HeapDumpOnOutOfMemoryError</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-10-23 9:20 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class StackOverFlowErrorDemo &#123;</span><br><span class="line"></span><br><span class="line">    static class OOMObject &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        List&lt;OOMObject&gt; list &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            list.add(new OOMObject());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;java -agentlib:jdwp&#x3D;transport&#x3D;dt_socket,address&#x3D;127.0.0.1:50373,suspend&#x3D;y,server&#x3D;n -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+HeapDumpOnOutOfMemoryError -javaagent:&#x2F;Users&#x2F;zhuningning&#x2F;Library&#x2F;Caches&#x2F;IntelliJIdea2017.3&#x2F;captureAgent&#x2F;debugger-agent.jar&#x3D;&#x2F;private&#x2F;var&#x2F;folders&#x2F;52&#x2F;sbvwq6v93ns69v8s34_drz9h0000gn&#x2F;T&#x2F;capture341.props -Dfile.encoding&#x3D;UTF-8 -classpath &quot;&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;charsets.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;deploy.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;cldrdata.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;dnsns.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;jaccess.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;jfxrt.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;localedata.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;nashorn.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;sunec.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;sunjce_provider.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;sunpkcs11.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;ext&#x2F;zipfs.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;javaws.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;jce.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;jfr.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;jfxswt.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;jsse.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;management-agent.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;plugin.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;resources.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;jre&#x2F;lib&#x2F;rt.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;lib&#x2F;ant-javafx.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;lib&#x2F;dt.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;lib&#x2F;javafx-mx.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;lib&#x2F;jconsole.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;lib&#x2F;packager.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;lib&#x2F;sa-jdi.jar:&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_161.jdk&#x2F;Contents&#x2F;Home&#x2F;lib&#x2F;tools.jar:&#x2F;Users&#x2F;zhuningning&#x2F;ideaWorkSpace&#x2F;javaBase&#x2F;target&#x2F;classes:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;dom4j&#x2F;dom4j&#x2F;2.0.0&#x2F;dom4j-2.0.0.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;jaxen&#x2F;jaxen&#x2F;1.1.6&#x2F;jaxen-1.1.6.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;junit&#x2F;junit&#x2F;4.12&#x2F;junit-4.12.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;hamcrest&#x2F;hamcrest-core&#x2F;1.3&#x2F;hamcrest-core-1.3.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;mongodb&#x2F;mongodb-driver-async&#x2F;3.2.2&#x2F;mongodb-driver-async-3.2.2.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;mongodb&#x2F;mongodb-driver-core&#x2F;3.2.2&#x2F;mongodb-driver-core-3.2.2.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;mongodb&#x2F;bson&#x2F;3.2.2&#x2F;bson-3.2.2.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-context&#x2F;4.3.5.RELEASE&#x2F;spring-context-4.3.5.RELEASE.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-aop&#x2F;4.3.5.RELEASE&#x2F;spring-aop-4.3.5.RELEASE.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-beans&#x2F;4.3.5.RELEASE&#x2F;spring-beans-4.3.5.RELEASE.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-core&#x2F;4.3.5.RELEASE&#x2F;spring-core-4.3.5.RELEASE.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;commons-logging&#x2F;commons-logging&#x2F;1.2&#x2F;commons-logging-1.2.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-expression&#x2F;4.3.5.RELEASE&#x2F;spring-expression-4.3.5.RELEASE.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;logging&#x2F;log4j&#x2F;log4j-api&#x2F;2.7&#x2F;log4j-api-2.7.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;logging&#x2F;log4j&#x2F;log4j-core&#x2F;2.7&#x2F;log4j-core-2.7.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;mysql&#x2F;mysql-connector-java&#x2F;5.1.40&#x2F;mysql-connector-java-5.1.40.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;cn&#x2F;afterturn&#x2F;easypoi-base&#x2F;3.0.3&#x2F;easypoi-base-3.0.3.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;poi&#x2F;poi&#x2F;3.15&#x2F;poi-3.15.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;commons-codec&#x2F;commons-codec&#x2F;1.10&#x2F;commons-codec-1.10.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;commons&#x2F;commons-collections4&#x2F;4.1&#x2F;commons-collections4-4.1.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;poi&#x2F;poi-ooxml&#x2F;3.15&#x2F;poi-ooxml-3.15.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;com&#x2F;github&#x2F;virtuald&#x2F;curvesapi&#x2F;1.04&#x2F;curvesapi-1.04.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;poi&#x2F;poi-ooxml-schemas&#x2F;3.15&#x2F;poi-ooxml-schemas-3.15.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;xmlbeans&#x2F;xmlbeans&#x2F;2.6.0&#x2F;xmlbeans-2.6.0.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;stax&#x2F;stax-api&#x2F;1.0.1&#x2F;stax-api-1.0.1.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;com&#x2F;google&#x2F;guava&#x2F;guava&#x2F;16.0.1&#x2F;guava-16.0.1.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;commons&#x2F;commons-lang3&#x2F;3.2.1&#x2F;commons-lang3-3.2.1.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;slf4j&#x2F;slf4j-api&#x2F;1.6.1&#x2F;slf4j-api-1.6.1.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;validation&#x2F;validation-api&#x2F;1.1.0.Final&#x2F;validation-api-1.1.0.Final.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;cn&#x2F;afterturn&#x2F;easypoi-web&#x2F;3.0.3&#x2F;easypoi-web-3.0.3.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-web&#x2F;3.1.1.RELEASE&#x2F;spring-web-3.1.1.RELEASE.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;aopalliance&#x2F;aopalliance&#x2F;1.0&#x2F;aopalliance-1.0.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-webmvc&#x2F;3.1.1.RELEASE&#x2F;spring-webmvc-3.1.1.RELEASE.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-asm&#x2F;3.1.1.RELEASE&#x2F;spring-asm-3.1.1.RELEASE.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-context-support&#x2F;3.1.1.RELEASE&#x2F;spring-context-support-3.1.1.RELEASE.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;cn&#x2F;afterturn&#x2F;easypoi-annotation&#x2F;3.0.3&#x2F;easypoi-annotation-3.0.3.jar:&#x2F;Users&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;servlet&#x2F;javax.servlet-api&#x2F;3.1.0&#x2F;javax.servlet-api-3.1.0.jar:&#x2F;Applications&#x2F;IntelliJ IDEA.app&#x2F;Contents&#x2F;lib&#x2F;idea_rt.jar&quot; com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo</span><br><span class="line">Connected to the target VM, address: &#39;127.0.0.1:50373&#39;, transport: &#39;socket&#39;</span><br><span class="line">[GC (Allocation Failure)  7699K-&gt;3961K(19456K), 0.0045637 secs]</span><br><span class="line">[GC (Allocation Failure)  12153K-&gt;9254K(19456K), 0.0079381 secs]</span><br><span class="line">[Full GC (Ergonomics)  9254K-&gt;9133K(19456K), 0.1111956 secs]</span><br><span class="line">[Full GC (Ergonomics)  17325K-&gt;14883K(19456K), 0.1398179 secs]</span><br><span class="line">[Full GC (Ergonomics)  16577K-&gt;16432K(19456K), 0.1255392 secs]</span><br><span class="line">[Full GC (Allocation Failure)  16432K-&gt;16415K(19456K), 0.1088586 secs]</span><br><span class="line">java.lang.OutOfMemoryError: Java heap space</span><br><span class="line">Dumping heap to java_pid731.hprof ...</span><br><span class="line">Heap dump file created [28119578 bytes in 0.146 secs]</span><br><span class="line">Exception in thread &quot;main&quot; Disconnected from the target VM, address: &#39;127.0.0.1:50373&#39;, transport: &#39;socket&#39;</span><br><span class="line">java.lang.OutOfMemoryError: Java heap space</span><br><span class="line">    at java.util.Arrays.copyOf(Arrays.java:3210)</span><br><span class="line">    at java.util.Arrays.copyOf(Arrays.java:3181)</span><br><span class="line">    at java.util.ArrayList.grow(ArrayList.java:265)</span><br><span class="line">    at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:239)</span><br><span class="line">    at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:231)</span><br><span class="line">    at java.util.ArrayList.add(ArrayList.java:462)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.main(StackOverFlowErrorDemo.java:21)</span><br><span class="line"></span><br><span class="line">Process finished with exit code 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>异常堆栈信息 java.lang.OutOfMemoryError 紧接着回提示 java heap space</p>
<p>一般是用内存分析工具检查是否是内存泄漏，如果是内存泄漏则可以查看泄漏对到GC roots的因用力按，于是就找到了泄漏对象是通过怎样的路径与roots相关联的导致垃圾收集器无法自动回收他们；</p>
<p>如果不是内存泄漏（内存中的对象确实都还必须存活的），那就要检查虚拟机的堆参数，与机器物理内存对比看是否可以调大，从代码上检查是否在某些对象生命周期过长，持有有状态时间过长的情况，尝试减少程序运行的内存消耗。</p>
<h2 id="虚拟机栈和本地方法栈溢出"><a href="#虚拟机栈和本地方法栈溢出" class="headerlink" title="虚拟机栈和本地方法栈溢出"></a>虚拟机栈和本地方法栈溢出</h2><p>使用 -Xss参数设置栈容量</p>
<p>如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常；如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.chen.api.util.jvm.chapter2;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 虚拟机栈和本地方法栈内存溢出测试</span><br><span class="line"> *</span><br><span class="line"> * -verbose:gc -Xms20M -Xmx20M -Xmn10M -Xss300k</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-10-23 10:00 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class StackOverFlowErrorDemo &#123;</span><br><span class="line"></span><br><span class="line">    private int stackLength &#x3D; 1;</span><br><span class="line"></span><br><span class="line">    public void stackLeak() &#123;</span><br><span class="line">        stackLength++;</span><br><span class="line">        stackLeak();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Throwable &#123;</span><br><span class="line">        StackOverFlowErrorDemo oom &#x3D; new StackOverFlowErrorDemo();</span><br><span class="line">        try &#123;</span><br><span class="line">            oom.stackLeak();</span><br><span class="line">        &#125; catch (Throwable e) &#123;</span><br><span class="line">            System.out.println(&quot;stack length:&quot; + oom.stackLength);</span><br><span class="line">            throw e;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stack length:2788</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.StackOverflowError</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.stackLeak(StackOverFlowErrorDemo.java:15)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.stackLeak(StackOverFlowErrorDemo.java:15)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.stackLeak(StackOverFlowErrorDemo.java:15)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.stackLeak(StackOverFlowErrorDemo.java:15)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.stackLeak(StackOverFlowErrorDemo.java:15)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.stackLeak(StackOverFlowErrorDemo.java:15)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.stackLeak(StackOverFlowErrorDemo.java:15)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.stackLeak(StackOverFlowErrorDemo.java:15)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.StackOverFlowErrorDemo.stackLeak(StackOverFlowErrorDemo.java:15)</span><br></pre></td></tr></table></figure>

<p>可以看出抛出栈内存溢出的异常，在单个线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的都是StackOverflowError异常。</p>
<p>如果是建立过多线程导致内存溢出，在不能减少线程数或者更换64位虚拟机的情况下，就只能通过减少最大堆和减少栈容量来换取更多的线程。</p>
<h3 id="创建线程导致内存溢出"><a href="#创建线程导致内存溢出" class="headerlink" title="创建线程导致内存溢出"></a>创建线程导致内存溢出</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 创建线程导致内存溢出异常</span><br><span class="line"> * 需要将线程栈设置的大些  -Xss2M</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-10-23 10:22 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class OutOfMemoryErrorForEachDemo &#123;</span><br><span class="line"></span><br><span class="line">    int i &#x3D;0;</span><br><span class="line"></span><br><span class="line">    private void dontStop()&#123;</span><br><span class="line">        while (true)&#123;</span><br><span class="line">            i++;</span><br><span class="line">            System.out.println(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void stackLeakByThread()&#123;</span><br><span class="line">        while (true)&#123;</span><br><span class="line">            Thread thread &#x3D;new Thread(new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    dontStop();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        OutOfMemoryErrorForEachDemo oom &#x3D; new OutOfMemoryErrorForEachDemo();</span><br><span class="line">        oom.stackLeakByThread();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">1745594</span><br><span class="line">1745595</span><br><span class="line">1745596</span><br><span class="line">1745597</span><br><span class="line">Oct 23, 2018 10:30:55 AM sun.rmi.transport.tcp.TCPTransport$AcceptLoop executeAcceptLoop</span><br><span class="line">WARNING: RMI TCP Accept-0: accept loop for ServerSocket[addr&#x3D;0.0.0.0&#x2F;0.0.0.0,localport&#x3D;51751] throws</span><br><span class="line">java.lang.OutOfMemoryError: unable to create new native thread</span><br><span class="line">    at java.lang.Thread.start0(Native Method)</span><br><span class="line">    at java.lang.Thread.start(Thread.java:717)</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957)</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1378)</span><br><span class="line">    at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:415)</span><br><span class="line">    at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:372)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:748)</span><br><span class="line"></span><br><span class="line">1745598</span><br></pre></td></tr></table></figure>

<h2 id="方法区和运行时常量池溢出"><a href="#方法区和运行时常量池溢出" class="headerlink" title="方法区和运行时常量池溢出"></a>方法区和运行时常量池溢出</h2><p>由于运行时常量池是方法区的一部分，所以放在一起测试进行。</p>
<h3 id="运行时常量池内存溢出"><a href="#运行时常量池内存溢出" class="headerlink" title="运行时常量池内存溢出"></a>运行时常量池内存溢出</h3><p>String.intern（）方法是一个native方法，它的作用是:如果字符串常量池中已经包含一个等于String对象的字符串，则返回代表池中的字符串的String对象；否则将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * -verbose:gc -Xms20M -Xmx20M -Xmn10M -Xss2M -XX:PermSize&#x3D;10M -XX:MaxPermSize&#x3D;10M</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-10-23 11:09 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class DistantsPoolMemoryStackOverflowDemo &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        &#x2F;&#x2F;使用list保持常量池引用，避免full GC回收常量池行为</span><br><span class="line">        List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">        int i &#x3D; 0;</span><br><span class="line">        for (; ; ) &#123;</span><br><span class="line">            list.add(String.valueOf(i++).intern());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>java.lang.OutOfMemoryError: GC overhead limit exceeded 这种情况发生的原因是, 程序基本上耗尽了所有的可用内存, GC也清理不了</p>
<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Full GC (Ergonomics)  18393K-&gt;18393K(19456K), 0.0671862 secs]</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded</span><br><span class="line">[Full GC (Ergonomics)  18410K-&gt;602K(19456K), 0.0118358 secs]</span><br><span class="line">    at java.lang.Integer.toString(Integer.java:401)</span><br><span class="line">    at java.lang.String.valueOf(String.java:3099)</span><br><span class="line">    at com.chen.api.util.jvm.chapter2.DistantsPoolMemoryStackOverflowDemo.main(DistantsPoolMemoryStackOverflowDemo.java:18)</span><br><span class="line">Disconnected from the target VM, address: &#39;127.0.0.1:52849&#39;, transport: &#39;socket&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="方法区内存溢出"><a href="#方法区内存溢出" class="headerlink" title="方法区内存溢出"></a>方法区内存溢出</h3><p>方法区用于存储class的相关信息，如类名、访问修饰符、常量池、字段描述等。</p>
<p>当前很多主流的框架如spring，在对类进行增强时都使用到CGLib这类字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的class加入到内存。</p>
<p>方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">E:\workSoftware\jdk\jdk1.7.0_80\bin\java -agentlib:jdwp&#x3D;transport&#x3D;dt_socket,address&#x3D;127.0.0.1:62719,suspend&#x3D;y,server&#x3D;n -verbose:gc -Xms20M -Xmx20M -Xmn10M -Xss2M -XX:PermSize&#x3D;10M -XX:MaxPermSize&#x3D;10M -Dfile.encoding&#x3D;UTF-8 -classpath E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\charsets.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\deploy.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\ext\access-bridge-64.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\ext\dnsns.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\ext\jaccess.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\ext\localedata.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\ext\sunec.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\ext\sunjce_provider.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\ext\sunmscapi.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\ext\zipfs.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\javaws.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\jce.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\jfr.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\jfxrt.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\jsse.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\management-agent.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\plugin.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\resources.jar;E:\workSoftware\jdk\jdk1.7.0_80\jre\lib\rt.jar;F:\ideaWorkSpace\JVMTest\target\classes;E:\workSoftware\maven\maven-repository\org\springframework\spring-context\4.3.5.RELEASE\spring-context-4.3.5.RELEASE.jar;E:\workSoftware\maven\maven-repository\org\springframework\spring-aop\4.3.5.RELEASE\spring-aop-4.3.5.RELEASE.jar;E:\workSoftware\maven\maven-repository\org\springframework\spring-beans\4.3.5.RELEASE\spring-beans-4.3.5.RELEASE.jar;E:\workSoftware\maven\maven-repository\org\springframework\spring-core\4.3.5.RELEASE\spring-core-4.3.5.RELEASE.jar;E:\workSoftware\maven\maven-repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;E:\workSoftware\maven\maven-repository\org\springframework\spring-expression\4.3.5.RELEASE\spring-expression-4.3.5.RELEASE.jar;E:\workSoftware\idea\lib\idea_rt.jar com.sunlands.test.CGLibStackOverflowError</span><br><span class="line">Connected to the target VM, address: &#39;127.0.0.1:62719&#39;, transport: &#39;socket&#39;</span><br><span class="line">[GC 8192K-&gt;1427K(19456K), 0.0024569 secs]</span><br><span class="line">[GC 9619K-&gt;1437K(19456K), 0.0010156 secs]</span><br><span class="line">[GC 9629K-&gt;1493K(19456K), 0.0010742 secs]</span><br><span class="line">[GC 9685K-&gt;1669K(19456K), 0.0021826 secs]</span><br><span class="line">[GC 9861K-&gt;1813K(19456K), 0.0011027 secs]</span><br><span class="line">[GC 10005K-&gt;2029K(18432K), 0.0013455 secs]</span><br><span class="line">[GC 9197K-&gt;2245K(18944K), 0.0012436 secs]</span><br><span class="line">[GC 9413K-&gt;2413K(18944K), 0.0012815 secs]</span><br><span class="line">[GC 9581K-&gt;2477K(17920K), 0.0009801 secs]</span><br><span class="line">[GC 9645K-&gt;2621K(18432K), 0.0009705 secs]</span><br><span class="line">[GC 8765K-&gt;2757K(18432K), 0.0007623 secs]</span><br><span class="line">[GC 8901K-&gt;2809K(18432K), 0.0004651 secs]</span><br><span class="line">[GC 8953K-&gt;2945K(18432K), 0.0005616 secs]</span><br><span class="line">[GC 9089K-&gt;3069K(18432K), 0.0004116 secs]</span><br><span class="line">[GC 9213K-&gt;3181K(18432K), 0.0005763 secs]</span><br><span class="line">[GC 9325K-&gt;3245K(18432K), 0.0128357 secs]</span><br><span class="line">[GC 9389K-&gt;3341K(18432K), 0.0029091 secs]</span><br><span class="line">[GC 9485K-&gt;3509K(18432K), 0.0004798 secs]</span><br><span class="line">[GC 9653K-&gt;3549K(18432K), 0.0004426 secs]</span><br><span class="line">[GC 9693K-&gt;3690K(18944K), 0.0005880 secs]</span><br><span class="line">[GC 10858K-&gt;3786K(18944K), 0.0005387 secs]</span><br><span class="line">[GC 10954K-&gt;3898K(18944K), 0.0005562 secs]</span><br><span class="line">[GC 11066K-&gt;4010K(18944K), 0.0006051 secs]</span><br><span class="line">[GC 11178K-&gt;4154K(18944K), 0.0005066 secs]</span><br><span class="line">[GC 11322K-&gt;4234K(18944K), 0.0004826 secs]</span><br><span class="line">[GC 11402K-&gt;4298K(18944K), 0.0008164 secs]</span><br><span class="line">[GC 6751K-&gt;4346K(18944K), 0.0005177 secs]</span><br><span class="line">[Full GC 4346K-&gt;3505K(18944K), 0.0425954 secs]</span><br><span class="line">[GC 3505K-&gt;3505K(18944K), 0.0003107 secs]</span><br><span class="line">[Full GC 3505K-&gt;3505K(18944K), 0.0105272 secs]</span><br><span class="line">[GC 3505K-&gt;3505K(18944K), 0.0003374 secs]</span><br><span class="line">[Full GC 3505K-&gt;1687K(18944K), 0.0204737 secs]</span><br><span class="line">[GC 1687K-&gt;1687K(19456K), 0.0003900 secs]</span><br><span class="line">[Full GC 1687K-&gt;1686K(19456K), 0.0088587 secs]</span><br><span class="line">[GC 1851K-&gt;1750K(19456K), 0.0003633 secs]</span><br><span class="line">[Full GCException in thread &quot;main&quot;  1750K-&gt;1682K(19456K), 0.0109055 secs]</span><br><span class="line">[GC 1682K-&gt;1682K(19456K), 0.0002975 secs]</span><br><span class="line">[Full GC 1682K-&gt;1682K(19456K), 0.0092689 secs]</span><br><span class="line">[GC 1846K-&gt;1778K(19456K), 0.0003080 secs]</span><br><span class="line">[Full GC 1778K-&gt;1650K(19456K), 0.0214303 secs]</span><br><span class="line">[GC 1650K-&gt;1650K(19456K), 0.0002951 secs]</span><br><span class="line">[Full GC 1650K-&gt;1650K(19456K), 0.0097328 secs]</span><br><span class="line">[GC 1650K-&gt;1650K(19456K), 0.0002996 secs]</span><br><span class="line">[Full GC 1650K-&gt;1650K(19456K), 0.0082941 secs]</span><br><span class="line">[GC 1650K-&gt;1650K(19456K), 0.0003107 secs]</span><br><span class="line">[Full GCDisconnected from the target VM, address: &#39;127.0.0.1:62719&#39;, transport: &#39;socket&#39;</span><br><span class="line"></span><br><span class="line">Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread &quot;main&quot;</span><br><span class="line"> 1650K-&gt;1650K(19456K), 0.0098416 secs]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>CGLib字节码增强和动态语言以及JSP文件生产的java类文件都需要注意累的回收情况。</p>
<h3 id="本机直接内存溢出"><a href="#本机直接内存溢出" class="headerlink" title="本机直接内存溢出"></a>本机直接内存溢出</h3><p>DirectMemory容量可以通过-XX:MaxDirectoryMemorySize指定，如果不指定这与java最大对内存一直，代码直接通过反射火族Unsafe实例进行内存分类。因此虽使用DirectBuffer分配内存也会抛出内存溢出异常，但它抛出异常并没有真正向操作系统申请分配内存，而是通过计算得知内存无法分配，于是手动抛出异常。</p>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解java虚拟机-性能监控与故障处理工具</title>
    <url>/2018-10-28/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<p>jdk的性能监控和故障处理工具如下图：</p>
<p><img src="/images/jvm/JDK%E7%9A%84%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7.png" alt="JDK的故障处理工具"></p>
<p><a href="http://www.51testing.com/html/92/77492-203728.html">jstat工具</a></p>
<p><a href="https://www.cnblogs.com/baihuitestsoftware/articles/6405580.html">jconsole工具使用</a></p>
<p><a href="https://www.cnblogs.com/kongzhongqijing/articles/3625340.html">jvisualvm 工具使用</a></p>
<p><a href="https://www.cnblogs.com/kongzhongqijing/articles/3630264.html">jstack工具使用</a></p>
<h1 id="jps：虚拟机进程状况工具"><a href="#jps：虚拟机进程状况工具" class="headerlink" title="jps：虚拟机进程状况工具"></a>jps：虚拟机进程状况工具</h1><h2 id="JPS-名称"><a href="#JPS-名称" class="headerlink" title="JPS 名称:"></a>JPS 名称:</h2><p>jps - Java Virtual Machine Process Status Tool</p>
<h2 id="命令用法"><a href="#命令用法" class="headerlink" title="命令用法"></a>命令用法</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">: jps [options] [hostid]</span><br><span class="line">              options:命令选项，用来对输出格式进行控制</span><br><span class="line">              hostid:指定特定主机，可以是ip地址和域名, 也可以指定具体协议，端口。</span><br></pre></td></tr></table></figure>
<h2 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h2><p>jps是用于查看有权访问的hotspot虚拟机的进程. 当未指定hostid时，默认查看本机jvm进程，否者查看指定的hostid机器上的jvm进程，此时hostid所指机器必须开启jstatd服务。 jps可以列出jvm进程lvmid，主类类名，main函数参数, jvm参数，jar名称等信息。</p>
<p><img src="/images/jvm/JPS%E5%B7%A5%E5%85%B7%E7%9A%84%E4%B8%BB%E8%A6%81%E9%80%89%E9%A1%B9.png" alt="JPS工具的主要选项"></p>
<p>例子：</p>
<ul>
<li>没添加option的时候，默认列出VM标示符号和简单的class或jar名称.如下:</li>
</ul>
<p><img src="/images/jvm/jps%E6%97%A0%E5%8F%82%E6%95%B0.png" alt="jps无参数"></p>
<ul>
<li>-q 仅仅显示VM 标示，不显示jar,class, main参数等信息.</li>
</ul>
<p><img src="/images/jvm/jps-q%E5%91%BD%E4%BB%A4.png" alt="jps-q命令"></p>
<ul>
<li>-m 输出主函数传入的参数. 下的hello 就是在执行程序时从命令行输入的参数</li>
</ul>
<p><img src="/images/jvm/jps-m%E7%9A%84%E5%91%BD%E4%BB%A4.png" alt="jps-m的命令"></p>
<ul>
<li>-l: 输出应用程序主类完整package名称或jar完整名称.</li>
</ul>
<p><img src="/images/jvm/jps-m%E5%91%BD%E4%BB%A4.png" alt="jps-m命令"></p>
<ul>
<li>-v: 列出jvm参数, -Xms20m -Xmx50m是启动程序指定的jvm参数</li>
</ul>
<p><img src="/images/jvm/jps-v%E5%91%BD%E4%BB%A4.png" alt="jps-v命令"></p>
<h1 id="jstat-监视JVM内存工具"><a href="#jstat-监视JVM内存工具" class="headerlink" title="jstat 监视JVM内存工具"></a>jstat 监视JVM内存工具</h1><p>jstat（JVM Statistics Monitoring Tool）是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程 [1] 虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据</p>
<p><img src="/images/jvm/jstat%E5%B7%A5%E5%85%B7%E7%9A%84%E7%9F%A5%E8%B6%B3%E8%A6%81%E9%80%89%E9%A1%B9.png" alt="jstat工具的知足要选项"></p>
<h2 id="语法结构："><a href="#语法结构：" class="headerlink" title="语法结构："></a>语法结构：</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Usage: jstat -help|-options</span><br><span class="line">       jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]</span><br><span class="line">       </span><br><span class="line">参数解释</span><br><span class="line"></span><br><span class="line">Options — 选项，我们一般使用 -gcutil 查看gc情况</span><br><span class="line">vmid    — VM的进程号，即当前运行的java进程号</span><br><span class="line">interval– 间隔时间，单位为秒或者毫秒</span><br><span class="line">count   — 打印次数，如果缺省则打印无数次</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结果项解释：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">S0  — Heap上的 Survivor space 0 区已使用空间的百分比</span><br><span class="line">S1  — Heap上的 Survivor space 1 区已使用空间的百分比</span><br><span class="line">E   — Heap上的 Eden space 区已使用空间的百分比</span><br><span class="line">O   — Heap上的 Old space 区已使用空间的百分比</span><br><span class="line">P   — Perm space 区已使用空间的百分比</span><br><span class="line">YGC — 从应用程序启动到采样时发生 Young GC 的次数</span><br><span class="line">YGCT– 从应用程序启动到采样时 Young GC 所用的时间(单位秒)</span><br><span class="line">FGC — 从应用程序启动到采样时发生 Full GC 的次数</span><br><span class="line">FGCT– 从应用程序启动到采样时 Full GC 所用的时间(单位秒)</span><br><span class="line">GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>使用实例1：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# jstat -gcutil 25444</span><br><span class="line">  S0     S1     E      O      P     YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line"> 11.63   0.00   56.46  66.92  98.49 162    0.248    6      0.331    0.579</span><br></pre></td></tr></table></figure>
<ul>
<li>使用实例2  jstat -gcutil</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(25444是java的进程号，ps -ef | grep java)</span><br><span class="line"></span><br><span class="line">[root@localhost bin]# jstat -gcutil 25444 1000 5</span><br><span class="line">  S0     S1     E      O      P     YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line"> 73.54   0.00  99.04  67.52  98.49    166    0.252     6    0.331    0.583</span><br><span class="line"> 73.54   0.00  99.04  67.52  98.49    166    0.252     6    0.331    0.583</span><br><span class="line"> 73.54   0.00  99.04  67.52  98.49    166    0.252     6    0.331    0.583</span><br><span class="line"> 73.54   0.00  99.04  67.52  98.49    166    0.252     6    0.331    0.583</span><br><span class="line"> 73.54   0.00  99.04  67.52  98.49    166    0.252     6    0.331    0.583</span><br><span class="line"></span><br><span class="line">我们可以看到，5次young gc之后，垃圾内存被从Eden space区(E)放入了Old space区(O)，并引起了百分比的变化，</span><br><span class="line">导致Survivor space使用的百分比从73.54%(S0)降到0%(S1)。有效释放了内存空间。绿框中，我们可以看到，一次full </span><br><span class="line">gc之后，Old space区(O)的内存被回收，从99.05%降到67.52%。图中同时打印了young gc和full gc的总次数、总耗时。</span><br><span class="line">而，每次young gc消耗的时间，可以用相间隔的两行YGCT相减得到。每次full gc消耗的时间，可以用相隔的两行FGCT相减得到。</span><br><span class="line">例如红框中表示的第一行、第二行之间发生了1次young gc，消耗的时间为0.252-0.252＝0.0秒。常驻内存区(P)的使用率，</span><br><span class="line">始终停留在98.49%左右，说明常驻内存没有突变，比较正常。如果young gc和full gc能够正常发生，而且都能有效回收内存，</span><br><span class="line">常驻内存区变化不明显，则说明java内存释放情况正常，垃圾回收及时，java内存泄露的几率就会大大降低。但也不能说明一定没有内存泄露。</span><br><span class="line"></span><br><span class="line">GCT 是YGCT 和FGCT的时间总和。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>使用实例3 jstat -class pid</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jstat -class pid:显示加载class的数量，及所占空间等信息。</span><br><span class="line"></span><br><span class="line">[root@localhost bin]# ps -ef | grep java</span><br><span class="line">root     25917     1  2 23:23 pts&#x2F;2    00:00:05 &#x2F;usr&#x2F;local&#x2F;jdk1.5&#x2F;bin&#x2F;java -Djava.endorsed.dirs&#x3D;&#x2F;usr&#x2F;local&#x2F;jakarta-tomcat-5.0.30&#x2F;common&#x2F;endorsed -classpath &#x2F;usr&#x2F;local&#x2F;jdk1.5&#x2F;lib&#x2F;tools.jar:&#x2F;usr&#x2F;local&#x2F;jakarta-tomcat-5.0.30&#x2F;bin&#x2F;bootstrap.jar:&#x2F;usr&#x2F;local&#x2F;jakarta-tomcat-5.0.30&#x2F;bin&#x2F;commons-logging-api.jar -Dcatalina.base&#x3D;&#x2F;usr&#x2F;local&#x2F;jakarta-tomcat-5.0.30 -Dcatalina.home&#x3D;&#x2F;usr&#x2F;local&#x2F;jakarta-tomcat-5.0.30 -Djava.io.tmpdir&#x3D;&#x2F;usr&#x2F;local&#x2F;jakarta-tomcat-5.0.30&#x2F;temp org.apache.catalina.startup.Bootstrap start</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>使用实例4   jstat -compiler pid:显示VM实时编译的数量等信息。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Compiled Failed Invalid   Time   FailedType FailedMethod</span><br><span class="line"></span><br><span class="line">     768      0       0   0.70            0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>使用实例5  jstat –gccapacity :可以显示，VM内存中三代（young,old,perm）对象的使用和占用大小，</li>
</ul>
<p>如：PGCMN显示的是最小perm的内存使用量，PGCMX显示的是perm的内存最大使用量，PGC是当前新生成的perm内存占用量，PC是但前perm内存占用量。其他的可以根据这个类推， OC是old内纯的占用量。</p>
<p>[root@localhost bin]# jstat -gccapacity 25917</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NGCMN       640.0</span><br><span class="line">NGCMX       4992.0</span><br><span class="line">NGC         832.0</span><br><span class="line">S0C         64.0</span><br><span class="line">S1C         64.0</span><br><span class="line">EC          704.0</span><br><span class="line">OGCMN       1408.0</span><br><span class="line">OGCMX       60544.0</span><br><span class="line">OGC         9504.0</span><br><span class="line">OC          9504.0                  OC是old内纯的占用量</span><br><span class="line">PGCMN       8192.0                  PGCMN显示的是最小perm的内存使用量</span><br><span class="line">PGCMX       65536.0                 PGCMX显示的是perm的内存最大使用量</span><br><span class="line">PGC         12800.0                 PGC是当前新生成的perm内存占用量</span><br><span class="line">PC          12800.0                 PC是但前perm内存占用量</span><br><span class="line">YGC         164</span><br><span class="line">FGC         6</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>使用实例6 jstat -gcnew pid: new对象的信息</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# jstat -gcnew 25917</span><br><span class="line"> S0C    S1C    S0U    S1U   TT MTT  DSS      EC       EU     YGC     YGCT</span><br><span class="line"> 64.0   64.0   47.4   0.0   2  15   32.0    704.0    145.7    168    0.254</span><br></pre></td></tr></table></figure>

<ul>
<li>使用实例7 jstat -gcnewcapacity pid: new对象的信息及其占用量</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# jstat -gcnewcapacity 25917</span><br><span class="line"> NGCMN  NGCMX   NGC   S0CMX  S0C   S1CMX  S1C   ECMX    EC      YGC   FGC</span><br><span class="line">640.0  4992.0  832.0 64.0   448.0 448.0  64.0   4096.0  704.0  168     6</span><br></pre></td></tr></table></figure>


<ul>
<li>使用实例8 jstat -gcold pid: old对象的信息。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# jstat -gcold 25917</span><br><span class="line">   PC       PU        OC          OU       YGC    FGC    FGCT     GCT</span><br><span class="line"> 12800.0  12617.6     9504.0      6561.3   169     6    0.335    0.591</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>使用实例9 jstat -gcoldcapacity pid:old对象的信息及其占用量。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# jstat -gcoldcapacity 25917</span><br><span class="line">OGCMN      OGCMX        OGC         OC       YGC   FGC    FGCT     GCT</span><br><span class="line">1408.0     60544.0      9504.0      9504.0   169     6    0.335    0.591</span><br></pre></td></tr></table></figure>


<ul>
<li>使用实例10 jstat -gcpermcapacity pid: perm对象的信息及其占用量。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# jstat -gcpermcapacity 25917</span><br><span class="line">PGCMN      PGCMX       PGC         PC      YGC   FGC    FGCT     GCT</span><br><span class="line">8192.0    65536.0    12800.0    12800.0   169     6    0.335    0.591</span><br></pre></td></tr></table></figure>


<ul>
<li>使用实例11 jstat -printcompilation pid:当前VM执行的信息。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# jstat -printcompilation -h3  25917 1000 5</span><br><span class="line"></span><br><span class="line">每1000毫秒打印一次，一共打印5次，还可以加上-h3每三行显示一下标题。</span><br><span class="line"></span><br><span class="line">Compiled  Size  Type Method</span><br><span class="line">     788     73    1 java&#x2F;io&#x2F;File &lt;init&gt;</span><br><span class="line">     788     73    1 java&#x2F;io&#x2F;File &lt;init&gt;</span><br><span class="line">     788     73    1 java&#x2F;io&#x2F;File &lt;init&gt;</span><br><span class="line">Compiled  Size  Type Method</span><br><span class="line">     788     73    1 java&#x2F;io&#x2F;File &lt;init&gt;</span><br><span class="line">     788     73    1 java&#x2F;io&#x2F;File &lt;init&gt;</span><br></pre></td></tr></table></figure>


<h1 id="jinfo。查看和修改JVM运行参数"><a href="#jinfo。查看和修改JVM运行参数" class="headerlink" title="jinfo。查看和修改JVM运行参数"></a>jinfo。查看和修改JVM运行参数</h1><p>jinfo（Configuration Info for Java）的作用是实时地查看和调整虚拟机各项参数。使用jps命令的-v参数可以查看虚拟机启动时显式指定的参数列表，但如果想知道未被显式指定的参<br>数的系统默认值，除了去找资料外，就只能使用jinfo的-flag选项进行查询了（如果只限于JDK  1.6或以上版本的话，使用java-XX：+PrintFlagsFinal查看参数默认值也是一个很好的选<br>择），jinfo还可以使用-sysprops选项把虚拟机进程的System.getProperties（）的内容打印出来。JDK  1.6之后，jinfo在Windows和Linux平台都有提供，并且加入了运行期修改参数的能力，可以使用-flag[+|-]name或者-flag  name=value修改一部分运行期可写的虚拟机参数值。<br>JDK 1.6中，jinfo对于Windows平台功能仍然有较大限制，只提供了最基本的-flag选项</p>
<p>执行样例：查询CMSInitiatingOccupancyFraction参数值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jinfo -flag CMSInitiatingOccupancyFration 1444</span><br><span class="line">-XX: CMSInitiatingOccupancyFration&#x3D;95</span><br></pre></td></tr></table></figure>
<h1 id="jmap：Java内存映像工具"><a href="#jmap：Java内存映像工具" class="headerlink" title="jmap：Java内存映像工具"></a>jmap：Java内存映像工具</h1><p><a href="http://www.cnblogs.com/myna/p/7573843.html">引用</a></p>
<p><img src="/images/jvm/jmap%E5%B7%A5%E5%85%B7%E7%9A%84%E4%B8%BB%E8%A6%81%E9%80%89%E9%A1%B9.png" alt="jmap工具的主要选项"></p>
<p>jmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文件）。如果不使用jmap命令，要想获取Java堆转储快照，还有一些比较“暴力”的手段：譬如<br>在第2章中用过的-XX：+HeapDumpOnOutOfMemoryError参数，可以让虚拟机在OOM异常出现之后自动生成dump文件</p>
<h2 id="命令格式："><a href="#命令格式：" class="headerlink" title="命令格式："></a>命令格式：</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jmap [ option ] pid</span><br><span class="line">jmap [ option ] executable core</span><br><span class="line">jmap [ option ] [server-id@]remote-hostname-or-IP</span><br></pre></td></tr></table></figure>

<h2 id="参数"><a href="#参数" class="headerlink" title="参数:"></a>参数:</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">option：选项参数，不可同时使用多个选项参数</span><br><span class="line">pid：java进程id，命令ps -ef | grep java获取</span><br><span class="line">executable：产生核心dump的java可执行文件</span><br><span class="line">core：需要打印配置信息的核心文件</span><br><span class="line">remote-hostname-or-ip：远程调试的主机名或ip</span><br><span class="line">server-id：可选的唯一id，如果相同的远程主机上运行了多台调试服务器，用此选项参数标识服务器</span><br></pre></td></tr></table></figure>

<h2 id="options参数"><a href="#options参数" class="headerlink" title="options参数"></a>options参数</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">heap : 显示Java堆详细信息</span><br><span class="line">histo : 显示堆中对象的统计信息</span><br><span class="line">permstat :Java堆内存的永久保存区域的类加载器的统计信息</span><br><span class="line">finalizerinfo : 显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象</span><br><span class="line">dump : 生成堆转储快照</span><br><span class="line">F : 当-dump没有响应时，强制生成dump快照</span><br></pre></td></tr></table></figure>

<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><ul>
<li>dump</li>
</ul>
<p>dump堆到文件,format指定输出格式，live指明是活着的对象,file指定文件名</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost jdk1.7.0_79]# jmap -dump:live,format&#x3D;b,file&#x3D;dump.hprof 24971</span><br><span class="line">Dumping heap to &#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk1.7.0_79&#x2F;dump.hprof ...</span><br><span class="line">Heap dump file created</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>heap</li>
</ul>
<p>打印heap的概要信息，GC使用的算法，heap的配置及使用情况，可以用此来判断内存目前的使用情况以及垃圾回收情况</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost jdk1.7.0_79]# jmap -heap 24971</span><br><span class="line">Attaching to process ID 24971, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 24.79-b02</span><br><span class="line"> </span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Parallel GC with 4 thread(s)</span><br><span class="line"> </span><br><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio &#x3D; 0</span><br><span class="line">   MaxHeapFreeRatio &#x3D; 100</span><br><span class="line">   MaxHeapSize      &#x3D; 4146069504 (3954.0MB)</span><br><span class="line">   NewSize          &#x3D; 1310720 (1.25MB)</span><br><span class="line">   MaxNewSize       &#x3D; 17592186044415 MB</span><br><span class="line">   OldSize          &#x3D; 5439488 (5.1875MB)</span><br><span class="line">   NewRatio         &#x3D; 2</span><br><span class="line">   SurvivorRatio    &#x3D; 8</span><br><span class="line">   PermSize         &#x3D; 21757952 (20.75MB)</span><br><span class="line">   MaxPermSize      &#x3D; 85983232 (82.0MB)</span><br><span class="line">   G1HeapRegionSize &#x3D; 0 (0.0MB)</span><br><span class="line"> </span><br><span class="line">Heap Usage:</span><br><span class="line">PS Young Generation</span><br><span class="line">Eden Space:</span><br><span class="line">   capacity &#x3D; 517996544 (494.0MB)</span><br><span class="line">   used     &#x3D; 151567520 (144.54605102539062MB)</span><br><span class="line">   free     &#x3D; 366429024 (349.4539489746094MB)</span><br><span class="line">   29.26033421566612% used</span><br><span class="line">From Space:</span><br><span class="line">   capacity &#x3D; 41943040 (40.0MB)</span><br><span class="line">   used     &#x3D; 0 (0.0MB)</span><br><span class="line">   free     &#x3D; 41943040 (40.0MB)</span><br><span class="line">   0.0% used</span><br><span class="line">To Space:</span><br><span class="line">   capacity &#x3D; 40370176 (38.5MB)</span><br><span class="line">   used     &#x3D; 0 (0.0MB)</span><br><span class="line">   free     &#x3D; 40370176 (38.5MB)</span><br><span class="line">   0.0% used</span><br><span class="line">PS Old Generation</span><br><span class="line">   capacity &#x3D; 115343360 (110.0MB)</span><br><span class="line">   used     &#x3D; 32927184 (31.401809692382812MB)</span><br><span class="line">   free     &#x3D; 82416176 (78.59819030761719MB)</span><br><span class="line">   28.54709972034801% used</span><br><span class="line">PS Perm Generation</span><br><span class="line">   capacity &#x3D; 85983232 (82.0MB)</span><br><span class="line">   used     &#x3D; 54701200 (52.16712951660156MB)</span><br><span class="line">   free     &#x3D; 31282032 (29.832870483398438MB)</span><br><span class="line">   63.6184506300019% used</span><br><span class="line"> </span><br><span class="line">20822 interned Strings occupying 2441752 bytes.</span><br></pre></td></tr></table></figure>
<ul>
<li>finalizerinfo</li>
</ul>
<p>打印等待回收的对象信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost jdk1.7.0_79]# jmap -finalizerinfo 24971</span><br><span class="line">Attaching to process ID 24971, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 24.79-b02</span><br><span class="line">Number of objects pending for finalization: 0</span><br></pre></td></tr></table></figure>
<p>Number of objects pending for finalization: 0 说明当前F-QUEUE队列中并没有等待Fializer线程执行finalizer方法的对象</p>
<ul>
<li>histo</li>
</ul>
<p>打印堆的对象统计，包括对象数、内存大小等等。jmap -histo:live 这个命令执行，JVM会先触发gc，然后再统计信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost jdk1.7.0_79]# jmap -histo:live 24971 | more</span><br><span class="line"> </span><br><span class="line"> num     #instances         #bytes  class name</span><br><span class="line">----------------------------------------------</span><br><span class="line">   1:        100134       14622728  &lt;constMethodKlass&gt;</span><br><span class="line">   2:        100134       12830128  &lt;methodKlass&gt;</span><br><span class="line">   3:         88438       12708392  [C</span><br><span class="line">   4:          8271       10163584  &lt;constantPoolKlass&gt;</span><br><span class="line">   5:         27806        9115784  [B</span><br><span class="line">   6:          8271        6225312  &lt;instanceKlassKlass&gt;</span><br><span class="line">   7:          6830        5632192  &lt;constantPoolCacheKlass&gt;</span><br><span class="line">   8:         86717        2081208  java.lang.String</span><br><span class="line">   9:          2264        1311720  &lt;methodDataKlass&gt;</span><br><span class="line">  10:         10880         870400  java.lang.reflect.Method</span><br><span class="line">  11:          8987         869888  java.lang.Class</span><br><span class="line">  12:         13330         747264  [[I</span><br><span class="line">  13:         11808         733872  [S</span><br><span class="line">  14:         20110         643520  java.util.concurrent.ConcurrentHashMap$HashEntry</span><br><span class="line">  15:         18574         594368  java.util.HashMap$Entry</span><br><span class="line">  16:          3668         504592  [Ljava.util.HashMap$Entry;</span><br><span class="line">  17:         30698         491168  java.lang.Integer</span><br><span class="line">  18:          2247         486864  [I</span><br><span class="line">  19:          7486         479104  java.net.URL</span><br><span class="line">  20:          8032         453616  [Ljava.lang.Object;</span><br><span class="line">  21:         10259         410360  java.util.LinkedHashMap$Entry</span><br><span class="line">  22:           699         380256  &lt;objArrayKlassKlass&gt;</span><br><span class="line">  23:          5782         277536  org.apache.catalina.loader.ResourceEntry</span><br><span class="line">  24:          8327         266464  java.lang.ref.WeakReference</span><br><span class="line">  25:          2374         207928  [Ljava.util.concurrent.ConcurrentHashMap$HashEntry;</span><br><span class="line">  26:          3440         192640  java.util.LinkedHashMap</span><br><span class="line">  27:          4779         191160  java.lang.ref.SoftReference</span><br><span class="line">  28:          3576         171648  java.util.HashMap</span><br><span class="line">  29:         10080         161280  java.lang.Object</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>jmap -histo:live 24971 | grep com.yuhuo 查询类名包含com.yuhuo的信息</p>
<p>jmap -histo:live 24971 | grep com.yuhuo &gt; histo.txt 保存信息到histo.txt文件</p>
<p><img src="/images/jvm/jmap%E8%BE%93%E5%87%BA%E4%B8%ADclass-name%E9%9D%9E%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B1%BB%E7%9A%84%E8%AF%B4%E6%98%8E.png" alt="jmap输出中class-name非自定义类的说明"></p>
<ul>
<li>permstat</li>
</ul>
<p>打印Java堆内存的永久区的类加载器的智能统计信息。对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、它所加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost jdk1.7.0_79]# jmap -permstat 24971</span><br><span class="line">Attaching to process ID 24971, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is 24.79-b02</span><br><span class="line">finding class loader instances ..done.</span><br><span class="line">computing per loader stat ..done.</span><br><span class="line">please wait.. computing liveness....................................................liveness analysis may be inaccurate ...</span><br><span class="line">class_loader    classes bytes   parent_loader   alive?  type</span><br><span class="line"> </span><br><span class="line">&lt;bootstrap&gt;   3034    18149440      null      live    &lt;internal&gt;</span><br><span class="line">0x000000070a88fbb8  1   3048      null      dead    sun&#x2F;reflect&#x2F;DelegatingClassLoader@0x0000000703c50b58</span><br><span class="line">0x000000070a914860  1   3064    0x0000000709035198  dead    sun&#x2F;reflect&#x2F;DelegatingClassLoader@0x0000000703c50b58</span><br><span class="line">0x000000070a9fc320  1   3056    0x0000000709035198  dead    sun&#x2F;reflect&#x2F;DelegatingClassLoader@0x0000000703c50b58</span><br><span class="line">0x000000070adcb4c8  1   3064    0x0000000709035198  dead    sun&#x2F;reflect&#x2F;DelegatingClassLoader@0x0000000703c50b58</span><br><span class="line">0x000000070a913760  1   1888    0x0000000709035198  dead    sun&#x2F;reflect&#x2F;DelegatingClassLoader@0x0000000703c50b58</span><br><span class="line">0x0000000709f3fd40  1   3032      null      dead    sun&#x2F;reflect&#x2F;DelegatingClassLoader@0x0000000703c50b58</span><br><span class="line">0x000000070923ba78  1   3088    0x0000000709035260  dead    sun&#x2F;reflect&#x2F;DelegatingClassLoader@0x0000000703c50b58</span><br><span class="line">0x000000070a88fff8  1   3048      null      dead    sun&#x2F;reflect&#x2F;DelegatingClassLoader@0x0000000703c50b58</span><br><span class="line">0x000000070adcbc58  1   1888    0x0000000709035198  dead    sun&#x2F;reflect&#x2F;DelegatingClassLoader@0x0000000703c50b58</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="jstack：Java堆栈跟踪工具"><a href="#jstack：Java堆栈跟踪工具" class="headerlink" title="jstack：Java堆栈跟踪工具"></a>jstack：Java堆栈跟踪工具</h1><p>jstack（Stack  Trace  for  Java）命令用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈<br>的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。线程出现停顿<br>的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者等待着什么资源.</p>
<p><a href="https://blog.csdn.net/mr__fang/article/details/68496248">使用jstack精确找到异常代码</a><br><a href="https://www.cnblogs.com/kongzhongqijing/articles/3630264.html">jstack 工具使用</a><br><a href="https://blog.csdn.net/yaowj2/article/category/855894">性能调优</a></p>
<h1 id="JConsole：Java监视与管理控制台-虚拟机监控工具"><a href="#JConsole：Java监视与管理控制台-虚拟机监控工具" class="headerlink" title="JConsole：Java监视与管理控制台 虚拟机监控工具"></a>JConsole：Java监视与管理控制台 虚拟机监控工具</h1><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>通过JDK/bin目录下的“jconsole.exe”启动JConsole后，将自动搜索出本机运行的所有虚拟机进程，不需要用户自己再使用jps来查询了</p>
<h1 id="VisualVM-多合一故障处理工具"><a href="#VisualVM-多合一故障处理工具" class="headerlink" title="VisualVM 多合一故障处理工具"></a>VisualVM 多合一故障处理工具</h1>]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>性能监控与故障处理工具</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能myqsl-查询性能优化</title>
    <url>/2018-12-06/%E9%AB%98%E6%80%A7%E8%83%BDmyqsl-%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>如果查询很糟糕，即使表结构和索引再合适也无法实现高性能。</p>
<p>查询的大致生命周期可以按照顺序来看：从客户端，到服务端，然后在服务器上进行解析，生成执行计划，执行，并返回结果给客户端。其中执行可以认为是整个生命周期中最重要的阶段</p>
<h1 id="慢查询的基础：优化数据访问"><a href="#慢查询的基础：优化数据访问" class="headerlink" title="慢查询的基础：优化数据访问"></a>慢查询的基础：优化数据访问</h1><p>查询性能低下的最基本的原因是访问的数据太多，以下两个步骤来分析总是很有效。</p>
<p>1.确认应用程序是否在检索大量超时需要的数据，这通常是访问了太多的行。<br>2.确认mysql服务器是否在分析大量超时需求的数据行；</p>
<h2 id="是否向DB请求了不需要的数据"><a href="#是否向DB请求了不需要的数据" class="headerlink" title="是否向DB请求了不需要的数据"></a>是否向DB请求了不需要的数据</h2><p>查询超过实际需要的数据，增加服务器的负担，增加网络、cpu、内存资源的开销；</p>
<ul>
<li><strong>查询不需要的记录</strong>，比如前段页面需要10条数据，查询的时候未使用limit；</li>
<li><strong>多表关联时返回全部列</strong>， 比如select a.*,b.*，返回多个表的所有数据。是不被推荐使用的，应该只返回需要的数据；</li>
<li><strong>总是去除全部列</strong>，比如select *，这种一般是不需要的；不过这种可以提高代码的复用性，但是这种做法是有代价的。</li>
<li><strong>多次查询相同的数据</strong>，这种一般可以进行缓存到redis中，防止多次请求DB而给DB带来的压力；</li>
</ul>
<h2 id="mysql是否在扫描额外的记录"><a href="#mysql是否在扫描额外的记录" class="headerlink" title="mysql是否在扫描额外的记录"></a>mysql是否在扫描额外的记录</h2><p>衡量查询开销的三个指标：响应时间、扫描的行数、返回的行数，这些指标会被记录到慢sql中，检查慢sql是找出扫描过多行的办法。</p>
<h3 id="响应时间"><a href="#响应时间" class="headerlink" title="响应时间"></a>响应时间</h3><p>响应时间分为服务时间和队列时间。服务时间是数据库处理这个查询的真正时间，排队时间是服务器因为等在某些资源而等到的时间（可能是等待IO完成的时间。等待行锁的时间）。</p>
<h3 id="扫描的行数和返回的行数"><a href="#扫描的行数和返回的行数" class="headerlink" title="扫描的行数和返回的行数"></a>扫描的行数和返回的行数</h3><p>分析查询扫描的行数是非常有帮助的，一定程度上可以看看这个查询的效率是不是高。</p>
<h3 id="扫描的行数和访问类型"><a href="#扫描的行数和访问类型" class="headerlink" title="扫描的行数和访问类型"></a>扫描的行数和访问类型</h3><p>explain语句中的type列返回了访问类型，由慢到块依次是全表扫描、索引扫描、范围扫描、唯一索引查询、常数引用。扫描的范围也是由小到大。</p>
<p>如果没有找到一个合适的访问类型，通常的办法是增加一个合适的索引。</p>
<p>一般mysql能够使用如下三种方式应用where条件，从好到坏依次是：</p>
<ul>
<li>在索引中使用where条件来过滤不匹配的记录，这是在存储引擎层来完成的；</li>
<li>使用覆盖索引扫描（在extra列中出现了using index）来返回记录，直接从索引中过滤不需要的记录返回命中的记录，则是在mysql服务层来完成的，无需回表查询；</li>
<li>从数据表中返回数据，然后过滤不需要的条件记录（在extra列中出现using where）。在mysql的服务层完成，从mysql数局表读出记录然后过滤。</li>
</ul>
<h4 id="如果查询需要扫描大量的数据只是返回少数的行，则可以使用一下方法优化"><a href="#如果查询需要扫描大量的数据只是返回少数的行，则可以使用一下方法优化" class="headerlink" title="如果查询需要扫描大量的数据只是返回少数的行，则可以使用一下方法优化"></a>如果查询需要扫描大量的数据只是返回少数的行，则可以使用一下方法优化</h4><ul>
<li>使用覆盖索引，把所有需要的列放到索引中，这样索引无须回表就能返回结果了；</li>
<li>改变表结构，例如使用单独的汇总表；</li>
<li>重写复杂的查询，让mysql优化器能够以更优化的方式执行这个查询；</li>
</ul>
<h1 id="重构查询的方式"><a href="#重构查询的方式" class="headerlink" title="重构查询的方式"></a>重构查询的方式</h1><p>可以优化一个sql得到和原来一样的结果去完成需求，也是可以重写sql得到一个不一样的结果去完成需求；</p>
<h2 id="一个复杂的查询还是多个简单查询"><a href="#一个复杂的查询还是多个简单查询" class="headerlink" title="一个复杂的查询还是多个简单查询"></a>一个复杂的查询还是多个简单查询</h2><p>如果一个查询可以完成就不要写成多个简单的查询；</p>
<h2 id="切分查询"><a href="#切分查询" class="headerlink" title="切分查询"></a>切分查询</h2><p>有时候对于一个大查询需要分而治之。将大查询分成小查询，每个查询功能完全一样，只完成一小部分的查询。</p>
<p>比如删除1000万条数据，可以每次删除1万条来处理。</p>
<h1 id="查询执行的基础"><a href="#查询执行的基础" class="headerlink" title="查询执行的基础"></a>查询执行的基础</h1><p>弄清楚mysql是如何优化和执行查询是更高的性能查询的基础。</p>
<p><img src="/images/mysql/%E6%9F%A5%E8%AF%A2%E6%89%A7%E8%A1%8C%E8%B7%AF%E5%BE%84.png" alt="mysql的执行路径"></p>
<ul>
<li>客户端发送一条查询给服务器；</li>
<li>服务器先检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果，否则进入下一个阶段；</li>
<li>服务器进行sql解析、预处理、再由优化器生成对应的执行计划；</li>
<li>优化器生成的额执行计划，调用存储引擎的api来执行查询；</li>
<li>结果返回给客户端；</li>
</ul>
<h2 id="mysql客户端-服务端的通信协议"><a href="#mysql客户端-服务端的通信协议" class="headerlink" title="mysql客户端/服务端的通信协议"></a>mysql客户端/服务端的通信协议</h2><p>mysql客户端和服务端之前的通信协议是“半双工”的，这也意味着任何一个时刻，要么有服务器向客户端发送数据，要么由客户端向服务器发送数据，不能同时发生。</p>
<p>一旦客户端发送了请求，他只能等待结果了。当服务器开始响应客户端请求时，客户端必须完整的接收整个返回结果，而不是简单地只取前面几条结果而让服务器停止发送数据。客户端从服务端获取数据时，实际上是服务端向客户端推送数据的过程。</p>
<p>连接mysql的库函数通常可以获得全部结果缓存到内存中，他还可以逐行获取数据，一般都是前者。因为这样可以减小服务器的压力，让查询早点结果，早点释放资源。</p>
<p>多数情况下，从mysql的库函数中获取mysql的数据。如果结果太大不好，因为需要太大的内存消耗。</p>
<h3 id="查询状态"><a href="#查询状态" class="headerlink" title="查询状态"></a>查询状态</h3><p>对于一个mysql连接，或者说一个线程，任何时候都有一个状态，show full processlist (该命令返回结果的command列就是当前的准头盖)</p>
<ul>
<li>sleep 线程正在等待客户端发送新的请求；</li>
<li>query 线程正在执行查询或者正在将结果发送给客户端；</li>
<li>locked 在mysql服务器层，该线程正在等待表锁。在存储引擎级别的实现的锁，例如innoDB的行锁，并不会出现在线程状态中。</li>
<li>analyzing and statistics ，线程正在收集存储引擎的统计信息，并生成查询的执行计划；</li>
<li>copying to tmp table [on disk]:线程正在执行查询，并将结果复制到一个临时表中，这种状态要么是group by操作，要么是union操作。如果状态后面有on disk操作，则代表正在将一个内存临时表放到磁盘上。</li>
<li>sorting result 线程正在对结果集进行排序；</li>
<li>sending data 表示多种情况，线程可能在多个撞他间传送数据，或者生成结果集，或者正在给客户端返回数据；</li>
</ul>
<h2 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h2><p>解析一个查询语句之前先看查询缓存是否打开，打开的话优先查询是否明总缓存（通过一个大小写敏感的hash查找的）；</p>
<p>如果查询恰好命中了查询缓存，那么返回结果之前要检查一次用户权限。如果权限没有问题，则跳过其它阶段，返回数据。</p>
<h2 id="查询优化处理"><a href="#查询优化处理" class="headerlink" title="查询优化处理"></a>查询优化处理</h2><p>解析sql、预处理、优化sql执行计划是将一个sql转换成一个执行计划的三个步骤；</p>
<h3 id="语法解析器和预处理"><a href="#语法解析器和预处理" class="headerlink" title="语法解析器和预处理"></a>语法解析器和预处理</h3><p>解析器将sql生成“解析树”。检查mysql语法规则和解析查询。比如：是否使用错误的关键字、关键字的顺序是否争取，验证引号是否前后匹配，别名是否存在，数据列是否存在等；下一步是鉴权</p>
<h3 id="查询优化器"><a href="#查询优化器" class="headerlink" title="查询优化器"></a>查询优化器</h3><p>优化器将语法树转化成执行计划。mysql使用基于成本的优化器，它尝试预测一个查询使用某种执行计划的成本，选择成本最小的一个。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM t_user ;</span><br><span class="line">SHOW STATUS LIKE &#39;last_query_cost&#39;;</span><br><span class="line"></span><br><span class="line">+-----------------+-------------+</span><br><span class="line">| Variable_name   | Value       |</span><br><span class="line">+-----------------+-------------+</span><br><span class="line">| Last_query_cost | 1672.799000 |</span><br><span class="line">+-----------------+-------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>表示优化器认为大概需要做1673个数据页的随机访问才可以完成上面的查询，这是根据一系列统计信息计算得来的：每个表或者索引页面的个数、索引的基数、索引和数据行的长度、索引分布情况。这个时间的估算不考虑缓存</p>
<p><strong>mysql优化器选择错误的执行计划</strong></p>
<p>1.统计信息不准确；<br>2.执行计划中的成本估算不等同于实际执行的成本；<br>3.mysql的最优可能和你想象的不一样，我们只是认为是执行时间最短的，mysql不这么认为；<br>4.mysql不考虑其它并发执行的查询；<br>5.mysql并意识任何时候都是基于成本的优化；<br>6.mysql不会考虑不受其控制的成本；</p>
<h3 id="mysql能够处理的优化类型"><a href="#mysql能够处理的优化类型" class="headerlink" title="mysql能够处理的优化类型"></a>mysql能够处理的优化类型</h3><ul>
<li>重新定义关联表的顺序</li>
<li>将外连接转化为内连接，比如where条件、库表结构让外连接等价于一个内连接；</li>
<li>使用等价变换规则，将复杂的表达式转化为简单的，移除一些恒等式；</li>
<li>优化count()、min()、max(),例如min是b-tree索引的最左端记录，max是索引的最后一条记录。count（*）可以使用存储引擎提供的一些优化。</li>
<li>预估并转化为常数表达式</li>
<li>覆盖索引扫描，当索引中的列包含所有查询中需要使用的列的时候，mysql就回使用索引返回需要的数据，而无需查询对应的数据列；</li>
<li>子查询优化，将子查询转化为一种效率更高的形式，减少多个查询多次对数据的访问；</li>
<li>提前终止查询。limit子句，发现已经满足需求的时候，立刻终止查询；</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; explain SELECT * FROM t_user WHERE id &#x3D;-1 ;</span><br><span class="line">+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+</span><br><span class="line">| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                          |</span><br><span class="line">+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+</span><br><span class="line">|  1 | SIMPLE      | NULL  | NULL       | NULL | NULL          | NULL | NULL    | NULL | NULL | NULL     | no matching row in const table |</span><br><span class="line">+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">Extra字段中的值表示查询在优化阶段就提前终止查询；</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>等值传播，如果两个列的值通过等式关联，那么mysql能够把其中一列的where条件传递到另一列上。</li>
<li>列表in的比较。mysql中的in和or列表的子句是同步的，前者会先排序然后二分查找（o（logn)）），后者是O(n)</li>
</ul>
<h3 id="mysql如何执行关联查询"><a href="#mysql如何执行关联查询" class="headerlink" title="mysql如何执行关联查询"></a>mysql如何执行关联查询</h3><p>在mysql中每一次查询都是关联，在union语句中，现将一些列的单个查询放到一个临时表中，然后重新读出临时表数据来完成union查询，每一次查询都是一次关联，所以读取临时表的结果也是一次关联。</p>
<p>mysql执行关联的策略是mysql对任何关联都执行嵌套关联操作。mysql先在表中循环读取单条数据，然后嵌套循环到下一个表中寻找匹配的行，依次下去，直到找到表中匹配的行为止。</p>
<h3 id="执行计划"><a href="#执行计划" class="headerlink" title="执行计划"></a>执行计划</h3><p>mysql不会生成查询字节码来执行查询，而是生成查询的一颗指令树，然后通过存储引擎执行完成这颗指令树并返回结果。</p>
<h3 id="关联查询优化器"><a href="#关联查询优化器" class="headerlink" title="关联查询优化器"></a>关联查询优化器</h3><p>多表关联的时候，筒仓有多重关联顺序来完成相同的执行结果，关联查询评估不同的顺序成本来选择一个代价小的关联查询。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; EXPLAIN</span><br><span class="line">SELECT</span><br><span class="line">    b.group_id </span><br><span class="line">FROM</span><br><span class="line">    t_user a</span><br><span class="line">    LEFT JOIN t_group_user_rel b ON a.id &#x3D; b.user_id</span><br><span class="line">    LEFT JOIN t_group c ON b.group_id &#x3D; c.id </span><br><span class="line">WHERE</span><br><span class="line">    a.id &#x3D; 1;</span><br><span class="line">+----+-------------+-------+------------+--------+------------------------------+------------------------------+---------+---------------------+------+----------+--------------------------+</span><br><span class="line">| id | select_type | table | partitions | type   | possible_keys                | key                          | key_len | ref                 | rows | filtered | Extra                    |</span><br><span class="line">+----+-------------+-------+------------+--------+------------------------------+------------------------------+---------+---------------------+------+----------+--------------------------+</span><br><span class="line">|  1 | SIMPLE      | a     | NULL       | const  | PRIMARY                      | PRIMARY                      | 4       | const               |    1 |   100.00 | Using index              |</span><br><span class="line">|  1 | SIMPLE      | b     | NULL       | ref    | index_group_user_rel_user_id | index_group_user_rel_user_id | 4       | const               |   17 |   100.00 | NULL                     |</span><br><span class="line">|  1 | SIMPLE      | c     | NULL       | eq_ref | PRIMARY                      | PRIMARY                      | 4       | sso_test.b.group_id |    1 |   100.00 | Using where; Using index |</span><br><span class="line">+----+-------------+-------+------------+--------+------------------------------+------------------------------+---------+---------------------+------+----------+--------------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"> </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>关联查询，由于是嵌套查询的，所以优化器会将小表放到前面；</p>
<h3 id="排序优化"><a href="#排序优化" class="headerlink" title="排序优化"></a>排序优化</h3><p>如果数据量小，则会在内存中排序，如果数据量大则需要使用磁盘。进行文件排序会使用临时存储空间，可能比想象的要大。</p>
<p><img src="/images/mysql/%E5%85%B3%E8%81%94%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%8E%92%E5%BA%8F.png" alt="关联查询的排序"></p>
<h2 id="查询执行引擎"><a href="#查询执行引擎" class="headerlink" title="查询执行引擎"></a>查询执行引擎</h2><p>在解析优化节阶段，mysql将生成查询对应的执行计划，mysql查询执行引擎则根据这个执行计划来完成整个查询。</p>
<p>在根据执行计划逐步执行的过程中，大量的操作需要调用存储引擎实现的接口来完成。</p>
<h2 id="返回结果给客户端"><a href="#返回结果给客户端" class="headerlink" title="返回结果给客户端"></a>返回结果给客户端</h2><p>即使查询不需要返回结果给客户端，mysql仍然会返回这个查询的一些信息比如影响查询的行数。如果查询结果可以被缓存，则mysql在这个阶段的结果也会放到查询缓存中。</p>
<p>mysql将结果集返回客户端是一个增量，逐步返回的过程。当查询结果生成第一条结果时，mysql就可以开始想客户端逐步返回了。这样做服务端无需缓存太多的结果，客户端可以第一时间获取返回的结果。结果中的每一行都会以一个满足 客户端和服务器通信协议的封包发送。</p>
<h1 id="mysql查询优化器的局限性"><a href="#mysql查询优化器的局限性" class="headerlink" title="mysql查询优化器的局限性"></a>mysql查询优化器的局限性</h1><p>mysql的万能嵌套循环是对大部分的查询都适用的。</p>
<h2 id="关联子查询"><a href="#关联子查询" class="headerlink" title="关联子查询"></a>关联子查询</h2><p>最糟糕的子查询是where条件中包含In（）的子查询语句。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from film where film_id in (select film_id from film_actor where actor_id &#x3D; 1);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>mysql对in列表中的选项有专门的额优化策略，我们以为in的子查询会被执行为 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select group_concat(film_id) from film_actor where actor_id &#x3D;1;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其实不是这样的，它会被优化为(mysql 5.6的版本，5.7的版本可以不是如此)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from film where exists (select * from film_actor where actor_id &#x3D;1 and film_actor.film_id &#x3D;film.film_id)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这时候需要根据film_id来关联外部表的film，因为需要film_id字段，所以mysql认为无法先查询这个子查询，通过explain我们可以看到子查询是 一个相关子查询（dependent subquery）。（可以使用explain extend查看整个查询被改写成什么样子）</p>
<p>可以优化为 group_concat()逗号分隔查询，也可以改成关联查询。</p>
<h2 id="union的限制"><a href="#union的限制" class="headerlink" title="union的限制"></a>union的限制</h2><p>从两个子句中order by之后limit出来200条，然后对总的order by 和limit。但是这个并不一定准确。</p>
<h1 id="查询优化器提示（hint）"><a href="#查询优化器提示（hint）" class="headerlink" title="查询优化器提示（hint）"></a>查询优化器提示（hint）</h1><p>如果对优化器选择的执行计划不满意，可以使用优化器提供的几个提示来控制最终的执行计划。</p>
<p>但是这个是对优化器不友好的，收效甚微，不建议使用。</p>
<h1 id="优化特定类型的查询"><a href="#优化特定类型的查询" class="headerlink" title="优化特定类型的查询"></a>优化特定类型的查询</h1><h2 id="优化count（）查询"><a href="#优化count（）查询" class="headerlink" title="优化count（）查询"></a>优化count（）查询</h2><ul>
<li><p>count()的作用，可以统计某个列值的数量，也可以统计行数，在统计列值时要求列值是非空的。如果括号中执行了列或者列的表达式，则统计的就是这个表达式有值的结果数。count（*）是在统计行数。</p>
</li>
<li><p>MylSAM的count（）函数在没有where条件的时候直接利用存储引擎的特性获得这个值。当有where条件的时候，就和别的引擎没有区别了</p>
</li>
<li><p>简单优化，反向取值</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    ( SELECT count( * ) FROM world.city ) - count( * ) </span><br><span class="line">FROM</span><br><span class="line">    world.city </span><br><span class="line">WHERE</span><br><span class="line">    id &lt;&#x3D; 5;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>使用近似值</li>
</ul>
<p>计算精确值的成本非常高，计算近似值则非常简单。有的情况可以使用explain出来的优化器估算值的行数就是一个不错的近似值。</p>
<h2 id="优化子查询"><a href="#优化子查询" class="headerlink" title="优化子查询"></a>优化子查询</h2><p>尽可能的使用关联查询代替子查询，但不是绝对的。</p>
<h2 id="优化limit分页"><a href="#优化limit分页" class="headerlink" title="优化limit分页"></a>优化limit分页</h2><ul>
<li>limit 10000，20这种的查询的代价非常高，尽量的使用索引覆盖扫描，而不是查询所有的列。然后根据需要做一次关联擦再做返回需要的列。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select film_id,description from film order by title limit 10000,20;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以改成</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select film.film_id,film.description from film a inner join (select film_id from film b order by title limit 10000,20) on a.film_id &#x3D;b.film_id; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这种延迟关联，大大提升效率。他让mysql尽可能扫描少的页面。</p>
<ul>
<li>找到上一页的临界值，做筛选。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from film where film_id &lt;16030 order by film_id limit 20;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="优化union查询"><a href="#优化union查询" class="headerlink" title="优化union查询"></a>优化union查询</h2><ul>
<li><p>mysql总是使用创建填充临时表的方式执行union查询。因此很多优化策略在union查询中没法很好的使用。因此将limit、where等子句放到各个子查询中。</p>
</li>
<li><p>除非确实需要服务器消除重复的行，否则一定要使用union all。如果没有all关键字，mysql会在临时表上添加distinct关键字，这会使表做唯一性检查，待见非常高。</p>
</li>
</ul>
<h2 id="使用用户自定义变量"><a href="#使用用户自定义变量" class="headerlink" title="使用用户自定义变量"></a>使用用户自定义变量</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set @one: &#x3D; (select min(actor_id) from actor);</span><br></pre></td></tr></table></figure>

<ul>
<li>使用自定义变量无法使用查询缓存；</li>
<li>自定义变量在一个连接中有效；</li>
<li>赋值符号‘:=’的优先级非常低，所以需要注意，赋值表达式应该使用明确的括号；</li>
</ul>
<h3 id="优化排名语句"><a href="#优化排名语句" class="headerlink" title="优化排名语句"></a>优化排名语句</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set @rownum &#x3D; 0;</span><br><span class="line">select actor_id,@rownum:&#x3D;@rownum+1 as rownum from actor limit 1;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="查询刚刚插入的数据"><a href="#查询刚刚插入的数据" class="headerlink" title="查询刚刚插入的数据"></a>查询刚刚插入的数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update t1 set lastUpdated &#x3D;NOW() where id &#x3D;1;</span><br><span class="line">select lastUpdated from t1 where id &#x3D;1;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>使用变量可以如下实现；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update t1 set lastUpdated &#x3D; NOW() where id &#x3D;1 and @now:&#x3D;NOW();</span><br><span class="line">select @now;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>第二个语句和服务端只有一次交互，所以快很多；</p>
<h3 id="统计更新和插入的数量"><a href="#统计更新和插入的数量" class="headerlink" title="统计更新和插入的数量"></a>统计更新和插入的数量</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert into t1(c1,c2) values (4,4),(2,1),(3,1) on duplicate key update c1 &#x3D; values(c1) +(0*( @x:&#x3D;@x+1));</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>冲突时对c1 加一；</p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql查询性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能mysql-创建高性能的索引</title>
    <url>/2018-11-28/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E5%88%9B%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<p>索引是存储引擎用于快速找到记录的一种数据结构。</p>
<p>数据量越大，索引对性能的影响越重要；不恰当的索引对性能的影响不明显，数据量增大时性能急剧下降；</p>
<h1 id="索引基础"><a href="#索引基础" class="headerlink" title="索引基础"></a>索引基础</h1><p>存储引擎首先在索引中找到对应的值，然后根据匹配的索引记录找到对应的数据行。</p>
<p>创建一个包含两个列的索引和创建两个只包含一列的索引是大不相同的。</p>
<h2 id="索引的类型"><a href="#索引的类型" class="headerlink" title="索引的类型"></a>索引的类型</h2><p>mysql中，索引是在存储引擎层，而不是在服务器层的。索引没有统一的标准。</p>
<h3 id="B-Tree索引"><a href="#B-Tree索引" class="headerlink" title="B-Tree索引"></a>B-Tree索引</h3><p>大部分mysql引擎都支持这种索引，它使用的是B-Tree数据结构来存储数据。但是NDB集群存储引擎实际采用T-Tree结构存储这种索引，InnoDB则使用B+Tree。</p>
<p>存储引擎以不同的方式使用B-Tree索引，性能也是各不相同的，例如MylSAM使用前缀压缩技术使得索引更小，但是innoDB则按照原数据格式进行存储，MylSAM索引通过数据的物理位置引用被索引的行，而innoDB则根据主键来引用被索引的行。</p>
<p><img src="/images/mysql/B-Tree%E7%B4%A2%E5%BC%95%E7%9A%84%E6%8A%BD%E8%B1%A1%E8%A1%A8%E7%A4%BA.png" alt="B-Tree索引的抽象表示"></p>
<p><a href="https://blog.csdn.net/xu_flash/article/details/62216969">bTree索引</a></p>
<ul>
<li>简单表述实现</li>
</ul>
<p>B-Tree索引可以加快访问速度。因为不需要全表扫描，而是从索引的根节点开始搜索，根节点的槽中存放了指向子节点的指针，存储引擎根据这些指针向下查找，通过比较节点页的值和要查找的值可以找到合适指针进入下层子节点，这些指针实际上定义了子节点页中值的上线和下限。</p>
<p>最终存储引擎要么找到对应的额值，要么记录不存在。</p>
<h4 id="索引对如下类型查询有效"><a href="#索引对如下类型查询有效" class="headerlink" title="索引对如下类型查询有效"></a>索引对如下类型查询有效</h4><ul>
<li><p>全值匹配</p>
</li>
<li><p>匹配最左前缀</p>
</li>
<li><p>匹配列前缀 </p>
</li>
<li><p>匹配范围值</p>
</li>
<li><p>精确匹配某一列并匹配范围外的另外一列</p>
</li>
<li><p>只访问索引的查询</p>
</li>
</ul>
<h4 id="B-tree索引的限制"><a href="#B-tree索引的限制" class="headerlink" title="B-tree索引的限制"></a>B-tree索引的限制</h4><ul>
<li><p>如果不是按照索引的最左列开始查找，则无法使用索引；</p>
</li>
<li><p>不能跳过索引中的列，如果不指定索引名字，在mysq只能使用索引的第一列；</p>
</li>
<li><p>如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引优化查询，如：where last_name=’AD’ and first_name like ‘J%’ and dob = ‘1976-12-23’,只能使用索引的前两列；</p>
</li>
</ul>
<h3 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h3><p>哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个hash码。hash索引将所有的hash码存储在索引中，hash表中存储指向每个数据行的指针。</p>
<p>在mysql中，只有memory引擎显示支持hash索引，也是memory引擎的默认引擎。</p>
<p>memory引擎过是支持非唯一hash索引的，这在数据库中与众不同。如果多列的hash值相同，索引会以链表的方式存放多个记录指针在同一个hash条目中。</p>
<h4 id="hash索引的限制"><a href="#hash索引的限制" class="headerlink" title="hash索引的限制"></a>hash索引的限制</h4><ul>
<li><p>hash索引只包含hash值和行指针，而不存储字段，所以不能使用索引中的值来避免读取行；</p>
</li>
<li><p>hash索引数据并不是按照索引值顺序存储，所以也就无法用于排序；</p>
</li>
<li><p>hash索引也不支持部分索引列匹配查找，所以hash索引始终是使用索引列的全部内容来计算hash值的。</p>
</li>
<li><p>hash索引只是支持等值比较查询，不支持范围查询；</p>
</li>
<li><p>访问hash索引的顺序非常快，除非有很多hash冲突。当出现hash冲突的时候，存储引擎必须遍历链表中的所有行指针，逐行进行比较，直到找到所有符合条件的才可以。</p>
</li>
<li><p>如果hash冲突很多的话，一些索引维护的代价也会很高；</p>
</li>
</ul>
<p>由于以上的限制，hash索引只是适合特定的场合，一旦适合hash索引，它带来的性能提升非常明显。</p>
<p>innodb引擎有一个特殊的功能叫做‘自适应hash索引’，当innoDB注意到某些索引使用的非常频繁时，它会在B-Tree索引的基础上再创建一个hash索引，这样就让B-Tree索引页具有hash索引的一些优点，比如快速的hash查找。</p>
<p><strong>自定义hash索引</strong>：如果存储一个url，可以存储一个url和hash码，查询时执行如下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select id from url_table where url &#x3D; &quot;http:&#x2F;&#x2F;www.mysql.com&quot; and url_crc &#x3D; CRC32(&quot;http:&#x2F;&#x2F;www.mysql.com&quot;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这样性能会非常高，mysql优化性很高而体积很小的基于url_crc列的索引来查找。</p>
<p>缺陷是需要手动维护hash值，不过可以使用触发器实现；</p>
<h3 id="空间数据索引"><a href="#空间数据索引" class="headerlink" title="空间数据索引"></a>空间数据索引</h3><p>MylSAM 表支持空间索引，可以用作地理数据存储。mysql的gis支持不完善，所以大部分不适用这个特性。</p>
<h3 id="全文索引"><a href="#全文索引" class="headerlink" title="全文索引"></a>全文索引</h3><p>全文索引是一种特殊类型的索引，它查找的是文中的关键词，而不是直接比较索引中的值。全文索引和其他几类索引的匹配方式完全不一样。</p>
<h3 id="其它索引类别"><a href="#其它索引类别" class="headerlink" title="其它索引类别"></a>其它索引类别</h3><h1 id="索引的优点"><a href="#索引的优点" class="headerlink" title="索引的优点"></a>索引的优点</h1><p>索引可以让服务器快速定位到表的指定位置，而且由于索引的数据结构不同，索引也有一些其它的附加作用。</p>
<h2 id="优点如下："><a href="#优点如下：" class="headerlink" title="优点如下："></a>优点如下：</h2><ul>
<li>索引大大减小了服务器需要扫描的数据量；</li>
<li>索引可以帮助服务器避免排序和临时表；</li>
<li>索引可以将随机IO变为顺序IO；</li>
</ul>
<h1 id="高性能的索引策略"><a href="#高性能的索引策略" class="headerlink" title="高性能的索引策略"></a>高性能的索引策略</h1><h2 id="独立的列"><a href="#独立的列" class="headerlink" title="独立的列"></a>独立的列</h2><p>独立的列是指不能是表达式的一部分。</p>
<ul>
<li>下列的表达式不能使用actor_id列的索引。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">select actor_id from actor_table where actor_id +1 &#x3D; 5;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>以下是另一个常见的错误,使用不到DATE_COL列的索引；</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from TO_DAYS(CURRENT_DATE) - TO_DAYS(DATE_COL) &lt;&#x3D;10;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="前缀索引和索引的选择性"><a href="#前缀索引和索引的选择性" class="headerlink" title="前缀索引和索引的选择性"></a>前缀索引和索引的选择性</h2><ul>
<li><p>索引比较长的字符串，模拟hash索引是一个策略。通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率，但这样也会降低索引的选择性。索引的选择性越高则查询效率越高。</p>
</li>
<li><p>索引的选择性是指不重复的索引值和数据表的记录总数的比值。</p>
</li>
<li><p>前缀索引的缺点：无法使用前缀索引做order by和 group by，也无法使用前缀索引做覆盖扫描。</p>
</li>
<li><p>对于blob和text的字符串类型的列，必须使用前缀索引，因为mysql不允许索引这些列的完整长度。</p>
</li>
</ul>
<p>1.前缀选择时需要做测试,可以一直增加前缀长度，至到前缀的选择性接近完整列的选择性。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select count(*) as cnt, LEFT(city,3) as pref from sakil.city_demo group by pref order by cnt desc limit 10;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.计算合适的前缀长度的另外一个办法是计算完整列的选择性，并使得前缀的选择性接近于完整列的选择性。通常接近于0.031就可以用了.最坏的情况，平均选择性如果是4或5的索引已经足够了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select count(distinct LEFT(city,3))&#x2F;count(*) from sakila.city_demo;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="多列索引"><a href="#多列索引" class="headerlink" title="多列索引"></a>多列索引</h2><p>比较错误的多列索引使用方法：为每个列创建独立的索引，或者按照错误的顺序创建多列索引；</p>
<p>MySQL会对索引做优化，将多个单列的索引做优化合并，但更多时候说明了表上的索引建的很糟糕。</p>
<ul>
<li><p>当出现服务器对多个索引做相交操作时（通常有多个AND条件），通常意味着需要一个包含多个相关列的多列索引，而不是多个独立的单列索引；</p>
</li>
<li><p>当服务器需要多个索引做联合操作时（通常有多个OR条件），通常消耗大量的CPU和内存资源在算法的缓存、排序和合并操作上，</p>
</li>
</ul>
<h2 id="选择合适的索引顺序"><a href="#选择合适的索引顺序" class="headerlink" title="选择合适的索引顺序"></a>选择合适的索引顺序</h2><p>正确的顺序依赖于使用该索引的查询，并且同时需要考虑满足排序和分组的需要。</p>
<p>在一个多列B-Tree索引中，索引列的顺序意味着索引首先按照最左列进行排序。其次是第二列。</p>
<p>在不考虑排序和分组时，将选择性最高的列放到索引的最前列是很好的。这时候索引的作用只是优化where条件的查询。</p>
<h3 id="查询例子："><a href="#查询例子：" class="headerlink" title="查询例子："></a>查询例子：</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select sum(staff_id &#x3D;2),sum(customer_id &#x3D; 584) from payment ;</span><br><span class="line"></span><br><span class="line">sum(staff_id):7922</span><br><span class="line"></span><br><span class="line">sum(customer_id):30</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>根据前面的经验，customer_id应该放到前面，因为对应条件值的customer_id数量更小。</p>
<p>或者判断选择性更高的 customer_id，所以选择customer_id在最前面。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select count(distinct staff_id)&#x2F;count(*) as staff_id_selectvity,count(distinct customer_id)&#x2F;count(*) as customer_id_selectvity, count(*) from payment</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h2><p>聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。具体的细节依赖于其实现方式，但innoDB的聚簇索引实际上在同一个结构中保存了B-Tree索引和数据行。</p>
<p>当表有聚簇索引时，它的数据实际上存放在索引的叶子页中。术语‘聚簇’表示数据行和相邻的键值紧凑的存储在一起。因为无法同事把数据航存放在两个不同的地方，所以一个表只能有一个聚簇索引。</p>
<p>因为存储引擎负责实现索引，因此不是所有的存储引擎都支持聚簇索引。innoDB是支持聚簇索引的。</p>
<h3 id="聚簇索引的优点"><a href="#聚簇索引的优点" class="headerlink" title="聚簇索引的优点"></a>聚簇索引的优点</h3><ul>
<li><p>可以把相关数据保存在一起，例如实现电子邮箱时，可以根据用户id来聚集数据，这样可以从磁盘读取很少的数据也就能获取某个用户的全部邮件，如果没有使用聚簇索引，每封邮件都可能导致一次磁盘IO。</p>
</li>
<li><p>数据访问更快，聚簇索引将索引和数据保存在一个B-Tree中，因此从聚簇索引中获取数据通常比在非聚簇索引中查找更快；</p>
</li>
<li><p>使用覆盖索引扫描的查询可以直接使用页节点中的主键值；</p>
</li>
</ul>
<h3 id="聚簇索引的缺点"><a href="#聚簇索引的缺点" class="headerlink" title="聚簇索引的缺点"></a>聚簇索引的缺点</h3><ul>
<li><p>极大提高了IO密集型的应用的性能，<strong>但是如果数据全部放在内存中</strong>，则访问顺序就没那么重要了，聚簇索引也就没有优势了；</p>
</li>
<li><p>插入速度严重依赖于插入顺序，按照主键的顺序插入到innoDB表中速度最快，如果不是按照主键顺序加载数据，则加载完后最好使用optimize table命令重新组织一下表；</p>
</li>
<li><p>更新聚簇索引的代价很高，因为会强制innoDB将每个更新的行移动到新的位置；</p>
</li>
<li><p>聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于分裂导致数据存储不连续的时候；</p>
</li>
<li><p>非聚簇索引可能比想象的要更大，因为在非聚簇索引的叶子节点包含了引用行的主键列；</p>
</li>
<li><p>二级索引访问需要两次索引查找，而不是一次，因为二级索引的叶子节点存储的的不是行指针，而是主键值；</p>
</li>
</ul>
<p><img src="/images/mysql/%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E5%92%8C%E9%9D%9E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E7%9A%84%E5%AF%B9%E6%AF%94%E5%9B%BE.png" alt="聚簇索引和非聚簇索引的对比图"></p>
<h2 id="在innoDB表中按主键顺序插入行或UUID最为主键"><a href="#在innoDB表中按主键顺序插入行或UUID最为主键" class="headerlink" title="在innoDB表中按主键顺序插入行或UUID最为主键"></a>在innoDB表中按主键顺序插入行或UUID最为主键</h2><p>使用自增主键（顺序的），避免随机的（不连续且值的分布范围非常大）聚簇索引，特别是对于IO密集型的应用。从性能角度考虑，使用UUID作为聚簇索引则会很糟糕。它使得聚簇索引的插入变得随机。</p>
<p>使用自增主键，因为主键的值是顺序的，所以innoDB把每一条记录都存储在上一条记录的后面。当达到页的最大填充因子时，下一条记录会被写入新的页中。</p>
<p>使用UUID作为聚簇索引插入新的行时，因为新行的主键值不一定比之前插入的大，所以innoDB无法简单地总是把新行插入到碎银的后面，而是需要为新的俄航寻找合适的位置，通常是使用已有数据的中间位置，并分配空间，这回增减很多额外的工作，导致数据部分不够优化；</p>
<ul>
<li>使用UUID作为聚簇索引的缺点</li>
</ul>
<p>1.写入的目标页可能已经刷到磁盘上并从缓存中溢出，或者是没有被加载到缓存中，innoDB在插入之前不得不先找到并从磁盘读取目标页到内存中，这<strong>导致大量的随机IO</strong>；<br>2.因为写入是乱序的，<strong>innoDB不得不频繁的做页分裂操作</strong>，以便为新的行分配空间。页分裂导致移动大量的数据，一次插入最少需要更改三个页而不是一个页；<br>3.由于频繁的页分裂，页会变得洗漱并被不规则的填充，最终<strong>数据会有碎片</strong>；</p>
<h2 id="顺序的主键什么时候回造成更坏的结果"><a href="#顺序的主键什么时候回造成更坏的结果" class="headerlink" title="顺序的主键什么时候回造成更坏的结果"></a>顺序的主键什么时候回造成更坏的结果</h2><p>对于高并发的的工作负载，在innoDB中按照主键插入会造成明显的争用。</p>
<h2 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h2><p>如果索引的叶子节点中已经包含要查询的数据，就不需要再回表查询。如果一个索引包含所有需要查询的字段的值，我们就称之为覆盖索引。</p>
<h3 id="覆盖索引的好处（不需要回表查询）"><a href="#覆盖索引的好处（不需要回表查询）" class="headerlink" title="覆盖索引的好处（不需要回表查询）"></a>覆盖索引的好处（不需要回表查询）</h3><ul>
<li><p>索引条目通常远小于数据行大小，所以如果只需要读取索引，那么mysql会极大的减少数据访问量。</p>
</li>
<li><p>因为索引是按照列值顺序存储的（至少单个页内是如此），所以IO密集型的查询范围查询会比随机从磁盘读取每一行数据的IO少得多。</p>
</li>
<li><p>一些存储引擎入MySAM在内存中只缓存索引，数据则依赖于操作系统来缓存，因此访问数据需要一次系统调用，这回导致严重的性能问题。</p>
</li>
<li><p>由于innoDB的聚簇索引，覆盖索引对innoDB表特别有用，innoDB的二级索引在叶子节点保存了行的主键索引，如果二级主键能够覆盖查询，可以避免对主键索引的二次查询。</p>
</li>
</ul>
<h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>不是所有的类型的索引都可以成为覆盖索引，覆盖索引必须要存储索引列的值，而hash索引、空间索引、全文索引都不存储索引列的值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select store_id,film_id from sakila.inventory;</span><br></pre></td></tr></table></figure>
<p>如表inventory中有一个多列索引（store_id,film_id）。mysql 如果只是需要访问这两列，就可以使用这个索引做覆盖索引；</p>
<p><img src="/images/mysql/%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BD%BF%E7%94%A8.png" alt="覆盖索引的使用"></p>
<p>在extra列显示 using index,而不是type列的index。</p>
<h2 id="使用索引扫描来做排序"><a href="#使用索引扫描来做排序" class="headerlink" title="使用索引扫描来做排序"></a>使用索引扫描来做排序</h2><p>mysql有两种方式可以生成有序的结果，通过排序操作；或者通过索引顺序扫描。如果mysql使用explain处理啊的type值为index，则说明mysql使用了索引扫描来做排序。</p>
<p>扫描本身很快，只需要从一条索引到下一条记录，但是如果索引不能覆盖查询的所有列，那就不得不每扫描一条索引记录就都回表查询一次。</p>
<ul>
<li><p>如果查询需要关联多张表，则只有order by 子句引用的字段全部为第一张表时，才可以使用索引做排序。</p>
</li>
<li><p>即使order by子句不满足索引的最左前缀的要求，也可以用于查询排序，这是因为索引的第一列被指定为一个常数。</p>
</li>
</ul>
<p><img src="/images/mysql/orderBy%E7%9A%84%E8%A1%A8.png" alt="orderBy的表"></p>
<p><img src="/images/mysql/%E9%9D%9E%E6%9C%80%E5%B7%A6%E7%B4%A2%E5%BC%95-%E7%9A%84orderBy%E5%AD%90%E5%8F%A5.png" alt="非最左索引-的orderBy子句"></p>
<p><img src="/images/mysql/%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E7%B4%A2%E5%BC%95%E5%81%9A%E6%8E%92%E5%BA%8F%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt="不能使用索引做排序的例子"></p>
<h2 id="冗余和重复索引"><a href="#冗余和重复索引" class="headerlink" title="冗余和重复索引"></a>冗余和重复索引</h2><p>mysql是允许在相同的列上创建多个索引，无论是有意义的还是无意义的，mysql需要单独维护重复的索引。</p>
<p>重复索引是指在相同的列上按照相同的顺序创建相同类型的索引，应该避免创建重复索引。</p>
<p>冗余索引和重复索引有一些不同，如果创建了索引（A，B）,在创建索引（A）就是冗余索引，因为这只是前一个索引的前缀索引。如果创建索引（B,A）就不是冗余索引，索引（B）也不是。</p>
<h3 id="冗余索引的情况"><a href="#冗余索引的情况" class="headerlink" title="冗余索引的情况"></a>冗余索引的情况</h3><p>有人可能会增加一个新的索引（A,B）,而不是扩展已有的索引（A）。还有一种情况是扩展为（A,ID）,其中ID是主键，对于innoDB来说，主键列已经包含在二级索引中了，这也是冗余索引。</p>
<p><img src="/images/mysql/%E9%9C%80%E8%A6%81%E5%86%97%E4%BD%99%E7%B4%A2%E5%BC%95%E7%9A%84%E6%83%85%E5%86%B5.png" alt="需要冗余索引的情况"></p>
<p>有两个索引的缺点就是维护成本更高。插入数据需要的时间大大增加。</p>
<h2 id="索引和锁"><a href="#索引和锁" class="headerlink" title="索引和锁"></a>索引和锁</h2><p>索引可以让查询锁定更少的行，如果你的查询从来不访问那些不需要的行，那么就可以锁定更少的行。锁定行仍然会带来额外的开销，而且锁定超过需要的行会增加锁争用并减少并发性；</p>
<p>innoDB只有在访问行的时候才会对其加锁，而索引能够见啥innoDB访问的行数，从而减少锁的数量，但这只有当innoDB在存储引擎层能够过滤掉所有不需要的行时才有效。如果索引无法过滤掉无效的行，那么在innoDB检索到数据返回给服务器层时，mysql服务器才会应用where子句，这时候已经无法避免应用where子句。</p>
<h1 id="索引案例学习"><a href="#索引案例学习" class="headerlink" title="索引案例学习"></a>索引案例学习</h1><p><img src="/images/mysql/%E7%B4%A2%E5%BC%95%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0%E9%9C%80%E6%B1%82.png" alt="索引案例学习需求"></p>
<h2 id="支持多种过滤条件"><a href="#支持多种过滤条件" class="headerlink" title="支持多种过滤条件"></a>支持多种过滤条件</h2><p>哪些列在where子句中出现的最频繁，在有更多的不同值的列上创建索引的选择性会更好。</p>
<p>country列的选择性通常不高，但是很多查询用到，sex的选择性更低，但是很多查询中也会用到。建议将（sex，country）列作为前缀。</p>
<ul>
<li>正常情况下是把选择性更高的字段放前面。因为几乎所有的查询都会用到sex字段。也可以使用in（‘male’，‘female’）让mysql来进行选择。所以可以使用（sex，country）作为索引。</li>
</ul>
<p><strong>索引设计的基本原则</strong></p>
<p>当设计索引时，不要只为现有的查询考虑需要哪些索引，还要考虑对查询进行优化。如果发现某些查询需要创建新的索引时，但是这个索引优惠降低另外一些的查询效率，那么应该考虑优化原来的查询。</p>
<ul>
<li><p>考虑where条件组合，并了解哪些索引在没有合适的索引的情况下会很慢。</p>
</li>
<li><p>age一般是范围查询的，所以age可以放到最后。可以使用IN来代替范围查询。尽可能的将范围查询的列放到索引的后面，以便优化器可以使用更多的列。</p>
</li>
</ul>
<h2 id="避免多个范围条件"><a href="#避免多个范围条件" class="headerlink" title="避免多个范围条件"></a>避免多个范围条件</h2><p>范围条件 actor_id&gt;45, explain 的type是range类型；in（2，3，4）是列表条件，explain 的type也是range类型。</p>
<p>第一个是范围条件，第二个是多个等值条件查询。<strong>对于范围条件，mysql无法再使用范围列后面的其他索引列了，但是对于多个等值条件查询则没有这个限制。</strong></p>
<p><img src="/images/mysql/%E5%A4%9A%E4%B8%AA%E8%8C%83%E5%9B%B4%E6%9D%A1%E4%BB%B6%E7%9A%84%E4%BE%8B%E5%AD%90.png" alt="多个范围条件的例子"></p>
<p>上述查询有2个范围条件，last_online列和age列。可以使用一个它们中的一个索引，但是无法同事使用。</p>
<h2 id="优化排序"><a href="#优化排序" class="headerlink" title="优化排序"></a>优化排序</h2><p>优化大量翻页的排序的一种方法是限制用户能够翻页的数量；另一种是使用延迟关联，可以使用覆盖索引去查询返回需要的主键，再根据主键关联原表获得需要的行。</p>
<h1 id="维护索引和表"><a href="#维护索引和表" class="headerlink" title="维护索引和表"></a>维护索引和表</h1><p>即使使用争取的类型创建了表并加上合适的索引，工作也没有结束，还需要维护表和索引来确保他们都正常工作。维护表主要有三个目的：找到并修复损坏的表，维护准确的索引统信息，减少碎片。</p>
<h2 id="找到并修复损坏的表"><a href="#找到并修复损坏的表" class="headerlink" title="找到并修复损坏的表"></a>找到并修复损坏的表</h2><p>索引损坏会发生一些奇怪的问题，可以使用check table命令来检查是否发生了表损坏，可以使用repair table命令来修复损坏的表，但同样不是所有的存储引擎都支持该命令。可以使用数据备份然后重新导入，如果不是索引损坏了那么就没有用了。</p>
<p>如果数据损坏，最重要的是找出是什么导致了损坏，而不是简单的修复。</p>
<h2 id="更新索引统计信息"><a href="#更新索引统计信息" class="headerlink" title="更新索引统计信息"></a>更新索引统计信息</h2><p>mysql的查询优化器会通过两个API来了解存储引擎的索引值的分布信息，以决定如何使用索引。</p>
<p>1.第一个是records_in_range(),通过向存储引擎传入两个边界值来获取这个范围大概有多少记录。这对于InnoDB来说会返回估算值，而MylSAM会返回精确值；<br>2.第二个是info（），该接口返回各种类型的数据，包括索引的基数（每个键值有多少记录）。</p>
<p>如果统计信息有误或者不准确，优化器可能会做出错误的决定，可以通过使用analyze table来重新生成统计信息来解决问题。</p>
<p>不同的存储引擎对统计信息的存储时不同的，memory引擎根本不存储索引统计信息；mylSAM将索引统计信息存储在磁盘，analyze table需要全索引扫面，且整个过程锁表；innoDB不在磁盘存储索引统计信息，而是通过随机访问进行评估并存储在内存中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; SHOW INDEX FROM t_sys;</span><br><span class="line">+-------+------------+----------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| Table | Non_unique | Key_name       | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |</span><br><span class="line">+-------+------------+----------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| t_sys |          0 | PRIMARY        |            1 | id          | A         |          33 | NULL     | NULL   |      | BTREE      |         |               |</span><br><span class="line">| t_sys |          0 | unique_app_id  |            1 | app_id      | A         |          31 | NULL     | NULL   | YES  | BTREE      |         |               |</span><br><span class="line">| t_sys |          1 | index_sys_name |            1 | sys_name    | A         |          32 | NULL     | NULL   |      | BTREE      |         |               |</span><br><span class="line">+-------+------------+----------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Cardinality是索引列的基数，显示了存储引擎估算索引列有多少个不同的值。</p>
<h2 id="减少索引和数据的碎片"><a href="#减少索引和数据的碎片" class="headerlink" title="减少索引和数据的碎片"></a>减少索引和数据的碎片</h2><p>B-Tree索引可能会碎片化，这会降低查询的效率。碎片化的索引可能会以很差或者无序的方式存储在磁盘上。</p>
<p>表数据的碎片化分为三种：行碎片、行间碎片、剩余空间碎片；</p>
<ul>
<li><p>行碎片：这种碎片指的是数据行被存储在多个地方的多个片段中，及时查询只从索引中范文一行记录，行碎片也会导致性能下降；</p>
</li>
<li><p>行间碎片：行间碎片是指逻辑上顺序的页，或者行在磁盘上不是顺序存储的。行间碎片对诸如全表扫描和聚簇索引扫描之类的操作有很大影响，因为这些操作原本能够从磁盘上顺序存储的数据中获益。</p>
</li>
<li><p>剩余空间碎片：剩余空间碎片是指数据页中有大量的空余空间，这会导致服务器读取大量不需要的数据，从而造成浪费。</p>
</li>
</ul>
<p>对于MylSAM表，这三类碎片都会发生。但是innoDB不会出现短小的行碎片，innoDB会移动短小的行并重新写到一个片段中。</p>
<p><strong>处理办法</strong></p>
<p>可以通过执行 optimize table或者导出在导入的方式来整理数据，这对大多数存储引擎是有效的。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>1.大部分情况下都会使用B-tree索引，其它的索引只适合特殊的目的。</p>
<p>2.在选择和编写利用这些索引的查询时，有如下三个原则需要记住：</p>
<p><img src="/images/mysql/%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9A%84%E4%B8%89%E4%B8%AA%E5%8E%9F%E5%88%99.png" alt="创建索引的三个原则"></p>
<p>编写查询语句时尽可能的选择合适的索引以避免单行查找、尽可能的使用数据原生顺序从而避免额外的排序操作、尽可能使用索引覆盖查询；</p>
<p>3.没有完美的索引时，需要创建大量的索引，（两个列，一个是正序，一个是倒叙，不能达到三星索引）。必须有所取舍选择合适的索引。</p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql索引</tag>
      </tags>
  </entry>
  <entry>
    <title>《SQL基础》SQL学习指南学习笔记二 查询入门 过滤 多表查询</title>
    <url>/2017-11-10/SQL%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C%20%E6%9F%A5%E8%AF%A2%E5%85%A5%E9%97%A8%20%E8%BF%87%E6%BB%A4%20%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2/</url>
    <content><![CDATA[<h2 id="查询机制"><a href="#查询机制" class="headerlink" title="查询机制"></a>查询机制</h2><p>当使用如下命令连接上数据库后，会提示你的connecttion id 是多少。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~$ mysql -u lrngsql -p </span><br><span class="line">Enter password: </span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 4</span><br><span class="line">Server version: 5.7.20 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2017, Oracle and&#x2F;or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and&#x2F;or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在执行你的语句之前，要进行以下验证</p>
<ul>
<li>用户是否有权限执行以下语句；</li>
<li>用户是否有权限访问目标数据；</li>
<li>语句的语法是否正确；</li>
</ul>
<p>通过了以上测试，语句会传递给查询优化器（负责查询到最有效率的执行方式），之后执行查询。</p>
<h2 id="查询语句"><a href="#查询语句" class="headerlink" title="查询语句"></a>查询语句</h2><p>查询语句由以下子句组成</p>
<ul>
<li>select： 确定结果集中应该包含哪些列。</li>
<li>from：指明所要提取数据的表，以及这些表时如何连接的。</li>
<li>where：过滤不需要的表。</li>
<li>group by ：用于对具有相同列值的行进行分组。</li>
<li>having：过滤不需要的组。</li>
<li>order by：按一个或者多个列，对最后的结果集中的行进行排序。</li>
</ul>
<h3 id="select子句"><a href="#select子句" class="headerlink" title="select子句"></a>select子句</h3><p>该子句用于在所有的可能的列中，选择查询结果集包包含哪些列。<br>在该子句中可以包括字符串、表达式、内建函数等。</p>
<p>例子如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; select emp_id,&#39;active&#39;,emp_id*3.14159,upper(lname) from employee;</span><br><span class="line">+--------+--------+----------------+--------------+</span><br><span class="line">| emp_id | active | emp_id*3.14159 | upper(lname) |</span><br><span class="line">+--------+--------+----------------+--------------+</span><br><span class="line">|      1 | active |        3.14159 | SMITH        |</span><br><span class="line">|      2 | active |        6.28318 | BARKER       |</span><br><span class="line">|      3 | active |        9.42477 | TYLER        |</span><br><span class="line">|      4 | active |       12.56636 | HAWTHORNE    |</span><br><span class="line">|      5 | active |       15.70795 | GOODING      |</span><br><span class="line">|      6 | active |       18.84954 | FLEMING      |</span><br><span class="line">|      7 | active |       21.99113 | TUCKER       |</span><br><span class="line">|      8 | active |       25.13272 | PARKER       |</span><br><span class="line">|      9 | active |       28.27431 | GROSSMAN     |</span><br><span class="line">|     10 | active |       31.41590 | ROBERTS      |</span><br><span class="line">|     11 | active |       34.55749 | ZIEGLER      |</span><br><span class="line">|     12 | active |       37.69908 | JAMESON      |</span><br><span class="line">|     13 | active |       40.84067 | BLAKE        |</span><br><span class="line">|     14 | active |       43.98226 | MASON        |</span><br><span class="line">|     15 | active |       47.12385 | PORTMAN      |</span><br><span class="line">|     16 | active |       50.26544 | MARKHAM      |</span><br><span class="line">|     17 | active |       53.40703 | FOWLER       |</span><br><span class="line">|     18 | active |       56.54862 | TULMAN       |</span><br><span class="line">+--------+--------+----------------+--------------+</span><br><span class="line">18 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>如果只是执行内置函数，就不需要加后面的子句。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; select version(),user(),database();</span><br><span class="line">+-----------+----------+------------+</span><br><span class="line">| version() | user()   | database() |</span><br><span class="line">+-----------+----------+------------+</span><br><span class="line">| 5.7.20    | lrngsql@ | bank       |</span><br><span class="line">+-----------+----------+------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="列的别名"><a href="#列的别名" class="headerlink" title="列的别名"></a>列的别名</h4><ul>
<li>列的别名,可以在查询的字段后使用 as 或者直接在列后添加别名。为了增加可读性，建议添加as关键字。</li>
</ul>
<p>例子如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; select emp_id,&#39;active&#39; as active,emp_id*3.14159 as empid_x_pi,upper(lname) as last_name_upper from employee;</span><br><span class="line">+--------+--------+------------+-----------------+</span><br><span class="line">| emp_id | active | empid_x_pi | last_name_upper |</span><br><span class="line">+--------+--------+------------+-----------------+</span><br><span class="line">|      1 | active |    3.14159 | SMITH           |</span><br><span class="line">|      2 | active |    6.28318 | BARKER          |</span><br><span class="line">|      3 | active |    9.42477 | TYLER           |</span><br><span class="line">|      4 | active |   12.56636 | HAWTHORNE       |</span><br><span class="line">|      5 | active |   15.70795 | GOODING         |</span><br><span class="line">|      6 | active |   18.84954 | FLEMING         |</span><br><span class="line">|      7 | active |   21.99113 | TUCKER          |</span><br><span class="line">|      8 | active |   25.13272 | PARKER          |</span><br><span class="line">|      9 | active |   28.27431 | GROSSMAN        |</span><br><span class="line">|     10 | active |   31.41590 | ROBERTS         |</span><br><span class="line">|     11 | active |   34.55749 | ZIEGLER         |</span><br><span class="line">|     12 | active |   37.69908 | JAMESON         |</span><br><span class="line">|     13 | active |   40.84067 | BLAKE           |</span><br><span class="line">|     14 | active |   43.98226 | MASON           |</span><br><span class="line">|     15 | active |   47.12385 | PORTMAN         |</span><br><span class="line">|     16 | active |   50.26544 | MARKHAM         |</span><br><span class="line">|     17 | active |   53.40703 | FOWLER          |</span><br><span class="line">|     18 | active |   56.54862 | TULMAN          |</span><br><span class="line">+--------+--------+------------+-----------------+</span><br><span class="line">18 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="去除重复行"><a href="#去除重复行" class="headerlink" title="去除重复行"></a>去除重复行</h4><p>去除重复行，可以使用distinct关键字。注意 ** 产生无重复结果集需要首先对数据进行排序 ,这对于大的结果是相当耗时的。因此当有需求时再使用DISTINCT关键字，否则没必要。 **</p>
<h3 id="from-子句"><a href="#from-子句" class="headerlink" title="from 子句"></a>from 子句</h3><p>from子句定义了查询中所使用的表，以及连接这些表的方式。</p>
<p>表的概念:</p>
<ul>
<li>永久表（create table语句创建的表）;</li>
</ul>
<p>从表中查询数据时，可以在表名后加 as 别名 为表添加一个实例的别名。</p>
<ul>
<li>临时表（子查询所返回的表）；</li>
</ul>
<p>子查询可以出现在select语句中的各个部分，并且别包含在圆括号中。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select e.emp_id,e.fname,e.lname from (select emp_id,fname,lname,start_date,title from employee) e;</span><br><span class="line">+--------+----------+-----------+</span><br><span class="line">| emp_id | fname    | lname     |</span><br><span class="line">+--------+----------+-----------+</span><br><span class="line">|      1 | Michael  | Smith     |</span><br><span class="line">|      2 | Susan    | Barker    |</span><br><span class="line">|      3 | Robert   | Tyler     |</span><br><span class="line">|      4 | Susan    | Hawthorne |</span><br><span class="line">|      5 | John     | Gooding   |</span><br><span class="line">|      6 | Helen    | Fleming   |</span><br><span class="line">|      7 | Chris    | Tucker    |</span><br><span class="line">|      8 | Sarah    | Parker    |</span><br><span class="line">|      9 | Jane     | Grossman  |</span><br><span class="line">|     10 | Paula    | Roberts   |</span><br><span class="line">|     11 | Thomas   | Ziegler   |</span><br><span class="line">|     12 | Samantha | Jameson   |</span><br><span class="line">|     13 | John     | Blake     |</span><br><span class="line">|     14 | Cindy    | Mason     |</span><br><span class="line">|     15 | Frank    | Portman   |</span><br><span class="line">|     16 | Theresa  | Markham   |</span><br><span class="line">|     17 | Beth     | Fowler    |</span><br><span class="line">|     18 | Rick     | Tulman    |</span><br><span class="line">+--------+----------+-----------+</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这是一个不是使用的例子，但可以表示临时表的用处。</p>
<ul>
<li>虚拟表 （使用create view子句所创建的视图）</li>
</ul>
<p>视图时存储在数据字典中的查询。它的行为表现的像一个表，但实际上并不是一个表。当查询视图时，该查询会被绑定到视图定义上。</p>
<p>视图的作用：</p>
<ul>
<li>用户隐藏列，简化数据库设计。</li>
</ul>
<p>如下例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 创建视图</span><br><span class="line">mysql&gt; create view employee_vw  as select emp_id,fname,lname,year(start_date) start_year from employee;</span><br><span class="line">Query OK, 0 rows affected (0.05 sec)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;查询视图</span><br><span class="line">mysql&gt; SELECT * from employee_vw;</span><br><span class="line">+--------+----------+-----------+------------+</span><br><span class="line">| emp_id | fname    | lname     | start_year |</span><br><span class="line">+--------+----------+-----------+------------+</span><br><span class="line">|      1 | Michael  | Smith     |       2001 |</span><br><span class="line">|      2 | Susan    | Barker    |       2002 |</span><br><span class="line">|      3 | Robert   | Tyler     |       2000 |</span><br><span class="line">|      4 | Susan    | Hawthorne |       2002 |</span><br><span class="line">|      5 | John     | Gooding   |       2003 |</span><br><span class="line">|      6 | Helen    | Fleming   |       2004 |</span><br><span class="line">|      7 | Chris    | Tucker    |       2004 |</span><br><span class="line">|      8 | Sarah    | Parker    |       2002 |</span><br><span class="line">|      9 | Jane     | Grossman  |       2002 |</span><br><span class="line">|     10 | Paula    | Roberts   |       2002 |</span><br><span class="line">|     11 | Thomas   | Ziegler   |       2000 |</span><br><span class="line">|     12 | Samantha | Jameson   |       2003 |</span><br><span class="line">|     13 | John     | Blake     |       2000 |</span><br><span class="line">|     14 | Cindy    | Mason     |       2002 |</span><br><span class="line">|     15 | Frank    | Portman   |       2003 |</span><br><span class="line">|     16 | Theresa  | Markham   |       2001 |</span><br><span class="line">|     17 | Beth     | Fowler    |       2002 |</span><br><span class="line">|     18 | Rick     | Tulman    |       2002 |</span><br><span class="line">+--------+----------+-----------+------------+</span><br><span class="line">18 rows in set (0.01 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="where子句"><a href="#where子句" class="headerlink" title="where子句"></a>where子句</h3><p>在结果集中过滤掉不需要的行。</p>
<p>当where子句中有多个条件时，可以使用AND或者OR进行连接。当混合使用不同的操作符时，开发者应当使用圆括号来分割成组的条件。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; select emp_id,fname,lname,start_date,title from employee where (title &#x3D;&#39;Head Teller&#39; AND start_date &gt;&#39;2003-01-01&#39;)  or (title&#x3D;&#39;Teller&#39; AND start_date &gt;&#39;2004-01-01&#39;);</span><br><span class="line">+--------+-------+---------+------------+-------------+</span><br><span class="line">| emp_id | fname | lname   | start_date | title       |</span><br><span class="line">+--------+-------+---------+------------+-------------+</span><br><span class="line">|      6 | Helen | Fleming | 2004-03-17 | Head Teller |</span><br><span class="line">|      7 | Chris | Tucker  | 2004-09-15 | Teller      |</span><br><span class="line">+--------+-------+---------+------------+-------------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="group-by子句和having子句"><a href="#group-by子句和having子句" class="headerlink" title="group by子句和having子句"></a>group by子句和having子句</h3><p>此例子是表示在服务器返回结果集之前对数据再一次进行提炼。</p>
<p>**where group by  和having的区别 ** </p>
<p><a href="http://blog.csdn.net/Shine_rise/article/details/54934242">参考</a>  该文章中最后两行是错误的，详细看下文中的执行顺序。</p>
<p>where：数据库中常用的是where关键字，用于在初始表中筛选查询。它是一个约束声明，用于约束数据，在返回结果集之前起作用。</p>
<p>group by：对select查询出来的结果集按照某个字段或者表达式进行分组（这里不能说明select语句时在group by中执行，<br>意思时说group by的字段必须在select的字段中存在。），获得一组组的集合，然后从每组中取出一个指定字段或者<br>表达式的值。 </p>
<p>在说group by的时候，我们还需要了解聚合函数，聚合函数是SQL语言中一种特殊的函数。例如：</p>
<ul>
<li>count(*)：获取数量</li>
<li>sum()：求和(这里要注意求和是忽略null值的，null与其他数值相加结果为null，所以可以通过ifnull(xxx,0)将null的值赋为0）</li>
<li>avg()：求平均数</li>
<li>max()：求最大值</li>
<li>min()：求最小值</li>
</ul>
<p>这些函数和其它函数的根本区别就是它们一般作用在多条记录上。<br>我们需要注意的是：在使用group by的SQL语句中，select中返回的字段，必须满足以下两个条件之一：(不太确定，欢迎讨论)</p>
<ul>
<li>包含在group by语句的后面，作为分组的依据；</li>
<li>这些字段包含在聚合函数中。</li>
</ul>
<p>having：用于对where和group by查询出来的分组经行过滤，查出满足条件的分组结果。它是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作。 </p>
<p><strong>所以having的使用需要注意以下几点：</strong></p>
<ul>
<li>having只能用于group by（分组统计语句中）分组包括显示分组group by 和隐式分组 如name =’张三’；</li>
<li>where 是用于在初始表中筛选查询，having用于在where和group by 结果分组中查询</li>
<li>having 子句中的每一个元素也必须出现在select列表中</li>
<li>having语句可以使用聚合函数，而where不使用。</li>
<li>where子句中不能使用聚合函数</li>
<li>当在包含group by子句的查询中增加过滤条件时，需要考虑过滤是针对原始数据（应该放在where子句中），还是针对分组后的数据（放到having子句中）</li>
</ul>
<p>回到开头的那个问题：当一个语句中同时含有where、group by 、having及聚集函数时，执行顺序如下：</p>
<p>执行where子句查找符合条件的数据；<br>使用group by 子句对数据进行分组；对group by 子句形成的组运行聚集函数计算每一组的值；<br>最后用having 子句去掉不符合条件的组，having处理的是分组数据，而不是原始数据。</p>
<p>需要注意的是:</p>
<ul>
<li>having 子句中的每一个元素也必须出现在select列表中。有些数据库例外，如oracle.</li>
<li>having子句和where子句都可以用来设定限制条件以使查询结果满足一定的条件限制。</li>
<li>having子句限制的是组，而不是行。where子句中不能使用聚集函数，而having子句中可以。</li>
</ul>
<p>在group by子句中使用with rollup修改后的查询</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select product_cd,open_branch_id,sum(avail_balance) tot_balance</span><br><span class="line">    -&gt; from account group by product_cd,open_branch_id with rollup;</span><br><span class="line">+------------+----------------+-------------+</span><br><span class="line">| product_cd | open_branch_id | tot_balance |</span><br><span class="line">+------------+----------------+-------------+</span><br><span class="line">| BUS        |              2 |     9345.55 |</span><br><span class="line">| BUS        |              4 |        0.00 |</span><br><span class="line">| BUS        |           NULL |     9345.55 |</span><br><span class="line">| CD         |              1 |    11500.00 |</span><br><span class="line">| CD         |              2 |     8000.00 |</span><br><span class="line">| CD         |           NULL |    19500.00 |</span><br><span class="line">| CHK        |              1 |      782.16 |</span><br><span class="line">| CHK        |              2 |     3315.77 |</span><br><span class="line">| CHK        |              3 |     1057.75 |</span><br><span class="line">| CHK        |              4 |    67852.33 |</span><br><span class="line">| CHK        |           NULL |    73008.01 |</span><br><span class="line">| MM         |              1 |    14832.64 |</span><br><span class="line">| MM         |              3 |     2212.50 |</span><br><span class="line">| MM         |           NULL |    17045.14 |</span><br><span class="line">| SAV        |              1 |      767.77 |</span><br><span class="line">| SAV        |              2 |      700.00 |</span><br><span class="line">| SAV        |              4 |      387.99 |</span><br><span class="line">| SAV        |           NULL |     1855.76 |</span><br><span class="line">| SBL        |              3 |    50000.00 |</span><br><span class="line">| SBL        |           NULL |    50000.00 |</span><br><span class="line">| NULL       |           NULL |   170754.46 |</span><br><span class="line">+------------+----------------+-------------+</span><br><span class="line">21 rows in set (0.01 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>对应着open_branch_id 为null的行即为对所有product_cd相同的行的合计。</p>
<p>**多个子句的执行顺序 **</p>
<p>SQL查询处理的步骤序号：</p>
<ol>
<li>FROM <left_table>  </li>
<li><join_type> JOIN <right_table> </li>
<li>ON <join_condition> </li>
<li>WHERE <where_condition> </li>
<li>GROUP BY <group_by_list>  （这个过程需要排序）</li>
<li>聚合函数 {CUBE | ROLLUP} </li>
<li>HAVING <having_condition> </li>
<li>SELECT  </li>
<li>DISTINCT   （这个过程需要排序）</li>
<li>ORDER BY <order_by_list></li>
<li>limit  <select_list></li>
</ol>
<p>以上每个步骤都会产生一个虚拟表，该虚拟表被用作下一个步骤的输入。这些虚拟表对调用者(客户端应用程序或者外部查询)不可用。只有最后一步生成的表才会会给调用者。如果没有在查询中指定某一个子句，将跳过相应的步骤。</p>
<p>逻辑查询处理阶段简介：</p>
<ol>
<li>FROM：对FROM子句中的前两个表执行笛卡尔积(交叉联接)，生成虚拟表VT1。</li>
<li>ON：对VT1应用ON筛选器，只有那些使为真才被插入到TV2。</li>
<li>OUTER (JOIN):如果指定了OUTER JOIN(相对于CROSS JOIN或INNER JOIN)，保留表中未找到匹配的行将作为外部行添加到VT2，生成TV3。如果FROM子句包含两个以上的表，则对上一个联接生成的结果表和下一个表重复执行步骤1到步骤3，直到处理完所有的表位置。</li>
<li>WHERE：对TV3应用WHERE筛选器，只有使为true的行才插入TV4。</li>
<li>GROUP BY：按GROUP BY子句中的列列表对TV4中的行进行分组，生成TV5。</li>
<li>聚合函数：把超组插入VT5，生成VT6。</li>
<li>HAVING：对VT6应用HAVING筛选器，只有使为true的组插入到VT7。</li>
<li>SELECT：处理SELECT列表，产生VT8。</li>
<li>DISTINCT：将重复的行从VT8中删除，产品VT9。</li>
<li>ORDER BY：将VT9中的行按ORDER BY子句中的列列表顺序，生成一个游标(VC10)。</li>
<li>limit：从VC10的开始处选择指定数量或比例的行，生成表TV11，并返回给调用者。</li>
</ol>
<h3 id="order子句"><a href="#order子句" class="headerlink" title="order子句"></a>order子句</h3><p>用于对结果集中的原始列数据或者根据列数据计算的表达式结果进行排序。</p>
<p>默认的 order by 字段A，对字段A进行升序排列（ASC），如果需要对数据将序排列，需要在字段后加DESC关键字。</p>
<p>如下例子：需要首先根据open_emp_id升序排列，然后根据product_cd进行降序排列。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; SELECT open_emp_id,product_cd FROM account ORDER BY open_emp_id,product_cd DESC;</span><br><span class="line">+-------------+------------+</span><br><span class="line">| open_emp_id | product_cd |</span><br><span class="line">+-------------+------------+</span><br><span class="line">|           1 | SAV        |</span><br><span class="line">|           1 | MM         |</span><br><span class="line">|           1 | MM         |</span><br><span class="line">|           1 | CHK        |</span><br><span class="line">|           1 | CHK        |</span><br><span class="line">|           1 | CHK        |</span><br><span class="line">|           1 | CD         |</span><br><span class="line">|           1 | CD         |</span><br><span class="line">|          10 | SAV        |</span><br><span class="line">|          10 | SAV        |</span><br><span class="line">|          10 | CHK        |</span><br><span class="line">|          10 | CHK        |</span><br><span class="line">|          10 | CD         |</span><br><span class="line">|          10 | CD         |</span><br><span class="line">|          10 | BUS        |</span><br><span class="line">|          13 | SBL        |</span><br><span class="line">|          13 | MM         |</span><br><span class="line">|          13 | CHK        |</span><br><span class="line">|          16 | SAV        |</span><br><span class="line">|          16 | CHK        |</span><br><span class="line">|          16 | CHK        |</span><br><span class="line">|          16 | CHK        |</span><br><span class="line">|          16 | CHK        |</span><br><span class="line">|          16 | BUS        |</span><br><span class="line">+-------------+------------+</span><br><span class="line">24 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h2><p>过滤查找条件可以分为 相等查找、不等条件、范围条件、成员条件和匹配条件。</p>
<p>其中范围查找中的 between and 查找需要注意：</p>
<ol>
<li>必须先制定范围的下限（在between后面），然后制定 范围的上限（在end后面），否则会查出空集合。</li>
<li>beeween and操作符是，包含边界值的。</li>
</ol>
<p>成员条件可以使用or关键字或者 in、not in关键字。</p>
<p>匹配条件是指使用通配符查找。</p>
<ol>
<li>正好匹配一个字符。使用 ‘_’</li>
<li>匹配任意数目的字符(包括0个)，使用’%’</li>
</ol>
<p>LIKE 操作符用于在 WHERE 子句中搜索列中的指定模式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">SELECT column_name(s)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE column_name LIKE pattern;</span><br><span class="line">例如：</span><br><span class="line">    like  ‘K% ’  表示以K开头的字符串。</span><br><span class="line">    like  &#39;%D&#39;  表示以D结尾的字符串。</span><br><span class="line">    like ‘_oogle’  表示以任一一个字符开始的，然后时oogle的字符串。如google</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="NULL关键字"><a href="#NULL关键字" class="headerlink" title="NULL关键字"></a>NULL关键字</h2><p>表示值的缺失：</p>
<ol>
<li>没有合适的值，比如ATM机上的自助交易并不需要employee ID列。</li>
<li>值未确定 比如在客户创建行的时候不知道他的id</li>
<li>值未定义 比如为某个还未添加到数据库的产品创建账户。</li>
</ol>
<p>注意：</p>
<ol>
<li>表达式可以为null，但是不能等于null </li>
<li>两个NUll值彼此不能判断为相等。</li>
</ol>
<p><strong>使用NULL时应注意：</strong></p>
<ul>
<li>普通的值一般都可能进行运算符操作,例如:ID列为int,所以可以这样:ID=ID+1等,但如果一列的值为null,<br>null+1=null,就是说null与任何运算符运算后都为null,这就是大家说的黑洞,会吃掉所有的东西.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update testNull</span><br><span class="line">set b&#x3D;b+1</span><br><span class="line">where b is null</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结论:查询后发现b的值没有变化,仍然为null.</p>
<ul>
<li>普通的值可以进行”=”操作,例如条件中一般都会这样出现:sUserName=’张三’,如果sUserName的值为null,<br>要想找出所有名字为null的记录时,不能这样用:sUserName=null,因为null不是一个具体的值,任何值与它比较<br>时都会返回false.此时可借用is null 或者是is not null.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from testNull where a&#x3D;null --返回空结果集</span><br><span class="line">select * from testNull where b is null --返回结果集 2 2 NULL</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结论:说明null是不能用”=”来比较,可用is null来替换</p>
<ul>
<li>在用统计函数count时会不同,例如count(ID):统计记录数.当统计的记录中的包含有null值时,它会忽略null值.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">select count(*),count(b) from testNull 它的返回值为2 1</span><br><span class="line">select count(*),count(isnull(b,&#39;&#39;)) from testNull 它的返回值为2 2</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结论:对于列包含null 时,统计行数是可用count(*),或者是先把null值转换成对应的值再统计,例如count(isnull(b,’’));</p>
<ul>
<li>对于in 的影响不同.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">select * from testNull</span><br><span class="line">where b in(null) --没有任何记录</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结论:in在查询时会忽略null的记录,查询的时候可用is not null来查询.</p>
<ul>
<li>排序时顺序有不同:当使用ORDER BY时，首先呈现NULL值。如果你用DESC以降序排序，NULL值最后显示。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; select emp_id ,fname,lname,superior_emp_id from employee  order by superior_emp_id;</span><br><span class="line">+--------+----------+-----------+-----------------+</span><br><span class="line">| emp_id | fname    | lname     | superior_emp_id |</span><br><span class="line">+--------+----------+-----------+-----------------+</span><br><span class="line">|      2 | Susan    | Barker    |            NULL |</span><br><span class="line">|      3 | Robert   | Tyler     |            NULL |</span><br><span class="line">|      1 | Michael  | Smith     |            NULL |</span><br><span class="line">|      4 | Susan    | Hawthorne |               3 |</span><br><span class="line">|     10 | Paula    | Roberts   |               4 |</span><br><span class="line">|     16 | Theresa  | Markham   |               4 |</span><br><span class="line">|     13 | John     | Blake     |               4 |</span><br><span class="line">|      6 | Helen    | Fleming   |               4 |</span><br><span class="line">|      5 | John     | Gooding   |               4 |</span><br><span class="line">|      8 | Sarah    | Parker    |               6 |</span><br><span class="line">|      9 | Jane     | Grossman  |               6 |</span><br><span class="line">|      7 | Chris    | Tucker    |               6 |</span><br><span class="line">|     11 | Thomas   | Ziegler   |              10 |</span><br><span class="line">|     12 | Samantha | Jameson   |              10 |</span><br><span class="line">|     14 | Cindy    | Mason     |              13 |</span><br><span class="line">|     15 | Frank    | Portman   |              13 |</span><br><span class="line">|     17 | Beth     | Fowler    |              16 |</span><br><span class="line">|     18 | Rick     | Tulman    |              16 |</span><br><span class="line">+--------+----------+-----------+-----------------+</span><br><span class="line">18 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p>永远不会有什么数据等于NULL。1不等于NULL，2也一样。但NULL也不等于NULL。所以我们只能比较它“是”或“不是”。</p>
</li>
<li><p>count(*)表示统计行数，而count(某一个字段)表示对该值的内容统计，如果它的值为null，则该列不计数。</p>
</li>
</ul>
<h2 id="case-when-else-end-条件逻辑语句"><a href="#case-when-else-end-条件逻辑语句" class="headerlink" title="case when else end 条件逻辑语句"></a>case when else end 条件逻辑语句</h2><p>简单的说，条件逻辑语句时程序执行时从多个路径中选择其一的能。</p>
<h3 id="case表达式返回字符串的例子"><a href="#case表达式返回字符串的例子" class="headerlink" title="case表达式返回字符串的例子"></a>case表达式返回字符串的例子</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">SELECT </span><br><span class="line">    c.cust_id,</span><br><span class="line">    c.fed_id,</span><br><span class="line">    CASE</span><br><span class="line">        WHEN c.cust_type_cd &#x3D; &#39;I&#39; THEN CONCAT(i.fname, &#39; &#39;, i.lname)</span><br><span class="line">        WHEN c.cust_type_cd &#x3D; &#39;B&#39; THEN b.name</span><br><span class="line">        ELSE &#39;Unknown&#39;</span><br><span class="line">    END name</span><br><span class="line">FROM</span><br><span class="line">    customer c</span><br><span class="line">        LEFT JOIN</span><br><span class="line">    individual i ON c.cust_id &#x3D; i.cust_id</span><br><span class="line">        LEFT JOIN</span><br><span class="line">    business b ON c.cust_id &#x3D; b.cust_id;</span><br><span class="line"></span><br><span class="line">+---------+-------------+------------------------+</span><br><span class="line">| cust_id | fed_id      | name                   |</span><br><span class="line">+---------+-------------+------------------------+</span><br><span class="line">|      10 | 04-1111111  | jamesd &#39;hand           |</span><br><span class="line">|      11 | 04-2222222  | Northeast Cooling Inc. |</span><br><span class="line">|      12 | 04-3333333  | Superior Auto Body     |</span><br><span class="line">|      13 | 04-4444444  | AAA Insurance Inc.     |</span><br><span class="line">|       1 | 111-11-1111 | James Hadley           |</span><br><span class="line">|       2 | 222-22-2222 | Susan Tingley          |</span><br><span class="line">|       3 | 333-33-3333 | Frank Tucker           |</span><br><span class="line">|       4 | 444-44-4444 | John Hayward           |</span><br><span class="line">|       5 | 555-55-5555 | Charles Frasier        |</span><br><span class="line">|       6 | 666-66-6666 | John Spencer           |</span><br><span class="line">|       7 | 777-77-7777 | Margaret Young         |</span><br><span class="line">|       8 | 888-88-8888 | Louis Blake            |</span><br><span class="line">|       9 | 999-99-9999 | Richard Farley         |</span><br><span class="line">+---------+-------------+------------------------+</span><br><span class="line">13 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="case表达式返回表达式类型的例子"><a href="#case表达式返回表达式类型的例子" class="headerlink" title="case表达式返回表达式类型的例子"></a>case表达式返回表达式类型的例子</h3><p>例子1</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">SELECT </span><br><span class="line">    c.cust_id,</span><br><span class="line">    c.fed_id,</span><br><span class="line">    CASE</span><br><span class="line">        WHEN</span><br><span class="line">            c.cust_type_cd &#x3D; &#39;I&#39;</span><br><span class="line">        THEN</span><br><span class="line">            (SELECT </span><br><span class="line">                    CONCAT(i.fname, &#39; &#39;, i.lname)</span><br><span class="line">                FROM</span><br><span class="line">                    individual i</span><br><span class="line">                WHERE</span><br><span class="line">                    i.cust_id &#x3D; c.cust_id)</span><br><span class="line">        WHEN</span><br><span class="line">            c.cust_type_cd &#x3D; &#39;B&#39;</span><br><span class="line">        THEN</span><br><span class="line">            (SELECT </span><br><span class="line">                    b.name</span><br><span class="line">                FROM</span><br><span class="line">                    business b</span><br><span class="line">                WHERE</span><br><span class="line">                    b.cust_id &#x3D; c.cust_id)</span><br><span class="line">        ELSE &#39;Unknown&#39;</span><br><span class="line">    END name</span><br><span class="line">FROM</span><br><span class="line">    customer c;</span><br><span class="line"></span><br><span class="line">+---------+-------------+------------------------+</span><br><span class="line">| cust_id | fed_id      | name                   |</span><br><span class="line">+---------+-------------+------------------------+</span><br><span class="line">|       1 | 111-11-1111 | James Hadley           |</span><br><span class="line">|       2 | 222-22-2222 | Susan Tingley          |</span><br><span class="line">|       3 | 333-33-3333 | Frank Tucker           |</span><br><span class="line">|       4 | 444-44-4444 | John Hayward           |</span><br><span class="line">|       5 | 555-55-5555 | Charles Frasier        |</span><br><span class="line">|       6 | 666-66-6666 | John Spencer           |</span><br><span class="line">|       7 | 777-77-7777 | Margaret Young         |</span><br><span class="line">|       8 | 888-88-8888 | Louis Blake            |</span><br><span class="line">|       9 | 999-99-9999 | Richard Farley         |</span><br><span class="line">|      10 | 04-1111111  | jamesd &#39;hand           |</span><br><span class="line">|      11 | 04-2222222  | Northeast Cooling Inc. |</span><br><span class="line">|      12 | 04-3333333  | Superior Auto Body     |</span><br><span class="line">|      13 | 04-4444444  | AAA Insurance Inc.     |</span><br><span class="line">+---------+-------------+------------------------+</span><br><span class="line">13 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>例子2</p>
<p>查询某个表达式的结果的个数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">    c.cust_id,</span><br><span class="line">    c.fed_id,</span><br><span class="line">    c.cust_type_cd,</span><br><span class="line">    CASE (SELECT </span><br><span class="line">            COUNT(*)</span><br><span class="line">        FROM</span><br><span class="line">            account a</span><br><span class="line">        WHERE</span><br><span class="line">            a.cust_id &#x3D; c.cust_id)</span><br><span class="line">        WHEN 0 THEN &#39;none&#39;</span><br><span class="line">        WHEN 1 THEN &#39;1&#39;</span><br><span class="line">        WHEN 2 THEN &#39;2&#39;</span><br><span class="line">        ELSE &#39;3+&#39;</span><br><span class="line">    END num_accounts</span><br><span class="line">FROM</span><br><span class="line">    customer c;</span><br><span class="line"></span><br><span class="line">+---------+-------------+--------------+--------------+</span><br><span class="line">| cust_id | fed_id      | cust_type_cd | num_accounts |</span><br><span class="line">+---------+-------------+--------------+--------------+</span><br><span class="line">|       1 | 111-11-1111 | I            | 3+           |</span><br><span class="line">|       2 | 222-22-2222 | I            | 2            |</span><br><span class="line">|       3 | 333-33-3333 | I            | 2            |</span><br><span class="line">|       4 | 444-44-4444 | I            | 3+           |</span><br><span class="line">|       5 | 555-55-5555 | I            | 1            |</span><br><span class="line">|       6 | 666-66-6666 | I            | 2            |</span><br><span class="line">|       7 | 777-77-7777 | I            | 1            |</span><br><span class="line">|       8 | 888-88-8888 | I            | 2            |</span><br><span class="line">|       9 | 999-99-9999 | I            | 3+           |</span><br><span class="line">|      10 | 04-1111111  | B            | 2            |</span><br><span class="line">|      11 | 04-2222222  | B            | 1            |</span><br><span class="line">|      12 | 04-3333333  | B            | 1            |</span><br><span class="line">|      13 | 04-4444444  | B            | 1            |</span><br><span class="line">+---------+-------------+--------------+--------------+</span><br><span class="line">13 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="多表查询"><a href="#多表查询" class="headerlink" title="多表查询"></a>多表查询</h2><h3 id="多表查询-需要使用连接。"><a href="#多表查询-需要使用连接。" class="headerlink" title="多表查询 需要使用连接。"></a>多表查询 需要使用连接。</h3><p>连接的结果可以在逻辑上看作是由SELECT语句指定的列组成的新表。<br>左连接与右连接的左右指的是以两张表中的哪一张为基准，它们都是外连接。<br>外连接就好像是为非基准表添加了一行全为空值的万能行，用来与基准表中找不到匹配<br>的行进行匹配。假设两个没有空值的表进行左连接，左表是基准表，<br>左表的所有行都出现在结果中，右表则可能因为无法与基准表匹配而出现是空值的字段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select e.fname,e.lname,d.name from employee e join department d on e.dept_id &#x3D; d.dept_id;</span><br><span class="line">+----------+-----------+----------------+</span><br><span class="line">| fname    | lname     | name           |</span><br><span class="line">+----------+-----------+----------------+</span><br><span class="line">| Susan    | Hawthorne | Operations     |</span><br><span class="line">| Helen    | Fleming   | Operations     |</span><br><span class="line">| Chris    | Tucker    | Operations     |</span><br><span class="line">| Sarah    | Parker    | Operations     |</span><br><span class="line">| Jane     | Grossman  | Operations     |</span><br><span class="line">| Paula    | Roberts   | Operations     |</span><br><span class="line">| Thomas   | Ziegler   | Operations     |</span><br><span class="line">| Samantha | Jameson   | Operations     |</span><br><span class="line">| John     | Blake     | Operations     |</span><br><span class="line">| Cindy    | Mason     | Operations     |</span><br><span class="line">| Frank    | Portman   | Operations     |</span><br><span class="line">| Theresa  | Markham   | Operations     |</span><br><span class="line">| Beth     | Fowler    | Operations     |</span><br><span class="line">| Rick     | Tulman    | Operations     |</span><br><span class="line">| John     | Gooding   | Loans          |</span><br><span class="line">| Michael  | Smith     | Administration |</span><br><span class="line">| Susan    | Barker    | Administration |</span><br><span class="line">| Robert   | Tyler     | Administration |</span><br><span class="line">+----------+-----------+----------------+</span><br><span class="line">18 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以上列子是内连接查询的结果，如果一个表中的dept_id 列中存在某个值，但这个值在另一个表的dept_id列中不存在，<br>那么相关行的链接会失败，在结果集中会排除包含该值的行。</p>
<ul>
<li>ANSI连接语法</li>
</ul>
<p>这种旧的连接方式不包含on子句，而是在from子句中定义个表的别名。并使用逗号隔开。</p>
<p>它具有以下优点：</p>
<ol>
<li>连接条件和过滤条件被分割到on子句和where子句，使查询语句容易被理解。</li>
<li>每两个表之间的连接条件都在自己的on子句中列出，这样不容易忽略这些条件。</li>
</ol>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; SELECT e.fname,e.lname,d.name from employee e ,department d where e.dept_id &#x3D;d.dept_id;</span><br><span class="line">+----------+-----------+----------------+</span><br><span class="line">| fname    | lname     | name           |</span><br><span class="line">+----------+-----------+----------------+</span><br><span class="line">| Susan    | Hawthorne | Operations     |</span><br><span class="line">| Helen    | Fleming   | Operations     |</span><br><span class="line">| Chris    | Tucker    | Operations     |</span><br><span class="line">| Sarah    | Parker    | Operations     |</span><br><span class="line">| Jane     | Grossman  | Operations     |</span><br><span class="line">| Paula    | Roberts   | Operations     |</span><br><span class="line">| Thomas   | Ziegler   | Operations     |</span><br><span class="line">| Samantha | Jameson   | Operations     |</span><br><span class="line">| John     | Blake     | Operations     |</span><br><span class="line">| Cindy    | Mason     | Operations     |</span><br><span class="line">| Frank    | Portman   | Operations     |</span><br><span class="line">| Theresa  | Markham   | Operations     |</span><br><span class="line">| Beth     | Fowler    | Operations     |</span><br><span class="line">| Rick     | Tulman    | Operations     |</span><br><span class="line">| John     | Gooding   | Loans          |</span><br><span class="line">| Michael  | Smith     | Administration |</span><br><span class="line">| Susan    | Barker    | Administration |</span><br><span class="line">| Robert   | Tyler     | Administration |</span><br><span class="line">+----------+-----------+----------------+</span><br><span class="line">18 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p>连接两次使用同一张表时，可以为表取别名。别名即表的实例，数据库服务器可以区分所引用的实例。</p>
</li>
<li><p>自连接</p>
</li>
</ul>
<p>一张表中存这雇员的信息和一个指向本表的外键。<br>此时要查询每个雇员的姓名和主管道的姓名，即可使用自连接。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; select e.fname,e_mgr.fname as emgrName from employee e  inner join employee e_mgr on e.superior_emp_id &#x3D;e_mgr.emp_id;</span><br><span class="line">+----------+----------+</span><br><span class="line">| fname    | emgrName |</span><br><span class="line">+----------+----------+</span><br><span class="line">| Susan    | Robert   |</span><br><span class="line">| John     | Susan    |</span><br><span class="line">| Helen    | Susan    |</span><br><span class="line">| Chris    | Helen    |</span><br><span class="line">| Sarah    | Helen    |</span><br><span class="line">| Jane     | Helen    |</span><br><span class="line">| Paula    | Susan    |</span><br><span class="line">| Thomas   | Paula    |</span><br><span class="line">| Samantha | Paula    |</span><br><span class="line">| John     | Susan    |</span><br><span class="line">| Cindy    | John     |</span><br><span class="line">| Frank    | John     |</span><br><span class="line">| Theresa  | Susan    |</span><br><span class="line">| Beth     | Theresa  |</span><br><span class="line">| Rick     | Theresa  |</span><br><span class="line">+----------+----------+</span><br><span class="line">15 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>自连接的不等连接</li>
</ul>
<p>每一个组中的成员与组里的别的成员进行一场象棋比赛。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F;这样会产生重复记录，即a VS b  和b VS a</span><br><span class="line">mysql&gt; select e1.fname,e1.lname, &#39;VS&#39; vs , e2.fname,e2.lname from employee e1 inner join employee e2 on e1.emp_id  !&#x3D;e2.emp_id where e1.title &#x3D;&#39;Teller&#39; and e2.title &#x3D;&#39;Teller&#39;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 所以需要过滤，采用&gt;的条件</span><br><span class="line"></span><br><span class="line">mysql&gt; select e1.fname,e1.lname, &#39;VS&#39; vs , e2.fname,e2.lname from employee e1 inner join employee e2 on e1.emp_id  &gt;e2.emp_id where e1.title &#x3D;&#39;Teller&#39; and e2.title &#x3D;&#39;Teller&#39;;</span><br><span class="line">+----------+----------+----+----------+----------+</span><br><span class="line">| fname    | lname    | vs | fname    | lname    |</span><br><span class="line">+----------+----------+----+----------+----------+</span><br><span class="line">| Sarah    | Parker   | VS | Chris    | Tucker   |</span><br><span class="line">| Jane     | Grossman | VS | Chris    | Tucker   |</span><br><span class="line">| Jane     | Grossman | VS | Sarah    | Parker   |</span><br><span class="line">| Thomas   | Ziegler  | VS | Chris    | Tucker   |</span><br><span class="line">| Thomas   | Ziegler  | VS | Sarah    | Parker   |</span><br><span class="line">| Thomas   | Ziegler  | VS | Jane     | Grossman |</span><br><span class="line">| Samantha | Jameson  | VS | Chris    | Tucker   |</span><br><span class="line">| Samantha | Jameson  | VS | Sarah    | Parker   |</span><br><span class="line">| Samantha | Jameson  | VS | Jane     | Grossman |</span><br><span class="line">| Samantha | Jameson  | VS | Thomas   | Ziegler  |</span><br><span class="line">| Cindy    | Mason    | VS | Chris    | Tucker   |</span><br><span class="line">| Cindy    | Mason    | VS | Sarah    | Parker   |</span><br><span class="line">| Cindy    | Mason    | VS | Jane     | Grossman |</span><br><span class="line">| Cindy    | Mason    | VS | Thomas   | Ziegler  |</span><br><span class="line">| Cindy    | Mason    | VS | Samantha | Jameson  |</span><br><span class="line">| Frank    | Portman  | VS | Chris    | Tucker   |</span><br><span class="line">| Frank    | Portman  | VS | Sarah    | Parker   |</span><br><span class="line">| Frank    | Portman  | VS | Jane     | Grossman |</span><br><span class="line">| Frank    | Portman  | VS | Thomas   | Ziegler  |</span><br><span class="line">| Frank    | Portman  | VS | Samantha | Jameson  |</span><br><span class="line">| Frank    | Portman  | VS | Cindy    | Mason    |</span><br><span class="line">| Beth     | Fowler   | VS | Chris    | Tucker   |</span><br><span class="line">| Beth     | Fowler   | VS | Sarah    | Parker   |</span><br><span class="line">| Beth     | Fowler   | VS | Jane     | Grossman |</span><br><span class="line">| Beth     | Fowler   | VS | Thomas   | Ziegler  |</span><br><span class="line">| Beth     | Fowler   | VS | Samantha | Jameson  |</span><br><span class="line">| Beth     | Fowler   | VS | Cindy    | Mason    |</span><br><span class="line">| Beth     | Fowler   | VS | Frank    | Portman  |</span><br><span class="line">| Rick     | Tulman   | VS | Chris    | Tucker   |</span><br><span class="line">| Rick     | Tulman   | VS | Sarah    | Parker   |</span><br><span class="line">| Rick     | Tulman   | VS | Jane     | Grossman |</span><br><span class="line">| Rick     | Tulman   | VS | Thomas   | Ziegler  |</span><br><span class="line">| Rick     | Tulman   | VS | Samantha | Jameson  |</span><br><span class="line">| Rick     | Tulman   | VS | Cindy    | Mason    |</span><br><span class="line">| Rick     | Tulman   | VS | Frank    | Portman  |</span><br><span class="line">| Rick     | Tulman   | VS | Beth     | Fowler   |</span><br><span class="line">+----------+----------+----+----------+----------+</span><br><span class="line">36 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="外连接"><a href="#外连接" class="headerlink" title="外连接"></a>外连接</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">LEFT JOIN (等价于LEFT OUT JOIN) 关键字从左表（table1）返回所有的行，即使右表（table2）中没有匹配。</span><br><span class="line">如果右表中没有匹配，则结果为 NULL。</span><br><span class="line"></span><br><span class="line">例子：</span><br><span class="line">SELECT  websites.name, access_log.count, access_log.date</span><br><span class="line">FROM   websites  LEFT JOIN　access_log ON websites.id &#x3D; access_log.site_id　ORDER BY access_log.count DESC;</span><br><span class="line"></span><br><span class="line">+---------------+-------+------------+</span><br><span class="line">| name          | count | date       |</span><br><span class="line">+---------------+-------+------------+</span><br><span class="line">| Facebook      |   545 | 2016-05-16 |</span><br><span class="line">| Google        |   230 | 2016-05-14 |</span><br><span class="line">| 菜鸟教程      |   220 | 2016-05-15 |</span><br><span class="line">| Facebook      |   205 | 2016-05-14 |</span><br><span class="line">| 菜鸟教程      |   201 | 2016-05-17 |</span><br><span class="line">| 菜鸟教程      |   100 | 2016-05-13 |</span><br><span class="line">| Google        |    45 | 2016-05-10 |</span><br><span class="line">| 微博          |    13 | 2016-05-15 |</span><br><span class="line">| 淘宝          |    10 | 2016-05-14 |</span><br><span class="line">| stackoverflow |  NULL | NULL       |</span><br><span class="line">+---------------+-------+------------+</span><br><span class="line"></span><br><span class="line">RIGHT JOIN 与INNER JOIN的意思相同，不做过多的解释。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="union和union-all关键字"><a href="#union和union-all关键字" class="headerlink" title="union和union all关键字"></a>union和union all关键字</h3><ul>
<li>要使用UNION或者UNION all 必须满足以下两个条件：</li>
</ul>
<p>两个数据集合必须具有相同的列；<br>两个数据集中对应的列的数据类型必须时一致的（或者时服务器中数据类型可以转换）；</p>
<ul>
<li>区别：</li>
</ul>
<p>union对连接后的集合排序并去除重复项，而union all保留重复项。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select &#39;ind&#39; type_cd,cust_id,lname name from individual union all select &#39;bus&#39; type_cd,cust_id,name from business;</span><br><span class="line">+---------+---------+------------------------+</span><br><span class="line">| type_cd | cust_id | name                   |</span><br><span class="line">+---------+---------+------------------------+</span><br><span class="line">| ind     |       1 | Hadley                 |</span><br><span class="line">| ind     |       2 | Tingley                |</span><br><span class="line">| ind     |       3 | Tucker                 |</span><br><span class="line">| ind     |       4 | Hayward                |</span><br><span class="line">| ind     |       5 | Frasier                |</span><br><span class="line">| ind     |       6 | Spencer                |</span><br><span class="line">| ind     |       7 | Young                  |</span><br><span class="line">| ind     |       8 | Blake                  |</span><br><span class="line">| ind     |       9 | Farley                 |</span><br><span class="line">| bus     |      10 | Chilton Engineering    |</span><br><span class="line">| bus     |      11 | Northeast Cooling Inc. |</span><br><span class="line">| bus     |      12 | Superior Auto Body     |</span><br><span class="line">| bus     |      13 | AAA Insurance Inc.     |</span><br><span class="line">+---------+---------+------------------------+</span><br><span class="line">13 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>对复合查询结果排序</li>
</ul>
<p>如果需要对复合查询的结果进行排序，那么可以在最后一个查询后面增加order by 子句。当在order by 子句中指定要排序的列时，需要从复合查询的第一个查询中选取列名。所以，建议对两个查询的各列定义不同的别名。</p>
<h3 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h3><p>子查询返回的结果集类型决定了它可能如何被使用。任何查询返回的数据在包含语句执行完成之后都会被丢弃，说这事的则查询像一个具有作用域的临时表。这意味着sql执行完毕，子查询结果所占用的内存将会被清空。</p>
<h4 id="非关联子查询"><a href="#非关联子查询" class="headerlink" title="非关联子查询"></a>非关联子查询</h4><p>非关联子查询是指，它可以单独执行不需要引用包含语句中的任何内容。</p>
<ul>
<li>如果在等式条件下使用子查询，而子查询返回多行结果，则会出错。</li>
</ul>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; select account_id,product_cd,cust_id from account where open_emp_id &lt;&gt; (select e.emp_id from employee e inner join  branch b on e.assigned_branch_id &#x3D;b.branch_id where e.title&#x3D;&#39;Teller&#39; AND b.city&#x3D;&#39;Woburn&#39;);</span><br><span class="line">ERROR 1242 (21000): Subquery returns more than 1 row</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>错误的原因时open_emp_id 不能等于结果集。</p>
<ul>
<li>多行单列子查询，即多行结果可以在非等式的 IN和NOT IN 运算符中使用。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; select branch_id ,name,city from branch where name In (&#39;HeadQuarters&#39;,&#39;Quincy Branch&#39;);</span><br><span class="line">+-----------+---------------+---------+</span><br><span class="line">| branch_id | name          | city    |</span><br><span class="line">+-----------+---------------+---------+</span><br><span class="line">|         1 | Headquarters  | Waltham |</span><br><span class="line">|         3 | Quincy Branch | Quincy  |</span><br><span class="line">+-----------+---------------+---------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>ALL和ANY运算符（不常用。一般使用IN和NOT IN代替。）</li>
</ul>
<p>all运算符用于将某单值与集合中的每个值比较，而any用于个结果集中的每个成员比较。与all不同的时，any运算符中，只要有一个比较成立，则条件为真。all需要每一个都成立，才为真。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select emp_id,fname,lname,title from employee where emp_id &lt;&gt; all (select superior_emp_id from employee where superior_emp_id is NOT NULL);</span><br><span class="line">+--------+----------+----------+----------------+</span><br><span class="line">| emp_id | fname    | lname    | title          |</span><br><span class="line">+--------+----------+----------+----------------+</span><br><span class="line">|      1 | Michael  | Smith    | President      |</span><br><span class="line">|      2 | Susan    | Barker   | Vice President |</span><br><span class="line">|      5 | John     | Gooding  | Loan Manager   |</span><br><span class="line">|      7 | Chris    | Tucker   | Teller         |</span><br><span class="line">|      8 | Sarah    | Parker   | Teller         |</span><br><span class="line">|      9 | Jane     | Grossman | Teller         |</span><br><span class="line">|     11 | Thomas   | Ziegler  | Teller         |</span><br><span class="line">|     12 | Samantha | Jameson  | Teller         |</span><br><span class="line">|     14 | Cindy    | Mason    | Teller         |</span><br><span class="line">|     15 | Frank    | Portman  | Teller         |</span><br><span class="line">|     17 | Beth     | Fowler   | Teller         |</span><br><span class="line">|     18 | Rick     | Tulman   | Teller         |</span><br><span class="line">+--------+----------+----------+----------------+</span><br><span class="line">12 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="关联子查询"><a href="#关联子查询" class="headerlink" title="关联子查询"></a>关联子查询</h4><ul>
<li>与非关联子查询不同，关联子查询不是在包含语句执行前执行一次，而是为每一个候选行都执行一次。</li>
</ul>
<p>下面的例子中首先关联查询计算每个客户的账户数，接着包含查询检索出哪些拥有两个账户。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select c.cust_id,c.cust_type_cd,c.city from customer c where 2 &#x3D;(select count(*) from account a where a.cust_id &#x3D;c.cust_id);</span><br><span class="line">+---------+--------------+---------+</span><br><span class="line">| cust_id | cust_type_cd | city    |</span><br><span class="line">+---------+--------------+---------+</span><br><span class="line">|       2 | I            | Woburn  |</span><br><span class="line">|       3 | I            | Quincy  |</span><br><span class="line">|       6 | I            | Waltham |</span><br><span class="line">|       8 | I            | Salem   |</span><br><span class="line">|      10 | B            | Salem   |</span><br><span class="line">+---------+--------------+---------+</span><br><span class="line">5 rows in set (0.01 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>exists运算符</li>
</ul>
<p>如果只关心存在关系，而不在乎数量就可以使用exists关键字。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;&#x2F;以下时exists和not exists的用法。</span><br><span class="line">mysql&gt; select a.account_id ,a.product_cd,a.cust_id,a.avail_balance from account a where not exists (select 1 from transaction t where t.account_id &#x3D;a.account_id and t.txn_date &#x3D;&#39;2008-09-22&#39;);</span><br><span class="line">+------------+------------+---------+---------------+</span><br><span class="line">| account_id | product_cd | cust_id | avail_balance |</span><br><span class="line">+------------+------------+---------+---------------+</span><br><span class="line">|          1 | CHK        |       1 |       1057.75 |</span><br><span class="line">|          2 | SAV        |       1 |        500.00 |</span><br><span class="line">|          3 | CD         |       1 |       3000.00 |</span><br><span class="line">|          4 | CHK        |       2 |       2258.02 |</span><br><span class="line">|          5 | SAV        |       2 |        200.00 |</span><br><span class="line">|          7 | CHK        |       3 |       1057.75 |</span><br><span class="line">|          8 | MM         |       3 |       2212.50 |</span><br><span class="line">|         10 | CHK        |       4 |        534.12 |</span><br><span class="line">|         11 | SAV        |       4 |        767.77 |</span><br><span class="line">|         12 | MM         |       4 |       5487.09 |</span><br><span class="line">|         13 | CHK        |       5 |       2237.97 |</span><br><span class="line">|         14 | CHK        |       6 |        122.37 |</span><br><span class="line">|         15 | CD         |       6 |      10000.00 |</span><br><span class="line">|         17 | CD         |       7 |       5000.00 |</span><br><span class="line">|         18 | CHK        |       8 |       3487.19 |</span><br><span class="line">|         19 | SAV        |       8 |        387.99 |</span><br><span class="line">|         21 | CHK        |       9 |        125.67 |</span><br><span class="line">|         22 | MM         |       9 |       9345.55 |</span><br><span class="line">|         23 | CD         |       9 |       1500.00 |</span><br><span class="line">|         24 | CHK        |      10 |      23575.12 |</span><br><span class="line">|         25 | BUS        |      10 |          0.00 |</span><br><span class="line">|         27 | BUS        |      11 |       9345.55 |</span><br><span class="line">|         28 | CHK        |      12 |      38552.05 |</span><br><span class="line">|         29 | SBL        |      13 |      50000.00 |</span><br><span class="line">+------------+------------+---------+---------------+</span><br><span class="line">24 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select a.account_id ,a.product_cd,a.cust_id,a.avail_balance from account a where exists (select 1 from transaction t where t.account_id &#x3D;a.account_id and t.txn_date &#x3D;&#39;2008-09-22&#39;);</span><br><span class="line">Empty set (0.01 sec)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">子查询可能返回1或者0 ，使用1代表是否至少能返回一行。</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<ul>
<li>update语句的关联查询</li>
</ul>
<p>例子：</p>
<p>查询出每个账户的最新交易日期，然后修改账户的每一行的last_activity_date字段。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; update account a set a.last_activity_date &#x3D;(select max(t.txn_date) from transaction t where t.account_id &#x3D;a.account_id);</span><br><span class="line">Query OK, 19 rows affected (0.15 sec)</span><br><span class="line">Rows matched: 24  Changed: 19  Warnings: 0</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>delete语句中的关联查询</li>
</ul>
<p>mysql中的delete语句使用关联子查询时，无论如何都不能使用表的别名。(暂时不知道原因)</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; delete from department where not exists (select 1 from employee  where employee.dept_id&#x3D;department.dept_id);</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="如何使用子查询"><a href="#如何使用子查询" class="headerlink" title="如何使用子查询"></a>如何使用子查询</h4><ul>
<li>子查询作为数据源</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select d.dept_id ,d.name ,e_ent.how_many num_employees from department d inner join (select dept_id ,count(*) how_many from employee group by dept_id) e_ent on d.dept_id&#x3D;e_ent.dept_id;</span><br><span class="line">+---------+----------------+---------------+</span><br><span class="line">| dept_id | name           | num_employees |</span><br><span class="line">+---------+----------------+---------------+</span><br><span class="line">|       1 | Operations     |            14 |</span><br><span class="line">|       2 | Loans          |             1 |</span><br><span class="line">|       3 | Administration |             3 |</span><br><span class="line">+---------+----------------+---------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>子查询在from子句中必须是非关联的，它必须首先执行，然后一直保存在内存中直至包含查询执行完毕。</p>
<ul>
<li>子查询作为过滤条件</li>
</ul>
<p>子查询作为过滤条件出现在having条件中，不会出现在where条件中。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">SELECT </span><br><span class="line">    open_emp_id, COUNT(*) how_many</span><br><span class="line">FROM</span><br><span class="line">    account</span><br><span class="line">GROUP BY open_emp_id</span><br><span class="line">HAVING COUNT(*) &#x3D; (SELECT </span><br><span class="line">        MAX(emp_cnt.how_many)</span><br><span class="line">    FROM</span><br><span class="line">        (SELECT </span><br><span class="line">            COUNT(*) how_many</span><br><span class="line">        FROM</span><br><span class="line">            account</span><br><span class="line">        GROUP BY open_emp_id) emp_cnt);</span><br><span class="line"></span><br><span class="line">+-------------+----------+</span><br><span class="line">| open_emp_id | how_many |</span><br><span class="line">+-------------+----------+</span><br><span class="line">|           1 |        8 |</span><br><span class="line">+-------------+----------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>子查询作为表达式生成器</li>
</ul>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">SELECT </span><br><span class="line">    emp.emp_id,</span><br><span class="line">    CONCAT(emp.fname, &#39; &#39;, emp.lname) emp_name,</span><br><span class="line">    (SELECT </span><br><span class="line">            CONCAT(boss.fname, &#39; &#39;, boss.lname)</span><br><span class="line">        FROM</span><br><span class="line">            employee boss</span><br><span class="line">        WHERE</span><br><span class="line">            boss.emp_id &#x3D; emp.superior_emp_id) boss_name</span><br><span class="line">FROM</span><br><span class="line">    employee emp</span><br><span class="line">WHERE</span><br><span class="line">    emp.superior_emp_id IS NOT NULL</span><br><span class="line">ORDER BY (SELECT </span><br><span class="line">        boss.lname</span><br><span class="line">    FROM</span><br><span class="line">        employee boss</span><br><span class="line">    WHERE</span><br><span class="line">        boss.emp_id &#x3D; emp.superior_emp_id) , emp.lname;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">+--------+------------------+-----------------+</span><br><span class="line">| emp_id | emp_name         | boss_name       |</span><br><span class="line">+--------+------------------+-----------------+</span><br><span class="line">|     14 | Cindy Mason      | John Blake      |</span><br><span class="line">|     15 | Frank Portman    | John Blake      |</span><br><span class="line">|      9 | Jane Grossman    | Helen Fleming   |</span><br><span class="line">|      8 | Sarah Parker     | Helen Fleming   |</span><br><span class="line">|      7 | Chris Tucker     | Helen Fleming   |</span><br><span class="line">|     13 | John Blake       | Susan Hawthorne |</span><br><span class="line">|      6 | Helen Fleming    | Susan Hawthorne |</span><br><span class="line">|      5 | John Gooding     | Susan Hawthorne |</span><br><span class="line">|     16 | Theresa Markham  | Susan Hawthorne |</span><br><span class="line">|     10 | Paula Roberts    | Susan Hawthorne |</span><br><span class="line">|     17 | Beth Fowler      | Theresa Markham |</span><br><span class="line">|     18 | Rick Tulman      | Theresa Markham |</span><br><span class="line">|     12 | Samantha Jameson | Paula Roberts   |</span><br><span class="line">|     11 | Thomas Ziegler   | Paula Roberts   |</span><br><span class="line">|      4 | Susan Hawthorne  | Robert Tyler    |</span><br><span class="line">+--------+------------------+-----------------+</span><br><span class="line">15 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>












































































]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>sql学习指南</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka源码剖析-producer</title>
    <url>/2018-04-06/kafka%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-producer/</url>
    <content><![CDATA[<h1 id="kafkaProducer分析"><a href="#kafkaProducer分析" class="headerlink" title="kafkaProducer分析"></a>kafkaProducer分析</h1><h2 id="发送消息的流程"><a href="#发送消息的流程" class="headerlink" title="发送消息的流程"></a>发送消息的流程</h2><p><img src="/images/kafka/producer/kafka%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E6%95%B4%E4%B8%AA%E6%B5%81%E7%A8%8B.png" alt="kafka发送消息的整个流程"></p>
<ol>
<li>producerInterceptors对消息进行拦截</li>
<li>Serializer对消息的key和value进行序列化</li>
<li>Partitioner为消息选择合适的分区</li>
<li>RecordAccumulator收集消息,实现批量发送</li>
<li>Sender从RecordAccumulator获取消息</li>
<li>构造ClientRequest</li>
<li>将ClientRequest交给networkClientRequest,准备发送</li>
<li>networkClient 将请求放入kafkaChanel缓存</li>
<li>执行网络IO,发送请求</li>
<li>收到响应,调用ClientRequest的回调函数</li>
<li>调用RecordBatch的回调函数,最终调用每个消息上注册的回调函数.</li>
</ol>
<h2 id="kafkaProducer接口实现的方法介绍"><a href="#kafkaProducer接口实现的方法介绍" class="headerlink" title="kafkaProducer接口实现的方法介绍"></a>kafkaProducer接口实现的方法介绍</h2><ol>
<li>send()方法,发送消息,将消息放入RecordAccumulator暂存,等待发送;</li>
<li>flush()方法,刷新操作,等待RecordAccumulator中所有消息发送完成,在刷新完成之前会阻塞调用的线程</li>
<li>partitionFor()方法,在kafkaProducer中维护了一个Metadata对象,用于存储kafka集群的元数据,会定时更新,该方法负责从元数据中获取制定topic中的分区信息</li>
<li>close()方法,关闭此producer对象,主要操作是设置close标志,等待RecordAccumulator中的消息清空,关闭sender线程.</li>
</ol>
<h2 id="kafkaProducer的具体实现"><a href="#kafkaProducer的具体实现" class="headerlink" title="kafkaProducer的具体实现:"></a>kafkaProducer的具体实现:</h2><p>kafkaProducer的重要参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;clientId生成器</span><br><span class="line">private static final AtomicInteger PRODUCER_CLIENT_ID_SEQUENCE &#x3D; new AtomicInteger(1);</span><br><span class="line">&#x2F;&#x2F;clientId</span><br><span class="line">private String clientId;</span><br><span class="line">&#x2F;&#x2F;分区选择器</span><br><span class="line">private final Partitioner partitioner;</span><br><span class="line">&#x2F;&#x2F;消息的最大长度,包括消息头.序列化后的key和value</span><br><span class="line">private final int maxRequestSize;</span><br><span class="line">&#x2F;&#x2F;发送单个消息的缓冲区大小</span><br><span class="line">private final long totalMemorySize;</span><br><span class="line">&#x2F;&#x2F;kafka的元数据</span><br><span class="line">private final Metadata metadata;</span><br><span class="line">&#x2F;&#x2F;用于收集缓存消息,等待Sender线程发送</span><br><span class="line">private final RecordAccumulator accumulator;</span><br><span class="line">&#x2F;&#x2F;发送消息的sender任务,实现了Runnable接口</span><br><span class="line">private final Sender sender;</span><br><span class="line">&#x2F;&#x2F;执行sender任务发送消息的线程</span><br><span class="line">private final Thread ioThread;</span><br><span class="line">&#x2F;&#x2F;压缩算法,收集器收集的消息进行压缩</span><br><span class="line">private final CompressionType compressionType;</span><br><span class="line">&#x2F;&#x2F;key序列化器</span><br><span class="line">private final Serializer&lt;K&gt; keySerializer;</span><br><span class="line">&#x2F;&#x2F;value序列化器</span><br><span class="line">private final Serializer&lt;V&gt; valueSerializer;</span><br><span class="line">&#x2F;&#x2F;配置对象</span><br><span class="line">private final ProducerConfig producerConfig;</span><br><span class="line">&#x2F;&#x2F;等待更新kafka集群元数据的最大时长</span><br><span class="line">private final long maxBlockTimeMs;</span><br><span class="line">&#x2F;&#x2F;从消息发送到收到ACK相应的最大时长</span><br><span class="line">private final int requestTimeoutMs;</span><br><span class="line">&#x2F;&#x2F;消息发送之前对消息进行拦截或者修改</span><br><span class="line">private final ProducerInterceptors&lt;K, V&gt; interceptors;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/images/kafka/producer/send%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B.png" alt="send方法的调用流程"></p>
<h2 id="ProducerInterceptor"><a href="#ProducerInterceptor" class="headerlink" title="ProducerInterceptor"></a>ProducerInterceptor</h2><p>该对象是可以在消息发送之前对其进行拦截或者修改,用户可以实现该接口,然后自定义方法的实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public interface ProducerInterceptor&lt;K, V&gt; extends Configurable &#123;</span><br><span class="line">    public ProducerRecord&lt;K, V&gt; onSend(ProducerRecord&lt;K, V&gt; record);</span><br><span class="line">    public void onAcknowledgement(RecordMetadata metadata, Exception exception);</span><br><span class="line">    public void close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="kafka集群元数据"><a href="#kafka集群元数据" class="headerlink" title="kafka集群元数据"></a>kafka集群元数据</h2><h3 id="基本类"><a href="#基本类" class="headerlink" title="基本类"></a>基本类</h3><p>由于kafka生产者在发送消息的时候需要实时的了解kafka分区的相关情况,kafkaProducer中维护了Metadata其中,它用以下三个类封装了集群的相关的元数据</p>
<p><img src="/images/kafka/producer/kafka%E5%85%83%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E5%B0%81%E8%A3%85%E7%9A%84%E5%AF%B9%E8%B1%A1.png" alt="kafka元数据对象封装的对象"></p>
<h4 id="kafka集群的元数据"><a href="#kafka集群的元数据" class="headerlink" title="kafka集群的元数据"></a>kafka集群的元数据</h4><p>某个topic有几个分区、每个分区的leader副本在哪个节点上、follower副本在哪个节点上、isr集合、这些节点的ip和端口号。</p>
<h3 id="cluster类"><a href="#cluster类" class="headerlink" title="cluster类"></a>cluster类</h3><p>这三个类所组成的对象封装在一个叫做Cluster的类中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;kafka集群中节点列表</span><br><span class="line">private final List&lt;Node&gt; nodes;</span><br><span class="line">&#x2F;&#x2F;</span><br><span class="line">private final Set&lt;String&gt; unauthorizedTopics;</span><br><span class="line">&#x2F;&#x2F;记录了topicPartition 与partitionInfo之间的关系</span><br><span class="line">private final Map&lt;TopicPartition, PartitionInfo&gt; partitionsByTopicPartition;</span><br><span class="line">&#x2F;&#x2F;topic名称与PartitionInfo的映射关系</span><br><span class="line">private final Map&lt;String, List&lt;PartitionInfo&gt;&gt; partitionsByTopic;</span><br><span class="line">private final Map&lt;String, List&lt;PartitionInfo&gt;&gt; availablePartitionsByTopic;</span><br><span class="line">&#x2F;&#x2F;node与partitionInfo的映射关系</span><br><span class="line">private final Map&lt;Integer, List&lt;PartitionInfo&gt;&gt; partitionsByNode;</span><br><span class="line">&#x2F;&#x2F;BrokerId与node节点之间的对应关系</span><br><span class="line">private final Map&lt;Integer, Node&gt; nodesById;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="metadata类"><a href="#metadata类" class="headerlink" title="metadata类"></a>metadata类</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;两次发出更新clsuter保存的元数据信息的最小时间差</span><br><span class="line">private final long refreshBackoffMs;</span><br><span class="line">&#x2F;&#x2F;每隔多久更新一次</span><br><span class="line">private final long metadataExpireMs;</span><br><span class="line">&#x2F;&#x2F;kafka集群元数据的版本号,每更新一次,值加1</span><br><span class="line">private int version;</span><br><span class="line">&#x2F;&#x2F;上一次更新元数据的时间戳</span><br><span class="line">private long lastRefreshMs;</span><br><span class="line">&#x2F;&#x2F;上一次更新元数据成功的时间戳</span><br><span class="line">private long lastSuccessfulRefreshMs;</span><br><span class="line">&#x2F;&#x2F;记录kafka集群的元数据</span><br><span class="line">private Cluster cluster;</span><br><span class="line">private boolean needUpdate;</span><br><span class="line">&#x2F;&#x2F;topic最新的元数据</span><br><span class="line">private final Set&lt;String&gt; topics;</span><br><span class="line">private final List&lt;Listener&gt; listeners;</span><br><span class="line">private boolean needMetadataForAllTopics;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>metadata类中主要的waitOnMetadata()方法主要时触发元数据的更新</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private long waitOnMetadata(String topic, long maxWaitMs) throws InterruptedException &#123;</span><br><span class="line">      &#x2F;&#x2F; add topic to metadata topic list if it is not there already.</span><br><span class="line">      if (!this.metadata.containsTopic(topic))</span><br><span class="line">          this.metadata.add(topic);</span><br><span class="line">          </span><br><span class="line">      &#x2F;&#x2F;成功获取分区的详细信息</span><br><span class="line">      if (metadata.fetch().partitionsForTopic(topic) !&#x3D; null)</span><br><span class="line">          return 0;</span><br><span class="line"></span><br><span class="line">      long begin &#x3D; time.milliseconds();</span><br><span class="line">      long remainingWaitMs &#x3D; maxWaitMs;</span><br><span class="line">      while (metadata.fetch().partitionsForTopic(topic) &#x3D;&#x3D; null) &#123;</span><br><span class="line">          &#x2F;&#x2F;设置needupdate,获取当前元数据版本号</span><br><span class="line">          int version &#x3D; metadata.requestUpdate();</span><br><span class="line">          sender.wakeup();&#x2F;&#x2F;唤醒sender线程</span><br><span class="line">          &#x2F;&#x2F;阻塞等待元数据更新完毕</span><br><span class="line">          metadata.awaitUpdate(version, remainingWaitMs);</span><br><span class="line">          long elapsed &#x3D; time.milliseconds() - begin;</span><br><span class="line">          if (elapsed &gt;&#x3D; maxWaitMs)</span><br><span class="line">              throw new TimeoutException(&quot;Failed to update metadata after &quot; + maxWaitMs + &quot; ms.&quot;);</span><br><span class="line">          if (metadata.fetch().unauthorizedTopics().contains(topic))</span><br><span class="line">              throw new TopicAuthorizationException(topic);</span><br><span class="line">          remainingWaitMs &#x3D; maxWaitMs - elapsed;</span><br><span class="line">      &#125;</span><br><span class="line">      return time.milliseconds() - begin;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="Serializer和Deserializer"><a href="#Serializer和Deserializer" class="headerlink" title="Serializer和Deserializer"></a>Serializer和Deserializer</h2><p>客户端发送的消息的key和value都是byte数组,这两个接口实现了将java对象序列化和反序列化为byte数组的功能.</p>
<h2 id="partitioner"><a href="#partitioner" class="headerlink" title="partitioner"></a>partitioner</h2><p>kafkaProducer.send()方法的下一步操作是选择消息的分区.DefaultPartitioner中对partition的实现.直接上代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;初始化一个随机数,是线程安全的AtomicInteger对象</span><br><span class="line">private final AtomicInteger counter &#x3D; new AtomicInteger(new Random().nextInt());</span><br><span class="line"></span><br><span class="line">public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123;</span><br><span class="line">    &#x2F;&#x2F;从cluster中获取分片信息</span><br><span class="line">    List&lt;PartitionInfo&gt; partitions &#x3D; cluster.partitionsForTopic(topic);</span><br><span class="line">    int numPartitions &#x3D; partitions.size();</span><br><span class="line">    if (keyBytes &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;对于没有key的情况,递增counter</span><br><span class="line">        int nextValue &#x3D; counter.getAndIncrement();</span><br><span class="line">        List&lt;PartitionInfo&gt; availablePartitions &#x3D; cluster.availablePartitionsForTopic(topic);</span><br><span class="line">        if (availablePartitions.size() &gt; 0) &#123;</span><br><span class="line">            int part &#x3D; DefaultPartitioner.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">            return availablePartitions.get(part).partition();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            &#x2F;&#x2F; no partitions are available, give a non-available partition</span><br><span class="line">            return DefaultPartitioner.toPositive(nextValue) % numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        &#x2F;&#x2F; hash the keyBytes to choose a partition</span><br><span class="line">        &#x2F;&#x2F;对于有key的情况,对key进行hash(murmur2的hash算法),然后与分区数量取模</span><br><span class="line">        return DefaultPartitioner.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="RecordAccumulator分析"><a href="#RecordAccumulator分析" class="headerlink" title="RecordAccumulator分析"></a>RecordAccumulator分析</h1><p>kafkaProducer可以有同步和异步两种方式发送消息,两者的底层实现都是异步的.主线程send()方法发送消息的时候,现将消息放到RecordAccumulator中缓存,然后主线程可以从send()方法中返回了,其实消息没有真正的发送,而是缓存在RecordAccumulator对象中,业务线程不断的通过send方法追加消息,达到一定条件会唤醒Sender线程,发送RecordAccumulator中的消息.</p>
<p>RecordAccumulator至少有一个业务线程和一个Sender线程并发操作,所以RecordAccumulator时线程安全的.</p>
<p>RecordAccumulator中有一个以TopicPartition为key的ConcurrentMap,每个value都是Deque<RecordBatch>,每个RecordBatch都拥有一个MemoryRecords的对象的引用,MemoryRecords才是消息最终存放的地方</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public final class RecordAccumulator&#123;</span><br><span class="line"></span><br><span class="line">    private final ConcurrentMap&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; batches;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="MemoryRecords对象"><a href="#MemoryRecords对象" class="headerlink" title="MemoryRecords对象"></a>MemoryRecords对象</h2><p>该对象很重有四个字段比较重要</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;压缩器,对消息数据进行压缩,将压缩后的数据输出到buffer</span><br><span class="line">private final Compressor compressor;</span><br><span class="line">&#x2F;&#x2F;记录buffer字段最多可以写入多少字节的数据</span><br><span class="line">private final int writeLimit;</span><br><span class="line">&#x2F;&#x2F;用于保存消息数据的javaNIO ByteBuffer</span><br><span class="line">private ByteBuffer buffer;</span><br><span class="line">&#x2F;&#x2F;MemoryRecords对象是只读模式,还是可写模式,该对象发送前时,将其设置为只读模式.</span><br><span class="line">private boolean writable;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>compressor中重要的字段有bufferStream和appendStream.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 压缩操作</span><br><span class="line">public Compressor(ByteBuffer buffer, CompressionType type) &#123;</span><br><span class="line">        this.type &#x3D; type;</span><br><span class="line"></span><br><span class="line">        if (type !&#x3D; CompressionType.NONE) &#123;</span><br><span class="line">            &#x2F;&#x2F; for compressed records, leave space for the header and the shallow message metadata</span><br><span class="line">            &#x2F;&#x2F; and move the starting position to the value payload offset</span><br><span class="line">            buffer.position(initPos + Records.LOG_OVERHEAD + Record.RECORD_OVERHEAD);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; create the stream</span><br><span class="line">        bufferStream &#x3D; new ByteBufferOutputStream(buffer);</span><br><span class="line">        &#x2F;&#x2F;根据压缩类型创建合适的压缩流</span><br><span class="line">        appendStream &#x3D; wrapForOutput(bufferStream, type, COMPRESSION_DEFAULT_BUFFER_SIZE);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#x2F;&#x2F;包装压缩流</span><br><span class="line">    public static DataOutputStream wrapForOutput(ByteBufferOutputStream buffer, CompressionType type, int bufferSize) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            switch (type) &#123;</span><br><span class="line">                case NONE:</span><br><span class="line">                    return new DataOutputStream(buffer);</span><br><span class="line">                case GZIP:</span><br><span class="line">                    return new DataOutputStream(new GZIPOutputStream(buffer, bufferSize));</span><br><span class="line">                case SNAPPY:</span><br><span class="line">                    try &#123;</span><br><span class="line">                        OutputStream stream &#x3D; (OutputStream) snappyOutputStreamSupplier.get().newInstance(buffer, bufferSize);</span><br><span class="line">                        return new DataOutputStream(stream);</span><br><span class="line">                    &#125; catch (Exception e) &#123;</span><br><span class="line">                        throw new KafkaException(e);</span><br><span class="line">                    &#125;</span><br><span class="line">                case LZ4:</span><br><span class="line">                    try &#123;</span><br><span class="line">                        OutputStream stream &#x3D; (OutputStream) lz4OutputStreamSupplier.get().newInstance(buffer);</span><br><span class="line">                        return new DataOutputStream(stream);</span><br><span class="line">                    &#125; catch (Exception e) &#123;</span><br><span class="line">                        throw new KafkaException(e);</span><br><span class="line">                    &#125;</span><br><span class="line">                default:</span><br><span class="line">                    throw new IllegalArgumentException(&quot;Unknown compression type: &quot; + type);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            throw new KafkaException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> compressor提供了一系列put*()方法,向appendStream中写入数据,这是个装饰器模式,通过bufferStream装饰,添加自动扩容的功能.</span><br><span class="line"> </span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>通过emptyRecords()方法得到MemoryRecords对象,</p>
<p>append() 判断MemoryRecords对象是否为可写模式,然后调用Compressor.put*()方法,将消息写入到ByteBuffer对象</p>
<p>hashRoomFor() 估计对象中是否有空间继续吸入数据</p>
<p>close()方法,将buffer字段指向另一个ByteBuffer对象,将writable设置为false.</p>
<p>sizeInBytes()方法:返回MemoryRecords.buffer()的大小</p>
<h2 id="RecordBatch"><a href="#RecordBatch" class="headerlink" title="RecordBatch"></a>RecordBatch</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final class RecordBatch &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 记录的个数</span><br><span class="line">    public int recordCount &#x3D; 0;</span><br><span class="line">    &#x2F;&#x2F;最大record的字节数</span><br><span class="line">    public int maxRecordSize &#x3D; 0;</span><br><span class="line">    &#x2F;&#x2F;尝试发送当前recordBatch的次数</span><br><span class="line">    public volatile int attempts &#x3D; 0;</span><br><span class="line">    &#x2F;&#x2F;最后一次尝试发送的时间戳    </span><br><span class="line">    public long lastAttemptMs;</span><br><span class="line">    &#x2F;&#x2F;用来存储数据的MemoryRecords对象</span><br><span class="line">    public final MemoryRecords records;</span><br><span class="line">    &#x2F;&#x2F;MemoryRecords对象中存储的数据会批量发送给topicPartition</span><br><span class="line">    public final TopicPartition topicPartition;</span><br><span class="line">    &#x2F;&#x2F;标示RecordBatch状态的future对象</span><br><span class="line">    public final ProduceRequestResult produceFuture;</span><br><span class="line">    &#x2F;&#x2F;上一次追加消息的时间</span><br><span class="line">    public long lastAppendTime;</span><br><span class="line">    &#x2F;&#x2F;thunks对象的集合</span><br><span class="line">    private final List&lt;Thunk&gt; thunks;</span><br><span class="line">    &#x2F;&#x2F;某消息在recordBatch对象中的偏移量</span><br><span class="line">    private long offsetCounter &#x3D; 0L;</span><br><span class="line">    &#x2F;&#x2F;是否正在进行重试</span><br><span class="line">    private boolean retry;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>RecordBatch主要用于封装MemoryRecords以及其他的一些统计类型的信息。</p>
<p>ProduceRequestResult: 完成生产者请求的一个结果类，但是该类并没有根据并发库下的Future来实现而是根据CountDownLatch来实现。当RecordBatch中全部消息被正常响应，或超市或关闭生产者时，会调用done方法标记完成，可以通过error字段区分是异常完成还是正常完成</p>
<h3 id="bufferPool"><a href="#bufferPool" class="headerlink" title="bufferPool"></a>bufferPool</h3><p>ByteBuffer的创建和释放是比较消耗资源的,为了实现资源的高效利用,基本上每个成熟的框架或者工具都有一套管理机制.kafka使用bufferPool进行管理.</p>
<p>bufferPool对象只针对特定大小的byteBuffer字段进行管理,memoryRecords的大小由RecordAccumulator.bathSize字段指定</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public final class BufferPool &#123;</span><br><span class="line">    </span><br><span class="line">    &#x2F;&#x2F;整个bufferPool的大小</span><br><span class="line">    private final long totalMemory;</span><br><span class="line">    private final int poolableSize;</span><br><span class="line">    &#x2F;&#x2F;因为有多线程并发分配和回收byteBuffer,所以使用所控制并发线程的安全</span><br><span class="line">    private final ReentrantLock lock;</span><br><span class="line">    &#x2F;&#x2F;是一个队列,缓存了指定大小的byteBuffer对象</span><br><span class="line">    private final Deque&lt;ByteBuffer&gt; free;</span><br><span class="line">    &#x2F;&#x2F;记录因申请不到足够空间而阻塞的线程,此队列中实际记录的是阻塞线程对应的Condition对象</span><br><span class="line">    private final Deque&lt;Condition&gt; waiters;</span><br><span class="line">    &#x2F;&#x2F;整个可用空间的大小,totalMemory-free</span><br><span class="line">    private long availableMemory;</span><br><span class="line">    private final Metrics metrics;</span><br><span class="line">    private final Time time;</span><br><span class="line">    private final Sensor waitTime;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>allocate方法负责从bufferPool中申请ByteBuffer,当缓冲池中空间不足时,就会阻塞调用线程.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;申请空间</span><br><span class="line"></span><br><span class="line">public ByteBuffer allocate(int size, long maxTimeToBlockMs) throws InterruptedException &#123;</span><br><span class="line">        if (size &gt; this.totalMemory)</span><br><span class="line">            throw new IllegalArgumentException(&quot;Attempt to allocate &quot; + size</span><br><span class="line">                                               + &quot; bytes, but there is a hard limit of &quot;</span><br><span class="line">                                               + this.totalMemory</span><br><span class="line">                                               + &quot; on memory allocations.&quot;);</span><br><span class="line">    &#x2F;&#x2F;加锁同步</span><br><span class="line">        this.lock.lock();</span><br><span class="line">        try &#123;</span><br><span class="line">            &#x2F;&#x2F; check if we have a free buffer of the right size pooled</span><br><span class="line">            if (size &#x3D;&#x3D; poolableSize &amp;&amp; !this.free.isEmpty())</span><br><span class="line">                return this.free.pollFirst();</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; now check if the request is immediately satisfiable with the</span><br><span class="line">            &#x2F;&#x2F; memory on hand or if we need to block</span><br><span class="line">            int freeListSize &#x3D; this.free.size() * this.poolableSize;</span><br><span class="line">            if (this.availableMemory + freeListSize &gt;&#x3D; size) &#123;</span><br><span class="line">                &#x2F;&#x2F; we have enough unallocated or pooled memory to immediately</span><br><span class="line">                &#x2F;&#x2F; satisfy the request</span><br><span class="line">                freeUp(size);</span><br><span class="line">                this.availableMemory -&#x3D; size;</span><br><span class="line">                lock.unlock();</span><br><span class="line">                return ByteBuffer.allocate(size);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                &#x2F;&#x2F; we are out of memory and will have to block</span><br><span class="line">                int accumulated &#x3D; 0;</span><br><span class="line">                ByteBuffer buffer &#x3D; null;</span><br><span class="line">                Condition moreMemory &#x3D; this.lock.newCondition();</span><br><span class="line">                long remainingTimeToBlockNs &#x3D; TimeUnit.MILLISECONDS.toNanos(maxTimeToBlockMs);</span><br><span class="line">                this.waiters.addLast(moreMemory);</span><br><span class="line">                &#x2F;&#x2F; loop over and over until we have a buffer or have reserved</span><br><span class="line">                &#x2F;&#x2F; enough memory to allocate one</span><br><span class="line">                while (accumulated &lt; size) &#123;</span><br><span class="line">                    long startWaitNs &#x3D; time.nanoseconds();</span><br><span class="line">                    long timeNs;</span><br><span class="line">                    boolean waitingTimeElapsed;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        waitingTimeElapsed &#x3D; !moreMemory.await(remainingTimeToBlockNs, TimeUnit.NANOSECONDS);</span><br><span class="line">                    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                        this.waiters.remove(moreMemory);</span><br><span class="line">                        throw e;</span><br><span class="line">                    &#125; finally &#123;</span><br><span class="line">                        long endWaitNs &#x3D; time.nanoseconds();</span><br><span class="line">                        timeNs &#x3D; Math.max(0L, endWaitNs - startWaitNs);</span><br><span class="line">                        this.waitTime.record(timeNs, time.milliseconds());</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    if (waitingTimeElapsed) &#123;</span><br><span class="line">                        this.waiters.remove(moreMemory);</span><br><span class="line">                        throw new TimeoutException(&quot;Failed to allocate memory within the configured max blocking time &quot; + maxTimeToBlockMs + &quot; ms.&quot;);</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    remainingTimeToBlockNs -&#x3D; timeNs;</span><br><span class="line">                    &#x2F;&#x2F; check if we can satisfy this request from the free list,</span><br><span class="line">                    &#x2F;&#x2F; otherwise allocate memory</span><br><span class="line">                    if (accumulated &#x3D;&#x3D; 0 &amp;&amp; size &#x3D;&#x3D; this.poolableSize &amp;&amp; !this.free.isEmpty()) &#123;</span><br><span class="line">                        &#x2F;&#x2F; just grab a buffer from the free list</span><br><span class="line">                        buffer &#x3D; this.free.pollFirst();</span><br><span class="line">                        accumulated &#x3D; size;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        &#x2F;&#x2F; we&#39;ll need to allocate memory, but we may only get</span><br><span class="line">                        &#x2F;&#x2F; part of what we need on this iteration</span><br><span class="line">                        freeUp(size - accumulated);</span><br><span class="line">                        int got &#x3D; (int) Math.min(size - accumulated, this.availableMemory);</span><br><span class="line">                        this.availableMemory -&#x3D; got;</span><br><span class="line">                        accumulated +&#x3D; got;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; remove the condition for this thread to let the next thread</span><br><span class="line">                &#x2F;&#x2F; in line start getting memory</span><br><span class="line">                Condition removed &#x3D; this.waiters.removeFirst();</span><br><span class="line">                if (removed !&#x3D; moreMemory)</span><br><span class="line">                    throw new IllegalStateException(&quot;Wrong condition: this shouldn&#39;t happen.&quot;);</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; signal any additional waiters if there is more memory left</span><br><span class="line">                &#x2F;&#x2F; over for them</span><br><span class="line">                if (this.availableMemory &gt; 0 || !this.free.isEmpty()) &#123;</span><br><span class="line">                    if (!this.waiters.isEmpty())</span><br><span class="line">                        this.waiters.peekFirst().signal();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; unlock and return the buffer</span><br><span class="line">                lock.unlock();</span><br><span class="line">                if (buffer &#x3D;&#x3D; null)</span><br><span class="line">                    return ByteBuffer.allocate(size);</span><br><span class="line">                else</span><br><span class="line">                    return buffer;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            if (lock.isHeldByCurrentThread())</span><br><span class="line">                lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 释放空间</span><br><span class="line"></span><br><span class="line">public void deallocate(ByteBuffer buffer, int size) &#123;</span><br><span class="line">    lock.lock();</span><br><span class="line">    try &#123;</span><br><span class="line">        if (size &#x3D;&#x3D; this.poolableSize &amp;&amp; size &#x3D;&#x3D; buffer.capacity()) &#123;</span><br><span class="line">            buffer.clear();</span><br><span class="line">            this.free.add(buffer);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            this.availableMemory +&#x3D; size;</span><br><span class="line">        &#125;</span><br><span class="line">        Condition moreMem &#x3D; this.waiters.peekFirst();</span><br><span class="line">        if (moreMem !&#x3D; null)</span><br><span class="line">            moreMem.signal();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="RecordAccumulator详解"><a href="#RecordAccumulator详解" class="headerlink" title="RecordAccumulator详解"></a>RecordAccumulator详解</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final class RecordAccumulator &#123;</span><br><span class="line"></span><br><span class="line">    private volatile boolean closed;</span><br><span class="line">    private final AtomicInteger flushesInProgress;</span><br><span class="line">    private final AtomicInteger appendsInProgress;</span><br><span class="line">    &#x2F;&#x2F;每个recordBath底层ByteBuffer的大小</span><br><span class="line">    private final int batchSize;</span><br><span class="line">    &#x2F;&#x2F;压缩类型</span><br><span class="line">    private final CompressionType compression;</span><br><span class="line">    private final long lingerMs;</span><br><span class="line">    private final long retryBackoffMs;</span><br><span class="line">    &#x2F;&#x2F;bufferPool对象</span><br><span class="line">    private final BufferPool free;</span><br><span class="line">    private final Time time;</span><br><span class="line">    &#x2F;&#x2F;topicPartition与recordBath集合的映射关系,CopyOnWriteMap时线程安全的集合</span><br><span class="line">    private final ConcurrentMap&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; batches;</span><br><span class="line">    &#x2F;&#x2F;未发送完成的RecordBatch集合</span><br><span class="line">    private final IncompleteRecordBatches incomplete;</span><br><span class="line">    &#x2F;&#x2F; The following variables are only accessed by the sender thread, so we don&#39;t need to protect them.</span><br><span class="line">    private final Set&lt;TopicPartition&gt; muted;</span><br><span class="line">    &#x2F;&#x2F;使用drain方法批量导入RecordBath时,为了防止饥饿,记录上次发送停止时的位置,下次饥饿从此位置开始</span><br><span class="line">    private int drainIndex;</span><br><span class="line">    </span><br><span class="line">    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; drain(Cluster cluster,</span><br><span class="line">                                                     Set&lt;Node&gt; nodes,</span><br><span class="line">                                                     int maxSize,</span><br><span class="line">                                                     long now)</span><br><span class="line">                                                     </span><br><span class="line">    public ReadyCheckResult ready(Cluster cluster, long nowMs)                                                      </span><br><span class="line">                                                     </span><br><span class="line">    private RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Callback callback, Deque&lt;RecordBatch&gt; deque)</span><br><span class="line">    </span><br><span class="line">    public RecordAppendResult append(TopicPartition tp,</span><br><span class="line">                                               long timestamp,</span><br><span class="line">                                               byte[] key,</span><br><span class="line">                                               byte[] value,</span><br><span class="line">                                               Callback callback,</span><br><span class="line">                                               long maxTimeToBlock) throws InterruptedException                                  </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>kafkaProducer.send()方法最终会调用recordsAccumulator.append()方法将消息追加到RecordAccumulator中</p>
<ol>
<li>首先在batches集合中查找topicPartition对应的Deque,查找不到则创建新的Deque,并添加到batches集合中;</li>
<li>对Deque加锁(使用synchronize关键字加锁)</li>
<li>使用tryAppend()方法,尝试向Deque中最后一个RecordBatch追加record</li>
<li>synchronize块结束,自动解锁</li>
<li>追加成功,返回RecordAppendResult,</li>
<li>追加失败,则尝试从bufferPool中申请新的byteBuffer</li>
<li>对Deque加锁,</li>
<li>追加成功,则返回,追加失败则使用第五步得到的ByteBuffer创建RecordBatch,</li>
<li>将Record追加到新建的RecordBatch,并将新建的RecordBatch追加到Deque尾部</li>
<li>将新建的RecordBatch追加到incomplete集合中</li>
<li>synchronize代码块结束,自动解锁</li>
<li>返回RecordAppendResult,RecordAppendResult中的字段作为唤醒Sender线程的条件.</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public RecordAppendResult append(TopicPartition tp,</span><br><span class="line">                                 long timestamp,</span><br><span class="line">                                 byte[] key,</span><br><span class="line">                                 byte[] value,</span><br><span class="line">                                 Callback callback,</span><br><span class="line">                                 long maxTimeToBlock) throws InterruptedException &#123;</span><br><span class="line">    &#x2F;&#x2F; We keep track of the number of appending thread to make sure we do not miss batches in</span><br><span class="line">    &#x2F;&#x2F; abortIncompleteBatches().</span><br><span class="line">    appendsInProgress.incrementAndGet();</span><br><span class="line">    try &#123;</span><br><span class="line">        &#x2F;&#x2F; check if we have an in-progress batch</span><br><span class="line">        Deque&lt;RecordBatch&gt; dq &#x3D; getOrCreateDeque(tp);</span><br><span class="line">        synchronized (dq) &#123;</span><br><span class="line">            if (closed)</span><br><span class="line">                throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);</span><br><span class="line">            RecordAppendResult appendResult &#x3D; tryAppend(timestamp, key, value, callback, dq);</span><br><span class="line">            if (appendResult !&#x3D; null)</span><br><span class="line">                return appendResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; we don&#39;t have an in-progress record batch try to allocate a new batch</span><br><span class="line">        int size &#x3D; Math.max(this.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));</span><br><span class="line">        log.trace(&quot;Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;&quot;, size, tp.topic(), tp.partition());</span><br><span class="line">        ByteBuffer buffer &#x3D; free.allocate(size, maxTimeToBlock);</span><br><span class="line">        synchronized (dq) &#123;</span><br><span class="line">            &#x2F;&#x2F; Need to check if producer is closed again after grabbing the dequeue lock.</span><br><span class="line">            if (closed)</span><br><span class="line">                throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);</span><br><span class="line"></span><br><span class="line">            RecordAppendResult appendResult &#x3D; tryAppend(timestamp, key, value, callback, dq);</span><br><span class="line">            if (appendResult !&#x3D; null) &#123;</span><br><span class="line">                &#x2F;&#x2F; Somebody else found us a batch, return the one we waited for! Hopefully this doesn&#39;t happen often...</span><br><span class="line">                free.deallocate(buffer);</span><br><span class="line">                return appendResult;</span><br><span class="line">            &#125;</span><br><span class="line">            MemoryRecords records &#x3D; MemoryRecords.emptyRecords(buffer, compression, this.batchSize);</span><br><span class="line">            RecordBatch batch &#x3D; new RecordBatch(tp, records, time.milliseconds());</span><br><span class="line">            FutureRecordMetadata future &#x3D; Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">            dq.addLast(batch);</span><br><span class="line">            incomplete.add(batch);</span><br><span class="line">            return new RecordAppendResult(future, dq.size() &gt; 1 || batch.records.isFull(), true);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        appendsInProgress.decrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>drain方法是将各个node节点的RecordBatch进行分组.在网络IO层面发送的时候,生产者时面向node层面发送消息数据.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public Map&lt;Integer, List&lt;RecordBatch&gt;&gt; drain(Cluster cluster,</span><br><span class="line">                                                 Set&lt;Node&gt; nodes,</span><br><span class="line">                                                 int maxSize,</span><br><span class="line">                                                 long now) &#123;</span><br><span class="line">        if (nodes.isEmpty())</span><br><span class="line">            return Collections.emptyMap();</span><br><span class="line">        &#x2F;&#x2F;转换后的结果</span><br><span class="line">        Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        for (Node node : nodes) &#123; &#x2F;&#x2F;遍历指定ready node集合</span><br><span class="line">            int size &#x3D; 0;</span><br><span class="line">            &#x2F;&#x2F;获取当前node上的分区集合</span><br><span class="line">            List&lt;PartitionInfo&gt; parts &#x3D; cluster.partitionsForNode(node.id());</span><br><span class="line">            &#x2F;&#x2F;记录要发送的RecordBatch drainIndex 时Batches的下标,记录上次发送停止的位置, 如果一直从0开发发送,会造成其它的分区饥饿</span><br><span class="line">            List&lt;RecordBatch&gt; ready &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">            &#x2F;* to make starvation less likely this loop doesn&#39;t start at 0 *&#x2F;</span><br><span class="line">            int start &#x3D; drainIndex &#x3D; drainIndex % parts.size();</span><br><span class="line">            do &#123;</span><br><span class="line">            &#x2F;&#x2F;获取分区的详细情况</span><br><span class="line">                PartitionInfo part &#x3D; parts.get(drainIndex);</span><br><span class="line">                TopicPartition tp &#x3D; new TopicPartition(part.topic(), part.partition());</span><br><span class="line">                &#x2F;&#x2F; Only proceed if the partition has no in-flight batches.</span><br><span class="line">                if (!muted.contains(tp)) &#123;</span><br><span class="line">                    Deque&lt;RecordBatch&gt; deque &#x3D; getDeque(new TopicPartition(part.topic(), part.partition()));</span><br><span class="line">                    if (deque !&#x3D; null) &#123;</span><br><span class="line">                        synchronized (deque) &#123;</span><br><span class="line">                            RecordBatch first &#x3D; deque.peekFirst();</span><br><span class="line">                            if (first !&#x3D; null) &#123;</span><br><span class="line">                                boolean backoff &#x3D; first.attempts &gt; 0 &amp;&amp; first.lastAttemptMs + retryBackoffMs &gt; now;</span><br><span class="line">                                &#x2F;&#x2F; Only drain the batch if it is not during backoff period.</span><br><span class="line">                                if (!backoff) &#123;</span><br><span class="line">                                    if (size + first.records.sizeInBytes() &gt; maxSize &amp;&amp; !ready.isEmpty()) &#123;</span><br><span class="line">                                        &#x2F;&#x2F; there is a rare case that a single batch size is larger than the request size due</span><br><span class="line">                                        &#x2F;&#x2F; to compression; in this case we will still eventually send this batch in a single</span><br><span class="line">                                        &#x2F;&#x2F; request</span><br><span class="line">                                        break;</span><br><span class="line">                                    &#125; else &#123;</span><br><span class="line">                                        RecordBatch batch &#x3D; deque.pollFirst();</span><br><span class="line">                                        batch.records.close();</span><br><span class="line">                                        size +&#x3D; batch.records.sizeInBytes();</span><br><span class="line">                                        ready.add(batch);</span><br><span class="line">                                        batch.drainedMs &#x3D; now;</span><br><span class="line">                                    &#125;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                this.drainIndex &#x3D; (this.drainIndex + 1) % parts.size();</span><br><span class="line">            &#125; while (start !&#x3D; drainIndex);</span><br><span class="line">            batches.put(node.id(), ready);</span><br><span class="line">        &#125;</span><br><span class="line">        return batches;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="Sender分析"><a href="#Sender分析" class="headerlink" title="Sender分析"></a>Sender分析</h1><p>流程: 首先根据RecordAccumulator的缓存情况,筛选出可以向哪些node节点发送信息,即之前介绍的ready方法,然后根据生产者与各个节点的连接情况,过滤node节点,生成相应的请求,每个node节点只生成一个请求,最后调用netWorkClient将将请求发送出去.</p>
<p>Sender实现了Runnable接口,并运行在单独的ioThread中,sender的run()方法调用了其重载run(long),这是sender方法的核心.</p>
<p><img src="/images/kafka/producer/sender%E6%96%B9%E6%B3%95%E7%9A%84%E6%97%B6%E5%BA%8F%E5%9B%BE.png" alt="sender方法的时序图"></p>
<ol>
<li>从metadata获取kafka集群的元数据</li>
<li>调用RecordAccumulator.read()方法,根据RecordAccumulator的缓存情况,选出可以想那些node节点发送消息,返回readyCheckResult对象</li>
<li>如果readyCheckResult中标识有unknownLeadersExist,则调用Metadata的requestUpdate方法,标记需要更新kafka的集群消息.</li>
<li>针对readyCheckResult中readynodes集合,循环调用netWorkClient.Ready()方法,目的时检查网络IO是否符合发送消息的条件,不符合的将会从readyNodes节点中删除</li>
<li>调用RecordAccumulator.drain()方法获取待发送的消息集合.</li>
<li>调用RecordAccumulator.abortExpiredBatches()方法处理超时的消息,具体是遍历全部的recordBatch 调用maybeExpire()进行处理,如果已经超时调用recordBatch.done()方法出发自定义的callback,将RecordBatch从队列中移除,释放ByteBuffer.</li>
<li>调用Sender.createProduceRequests()方法将待发送的消息封装成ClientRequest</li>
<li>调用networkClient.send()方法,将ClientRequest写入kafkaChanel的send字段.</li>
<li>调用netWorkClient.poll()方法,将kafkaChannel.send字段中保存的clientRequest发送出去,还会处理客户端发回的相应,处理超时的请求,调用用户自定义的callback</li>
</ol>
<h2 id="创建请求"><a href="#创建请求" class="headerlink" title="创建请求"></a>创建请求</h2><p>![produce request和produce response](/images/kafka/producer/produce request和produce response.png)</p>
<p><img src="/images/kafka/producer/%E5%8D%8F%E8%AE%AE%E5%90%84%E4%B8%AA%E5%AD%97%E6%AE%B5%E7%9A%84%E8%A7%A3%E9%87%8A.png" alt="协议各个字段的解释"></p>
<p>createProduceRequests的代码:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * Transfer the record batches into a list of produce requests on a per-node basis</span><br><span class="line"> *&#x2F;</span><br><span class="line">private List&lt;ClientRequest&gt; createProduceRequests(Map&lt;Integer, List&lt;RecordBatch&gt;&gt; collated, long now) &#123;</span><br><span class="line">    List&lt;ClientRequest&gt; requests &#x3D; new ArrayList&lt;ClientRequest&gt;(collated.size());</span><br><span class="line">    for (Map.Entry&lt;Integer, List&lt;RecordBatch&gt;&gt; entry : collated.entrySet())</span><br><span class="line">    &#x2F;&#x2F;调用produceRequest方法,将发往同一node的RecordBatch分装成一个ClientRequest对象</span><br><span class="line">        requests.add(produceRequest(now, entry.getKey(), acks, requestTimeout, entry.getValue()));</span><br><span class="line">    return requests;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * Create a produce request from the given record batches</span><br><span class="line"> *&#x2F;</span><br><span class="line">private ClientRequest produceRequest(long now, int destination, short acks, int timeout, List&lt;RecordBatch&gt; batches) &#123;</span><br><span class="line">    Map&lt;TopicPartition, ByteBuffer&gt; produceRecordsByPartition &#x3D; new HashMap&lt;TopicPartition, ByteBuffer&gt;(batches.size());</span><br><span class="line">    final Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition &#x3D; new HashMap&lt;TopicPartition, RecordBatch&gt;(batches.size());</span><br><span class="line">    &#x2F;&#x2F;将recordBatch 列表按照partition分类,整理成上述两个集合</span><br><span class="line">    for (RecordBatch batch : batches) &#123;</span><br><span class="line">        TopicPartition tp &#x3D; batch.topicPartition;</span><br><span class="line">        produceRecordsByPartition.put(tp, batch.records.buffer());</span><br><span class="line">        recordsByPartition.put(tp, batch);</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;创建produceRequest 和requestSend</span><br><span class="line">    ProduceRequest request &#x3D; new ProduceRequest(acks, timeout, produceRecordsByPartition);</span><br><span class="line">    RequestSend send &#x3D; new RequestSend(Integer.toString(destination),</span><br><span class="line">                                       this.client.nextRequestHeader(ApiKeys.PRODUCE),</span><br><span class="line">                                       request.toStruct());</span><br><span class="line">    RequestCompletionHandler callback &#x3D; new RequestCompletionHandler() &#123;</span><br><span class="line">        public void onComplete(ClientResponse response) &#123;</span><br><span class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    return new ClientRequest(now, acks !&#x3D; 0, send, callback);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="KSelector"><a href="#KSelector" class="headerlink" title="KSelector"></a>KSelector</h2><p>在介绍netWorkClient之前,先了解其结构,它是属于kafka自己的包下的结构.</p>
<p><img src="/images/kafka/producer/kselector.png" alt="kselector"></p>
<h2 id="networkClient"><a href="#networkClient" class="headerlink" title="networkClient"></a>networkClient</h2><p><img src="/images/kafka/producer/networkClient.png" alt="networkClient"></p>
]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka的producer</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql实战-基础架构</title>
    <url>/2020-08-11/mysql%E5%AE%9E%E6%88%98-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<h4 id="mysql的架构逻辑"><a href="#mysql的架构逻辑" class="headerlink" title="mysql的架构逻辑"></a>mysql的架构逻辑</h4><p><img src="/images/mysql2/mysql%E7%9A%84%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="mysql的逻辑架构图"></p>
<blockquote>
<ul>
<li><p>连接器：负责跟客户端建立连接、获取权限、维持和管理连接；建议使用长连接，定期断开长连接，或者定期进行重置连接；</p>
</li>
<li><p>分析器：包括词法分析：多个字符串和和空格组成的sql语句，需要识别出里面的字符串分别代表什么，表字段是否存在，是否正确，是否有歧义；之后要做语法分析，就是判断一些语法规则，比如select需要符合什么规则；</p>
</li>
<li><p>优化器：优化器选择使用什么索引，使用连接的顺序等都是需要进行优化的；</p>
</li>
<li><h4 id="执行器：先判断是否有权限，然后进行遍历每一个满足条件的行并且执行操作；"><a href="#执行器：先判断是否有权限，然后进行遍历每一个满足条件的行并且执行操作；" class="headerlink" title="执行器：先判断是否有权限，然后进行遍历每一个满足条件的行并且执行操作；"></a>执行器：先判断是否有权限，然后进行遍历每一个满足条件的行并且执行操作；</h4></li>
</ul>
</blockquote>
<h4 id="mysql的日志系统"><a href="#mysql的日志系统" class="headerlink" title="mysql的日志系统"></a>mysql的日志系统</h4><blockquote>
<ul>
<li>redo log 日志，是innodb存储引擎特有的日志 <a href="https://www.cnblogs.com/hzmark/p/wal.html">wal机制</a></li>
</ul>
<p>如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高</p>
<p> <code>redo日志</code>：当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB。</p>
<p>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为<strong>crash-safe</strong>。</p>
<ul>
<li><p>binlog日志</p>
<p>binlog是MySQL的Server层实现的，所有引擎都可以使用，他记录的是原始语句；</p>
</li>
<li><p>两种日志的不同点</p>
<blockquote>
<ol>
<li>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</li>
<li>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。</li>
<li>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li>
</ol>
</blockquote>
</li>
<li><p>执行update语句的执行流程</p>
<blockquote>
<p> update T set c=c+1 where ID=2;</p>
<ol>
<li>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li>
<li>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li>
<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。</li>
<li>执行器生成这个操作的binlog，并把binlog写入磁盘。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。</li>
</ol>
</blockquote>
</li>
<li><p>redo日志两阶段提交</p>
<blockquote>
<p>流程是：redolog的prepare状态，写入binlog，然后commit；这样来保证两个日志存储的数据一致；</p>
<p>主要是为了让redo日志和binlog日志之间的逻辑一致；两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案。</p>
<p>如果不是两阶段提交，使用任意一个日志恢复出来的数据都有可能和原来的库里的数据不一致。</p>
</blockquote>
</li>
<li><p>参数设置</p>
<blockquote>
<p> innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如果把innodb_flush_log_at_trx_commit设置成1，那么redo log在prepare阶段就要持久化一次，因为有一个崩溃恢复逻辑是要 依赖于prepare 的redo log，再加上binlog来恢复的</span><br></pre></td></tr></table></figure>

<p>sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。</p>
</blockquote>
</li>
<li><p>数据持久化的过程</p>
<blockquote>
<p> 在记账的例子中，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。</p>
<p>掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是flush。在这个flush操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。</p>
<p><strong>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”</strong>。</p>
<p>MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。</p>
<p>  <strong>刷脏页的情况：</strong></p>
<ul>
<li><code>InnoDB的redo log写满了</code>。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写</li>
<li><code>对应的就是系统内存不足</code>。 当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。</li>
<li>对应的就是MySQL认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”</li>
<li>MySQL正常关闭的情况。</li>
</ul>
</blockquote>
</li>
<li><p>redo log和change buffer的区别</p>
<blockquote>
<p> <strong>redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。</strong></p>
</blockquote>
</li>
<li><p>如果某次写入使用了change buffer机制，之后主机异常重启，是否会丢失change buffer和数据。</p>
<blockquote>
<p> 虽然是只更新内存，但是在事务提交的时候，我们把change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。</p>
</blockquote>
</li>
<li><p>mysql是如何保证数据不丢失的</p>
<blockquote>
<p>结论： </p>
<p>只要redo log和binlog保证持久化到磁盘，就能确保MySQL异常重启后，数据可以恢复。</p>
</blockquote>
</li>
</ul>
<ul>
<li><p>binlog的写入流程</p>
<blockquote>
<p><code>binlog的写入机制</code>：事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。</p>
<p>一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了binlog cache的保存问题 </p>
<p>系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大 小。如果超过了这个参数规定的大小，就要暂存到磁盘。</p>
<p>事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache.</p>
<p><img src="/images/mysql2/binlog%E5%86%99%E7%9B%98%E7%8A%B6%E6%80%81.png" alt="binlog写盘状态"></p>
<p>可以看到，每个线程有自己binlog cache，但是共用同一份binlog文件。  </p>
<ul>
<li><p>图中的write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。 </p>
</li>
<li><p>图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的IOPS。</p>
</li>
</ul>
<p>write 和fsync的时机，是由参数sync_binlog控制的:</p>
<ol>
<li>sync_binlog=0的时候，表示每次提交事务都只write，不fsync;</li>
<li>sync_binlog=1的时候，表示每次提交事务都会执行fsync;</li>
<li>sync_binlog=N(N&gt;1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。</li>
</ol>
<p>出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日 志量的可控性，一般不建议将这个参数设成0，比较常⻅的是将其设置为100~1000中的某个数值</p>
</blockquote>
</li>
</ul>
<ul>
<li><p>redo log的写入流程</p>
<blockquote>
<p> 事务在执行过程中，生成的redo log是要先写到redo log buffer的。</p>
<p>redo log buffer里面的内容，是不是每次生成后都要直接持久化到磁盘呢?  不需要</p>
<p> 事务还没提交的时候，redo log buffer中的部分日志有没有可能被持久化到磁盘呢? 有可能</p>
<p><img src="/images/mysql2/redoLogCunchuzhuangtai.png" alt="redoLogCunchuzhuangtai"></p>
<ul>
<li>存在redo log buffer中，物理上是在MySQL进程内存中，就是图中的红色部分;</li>
<li>写到磁盘(write)，但是没有持久化(fsync)，物理上是在文件系统的page cache里面，也就是图中的⻩色部分; </li>
<li>持久化到磁盘，对应的是hard disk，也就是图中的绿色部分。</li>
</ul>
<p>为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，它有三种可能取值:</p>
<ul>
<li>设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中; </li>
<li>设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘;</li>
<li>设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。</li>
</ul>
<p>InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的page cache，然后调用fsync持久化到磁盘。</p>
<p>两种场景会让一个没有提交的事务的redo log写入到磁盘中:</p>
<ul>
<li><p>一种是，<strong>redo log buffer</strong>占用的空间即将达到 <strong>innodb_log_buffer_size</strong>一半的时候，后台线程会主动写盘。注意，由于 这个事务并没有提交，所以这个写盘动作只是write，而没有调用fsync，也就是只留在了文件系统的page cache。</p>
</li>
<li><p>另一种是，并行的事务提交的时候，顺带将这个事务的<strong>redo log buffer</strong>持久化到磁盘。</p>
</li>
</ul>
</blockquote>
</li>
<li><p>组提交</p>
<blockquote>
<p>日志逻辑序列号(log sequence number，LSN)。LSN是单调递增的，用来对应redo log的一个个写入点。每次写入⻓度为length的redo log， LSN的值就会加上length。</p>
<p>过程</p>
<ul>
<li>trx1是第一个到达的，会被选为这组的 leader;</li>
<li>等trx1要开始写盘的时候，这个组里面已经有了三个事务，这时候LSN也变成了160;</li>
<li>trx1去写盘的时候，带的就是LSN=160，因此等trx1返回时，所有LSN小于等于160的redo log，都已经被持久化到磁盘; 4. 这时候trx2和trx3就可以直接返回了。</li>
</ul>
<p>binlog也有相同的机制</p>
</blockquote>
</li>
<li><p>WAL机制主要得益于两个方面</p>
<blockquote>
<ul>
<li>redo log 和 binlog都是顺序写，磁盘的顺序写比随机写速度要快;</li>
<li>组提交机制，可以大幅度降低磁盘的IOPS消耗。</li>
</ul>
</blockquote>
</li>
<li><p><strong>MySQL</strong>现在出现了性能瓶颈，而且瓶颈在<strong>IO</strong>上，可以通过哪些方法来提升性 能呢?</p>
<blockquote>
<ol>
<li><p>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。</p>
<p>这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的⻛险。</p>
</li>
<li><p>将sync_binlog 设置为大于1的值(比较常⻅是100~1000)。这样做的⻛险是，主机掉电时会丢binlog日志。</p>
</li>
<li><p>将innodb_flush_log_at_trx_commit设置为2。这样做的⻛险是，主机掉电的时候会丢数据。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>常见日志问题</p>
<blockquote>
<ol>
<li><p>执行一个update语句以后，我再去执行hexdump命令直接查看ibd文件内容，为什么没有看到数据有改变呢? </p>
<p>**回答: ** 这可能是因为WAL机制的原因。update语句执行完成后，InnoDB只保证写完了redo log、内存，可能还没来得及将数据写到磁盘。</p>
</li>
<li><p>为什么binlog cache是每个线程自己维护的，而redo log buffer是全局共用的?</p>
<p><strong>回答:</strong> MySQL这么设计的主要原因是，binlog是不能“被打断的”。一个事务的binlog必须连续写，因此要整个事务完成后，再 一起写到文件里。而redo log并没有这个要求，中间有生成的日志可以写到redo log buffer中。redo log buffer中的内容还能“搭便⻋”，其他事务 提交的时候可以被一起写到磁盘中。</p>
</li>
<li><p>事务执行期间，还没到提交阶段，如果发生crash的话，redo log肯定丢了，这会不会导致主备不一致呢?</p>
<p> **回答:**不会。因为这时候binlog 也还在binlog cache里，没发给备库。crash以后redo log和binlog都没有了，从业务⻆度看这个事务也没有提交，所以数据是一致的。</p>
</li>
<li><p>如果binlog写完盘以后发生crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是bug?</p>
<p>**回答:**不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit完成了，备库也收到binlog并执行了。但是主库和客 户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不 能认为是bug。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>数据库的crash-safe保证的是:</p>
<blockquote>
<ul>
<li>如果客户端收到事务成功的消息，事务就一定持久化了;</li>
<li>如果客户端收到事务失败(比如主键冲突、回滚等)的消息，事务就一定失败了;</li>
<li>如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部 (数据和日志之间，主库和备库之间)一致就可以了。</li>
</ul>
</blockquote>
</li>
<li><p>什么情况下需要设置生产库设置为双非1</p>
<blockquote>
<ol>
<li>业务高峰期。一般如果有预知的高峰期，DBA会有预案，把主库设置成“非双1”。</li>
<li>备库延迟，为了让备库尽快赶上主库。</li>
<li>用备份恢复主库的副本，应用binlog的过程，这个跟上一种场景类似。</li>
<li>批量导入数据的时候。</li>
</ol>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="主从同步"><a href="#主从同步" class="headerlink" title="主从同步"></a>主从同步</h4><blockquote>
<ul>
<li><p>binlog可以用来归档，也可以用来做主备同步</p>
</li>
<li><p>建议你把备库设置成只读模式；</p>
</li>
<li><p><strong>主从同步流程</strong></p>
<blockquote>
<ol>
<li>在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位 置包含文件名和日志偏移量。</li>
<li>在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与 主库建立连接。</li>
<li>主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。</li>
<li>备库B拿到binlog后，写到本地文件，称为中转日志(relay log)。</li>
<li>sql_thread读取中转日志，解析出日志里的命令，并执行。</li>
</ol>
</blockquote>
<p>MySQL5.6以前的版本复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。 MySQL5.6版本参数slave-parallel-workers=1 表示启用多线程功能</p>
</li>
<li><p>三种格式对比</p>
<blockquote>
<ul>
<li><p>statement </p>
<blockquote>
<p>查看日志文件 ：show binlog events in ‘master.000001’; </p>
<p>记录的是原始的修改数据库的数据的sql；</p>
<p><code>占用较小的空间，比如删除所有表的数据，但是存在问题，delete from t limit 1 使用不同索引不同，导致删除数据不同，有可能导致主从不一致 </code></p>
</blockquote>
</li>
<li><p>row</p>
<blockquote>
<p>查看日志文件 ：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show binlog events in &#39;master.000001&#39;;</span><br><span class="line">mysqlbinlog -vv data&#x2F;master.000001 --start-position&#x3D;8900</span><br></pre></td></tr></table></figure>

<p>记录的是真实的对应的删除的主键id、或者具体的插入的数据；</p>
<p><code>可以准确记录操作的数据，但是由于记录需要删除很多数据，所以很耗费空间</code></p>
</blockquote>
</li>
</ul>
<ul>
<li><p>mixed</p>
<blockquote>
<p> Mixed 方法利用了两种格式的优点。</p>
<p>设置为mixed后，就会记录为row格式;而如果执行的语句去掉limit 1，就会记录为statement格式。</p>
<p>mixed格式可以利用statment格式的优点，同时又避免了数据不一致的⻛险。</p>
</blockquote>
</li>
</ul>
</blockquote>
</li>
<li><p>双M结构的数据库</p>
<blockquote>
<p>节点A和B之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。</p>
<p>业务逻辑在节点A上更新了一条语句，然后再把生成的binlog 发给节点B，节点B执行完这条更新语句后也会生成binlog。</p>
<p>如果节点A同时是节点B的备库，相当于又把节点B新生成的binlog拿过来执行了一次，然后节点A和B间，会不断地循 环执行这个更新语句，也就是循环复制了。这个要怎么解决呢?</p>
<p><strong>解决方案</strong></p>
<ul>
<li><p>规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系;</p>
</li>
<li><p>一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog;</p>
</li>
<li><p>每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这个日志是自己生成的，就直接 丢弃这个日志。</p>
</li>
</ul>
<p>按照这个逻辑，如果我们设置了双M结构，日志的执行流就会变成这样:</p>
<ul>
<li>从节点A更新的事务，binlog里面记的都是A的server id;</li>
<li>传到节点B执行一次以后，节点B生成的binlog  的server id也是A的server id;</li>
<li>再传回给节点A，A判断到这个server id与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><blockquote>
<p> 查询数据的时候，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>
<ul>
<li>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</li>
<li>在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。</li>
<li>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</li>
<li>“串行化”隔离级别下直接用加锁的方式来避免并行访问。</li>
</ul>
<p>视图是通过undolog日志来实现的，就是当系统里没有比这个回滚日志更早的read-view的时候，这些日志会被清除。</p>
<p><strong><em>为什么建议你尽量不要使用长事务？</em></strong></p>
<blockquote>
<ol>
<li><p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p>
</li>
<li><p>导致死锁的产生；</p>
</li>
</ol>
</blockquote>
<ul>
<li><p>查询大事务</p>
<blockquote>
<p> select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60</p>
</blockquote>
</li>
<li><p>如何避免大事务</p>
<blockquote>
<ul>
<li><p>尽可能的减小事务范围，少用长事务，如果无法避免，保证逻辑日志空间足够用（innodb_undo_tablespaces），并且支持动态日志空间增长。</p>
</li>
<li><p>监控Innodb_trx表，发现长事务报警。</p>
</li>
</ul>
</blockquote>
</li>
<li><p>事务中一个数据的可见性分析：读</p>
<blockquote>
<p> 对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能：</p>
<ol>
<li>如果低于低水位，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li>
<li>如果高于高水位，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</li>
<li>如果在高低水位之间，那就包括两种情况<br>  a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见；<br>  b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。</li>
</ol>
</blockquote>
</li>
<li><p>事务中一个数据的可见性分析：写</p>
<blockquote>
<p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。</p>
<p>当前读是要加锁的；</p>
</blockquote>
</li>
<li><p><strong>事务的可重复读的能力是怎么实现的？</strong></p>
<blockquote>
<p>可重复读的核心就是一致性读（consistent read）；</p>
<p>而事务更新数据的时候，只能用当前读（当前读是要加锁）。</p>
<p>如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><blockquote>
<ul>
<li><p>重建索引</p>
<p>正常重建二级索引，使用删除、新增的方式是合理的；但是重建主键索引这种方式是不合理的，因为删除主键索引需要删除所有的数据</p>
</li>
<li><p>为什么不适用hash、数组、平衡二叉树存储索引？</p>
<p>索引的维护：索引需要维护可能出现页分裂，页合并的问题；</p>
</li>
<li><p>索引下推</p>
</li>
</ul>
<p>在5.6之前，在联合索引中使用部分索引的情况需要找到对应的主键后立即回表查询；MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少<code>回表次数</code>。</p>
<ul>
<li><p>注意事项</p>
<blockquote>
<ul>
<li><p>在不影响排序结果的情况下，在取出主键后，回表之前，会在对所有获取到的主键排序</p>
</li>
<li><p>默认按照“查询使用的索引”排序</p>
</li>
</ul>
</blockquote>
</li>
<li><p>普通索引和唯一索引</p>
<blockquote>
<p>第一种情况是，<strong>这个记录要更新的目标页在内存中</strong>。这时，InnoDB的处理流程如下：</p>
<ul>
<li>对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；</li>
<li>对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。</li>
</ul>
<p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。</p>
<p>第二种情况是，<strong>这个记录要更新的目标页不在内存中</strong>。这时，InnoDB的处理流程如下：</p>
<ul>
<li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</li>
<li>对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。</li>
</ul>
</blockquote>
<p>这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。</p>
</li>
<li><p>mysql选择错误的索引</p>
<blockquote>
<p>MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。</p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这个统计信息就是索引的“区分度”，这个基数越大，索引的区分度越好</span><br><span class="line"></span><br><span class="line">show index from table；</span><br><span class="line"></span><br><span class="line">统计数据是使用采样统计，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。</span><br><span class="line"></span><br><span class="line">而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过1&#x2F;M的时候，会自动触发重新做一次索引统计。 innodb_stats_persistent</span><br></pre></td></tr></table></figure>

<p><strong>analyze table t 命令，可以用来重新统计索引信息</strong></p>
<p>其次还可以使用explain查看rows扫描的行。由于有可能回表，所以有可能不使用索引，直接全表扫描。</p>
<p><strong>一种方法是，采用force index强行选择一个索引</strong></p>
<p><strong>第二种方法就是，我们可以考虑修改语句，引导MySQL使用我们期望的索引</strong></p>
<p><strong>第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</strong></p>
</blockquote>
</li>
<li><p>前缀索引</p>
<blockquote>
<ul>
<li><p>如果使用前缀索引，损失是可能会增加额外的记录扫描次数。由于区分度比较低，需要拿到主键后回表比较；</p>
</li>
<li><p><strong>使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。</strong></p>
</li>
<li><p>方法：判断不同前缀的区分度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select count(distinct email) as L from SUser;</span><br><span class="line"></span><br><span class="line"> select </span><br><span class="line">  count(distinct left(email,4)）as L4,</span><br><span class="line">  count(distinct left(email,5)）as L5,</span><br><span class="line">  count(distinct left(email,6)）as L6,</span><br><span class="line">  count(distinct left(email,7)）as L7,</span><br><span class="line">from SUser;</span><br></pre></td></tr></table></figure>
</li>
<li><p>问题：使用前缀索引 有可能没办法用到覆盖索引；</p>
</li>
<li><p>总结</p>
<blockquote>
<ol>
<li>直接创建完整索引，这样可能比较占用空间；</li>
<li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；</li>
<li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；</li>
<li>创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。</li>
</ol>
</blockquote>
</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h4><blockquote>
<ul>
<li>锁分为表锁、行锁。</li>
<li>表锁主要用于大批量导入数据，或者修改表结构的时候；</li>
<li>行锁是存储引擎自己实现的，innodb支持行锁，MyLSAM就不支持行锁；</li>
</ul>
<p><strong>如何给小表加字段</strong></p>
<blockquote>
<p> 首先我们要解决长事务，事务不提交，就会一直占着表锁。在MySQL的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务；</p>
</blockquote>
<p><strong>如何给小表热点表加字段</strong></p>
<blockquote>
<p> 这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER TABLE tbl_name NOWAIT add column ...</span><br><span class="line">ALTER TABLE tbl_name WAIT N add column ...</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>两阶段锁协议</strong></p>
<p>在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。</p>
<p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>
<p><strong>如何避免死锁</strong></p>
<ul>
<li>使用表锁；</li>
<li>按照相同的顺序获取锁资源；</li>
<li>一次获取所有的锁资源；</li>
</ul>
<p><strong>如何处理死锁</strong></p>
<ol>
<li><p>进入等待直到超时，这种可以设置innodb_lock_wait_timeout参数，默认是50s；</p>
<p><code>存在问题</code> ：设置时间不好处理，50s太久了，1s假如是普通的锁等待，由会出现很多误伤；</p>
</li>
<li><p>另一种策略是发起死锁检测，发现死锁后，主动回滚另一个事务，让其他事务继续执行；innodb_deadlock_detect将该参数设置为on；</p>
<p>（show engine innodb status 可以查看最近检测到的死锁）</p>
<p><code>存在问题</code>：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。消耗cpu资源。</p>
</li>
<li><p>最终思路是减少访问相同资源的并发事务量；</p>
</li>
</ol>
</blockquote>
<h4 id="如何释放表空间"><a href="#如何释放表空间" class="headerlink" title="如何释放表空间"></a>如何释放表空间</h4><blockquote>
<ul>
<li>删除整个表</li>
</ul>
<blockquote>
<p>Innodb_file_per_table 为on的话表示每个InnoDB表数据存储在一个以 .ibd为后缀的文件中，独立表空间；使用drop table的话可以把.ibd文件删除，释放表空间；</p>
</blockquote>
<ul>
<li><p>删除行的表空间</p>
<blockquote>
<p>正常的删除行记录，只是在b+树中将记录逻辑删除，后续插入数据的时候替换原有的数据；但是这个是有范围限制的；分为b+树的行复用和页复用；</p>
<p>delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的；</p>
</blockquote>
</li>
<li><p>重建表释放表空间，同时释放碎片空间</p>
<blockquote>
<p>你可以新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。</p>
<ul>
<li><p>5.5版本之前 alter table A engine=InnoDB命令来重建表；</p>
</li>
<li><p>5.5之后需要使用online DDL：因为将数据插入到新表中的时候是online的会花很长时间，导致请求不可用； </p>
<blockquote>
<p>流程如下：</p>
<ol>
<li>建立一个临时文件，扫描表A主键的所有数据页；</li>
<li>用数据页中表A的记录生成B+树，存储到临时文件中；</li>
<li>生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；</li>
<li>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；</li>
<li>用临时文件替换表A的数据文件。</li>
</ol>
</blockquote>
</li>
</ul>
</blockquote>
</li>
<li><p>使用命令重建表</p>
<blockquote>
<ul>
<li>从MySQL 5.6版本开始，alter table t engine = InnoDB（也就是recreate）默认的就是上面图4的流程了；</li>
<li>analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；</li>
<li>optimize table t 等于recreate+analyze。</li>
<li>Truncate 可以理解为drop+create</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="order-by-工作原理"><a href="#order-by-工作原理" class="headerlink" title="order by 工作原理"></a>order by 工作原理</h4><blockquote>
<p>![order by 是如何工作的](/images/mysql2/order by 是如何工作的.png)</p>
<ul>
<li><p>流程如下：</p>
<ol>
<li>初始化sort_buffer，确定放入name、city、age这三个字段；</li>
<li>从索引city找到第一个满足city=’杭州’条件的主键id，也就是图中的ID_X；</li>
<li>到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中；</li>
<li>从索引city取下一个记录的主键id；</li>
<li>重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；</li>
<li>对sort_buffer中的数据按照字段name做快速排序；</li>
<li>按照排序结果取前1000行返回给客户端。</li>
</ol>
</li>
<li><p>原因</p>
<blockquote>
<ol>
<li>可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。排序的数据量小于sort_buffer_size，排序就在内存（sort_buffer）中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序（使用多个文件归并排序）。</li>
<li>除了上边的全字段排序算法还有这种rowId排序算法。 max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。</li>
</ol>
</blockquote>
<p>如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了（全字段排序），不用再回到原表去取数据（rowId排序）。</p>
<p><strong>如果内存够，就要多利用内存，尽量减少磁盘访问。</strong></p>
</li>
<li><p>优化</p>
<blockquote>
<ol>
<li>我们可以在这个市民表上创建一个city和name的联合索引。使用这个联合索引的查询出来的数据是按照name排序的，这样就不用使用临时文件进行排序。</li>
<li>我们可以创建一个city、name和age的联合索引，使用覆盖索引，不用回表查询；</li>
</ol>
</blockquote>
</li>
<li><p>升级</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from t where city in (&#39;杭州&#39;,&quot;苏州&quot;) order by name limit 100; &#x2F;&#x2F;已经有了city_name(city, name)这个联合索引</span><br></pre></td></tr></table></figure>

<p> 还是会file_sort  因为联合索引中只用到city索引，且使用到的事rowId排序算法。</p>
</blockquote>
</li>
<li><p>排序算法总结</p>
<blockquote>
<p><strong>全字段排序</strong></p>
<ol>
<li>通过索引将所需的字段全部读取到sort_buffer中</li>
<li>按照排序字段进行排序</li>
<li>将结果集返回给客户端</li>
</ol>
<ul>
<li>缺点：</li>
</ul>
<ol>
<li>造成sort_buffer中存放不下很多数据，因为除了排序字段还存放其他字段，对sort_buffer的利用效率不高</li>
<li>当所需排序数据量很大时，会有很多的临时文件，排序性能也会很差</li>
</ol>
<ul>
<li>优点：MySQL认为内存足够大时会优先选择全字段排序，因为这种方式比rowid 排序避免了一次回表操作</li>
</ul>
<p><strong>rowid排序</strong></p>
<ol>
<li>通过控制排序的行数据的长度来让sort_buffer中尽可能多的存放数据，max_length_for_sort_data</li>
<li>只将需要排序的字段和主键读取到sort_buffer中，并按照排序字段进行排序</li>
<li>按照排序后的顺序，取id进行回表取出想要获取的数据</li>
<li>将结果集返回给客户端</li>
</ol>
<ul>
<li><p>优点：更好的利用内存的sort_buffer进行排序操作，尽量减少对磁盘的访问</p>
</li>
<li><p>缺点：回表的操作是随机IO，会造成大量的随机读，不一定就比全字段排序减少对磁盘的访问</p>
</li>
</ul>
<p><strong>按照排序的结果返回客户所取行数</strong></p>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="索引失效的情况"><a href="#索引失效的情况" class="headerlink" title="索引失效的情况"></a>索引失效的情况</h4><blockquote>
<ol>
<li>查询条件中在索引列上使用函数</li>
<li>like “%_” 百分号在前. </li>
<li>or关键字使用</li>
<li>not in ,not exist 不等于等反向操作； </li>
<li>单独引用复合索引里非第一位置的索引列. </li>
<li>字符型字段为数字时在where条件里不添加引号（隐式转换）. </li>
<li>对小表查询；</li>
</ol>
</blockquote>
<h4 id="幻读详解"><a href="#幻读详解" class="headerlink" title="幻读详解"></a>幻读详解</h4><blockquote>
<p>幻读指的是一个事务在前后两次<code>查询同一个范围</code>的时候，后一次查询看到了前一次查询没有看到的行。</p>
<p>幻读是当前读才出现的，且幻读特指看到了新插入的行。</p>
<p>间隙锁：<strong>跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作</strong>。仅仅是插入，查询的话没问题；</p>
<p>间隙锁记为开区间，把next-key lock记为前开后闭区间</p>
</blockquote>
<h4 id="间隙锁"><a href="#间隙锁" class="headerlink" title="间隙锁"></a>间隙锁</h4><blockquote>
<p> <strong>我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。</strong></p>
<ol>
<li>原则1：加锁的基本单位是next-key lock。next-key lock是前开后闭区间。</li>
<li>原则2：查找过程中访问到的对象才会加锁。</li>
<li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。</li>
<li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。</li>
<li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>
</ol>
<p>读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。</p>
<p><img src="/images/mysql2/%E5%8A%A0gap%E9%94%81%E7%9A%84%E9%97%AE%E9%A2%98.png" alt="加gap锁的问题"></p>
</blockquote>
<h4 id="饮鸩止渴的提高性能的方法"><a href="#饮鸩止渴的提高性能的方法" class="headerlink" title="饮鸩止渴的提高性能的方法"></a>饮鸩止渴的提高性能的方法</h4><blockquote>
<ul>
<li><p>数据库连接不够用，干掉占用连接，但不工作的线程</p>
<blockquote>
<ol>
<li>show processlist 查看线程；</li>
<li>取出sleep状态且要查看具体事务状态，information_schema库的innodb_trx表</li>
<li>服务端断开连接使用的是kill connection + id</li>
</ol>
</blockquote>
</li>
<li><p>慢查询导致的原因</p>
<blockquote>
<ol>
<li><p>索引没有设计好</p>
<blockquote>
<p>比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库A、备库B，这个方案的大致流程是这样的: </p>
<ul>
<li>在备库B上执行 set sql_log_bin=off，也就是不写binlog，然后执行alter table 语句加上索引;</li>
<li>执行主备切换;</li>
<li>这时候主库是B，备库是A。在A上执行 set sql_log_bin=off，然后执行alter table 语句加上索引</li>
</ul>
<p>这是一个“古老”的DDL方案</p>
</blockquote>
</li>
<li><p>sql语句没有写好</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">可以通过改写SQL语句来处理。MySQL 5.7提供了query_rewrite功能</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (&quot;select * from call query_rewrite.flush_rewrite_rules();</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>mysql选错了索引</p>
<blockquote>
<p> 使用force index</p>
</blockquote>
</li>
</ol>
</blockquote>
</li>
<li><p><strong>QPS</strong>突增问题</p>
<blockquote>
<p>由上线新功能或者程序bug导致的某个语句的QPS突然暴涨；</p>
<ul>
<li>如果新功能是单独的用户，可以使用管理员把用户删除；</li>
<li>可以使用query-rewrite功能重写sql  改为  select 1;</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="mysql的高可用"><a href="#mysql的高可用" class="headerlink" title="mysql的高可用"></a>mysql的高可用</h4><blockquote>
<p> 在从库上执行  show slave status，返回的 seconds_behind_master表示备库延迟了多少。</p>
<p> <strong>主备延迟的原因</strong></p>
<ol>
<li><p>备库所在机器的性能要比主库所在的机器性能差。</p>
</li>
<li><p>备库的压力大；</p>
<blockquote>
<p>使用一主多从；</p>
<p>使用binlog或者消息队列同步到外部系统进行查询；</p>
</blockquote>
</li>
<li><p>大事务，大事务10分钟；</p>
<blockquote>
<p>不要使用一条sql删除大量的数据；</p>
<p>大表的ddl；</p>
</blockquote>
</li>
<li><p>备库的并行复制能力</p>
</li>
</ol>
<p> <strong>主备切换-可靠性优先策略</strong>（这个是使用HA工具操作的，不是手动操作的）</p>
<blockquote>
<ol>
<li>判断备库B现在的seconds_behind_master，如果小于某个值(5秒)继续下一步，否则持续重试这一步</li>
<li>把主库A改成只读状态，即把readonly设置为true;（<code>主库A和备库B都处于readonly状态，也就是说这时系统处 于不可写状态</code>）短时间</li>
<li>判断备库B的seconds_behind_master的值，直到这个值变成0为止;</li>
<li>把备库B改成可读写状态，也就是把readonly 设置为false;</li>
<li>把业务请求切到备库B。</li>
</ol>
</blockquote>
<p> <strong>主备切换-可用性优先策略</strong></p>
<blockquote>
<p>如果我强行把步骤4、5调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那 么系统几乎就没有不可用时间了。</p>
<p>可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。</p>
</blockquote>
<p> <strong>基于位点的主备切换</strong></p>
<blockquote>
<p> 节点B设置成节点A’的从库的时候，需要执行一条change master命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CHANGE MASTER TO </span><br><span class="line">MASTER_HOST&#x3D;$host_name </span><br><span class="line">MASTER_PORT&#x3D;$port </span><br><span class="line">MASTER_USER&#x3D;$user_name </span><br><span class="line">MASTER_PASSWORD&#x3D;$password </span><br><span class="line">master_auto_position&#x3D;1 &#x2F;&#x2F;就表示这个主备关系使用的是GTID协议</span><br></pre></td></tr></table></figure>


</blockquote>
</blockquote>
<h4 id="读写分离的方案和坑"><a href="#读写分离的方案和坑" class="headerlink" title="读写分离的方案和坑"></a>读写分离的方案和坑</h4><blockquote>
<p> <strong>客户端直连和带proxy的读写分离架构区别</strong></p>
<ul>
<li>客户端直连方案，因为少了一层proxy转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便</li>
<li>带proxy的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作</li>
</ul>
<p><strong>读写分离会导致主从延迟读取不到数据的问题</strong></p>
<blockquote>
<ul>
<li><p>强制走主库方案</p>
<blockquote>
<p>对于部分的需要强一致性的请求，可以使用强制走主库的方案；</p>
</blockquote>
</li>
<li><p>sleep方案;</p>
<blockquote>
<p> 用户发起请求前，先执行一次sleep操作；</p>
<p> 或者由前端执行ajax异步请求；</p>
</blockquote>
</li>
<li><p>判断主备无延迟方案;</p>
<blockquote>
<p>每次执行查询前执行 select slave master命令，查看seconds_behind_master查看主从延迟时间；</p>
<p>对比位点</p>
<p>对比GTID</p>
</blockquote>
</li>
<li><p>配合semi-sync方案</p>
<blockquote>
<p> 也就是半同步机制。存在问题是存在过度等待的问题；</p>
<ol>
<li>事务提交的时候，把主库的binlog发送给从库；</li>
<li>从库收到后返回主库一个ack，表示收到了；</li>
<li>从库收到ack后，才返回给客户端事务完成的确认；</li>
</ol>
</blockquote>
</li>
<li><p>等主库位点方案;</p>
<blockquote>
<ol>
<li><p>trx1事务更新完成后，⻢上执行show master status得到当前主库执行到的File和Position;</p>
</li>
<li><p>选定一个从库执行查询语句;</p>
</li>
<li><p>在从库上执行select master_pos_wait(File, Position, 1);  </p>
<p>参数file和pos指的是主库上的文件名和位置; </p>
<p> timeout可选，设置为正整数N表示这个函数最多等待N秒。</p>
</li>
<li><p>如果返回值是M&gt;=0的正整数，则在这个从库执行查询语句;</p>
</li>
<li><p>否则，到主库执行查询语句。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>等GTID方案。</p>
</li>
</ul>
</blockquote>
</blockquote>
<h4 id="误删除数据库"><a href="#误删除数据库" class="headerlink" title="误删除数据库"></a>误删除数据库</h4><blockquote>
<p>恢复数据，建议在临时库上做处理，然后恢复到主库。因为这期间这些数据有可能被别的事务修改；</p>
<ul>
<li><p>使用delete语句误删数据行;</p>
<blockquote>
<p>可以用Flashback工具通过闪回把数据恢复回来。 Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row 和binlog_row_image=FULL。</p>
<p><code>建议</code>： 把sql_safe_updates参数设置为on。这样一来，如果我们忘记在delete或者update语句中写where条件，或者where条件里面没有包含索引字段的话，这条语句的执行就会报错</p>
</blockquote>
</li>
<li><p>使用drop table或者truncate table语句误删数据表;</p>
<blockquote>
<p> 使用truncate /drop table和drop database命令删除的数据，无法使用日志恢复。只能使用全量备份进行恢复；</p>
<p> 在临时库上做恢复后，拿到除了误删库的语句的日志进行恢复；</p>
</blockquote>
</li>
<li><p>使用drop database语句误删数据库;</p>
<blockquote>
<p> 使用5.6版本后的 延迟复制备库的方式 。延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。</p>
</blockquote>
</li>
<li><p>使用rm命令误删整个MySQL实例。</p>
</li>
</ul>
<p><strong>建议</strong></p>
<blockquote>
<ul>
<li>建议做成自动化工具，经常演练。这样不至于手忙脚乱的处理突发状况；</li>
<li>账号分离。这样做的目的是，避免写错命令。DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</li>
<li>制定操作规范。这样做的目的，是避免写错要删除的表名。在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表</li>
</ul>
</blockquote>
</blockquote>
<h4 id="kill操作没有立即完成的状态"><a href="#kill操作没有立即完成的状态" class="headerlink" title="kill操作没有立即完成的状态"></a>kill操作没有立即完成的状态</h4><blockquote>
<p>kill ( connection )+线程id  ,并不是立即断开连接，告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。防止这个线程加了MDL锁，被强制kill掉后没办法释放锁。</p>
<p>这些“kill不掉”的情况，其实是因为发送kill命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。而被kill的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的。</p>
<ol>
<li><strong>线程没有执行到判断线程状态的逻辑</strong>，需要等待；</li>
<li><strong>终止逻辑耗时较长</strong>，</li>
</ol>
</blockquote>
<h4 id="join的执行原理和使用"><a href="#join的执行原理和使用" class="headerlink" title="join的执行原理和使用"></a>join的执行原理和使用</h4><blockquote>
<p> <strong>流程</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from t1 straight_join t2 on (t1.a&#x3D;t2.a);</span><br></pre></td></tr></table></figure>

<ol>
<li><p>从表t1中读入一行数据 R；</p>
</li>
<li><p>从数据行R中，取出a字段到表t2里去查找；</p>
</li>
<li><p>取出表t2中满足条件的行，跟R组成一行，作为结果集的一部分；</p>
</li>
<li><p>重复执行步骤1到3，直到表t1的末尾循环结束。</p>
</li>
</ol>
<p>在这个join语句执行过程中，<code>驱动表是走全表扫描</code>，而被驱动表是走树搜索。</p>
<p><strong>注意</strong></p>
<ol>
<li>在使用join的时候，应该让小表做驱动表</li>
<li>如果可以使用被驱动表的索引，join语句还是有其优势的；</li>
<li>不能使用被驱动表的索引，只能使用Block Nested-Loop Join算法（可能会因为join_buffer不够大，需要对被驱动表做多次全表扫描），这样的语句就尽量不要使用。</li>
<li>大量查询导致Buffer Pool的热数据被淘汰，影响内存命中率</li>
</ol>
<p><strong>优化</strong></p>
<p>回表查询的主键id如果是不连续的，则查询会变为随机IO；</p>
<p><code>MRR优化的设计思路</code>：</p>
<blockquote>
<ol>
<li>根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;</li>
<li>将read_rnd_buffer中的id进行递增排序；</li>
<li>排序后的id数组，依次到主键id索引中查记录，并作为结果返回。</li>
</ol>
<p>read_rnd_buffer的大小是由read_rnd_buffer_size参数控制的。如果步骤1中，read_rnd_buffer放满了，就会先执行完步骤2和3，然后清空read_rnd_buffer。之后继续找索引a的下个记录，并继续循环</p>
</blockquote>
</blockquote>
<h4 id="innoDB的LRU算法"><a href="#innoDB的LRU算法" class="headerlink" title="innoDB的LRU算法"></a>innoDB的LRU算法</h4><blockquote>
<p>innoDB按照5:3的比例把整个LRU链表分成了young区域和old区域。LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域 </p>
<p>InnoDB对Bufffer Pool的LRU算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在old区域。如果1秒之后这个数据页不再被访问了，就不会被移动到LRU链表头部，这样对Buffer Pool的命中率影响就不大。young区的数据，是正常的LRU，会被移动到头部。</p>
</blockquote>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解java虚拟机-java内存模型与线程</title>
    <url>/2018-10-30/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<p>让计算机同时去做几件事情，不仅是因为计算机的运算能力强大了，还有一个很重要的原因是计算机的运算速度与它的存储和通信子系统速度的差距太大，大量的时间都花费在磁盘I/O、</p>
<p>网络通信或者数据库访问上。衡量一个服务性能的高低好坏，每秒事务处理数（TransactionsPer Second,TPS）是最重要的指标之一，它代表着一秒内服务端平均能响应的请求总数，而TPS值与程序的并发能力又有非常密切的关系</p>
<h1 id="硬件的效率与一致性"><a href="#硬件的效率与一致性" class="headerlink" title="硬件的效率与一致性"></a>硬件的效率与一致性</h1><p>由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运<br>算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。但是也为计算机系统带来更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己<br>的高速缓存，而它们又共享同一主内存（Main Memory），当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为<br>准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等。</p>
<p><img src="/images/jvm/%E5%A4%84%E7%90%86%E5%99%A8%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E4%B8%BB%E5%86%85%E5%AD%98%E7%9A%84%E4%BA%A4%E4%BA%92%E5%85%B3%E7%B3%BB.png" alt="处理器高速缓存主内存的交互关系"></p>
<p>与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Reorder）优化</p>
<h1 id="java内存模型"><a href="#java内存模型" class="headerlink" title="java内存模型"></a>java内存模型</h1><p>Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。</p>
<p>此处的变量（Variables）与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的 ，不会被共享，自然就不会存在竞争问题。为了获得较<br>好的执行效能，Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施。</p>
<p><img src="/images/jvm/%E7%BA%BF%E7%A8%8B-%E4%B8%BB%E5%86%85%E5%AD%98-%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AD%98%E7%9A%84%E4%BA%A4%E4%BA%92%E5%85%B3%E7%B3%BB.png" alt="线程-主内存-工作内存的交互关系"></p>
<h2 id="内存交互工作"><a href="#内存交互工作" class="headerlink" title="内存交互工作"></a>内存交互工作</h2><p>关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节</p>
<ul>
<li><p>lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。</p>
</li>
<li><p>unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</p>
</li>
<li><p>read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。</p>
</li>
<li><p>load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。</p>
</li>
<li><p>use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。</p>
</li>
<li><p>assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。</p>
</li>
<li><p>store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。</p>
</li>
<li><p>write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。</p>
</li>
</ul>
<h3 id="操作规则"><a href="#操作规则" class="headerlink" title="操作规则"></a>操作规则</h3><ol>
<li>如果要把一个变量从主内存复制到工作内存，那就要顺序地执行read和load操作，如果要把变量从工作内存同步回主内存，就要顺序地执行store和write操作。注意，Java内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read与load之间、store与write之间是可插入其他指令的</li>
<li>不允许read和load、store和write操作之一单独出现</li>
<li>不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。</li>
<li>一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁</li>
<li>如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。</li>
<li>如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量。</li>
<li>对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）。</li>
</ol>
<h2 id="对于volatile型变量的特殊规则"><a href="#对于volatile型变量的特殊规则" class="headerlink" title="对于volatile型变量的特殊规则"></a>对于volatile型变量的特殊规则</h2><p>第一是保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。而普通变量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来完成</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class VolatileTest &#123;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * volatile变量自增运算测试</span><br><span class="line">     *</span><br><span class="line">     * @author zzm</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public static volatile int race &#x3D; 0;</span><br><span class="line"></span><br><span class="line">    public static void increase()&#123;</span><br><span class="line">        race++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private static final int THREADS_COUNT &#x3D; 20;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Thread[] threads &#x3D; new Thread[THREADS_COUNT];</span><br><span class="line">        for (int i &#x3D; 0; i &lt; THREADS_COUNT; i++) &#123;</span><br><span class="line">            threads[i] &#x3D; new Thread(new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    for (int i &#x3D; 0; i &lt; 10000; i++) &#123;</span><br><span class="line">                        increase();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;等待所有累加线程都结束</span><br><span class="line">        while (Thread.activeCount() &gt; 1) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(race);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>问题就出现在自增运算“race++”之中，我们用Javap反编译这后发现只有一行代码的increase（）方法在Class文件中是由4条字节码指令构成的（return<br>指令不是由race++产生的，这条指令可以不计算），从字节码层面上很容易就分析出并发失败的原因了：当getstatic指令把race的值取到操作栈顶时，volatile关键字保证了race的值在此<br>时是正确的，但是在执行iconst_1、iadd这些指令的时候，其他线程可能已经把race的值加大了，而在操作栈顶的值就变成了过期的数据，所以putstatic指令执行后就可能把较小的race值<br>同步回主内存之中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">volatile boolean shutdownRequested；</span><br><span class="line">public void shutdown（）&#123;</span><br><span class="line">shutdownRequested&#x3D;true；</span><br><span class="line">&#125;</span><br><span class="line">public void doWork（）&#123;</span><br><span class="line">while（！shutdownRequested）&#123;</span><br><span class="line">&#x2F;&#x2F;do stuff</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用volatile变量的第二个语义是禁止指令重排序优化，普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。</p>
<h2 id="原子性、可见性与有序性"><a href="#原子性、可见性与有序性" class="headerlink" title="原子性、可见性与有序性"></a>原子性、可见性与有序性</h2><ul>
<li>原子性</li>
</ul>
<p>由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write，我们大致可以认为基本数据类型的访问读写是具备原子性的（例外就是long和double的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些几乎不会发生的例外情况）</p>
<p>如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了lock和unlock操作来满足这种需求</p>
<ul>
<li>可见性</li>
</ul>
<p>可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。上文在讲解volatile变量的时候我们已详细讨论过这一点。Java内存模型是通过在变量修改后将新值同步回主内存，<br>在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是volatile变量都是如此，普通变量与volatile变量的区别是，</p>
<p>volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此，可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。</p>
<p>除了volatile之外，Java还有两个关键字能实现可见性，即synchronized和final。同步块的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）”这条规则获得的，<br>而final关键字的可见性是指：被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），<br>那在其他线程中就能看见final字段的值。</p>
<p>final与可见性</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static final int i；</span><br><span class="line">public final int j；</span><br><span class="line">static&#123;</span><br><span class="line">i&#x3D;0；</span><br><span class="line">&#x2F;&#x2F;do something</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">&#x2F;&#x2F;也可以选择在构造函数中初始化</span><br><span class="line">j&#x3D;0；</span><br><span class="line">&#x2F;&#x2F;do something</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>有序性</li>
</ul>
<p>Java内存模型的有序性在前面讲解volatile时也详细地讨论过了，Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。<br>前半句是指“线程内表现为串行的语义”（Within-Thread  As-If-Serial Semantics），后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。</p>
<p>Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这条规则决定了持有同一个锁的两个同步块只能串行地进入。</p>
<h2 id="先行发生原则"><a href="#先行发生原则" class="headerlink" title="先行发生原则"></a>先行发生原则</h2><p>Java语言中有一个“先行发生”（happens-before）的原则。这个原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地解决并发环境下两个操作之间是否可能存在冲突的所有问题。</p>
<p>先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等</p>
<ul>
<li>先行发生原则示例1</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;以下操作在线程A中执行</span><br><span class="line">i&#x3D;1；</span><br><span class="line">&#x2F;&#x2F;以下操作在线程B中执行</span><br><span class="line">j&#x3D;i；</span><br><span class="line">&#x2F;&#x2F;以下操作在线程C中执行</span><br><span class="line">i&#x3D;2；</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>假设线程A中的操作“i=1”先行发生于线程B的操作“j=i”，那么可以确定在线程B的操作执行后，变量j的值一定等于1，得出这个结论的依据有两个：一是根据先行发生原则，“i=1”的结果可以被观察到；二是线程C还没“登场”，线程A操作结束之后没有其他线程<br>会修改变量i的值。现在再来考虑线程C，我们依然保持线程A和线程B之间的先行发生关系，而线程C出现在线程A和线程B的操作之间，但是线程C与线程B没有先行发生关系，那j的值会是多少呢？答案是不确定！1和2都有可能，因为线程C对变量i的影响可能会被线程B<br>观察到，也可能不会，这时候线程B就存在读取到过期数据的风险，不具备多线程安全性。</p>
<h3 id="先行发生原则（happen-before）"><a href="#先行发生原则（happen-before）" class="headerlink" title="先行发生原则（happen-before）"></a>先行发生原则（happen-before）</h3><p>下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。</p>
<ol>
<li>程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。</li>
<li>管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。</li>
<li>volatile变量规则（V olatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。</li>
<li>线程启动规则（Thread Start Rule）：Thread对象的start（）方法先行发生于此线程的每一个动作。</li>
<li>线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。</li>
<li>线程中断规则（Thread Interruption Rule）：对线程interrupt（）方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted（）方法检测到是否有中断发生。</li>
<li>对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize（）方法的开始。</li>
<li>传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。</li>
</ol>
<ul>
<li>先行发生原则示例2</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private int value&#x3D;0；</span><br><span class="line">pubilc void setValue（int value）&#123;</span><br><span class="line">this.value&#x3D;value；</span><br><span class="line">&#125;</span><br><span class="line">public int getValue（）&#123;</span><br><span class="line">return value；</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>显示的是一组再普通不过的getter/setter方法，假设存在线程A和B，线程A先（时间上的先后）调用了“setValue（1）”，然后线程B调用了同一个对象的“getValue（）”，那么线程B收到的返回值是什么？</p>
<p>我们依次分析一下先行发生原则中的各项规则，由于两个方法分别由线程A和线程B调用，不在一个线程中，所以程序次序规则在这里不适用；由于没有同步块，自然就不会发生lock和unlock操作，所以管程锁定规则不适用；由于value变量没有被volatile关键字修饰，所<br>以volatile变量规则不适用；后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，因此我们可以判定尽管线程A在操作时间上先于线程B，但是无法确定线程B中“getValue（）”方法的<br>返回结果，换句话说，这里面的操作不是线程安全的。</p>
<p>一个操作“时间上的先发生”不代表这个操作会是“先行发生”，那如果一个操作“先行发生”是否就能推导出这个操作必定是“时间上的先发生”呢？很遗憾，这个推论也是不成立的，一个典型的例子就是多次提到的“指令重排序”</p>
<ul>
<li>先行发生原则示例3</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;以下操作在同一个线程中执行</span><br><span class="line">int i&#x3D;1；</span><br><span class="line">int j&#x3D;2；</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>两条赋值语句在同一个线程之中，根据程序次序规则，“int i=1”的操作先行发生于“int j=2”，但是“int j=2”的代码完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为我们在这条线程之中没有办法感知到这点。</p>
<h3 id="先行原则与先行发生规则的关系"><a href="#先行原则与先行发生规则的关系" class="headerlink" title="先行原则与先行发生规则的关系"></a>先行原则与先行发生规则的关系</h3><p>时间先后顺序与先行发生原则之间基本没有太大的关系，所以我们衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以先行发生原则为准。</p>
<h1 id="Java与线程"><a href="#Java与线程" class="headerlink" title="Java与线程"></a>Java与线程</h1><h2 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h2><p>在Java API中，一个Native方法往往意味着这个方法没有使用或无法使用平台无关的手段来实现（当然也可能是为了执行效率而使用Native方法，不过，通常最高效率的手段也就是平台相关的手段）</p>
<ul>
<li>实现线程主要有3种方式：使用内核线程实现、使用用户线程实现和使用用户线程加轻量级进程混合实现。</li>
</ul>
<h3 id="使用内核线程实现"><a href="#使用内核线程实现" class="headerlink" title="使用内核线程实现"></a>使用内核线程实现</h3><p>每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是有限的。</p>
<h3 id="使用用户线程实现"><a href="#使用用户线程实现" class="headerlink" title="使用用户线程实现"></a>使用用户线程实现</h3><p>用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，<br>也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。</p>
<p>使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理。线程的创建、切换和调度都是需要考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”、“多处理器系统中如何<br>将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至不可能完成。因而使用用户线程实现的程序一般都比较复杂 ，除了以前在不支持多线程的操作系统中（如DOS）的多线程程序与少数有特殊需求的程序外，现在使用用户线程的程序越来越少了，Java、Ruby等语言都曾经使用过用户线程，最终又都放弃使用它。</p>
<h3 id="使用用户线程加轻量级进程混合实现"><a href="#使用用户线程加轻量级进程混合实现" class="headerlink" title="使用用户线程加轻量级进程混合实现"></a>使用用户线程加轻量级进程混合实现</h3><p>线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现方式。在这种混合实现下，既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，<br>并且可以支持大规模的用户线程并发。而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级线程来完成，大大降低了整个进程被完全阻塞的风险。</p>
<h3 id="Java线程的实现"><a href="#Java线程的实现" class="headerlink" title="Java线程的实现"></a>Java线程的实现</h3><p>对于Sun JDK来说，它的Windows版与Linux版都是使用一对一的线程模型实现的，一条Java线程就映射到一条轻量级进程之中</p>
<h2 id="Java线程调度"><a href="#Java线程调度" class="headerlink" title="Java线程调度"></a>Java线程调度</h2><p>线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是协同式线程调度（Cooperative  Threads-Scheduling）和抢占式线程调度（Preemptive  Threads-Scheduling）。</p>
<ul>
<li>协同式线程调度</li>
</ul>
<p>使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上。协同式多线程的最大好处是实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可<br>知的，所以没有什么线程同步的问题。它的坏处也很明显：线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。</p>
<ul>
<li>抢占式线程调度</li>
</ul>
<p>使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定（在Java中，Thread.yield（）可以让出执行时间，但是要获取执行时间的话，线程本身是没有什么办法的）。在这种实现线程调度的方式下，线程的执行时间是<br>系统可控的，也不会有一个线程导致整个进程阻塞的问题，10个级别的线程优先级可以使得系统给线程尽可能的多分配时间。</p>
<p>线程优先级并不是太靠谱，原因是Java的线程是通过映射到系统的原生线程上来实现的，所以线程调度最终还是取决于操作系统，虽然现在很多操作系统都提供线程优先级的概念，但是并不见得能与Java线程的优先级一一对应</p>
<h2 id="状态转换"><a href="#状态转换" class="headerlink" title="状态转换"></a>状态转换</h2><ul>
<li>新建（New）：创建后尚未启动的线程处于这种状态。</li>
<li>运行（Runable）：Runable包括了操作系统线程状态中的Running和Ready，也就是处于此状态的线程有可能正在执行，也有可能正在等待着CPU为它分配执行时间</li>
<li>无限期等待（Waiting）：处于这种状态的线程不会被分配CPU执行时间，它们要等待被其他线程显式地唤醒。限期等待（Timed Waiting）：处于这种状态的线程也不会被分配CPU执行时间，不过无须等待被其他线程显式地唤醒，在一定时间之后它们会由系统自动唤醒</li>
<li>阻塞（Blocked）：线程被阻塞了，“阻塞状态”与“等待状态”的区别是：“阻塞状态”在等待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状态”则是在等待一段时间，或者唤醒动作的发生。</li>
<li>结束（Terminated）：已终止线程的线程状态，线程已经结束执行。</li>
</ul>
<p><img src="/images/jvm/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2.png" alt="线程状态转换"></p>
<h1 id="线程安全与锁优化"><a href="#线程安全与锁优化" class="headerlink" title="线程安全与锁优化"></a>线程安全与锁优化</h1><h2 id="面向对象和面向过程的区别"><a href="#面向对象和面向过程的区别" class="headerlink" title="面向对象和面向过程的区别"></a>面向对象和面向过程的区别</h2><p>把数据和过程分别作为独立的部分来考虑，数据代表问题空间中的客体，程序代码则用于处理这些数据，这种处理问题的角度称为面向过程的编程思想；</p>
<p>面向对象的编程思想是站在现实世界的角度去抽象和解决问题，它把数据和行为都看做是对象的一部分，这样可以让程序员能以符合现实世界的思维方式来编写和组织程序。</p>
<h2 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h2><p>如果一段代码在多线程的环境中运行和单线程运行的结果是一致的，那么这段代码是线程安全的。</p>
<p>或者说代码本身封装了所有必要的正确性保障手段（如互斥同步等），令调用者无须关心多线程的问题，更无须自己采取任何措施来保证多线程的正确调用。</p>
<h2 id="Java语言中的线程安全"><a href="#Java语言中的线程安全" class="headerlink" title="Java语言中的线程安全"></a>Java语言中的线程安全</h2><p>Java语言中各种操作共享的数据分为以下5类:不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。</p>
<ul>
<li>不可变</li>
</ul>
<p>不可变（Immutable）的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再采取任何的线程安全保障措施</p>
<p>Java语言中，如果共享数据是一个基本数据类型，那么只要在定义时使用final关键字修饰它就可以保证它是不可变的。如果共享数据是一个对象，那就需要保证对象的行为不会对其状态产生任何影响才行，如果读者还没想明白这句话，不妨想一想java.lang.String类的对<br>象，它是一个典型的不可变对象，我们调用它的substring（）、replace（）和concat（）这些方法都不会影响它原来的值，只会返回一个新构造的字符串对象。保证对象行为不影响自己状态的途径有很多种，其中最简单的就是把对象中带有状态的<br>变量都声明为final，这样在构造函数结束之后，它就是不可变的</p>
<ul>
<li>绝对线程安全</li>
</ul>
<p>在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。我们可以通过Java API中一个不是“绝对线程安全”的线程安全类来看看这里的“绝对”是什么意思。</p>
<p>如果说java.util.Vector是一个线程安全的容器，相信所有的Java程序员对此都不会有异议，因为它的add（）、get（）和size（）这类方法都是被synchronized修饰的，尽管这样效率很低，但确实是安全的。但是，即使它所有的方法都被修饰成同步，也不意味着调用它的时候永远都不再需要同步手段了</p>
<ul>
<li>相对线程安全</li>
</ul>
<p>相对的线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单独的操作是线程安全的，我们在调用的时候不需要做额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。</p>
<p>大部分的线程安全类都属于这种类型，例如Vector、HashTable、Collections的synchronizedCollection（）方法包装的集合等。</p>
<h2 id="线程安全的实现方法"><a href="#线程安全的实现方法" class="headerlink" title="线程安全的实现方法"></a>线程安全的实现方法</h2><ul>
<li>互斥同步</li>
</ul>
<p>互斥同步（Mutual Exclusion＆Synchronization）是常见的一种并发正确性保障手段。同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者是一些，<br>使用信号量的时候）线程使用。而互斥是实现同步的一种手段，临界区（CriticalSection）、互斥量（Mutex）和信号量（Semaphore）都是主要的互斥实现方式。因此，在这4个字里面，互斥是因，同步是果；互斥是方法，同步是目的。</p>
<p>synchronized实现互斥同步，该关键字在经过同步狗会形成形成monitorenter和monitorexit这两个字节码指令，这两个执行需要reference参数指明锁的对象。如果指明了reference，就是对象的reference，没有的话就是对象实例或者class对象</p>
<p>synchronized支持可重入锁，防止自己锁住自己。虚拟机本身也会进行一些优化，譬如在通知操作系统阻塞线程之前加入一段自旋等待过程</p>
<p>或者使用重入锁（ReentrantLock）来实现同步有三个更高级的特性：</p>
<ul>
<li>ReentrantLock锁的特点</li>
</ul>
<p>等待可中断：持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情</p>
<p>公平锁：指在多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock默认情况下也是非公平的</p>
<p>锁可以绑定多个条件：</p>
<p>锁绑定多个条件是指一个ReentrantLock对象可以同时绑定多个Condition对象，而在synchronized中，锁对象的wait（）和notify（）或notifyAll（）方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock则无须这样做，只需要多次调用newCondition（）方法即可</p>
<ul>
<li>非阻塞式同步</li>
</ul>
<p>互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步</p>
<p>基于冲突检测的乐观并发策略，通俗地说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施（最常见的补偿措施就是不断地重试，直到成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为非阻塞同步</p>
<p>CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static AtomicInteger atomicInteger &#x3D;new AtomicInteger(0);</span><br><span class="line"></span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">    for (int i &#x3D; 0; i &lt; 20; i++) &#123;</span><br><span class="line"></span><br><span class="line">        new Thread(new Runnable() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                for (int j &#x3D; 0; j &lt; 1000; j++) &#123;</span><br><span class="line">                    atomicInteger.incrementAndGet();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line">    while (Thread.activeCount()&gt;1)&#123;</span><br><span class="line">        Thread.yield();</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(atomicInteger);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>incrementAndGet 方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line">*Atomically increment by one the current value.</span><br><span class="line">*@return the updated value</span><br><span class="line">*&#x2F;</span><br><span class="line">public final int incrementAndGet（）&#123;</span><br><span class="line">for（；）&#123;</span><br><span class="line">int current&#x3D;get（）；</span><br><span class="line">int next&#x3D;current+1；</span><br><span class="line">if（compareAndSet（current,next））</span><br><span class="line">return next；</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">incrementAndGet（）方法在一个无限循环中，不断尝试将一个比当前值大1的新值赋给</span><br><span class="line">自己。如果失败了，那说明在执行“获取-设置”操作的时候值已经有了修改，于是再次循环</span><br><span class="line">进行下一次操作，直到设置成功为止</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>ABA問題.加版本號。</p>
<p>ThreadLocal對象實現縣城同步。</p>
<h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><p>锁优化技术，如适应性自旋（Adaptive  Spinning）、锁消除（Lock Elimination）、锁粗化（Lock Coarsening）、轻量级锁（Lightweight Locking）和偏向锁（Biased Locking）等，这些技术都是为了在线程之间更高效地共享数据，以及解决竞争问题，从而提高程序的执行效率</p>
<h3 id="自旋锁与自适应自旋"><a href="#自旋锁与自适应自旋" class="headerlink" title="自旋锁与自适应自旋"></a>自旋锁与自适应自旋</h3><p>互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成(因为用户态与内核态都有各自专用的内存空间，专用的寄存器等)，这些操作给系统的并发性能带来了很大的压力。而共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。<br>可以让后面请求锁的那个线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。</p>
<p>jdk1.6版本后，自旋锁是默认开启的，自旋的次数是10次。自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。</p>
<h3 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h3><p>锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。StringBuffer对象的append方法是一个锁消除的例子。</p>
<p>锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。</p>
<h3 id="锁粗化"><a href="#锁粗化" class="headerlink" title="锁粗化"></a>锁粗化</h3><p>同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。</p>
<p>大部分情况是正确的，但是如果一系列的连续操作都对同一个对象反复枷锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。</p>
<p>这样的情况下需要加大同步代码块的范围，只需要在最外面加一次锁就可以了，这就属于锁粗化。</p>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量</p>
<p>轻量级锁是JDK 1.6之中加入的新型锁机制，它名字中的“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的，因此传统的锁机制就称为“重量级”锁。首先需要强调一点的<br>是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。</p>
<p>HotSpot虚拟机的对象头（Object Header）分为两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄（Generational GC Age）等，这部分数据的长度在32位和64位的虚拟机中分别为32bit和<br>64bit，官方称它为“Mark Word”，它是实现轻量级锁和偏向锁的关键。另外一部分用于存储指向方法区对象类型数据的指针，如果是数组对象的话，还会有一个额外的部分用于存储数组长度。</p>
<p><img src="/images/jvm/HotSpot%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AF%B9%E8%B1%A1%E5%A4%B4Mark-Word.png" alt="HotSpot虚拟机对象头Mark-Word"></p>
<p>轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销，但如果存在锁竞争，<br>除了互斥量的开销外，还额外发生了CAS操作，因此在有竞争的情况下，轻量级锁会比传统的重量级锁更慢。</p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不做了。</p>
<p>偏向锁意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步</p>
<p>当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为“01”，即偏向模式。同时使用CAS操作把获取到这个锁<br>的线程的ID记录在对象的Mark Word之中，如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作</p>
<p>当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。根据锁对象目前是否处于被锁定的状态，撤销偏向（Revoke Bias）后恢复到未锁定（标志位为“01”）或轻量级锁定（标志位为“00”）的状态，后续的同步操作就如上面介绍的轻量级锁那样执行。</p>
<p><img src="/images/jvm/%E5%81%8F%E5%90%91%E9%94%81-%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%B4%A2%E7%9A%84%E7%8A%B6%E6%80%81%E8%BD%AC%E5%8C%96%E4%BB%A5%E5%8F%8A%E5%AF%B9%E8%B1%A1Mark-Word%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt="偏向锁-轻量级索的状态转化以及对象Mark-Word的关系"></p>
<p>偏向锁可以提高带有同步但无竞争的程序性能。它同样是一个带有效益权衡（TradeOff）性质的优化，也就是说，它并不一定总是对程序运行有利，如果程序中大多数的锁总<br>是被多个不同的线程访问，那偏向模式就是多余的。在具体问题具体分析的前提下，有时候使用参数-XX：-UseBiasedLocking来禁止偏向锁优化反而可以提升性能。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java内存模型与线程</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解java虚拟机-垃圾收集器与内存分配策略</title>
    <url>/2018-10-24/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<p>java内存运行区域的各个部分，其中程序计数器、虚拟机栈、本地方法栈三个区域岁线程而生而灭；栈中的栈帧随着方法的进入和退出而有条不紊的执行和出栈和入栈操作，每一个帧栈中分配多少内存基本上在类的结构确定下来的时候就已经确定了，所以这些区域就不需要考虑垃圾回收。<br>而java堆和方法则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存可能不一样，我们只有在程序处于运行期间才知道回创建那些对象，这些内存的分配都是动态的，垃圾收集器所关注的事这部分内存。</p>
<h1 id="对象存活判断算法"><a href="#对象存活判断算法" class="headerlink" title="对象存活判断算法"></a>对象存活判断算法</h1><h2 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h2><p>给对象添加一个引用计数器，每当有一个地方引用时加一，当引用失效时建议，为0时对象就不可以引用。优点是效率高，缺点是难以解决循环引用的问题。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 循环引用的垃圾回收</span><br><span class="line"> *</span><br><span class="line"> * @author :  chen weijie</span><br><span class="line"> * @Date: 2018-10-24 9:20 AM</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class ForEachReferenceDemo &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public Object instance &#x3D; null;</span><br><span class="line">    private static final int _1MB &#x3D; 1024 * 1024;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;这个成员变量的唯一作用就是站点内存，一边在GC日志中可以看清楚是否被回收过</span><br><span class="line"></span><br><span class="line">    private byte[] bigSize &#x3D; new byte[2 * _1MB];</span><br><span class="line">    public static void testGC() &#123;</span><br><span class="line">        ForEachReferenceDemo objectA &#x3D; new ForEachReferenceDemo();</span><br><span class="line">        ForEachReferenceDemo objectB &#x3D; new ForEachReferenceDemo();</span><br><span class="line">        objectA.instance &#x3D; objectA;</span><br><span class="line">        objectB.instance &#x3D; objectB;</span><br><span class="line">        objectA &#x3D; null;</span><br><span class="line">        objectB &#x3D; null;</span><br><span class="line">        System.gc();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        testGC();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>由5263K-&gt;648K(19456K) 可以得知内存有回收，所以虚拟机回收的算法并不是使用引用计数算法。</p>
<h2 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h2><p>这个算法的基本思路就是通过称为GC Roots 的对象作为起点，从这些节点作为起点向下搜索，走过的路径称为引用链，当一个对象没有 与任何一用力按相连时，证明对象是不可达的。</p>
<ul>
<li>java语言中可以作为GC roots的对象包括以下几种：</li>
</ul>
<p>1.虚拟机栈（帧栈中的本地变量表）中引用的对象；<br>2.方法区中类静态变量属性引用的对象；<br>3.方法区中常量引用的对象；<br>4.本地方法栈中JNI（一般的native方法）引用的对象；</p>
<h2 id="再谈引用"><a href="#再谈引用" class="headerlink" title="再谈引用"></a>再谈引用</h2><p>一般的引用是指，reference类型的数据中存储的数值代表的是另外一块内存的起始地址；</p>
<p>细分引用：</p>
<p>1.强引用：代码中普遍存在，Object o = new Object() 。只要强引用存在，垃圾收集器永远不会回收掉被引用的对象；<br>2.软引用：有用但是非必须的，在系统将要发生内存溢出异常之前，将会把这些对象进行第二次回收；<br>3.弱引用：非必须对象，但是强度比弱引用更低，被弱引用关联的对象只能生存到下一次垃圾收集发生之前；<br>4.虚引用：最弱的，完全对垃圾收集不产生影响，只不过在垃圾收集器回收时收到一个系统通知；</p>
<h2 id="生存还是死亡"><a href="#生存还是死亡" class="headerlink" title="生存还是死亡"></a>生存还是死亡</h2><p>即使在可达性分析算法中不可达的对象，也并非是非死不可的。至少要经过两次标记。</p>
<p>当对象在进行可达性分析后发现对象没有与GC Roots相连时，它将会被进行一次标记和一次筛选。筛选的条件是该对象是否有必要执行finalize()方法，当对象没有覆盖finalize()方法或者finalize()方法已经被虚拟机调用过，这2种情况就是没有必要执行。</p>
<p>如果有必要执行finalize方法，那么对象就会被放置到F-Queen队列中。finalize是对象逃脱死亡的最后机会，只要在此期间重新与任何一个对象发生关联即可，这样他会逃脱回收。</p>
<h2 id="方法区回收"><a href="#方法区回收" class="headerlink" title="方法区回收"></a>方法区回收</h2><p>方法区（HotSpot虚拟机中的永久带）是没有垃圾收集的，因为他的垃圾收集效率远低于此。因为新生代中的垃圾收集一般可以回收70%-90%的空间。</p>
<p>方法区（永久带）的垃圾收集包括废弃常量和无用类。</p>
<h3 id="废弃常量回收"><a href="#废弃常量回收" class="headerlink" title="废弃常量回收"></a>废弃常量回收</h3><p>例如一个abc字符串已经进入了常量池中，但是系统没有任何一个String对象引用该字符串。</p>
<h3 id="无用类回收"><a href="#无用类回收" class="headerlink" title="无用类回收"></a>无用类回收</h3><p>满足以下三个条件：</p>
<p>1.该类的所有的实例都已经被回收，就是java堆中不存在该对象的实例；<br>2.加载该类的classLoader类已经被回收；<br>3.该类对应的java.lang.Class对象没有任何地方引用，无法再任何地方通过反射获取该类；</p>
<p>满足以上三个条件可以回收，但是类的回收需要对参数进行设置。</p>
<p>大量的使用反射，动态代理，CGLib等byteCode框架、动态生成JSP的以及OSGi这类频繁自定义classLoader的场景都需要虚拟机聚类类卸载的功能，保证永久带不会溢出；</p>
<h1 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h1><h2 id="标记清除算法（mark-Sweep）"><a href="#标记清除算法（mark-Sweep）" class="headerlink" title="标记清除算法（mark-Sweep）"></a>标记清除算法（mark-Sweep）</h2><p>首先标记需要回收的对象，标记完统一回收被标记的对象。不足：一是 效率问题，标记和清除效率都不高；二是 标记清除后会产生大量的不连续的内存空间，无法为较大的对象分配空间。</p>
<h2 id="复制算法（copying）"><a href="#复制算法（copying）" class="headerlink" title="复制算法（copying）"></a>复制算法（copying）</h2><p>为了解决效率问题，使用的复制算法，由于新生代的对象98%都是“朝生夕死”的，将内存区域划分为eden、from survivor、to survivor区 比例为8:1:1,每次回收都是将eden和一个survivor中的存活的对象复制到另一个survivor中。如果此时另一个survivor区域没有足够的空间时，将对象直接放到老年代。</p>
<p>很明显缺点就是：浪费空间以及当有大量对象需要复制时效率很低；一般新生代使用这种算法</p>
<h2 id="标记整理算法（mark-compact）"><a href="#标记整理算法（mark-compact）" class="headerlink" title="标记整理算法（mark-compact）"></a>标记整理算法（mark-compact）</h2><p>复制算法在对象存活率较高的情况下需要进行较多的复制，效率会变低。根据老年代的特点，有一种标记整理（mark-compact）算法，标记过程与标记清理算法一样，后续步骤不是直接清理回收对象，而是让存货对象向一段移动，然后清理端边以外的内存。</p>
<h2 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h2><p>当前虚拟机的收集算法都是用分代收集。 </p>
<p>新生代：新生代中每次垃圾收集时，都会有大批对象死去，只有少量存活，采用复制算法，只需要付出少量的存活对象的复制成本就可以完成收集；</p>
<p>老年代：老年代存活率比较高，没有额外的空间分配担保，必须使用’标记清理’或者’标记整理’算法回收；</p>
<h1 id="HotSpot的算法实现"><a href="#HotSpot的算法实现" class="headerlink" title="HotSpot的算法实现"></a>HotSpot的算法实现</h1><p>在GC的过程中不可以出现分析过程中对象引用关系还在不断变化的情况，该点不满足的话，准确性就无法保证，所有GC进行时都是需要停顿的（Stop the world）</p>
<p>当执行系统停下来后，并不需要一个不漏的检查完所有的执行上下文和全局引用位置，虚拟机是有办法知道哪些地方存放对象引用。在HotSpot的实现中是使用一组称为OopMap的结构来达到这个目的的。</p>
<h2 id="安全点"><a href="#安全点" class="headerlink" title="安全点"></a>安全点</h2><p>HotSpot没有为每条指令都生产OopMap，只有在特定的位置记录了这些信息，这些位置被称为安全点（safePoint）,即程序执行时并非在所有地方的都能停顿下来GC，只有到达安全点才会暂停。</p>
<p>有2种方式可以让线程停止到最近的安全点上停顿下来：抢占式中断和主动式中断。</p>
<ul>
<li>抢占式中断不需要线程的执行代码主动去配合，在GC发生时，首先所有线程中断，如果发现线程中断的地方不在安全点，让线程回复，让它跑到安全点上。几乎没有虚拟机采用抢占式中断来暂停线程从而响应GC事件</li>
<li>主动式中断的思想是当GC需要中断线程的时候，不直接对线程操作，仅仅简单设置一个标记，各个线程执行时主动去轮训这个标记，发现标记位真时就中断挂起。</li>
</ul>
<h2 id="安全区域"><a href="#安全区域" class="headerlink" title="安全区域"></a>安全区域</h2><p>safePoint似乎近乎完美的解决了如何进入GC的问题，但是如果线程处于Sleep或者blocked状态时，这时候线程无法响应JVM的重拳请求，走到安全的地方挂起，这就需要一个安全区域（safe region）来解决问题。</p>
<h1 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h1><p><img src="/images/jvm/HotSpot%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8.png" alt="HotSpot虚拟机的垃圾收集器"></p>
<p>上图展示了HotSpot虚拟机的垃圾收集器，如果两个收集器之间存在连线，则说明他们可以搭配使用，所以你所处的区域咋代表他们属于新生代收集器还是老年代收集器。</p>
<p>虚拟机收集器没有最好的收集器，只有在某种场景下最适合的收集器。</p>
<h2 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h2><p>Serial收集器是最基本、历史最悠久的收集器，单线程收集器，</p>
<p>单线程收集器并不意味着它只会使用一个CPU或者一条收集线程去完成垃圾收集，重要的是GC时，必须暂停其它所有的工作线程，至到收集完成。</p>
<p>该收集器优点是：它是虚拟机运行在Client模式下的默认新生代收集器。简单而高效，因为对于单个CPU的环境说，Serial收集器由于没有线程交互的开销，他是最高效的。</p>
<p><img src="/images/jvm/Serial%E6%94%B6%E9%9B%86%E5%99%A8.png" alt="Serial收集器"></p>
<h2 id="ParNew收集器"><a href="#ParNew收集器" class="headerlink" title="ParNew收集器"></a>ParNew收集器</h2><p>ParNew收集器就是Serial收集器的多线程版本，使用多线程收集。</p>
<p><img src="/images/jvm/ParNew%E6%94%B6%E9%9B%86%E5%99%A8.png" alt="ParNew收集器"></p>
<p>它是运行在Server模式下的虚拟机中首选的新生代垃圾收集器，主要是因为除了Serial只有ParNew是CMS收集器一起使用的垃圾收集器。</p>
<p>ParNew收集器在单CPU的环境中没有Serial好。</p>
<ul>
<li>并行 是指多条垃圾收集线程并行工作。</li>
<li>并发 是指工作线程与垃圾收集线程同时执行（可以同时执行，可能是交替执行），用户线程在继续运行，而垃圾收集程序在另一个CPU上运行。</li>
</ul>
<h2 id="Parallel-Scavenge-收集器"><a href="#Parallel-Scavenge-收集器" class="headerlink" title="Parallel Scavenge 收集器"></a>Parallel Scavenge 收集器</h2><ul>
<li><p>Parallel Scavenge 收集器是一个新生代收集器，并行的多线程收集器，采用复制算法。这些和ParNew一样。它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能的缩短用户线程的停顿时间，而Parallel Scavenge 收集器的目标则是到达一个可控的吞吐量。吞吐量= 运行用户代码时间/（运行用户代码时间+垃圾回收时间）</p>
</li>
<li><p>停顿时间越短就越适合需要与用户交互的程序，可以提高用体验。吞吐量则可以高效的利用CPU时间，尽快完成程序的运算任务，适合在后台运算不需要太多交互的任务。对于同一个垃圾回收器来说：吞吐量和响应时间是相斥的属性。</p>
</li>
</ul>
<h3 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h3><ul>
<li>Parallel Scavenge 收集器 使用两个参数用于控制吞吐量：</li>
</ul>
<ol>
<li>-XX:GCTimeRatio(直接设置吞吐量大小，默认99)、</li>
<li>-XX:MAXGCPauseMillis(最大垃圾收集停顿时间)</li>
</ol>
<p>由于与吞吐量关系密切，Parallel Scavenge收集器也经常称为“吞吐量优先”收集器。除上述两个参数之外，Parallel Scavenge收集器还有一个参数-XX：+UseAdaptiveSizePolicy值得关<br>注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX：SurvivorRatio）、晋升老年代对象年龄（-XX：<br>PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）</p>
<h2 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h2><p>Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用“标记-整理”算法。这个收集器的主要意义也是在于给Client模式下的虚拟机使用。</p>
<p>如果在Server模式下，那么它主要还有两大用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用</p>
<p><img src="/images/jvm/SerialOld%E6%94%B6%E9%9B%86%E5%99%A8.png" alt="SerialOld收集器"></p>
<h2 id="Parallel-Old收集器"><a href="#Parallel-Old收集器" class="headerlink" title="Parallel Old收集器"></a>Parallel Old收集器</h2><p>Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。</p>
<p>![Parallel Old收集器与Parallel Scavenge收集器](/images/jvm/Parallel Old收集器与Parallel Scavenge收集器.png)</p>
<h2 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h2><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。基于“标记—清除”算法实现</p>
<h3 id="运行步骤"><a href="#运行步骤" class="headerlink" title="运行步骤"></a>运行步骤</h3><p>他的运行分为四个步骤：</p>
<ul>
<li>初始标记（CMS initial mark）：初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快；</li>
<li>并发标记（CMS concurrent mark）：并发标记阶段就是进行GC RootsTracing的过程；</li>
<li>重新标记（CMS remark）：重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录</li>
<li>并发清除（CMS concurrent sweep）：多个垃圾回收线程一起清除。</li>
</ul>
<p>整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以用时很短。</p>
<p>![Concurrent Mark Sweep收集器运行示意图](/images/jvm/Concurrent Mark Sweep收集器运行示意图.png)</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>CMS收集器对CPU资源非常敏感，虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低</li>
</ul>
<p>CMS默认启动的回收线程数是（CPU数量+3）/4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就可能变得很大，如果本来CPU负载就比较大，还分出一半的运算能力去执行收集器线程，就<br>可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受</p>
<p>为了解决这种问题，使用了一种增量式并发器，就是在并发标记、清理的时候让GC线程、用户线程交替运行，尽量减少GC线程的独占资源的时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得少一些，也就是速度下降没有那么明显</p>
<ul>
<li>CMS收集器无法处理浮动垃圾（Floating  Garbage），可能出现“Concurrent  Mode Failure”失败而导致另一次Full GC的产生</li>
</ul>
<p>由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”</p>
<p>在JDK  1.6中，CMS收集器的启动阈值已经提升至92%。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来<br>重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX：CMSInitiatingOccupancyFraction设置得太高很容易导致大量“Concurrent Mode Failure”失败，性能反而降低。</p>
<ul>
<li>CMS是一款基于“标记—清除”算法实现的收集器，就可能想到这意味着收集结束时会有大量空间碎片产生，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次FullGC</li>
</ul>
<p>两种解决方法：</p>
<ol>
<li>CMS收集器提供了一个-XX：+UseCMSCompactAtFullCollection开关参数（默认就是开启的），用于在CMS收集器顶不住要进行FullGC时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。</li>
<li>另外一个参数-XX：CMSFullGCsBeforeCompaction，这个参数是用于设置执行多少次不压缩的Full  GC后，跟着来一次带压缩的（默认值为0，表示每次进入Full GC时都进行碎片整理）</li>
</ol>
<h2 id="G1收集器"><a href="#G1收集器" class="headerlink" title="G1收集器"></a>G1收集器</h2><p>G1（Garbage-First）收集器是当今收集器技术发展的最前沿成果之一,G1是一款面向服务端应用的垃圾收集器。它的使命是替代CMS收集器。</p>
<h3 id="与CMS相比的特点："><a href="#与CMS相比的特点：" class="headerlink" title="与CMS相比的特点："></a>与CMS相比的特点：</h3><ul>
<li>并行与并发：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行</li>
<li>分代收集：与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。</li>
<li>空间整理：G1从整体上来看是基于‘标记-整理算法’，局部（两个region）来看，是基于复制算法来是实现的，无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后提供规整的可用内存。</li>
<li>可预测的停顿：G1除了追求停顿外，还能建立可预测的停顿时间模型，可以让使用者在一个长度M毫秒的时间段内消耗在垃圾收集上的时间不超过N毫秒。</li>
</ul>
<h3 id="详细描述"><a href="#详细描述" class="headerlink" title="详细描述"></a>详细描述</h3><p>使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合</p>
<p>G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时<br>间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率</p>
<p>在G1收集器中，Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使用Remembered Set来避免全堆扫描的</p>
<h3 id="运行步骤-1"><a href="#运行步骤-1" class="headerlink" title="运行步骤"></a>运行步骤</h3><ul>
<li>初始标记（Initial Marking） ：与CMS相同</li>
<li>并发标记（Concurrent Marking）：并发标记阶段是从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行</li>
<li>最终标记（Final Marking）：是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set</li>
<li>筛选回收（Live Data Counting and Evacuation）：首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划</li>
</ul>
<p><img src="/images/jvm/G1%E6%94%B6%E9%9B%86%E5%99%A8%E7%9A%84%E8%BF%90%E8%A1%8C%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="G1收集器的运行示意图"></p>
<p>如果你现在采用的收集器没有出现问题，那就没有任何理由现在去选择G1，如果你的应用追求低停顿，那G1现在已经可以作为一个可尝试的选择，如果你的应用追求吞吐量，那G1并不会为你带来什么特别的好处</p>
<h1 id="GC日志的理解"><a href="#GC日志的理解" class="headerlink" title="GC日志的理解"></a>GC日志的理解</h1><ul>
<li>典型的日志1</li>
</ul>
<p><img src="/images/jvm/JVM%E6%97%A5%E5%BF%971.png" alt="JVM日志1"></p>
<p>最前面的数字“33.125：”和“100.667：”代表了GC发生的时间，这个数字的含义是从Java虚拟机启动以来经过的秒数</p>
<p>GC日志开头的“[GC”和“[Full  GC”说明了这次垃圾收集的停顿类型，如果有“Full”，说明这次GC是发生了Stop-The-World的。</p>
<p><img src="/images/jvm/ParNew%E6%97%A5%E5%BF%97%E4%B9%9F%E4%BC%9A%E4%BA%A7%E7%94%9FfullGC%E6%97%A5%E5%BF%97.png" alt="ParNew日志也会产生fullGC日志"><br>这段新生代收集器ParNew的日志也会出现“[Full GC”（这一般是因为出现了分配担保失败之类的问题，所以才导致STW）。</p>
<p>如果是调用System.gc（）方法所触发的收集，那么在这里将显示“[Full GC（System）”</p>
<p>接下来的“[DefNew”、“[Tenured”、“[Perm”表示GC发生的区域，这里显示的区域名称与使用的GC收集器是密切相关的。<br>例如上面样例所使用的Serial收集器中的新生代名为“Default New  Generation”，所以显示的是“[DefNew”。<br>如果是ParNew收集器，新生代名称就会变为“[ParNew”，意为“Parallel New Generation”。<br>如果采用Parallel Scavenge收集器，那它配套的新生代称为“PSYoungGen”，老年代和永久代同理，名称也是由收集器决定的。</p>
<p>后面方括号内部的“3324K-＞152K（3712K）”含义是“GC前该内存区域已使用容量-＞GC后该内存区域已使用容量（该内存区域总容量）”。而在方括号之外的“3324K-＞<br>152K（11904K）”表示“GC前Java堆已使用容量-＞GC后Java堆已使用容量（Java堆总容量）”。再往后，“0.0025925 secs”表示该内存区域GC所占用的时间，单位是秒。<br>有的收集器会给出更具体的时间数据，如“[Times：user=0.01 sys=0.00，real=0.02 secs]”，这里面的user、sys和real与Linux的time命令所输出的时间含义一致，分别代表用户态消耗的CPU时间、内核<br>态消耗的CPU事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time）。</p>
<ul>
<li>典型的日志2</li>
</ul>
<p>程序运行时配置如下参数:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-Xms20M -Xmx20M -Xmn10M -verbose:gc -XX:+PrintGCDetails -XX:SurvivorRatio&#x3D;8 -XX:+PrintGCTimeStamps</span><br><span class="line">最终，程序输出：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">0.070: [GC (Allocation Failure) [PSYoungGen: 7127K-&gt;616K(9216K)] 11223K-&gt;4720K(19456K), 0.0008663 secs] [Times: user&#x3D;0.00 sys&#x3D;0.00, real&#x3D;0.00 secs] </span><br><span class="line">0.072: [GC (Allocation Failure) --[PSYoungGen: 6923K-&gt;6923K(9216K)] 11027K-&gt;15123K(19456K), 0.0016749 secs] [Times: user&#x3D;0.02 sys&#x3D;0.00, real&#x3D;0.00 secs] </span><br><span class="line">0.073: [Full GC (Ergonomics) [PSYoungGen: 6923K-&gt;0K(9216K)] [ParOldGen: 8200K-&gt;6660K(10240K)] 15123K-&gt;6660K(19456K), [Metaspace: 2559K-&gt;2559K(1056768K)], 0.0044663 secs] [Times: user&#x3D;0.00 sys&#x3D;0.00, real&#x3D;0.00 secs] </span><br><span class="line">Heap</span><br><span class="line"> PSYoungGen      total 9216K, used 4404K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000)</span><br><span class="line">  eden space 8192K, 53% used [0x00000000ff600000,0x00000000ffa4d1a0,0x00000000ffe00000)</span><br><span class="line">  from space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000)</span><br><span class="line">  to   space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000)</span><br><span class="line"> ParOldGen       total 10240K, used 6660K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000)</span><br><span class="line">  object space 10240K, 65% used [0x00000000fec00000,0x00000000ff281398,0x00000000ff600000)</span><br><span class="line"> Metaspace       used 2565K, capacity 4486K, committed 4864K, reserved 1056768K</span><br><span class="line">  class space    used 281K, capacity 386K, committed 512K, reserved 1048576K</span><br></pre></td></tr></table></figure>

<p>GC日志分析：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、最前面的数字 &quot;0,070&quot; 代表了GC发生的时间，这个数字的含义是从Java虚拟机启动以来经过的秒数</span><br><span class="line">2、GC日志开头的“[GC 和 [Full GC” 说明了这次垃圾收集的停顿类型，而不是用来区分新生代GC还是年老代GC的。</span><br><span class="line">3、PSYoungGen, ParOldGen，PSPermGen表示GC发生的区域，这里显示的区域名称与使用的GC收集器密切相关，不同收集器对于不同区域所显示的名称可能不同。</span><br><span class="line">4、后面方括号内部的 “ 7127K-&gt;616K(9216K) ”含义是“GC前该内存区域已使用容量 -&gt; GC后该内存区域已使用容量（该内存区域总容量）”。方括号之外的 11223K-&gt;4720K(19456K) 表示GC前java堆已使用容量 -&gt; GC后java堆已使用容量(Java堆总容量)</span><br><span class="line">5、0.0008663 secs表示该内存区域GC所占用的时间，单位是秒。</span><br><span class="line">6、[Times: user&#x3D;0.00 sys&#x3D;0.00, real&#x3D;0.00 secs] 这里面的user、sys、和real与Linux的time命令所输出的时间含义一致。分别代表用户消耗的CPU时间，内存态消耗的CPU时间，和操作从开始到结束所经过的墙钟时间。</span><br></pre></td></tr></table></figure>

<p>JVM的GC日志的主要参数包括如下几个：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+PrintGC 输出GC日志</span><br><span class="line">-XX:+PrintGCDetails 输出GC的详细日志</span><br><span class="line">-XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）</span><br><span class="line">-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）</span><br><span class="line">-XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息</span><br><span class="line">-XX:+PrintGCApplicationStoppedTime &#x2F;&#x2F; 输出GC造成应用暂停的时间</span><br><span class="line">-Xloggc:..&#x2F;logs&#x2F;gc.log 日志文件的输出路径</span><br></pre></td></tr></table></figure>
<h1 id="垃圾收集器参数的总结"><a href="#垃圾收集器参数的总结" class="headerlink" title="垃圾收集器参数的总结"></a>垃圾收集器参数的总结</h1><p><img src="/images/jvm/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%8F%82%E6%95%B01.png" alt="垃圾收集器参数1"><br><img src="/images/jvm/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%8F%82%E6%95%B02.png" alt="垃圾收集器参数2"></p>
<h1 id="内存分配与回收策略"><a href="#内存分配与回收策略" class="headerlink" title="内存分配与回收策略"></a>内存分配与回收策略</h1><p>对象的内存分配，对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配。<br>少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。</p>
<p>以下的虚拟机使用的是在Parallel Scavenge/Parallel Old收集器下的分配策略。</p>
<h2 id="对象优先在Eden分配"><a href="#对象优先在Eden分配" class="headerlink" title="对象优先在Eden分配"></a>对象优先在Eden分配</h2><p>大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。</p>
<p>虚拟机提供了-XX：+PrintGCDetails这个收集器日志参数，告诉虚拟机在发生垃圾收集行为时打印内存回收日志，并且在进程退出的时候输出当前的内存各区域分配情况。</p>
<p>例子1</p>
<p>以下代码尝试分配3个2MB大小和1个4MB大小的对象，在运行时通过-Xms20M、-Xmx20M、-Xmn10M这3个参数限制了Java堆大小为20MB，不可扩<br>展，其中10MB分配给新生代，剩下的10MB分配给老年代。-XX：SurvivorRatio=8决定了新生代中Eden区与一个Survivor区的空间比例是8:1，从输出的结果也可以清晰地看到“eden<br>space  8192K、from  space  1024K、to  space  1024K”的信息，新生代总可用空间为9216KB（Eden区+1个Survivor区的总容量）</p>
<ul>
<li><p>新生代GC（Minor GC）：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。</p>
</li>
<li><p>老年代GC（Major GC/Full GC）：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行<br>Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * VM参数：-verbose：gc -Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails</span><br><span class="line"> * -XX：SurvivorRatio&#x3D;8</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MinorGCTest &#123;</span><br><span class="line">    private static final int _1MB &#x3D; 1024 * 1024;</span><br><span class="line">    public static void testAllocation() &#123;</span><br><span class="line">        byte[] allocation1, allocation2, allocation3, allocation4;</span><br><span class="line">        allocation1 &#x3D; new byte[2 * _1MB];</span><br><span class="line">        allocation2 &#x3D; new byte[2 * _1MB];</span><br><span class="line">        allocation3 &#x3D; new byte[2 * _1MB];</span><br><span class="line">        allocation4 &#x3D; new byte[2 * _1MB]; &#x2F;&#x2F;出现一次minor GC</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        testAllocation();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">[GC [PSYoungGen: 7311K-&gt;632K(9216K)] 7311K-&gt;6776K(19456K), 0.0093838 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs] </span><br><span class="line">[Full GC [PSYoungGen: 632K-&gt;0K(9216K)] [ParOldGen: 6144K-&gt;6656K(10240K)] 6776K-&gt;6656K(19456K) [PSPermGen: 2752K-&gt;2751K(21504K)], 0.0385372 secs] [Times: user&#x3D;0.05 sys&#x3D;0.00, real&#x3D;0.04 secs] </span><br><span class="line">Heap</span><br><span class="line"> PSYoungGen      total 9216K, used 2213K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000)</span><br><span class="line">  eden space 8192K, 27% used [0x00000000ff600000,0x00000000ff829788,0x00000000ffe00000)</span><br><span class="line">  from space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000)</span><br><span class="line">  to   space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000)</span><br><span class="line"> ParOldGen       total 10240K, used 6656K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000)</span><br><span class="line">  object space 10240K, 65% used [0x00000000fec00000,0x00000000ff280040,0x00000000ff600000)</span><br><span class="line"> PSPermGen       total 21504K, used 2758K [0x00000000f9a00000, 0x00000000faf00000, 0x00000000fec00000)</span><br><span class="line">  object space 21504K, 12% used [0x00000000f9a00000,0x00000000f9cb18c0,0x00000000faf00000)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="大对象直接进入老年代"><a href="#大对象直接进入老年代" class="headerlink" title="大对象直接进入老年代"></a>大对象直接进入老年代</h2><p>所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组（笔者列出的例子中的byte[]数组就是典型的大对象）。大对象对虚拟机<br>的内存分配来说就是一个坏消息（替Java虚拟机抱怨一句，比遇到一个大对象更加坏的消息就是遇到一群“朝生夕灭”的“短命大对象”，写程序的时候应当避免），经常出现大对象容易<br>导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们</p>
<p>虚拟机提供了一个-XX：PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存复制.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * VM参数：-verbose：gc-Xms20M-Xmx20M-Xmn10M-XX：+PrintGCDetails-XX：SurvivorRatio&#x3D;8</span><br><span class="line"> * -XX：PretenureSizeThreshold&#x3D;3145728</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class BigObjectGCDemo &#123;</span><br><span class="line">    private static final int _1MB &#x3D; 1024 * 1024;</span><br><span class="line">    public static void testPretenureSizeThreshold() &#123;</span><br><span class="line">        byte[] allocation;</span><br><span class="line">        &#x2F;&#x2F;直接分配在老年代中</span><br><span class="line">        allocation &#x3D; new byte[4 * _1MB];</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        testPretenureSizeThreshold();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> PSYoungGen      total 9216K, used 5263K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000)</span><br><span class="line">  eden space 8192K, 64% used [0x00000000ff600000,0x00000000ffb23c70,0x00000000ffe00000)</span><br><span class="line">  from space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000)</span><br><span class="line">  to   space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000)</span><br><span class="line"> ParOldGen       total 10240K, used 0K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000)</span><br><span class="line">  object space 10240K, 0% used [0x00000000fec00000,0x00000000fec00000,0x00000000ff600000)</span><br><span class="line"> PSPermGen       total 21504K, used 2759K [0x00000000f9a00000, 0x00000000faf00000, 0x00000000fec00000)</span><br><span class="line">  object space 21504K, 12% used [0x00000000f9a00000,0x00000000f9cb1c28,0x00000000faf00000)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>PretenureSizeThreshold参数只对Serial和ParNew两款收集器有效，Parallel  Scavenge收集器不认识这个参数，Parallel  Scavenge收集器一般并不需要设置</p>
<h2 id="长期存活的对象将进入老年代"><a href="#长期存活的对象将进入老年代" class="headerlink" title="长期存活的对象将进入老年代"></a>长期存活的对象将进入老年代</h2><p>虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor区中<br>每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数-XX：MaxTenuringThreshold设置</p>
<p>代码实例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> -verbose:gc</span><br><span class="line"> -Xms20M</span><br><span class="line"> -Xmx20M</span><br><span class="line"> -Xmn10M</span><br><span class="line"> -XX:PrintGCDetails</span><br><span class="line"> -XX:SurvivorRatio&#x3D;8</span><br><span class="line"> -XX:MaxTenuringThreadshold&#x3D;1</span><br><span class="line"> -XX:+PrintTenuringDistribution</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class LongExistsObjectDemo &#123;</span><br><span class="line">    private static final int _1MB &#x3D; 1024 * 1024;</span><br><span class="line">    public static void testTenuringThreshold() &#123;</span><br><span class="line">        byte[] allocation1, allocation2, allocation3;</span><br><span class="line">        allocation1 &#x3D; new byte[_1MB &#x2F; 4];</span><br><span class="line">        &#x2F;&#x2F;什么时候进入老年代取决于XX：MaxTenuringThreshold设置</span><br><span class="line">        allocation2 &#x3D; new byte[4 * _1MB];</span><br><span class="line">        allocation3 &#x3D; new byte[4 * _1MB];</span><br><span class="line">        allocation3 &#x3D; null;</span><br><span class="line">        allocation3 &#x3D; new byte[4 * _1MB];</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        testTenuringThreshold();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输入日志：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Heap</span><br><span class="line"> PSYoungGen      total 9216K, used 5683K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000)</span><br><span class="line">  eden space 8192K, 69% used [0x00000000ff600000,0x00000000ffb8ccc0,0x00000000ffe00000)</span><br><span class="line">  from space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000)</span><br><span class="line">  to   space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000)</span><br><span class="line"> ParOldGen       total 10240K, used 8192K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000)</span><br><span class="line">  object space 10240K, 80% used [0x00000000fec00000,0x00000000ff400020,0x00000000ff600000)</span><br><span class="line"> PSPermGen       total 21504K, used 2759K [0x00000000f9a00000, 0x00000000faf00000, 0x00000000fec00000)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="动态对象年龄判定"><a href="#动态对象年龄判定" class="headerlink" title="动态对象年龄判定"></a>动态对象年龄判定</h2><p>为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总<br>和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。</p>
<h2 id="空间分配担保"><a href="#空间分配担保" class="headerlink" title="空间分配担保"></a>空间分配担保</h2><p>在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行<br>一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。</p>
<p>新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在MinorGC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。与生活中的贷款担保类<br>似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多空间。</p>
<p>如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避免Full GC过于频繁。</p>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>垃圾收集器与分配策略</tag>
      </tags>
  </entry>
  <entry>
    <title>高并发设计思想</title>
    <url>/2020-06-02/%E9%AB%98%E5%B9%B6%E5%8F%91%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/</url>
    <content><![CDATA[<h4 id="高并发系统的通用设计方案"><a href="#高并发系统的通用设计方案" class="headerlink" title="高并发系统的通用设计方案"></a>高并发系统的通用设计方案</h4><blockquote>
<ul>
<li>横向扩展：分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量；还有一种是直接升级机器提高单个服务器处理请求的能力；</li>
<li>缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击；</li>
<li>异步：在某些场景下，未处理完成之前，我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求；</li>
</ul>
<p><strong>高并发系统的演进应该是循序渐进，以解决系统中存在的问题为目的和驱动力的。</strong></p>
</blockquote>
<h5 id="磁盘的结构以及慢的原因"><a href="#磁盘的结构以及慢的原因" class="headerlink" title="磁盘的结构以及慢的原因"></a>磁盘的结构以及慢的原因</h5><blockquote>
<ol>
<li><p>我们知道数据是放在持久化存储中的，一般的持久化存储都是使用磁盘作为存储介质的，而普通磁盘数据由机械手臂、磁头、转轴、盘片组成，盘片又分为磁道、柱面和扇区。</p>
</li>
<li><p>盘片是存储介质，每个盘片被划分为多个同心圆，信息都被存储在同心圆之中，这些同心圆就是磁道。在磁盘工作时盘片是在高速旋转的，机械手臂驱动磁头沿着径向移动，在磁道上读取所需要的数据。我们把磁头寻找信息花费的时间叫做寻道时间。</p>
</li>
<li><p>普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 ns（纳秒）级别，从千兆网卡上读取数据的时间是在μs（微秒）级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。</p>
</li>
</ol>
</blockquote>
<h5 id="异步处理的例子"><a href="#异步处理的例子" class="headerlink" title="异步处理的例子"></a>异步处理的例子</h5><blockquote>
<ul>
<li><p>我们熟知的 12306 网站。当我们订票时，页面会显示系统正在排队，这个提示就代表着系统在异步处理我们的订票请求。</p>
</li>
<li><p>采用异步的方式，后端处理时会把请求丢到消息队列中，同时快速响应用户，告诉用户我们正在排队处理，然后释放出资源来处理更多的请求。订票请求处理完之后，再通知用户订票成功或者失败。</p>
</li>
<li><p>处理逻辑后移到异步处理程序中，Web 服务的压力小了，资源占用的少了，自然就能接收更多的用户订票请求，系统承受高并发的能力也就提升了。</p>
</li>
</ul>
</blockquote>
<h5 id="系统的演进过程"><a href="#系统的演进过程" class="headerlink" title="系统的演进过程"></a>系统的演进过程</h5><blockquote>
<ul>
<li>最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。</li>
<li>随着流量的增加和业务的变化，修正架构中存在问题的点，如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。</li>
<li>当对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题。</li>
</ul>
</blockquote>
<h4 id="高并发的分层架构"><a href="#高并发的分层架构" class="headerlink" title="高并发的分层架构"></a>高并发的分层架构</h4><blockquote>
<p>表现层、业务逻辑层、数据访问层；</p>
</blockquote>
<h5 id="分层的好处"><a href="#分层的好处" class="headerlink" title="分层的好处"></a>分层的好处</h5><blockquote>
<ul>
<li><strong>分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。</strong></li>
<li><strong>再有，分层之后可以做到很高的复用。</strong></li>
<li><strong>分层架构可以让我们更容易做横向扩展。</strong></li>
</ul>
</blockquote>
<p><img src="/images/concurrentServer/%E9%98%BF%E9%87%8C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%88%86%E5%B1%82%E8%A7%84%E7%BA%A6.png" alt="阿里系统的分层规约"></p>
<h5 id="高并发系统设计的三大目标：高并发、高性能、高可用、可扩展"><a href="#高并发系统设计的三大目标：高并发、高性能、高可用、可扩展" class="headerlink" title="高并发系统设计的三大目标：高并发、高性能、高可用、可扩展"></a>高并发系统设计的三大目标：高并发、高性能、高可用、可扩展</h5><blockquote>
<ul>
<li><p>健康系统的 99 分位值的响应时间通常需要控制在 200ms 之内，而不超过 1s 的请求占比要在 99.99% 以上。</p>
</li>
<li><p>系统的吞吐量：你现在有一个系统，这个系统中处理核心只有一个，执行的任务的响应时间都在 10ms，它的吞吐量是在每秒 100 次</p>
</li>
<li><p>成本考虑，在业务平稳期，我们会预留 30%～50% 的冗余以应对运营活动或者推广可能带来的峰值流量，但是当有一个突发事件发生时，流量可能瞬间提升到 2～3 倍甚至更高</p>
</li>
</ul>
</blockquote>
<h4 id="如何减少频繁创建数据库连接的性能损耗？"><a href="#如何减少频繁创建数据库连接的性能损耗？" class="headerlink" title="如何减少频繁创建数据库连接的性能损耗？"></a>如何减少频繁创建数据库连接的性能损耗？</h4><blockquote>
<p>池化技术的使用技巧</p>
<ul>
<li><p>池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。</p>
</li>
<li><p>池子中的对象需要在使用之前预先初始化完成，这叫做池子的预热，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。</p>
</li>
<li><p>池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。</p>
<p><a href="https://blog.csdn.net/zguoshuaiiii/article/details/78402883"> 数据库连接池监控的使用</a></p>
</li>
<li><p><code>线上建议数据库连接池是min=10 max =20-30</code></p>
</li>
<li><p>jdk的ThreadPoolExecutor可以调用executor.getQueue().size()监控队列的使用情况</p>
</li>
</ul>
</blockquote>
<h4 id="数据库技术-查询请求增加时，如何做主从分离？"><a href="#数据库技术-查询请求增加时，如何做主从分离？" class="headerlink" title="数据库技术-查询请求增加时，如何做主从分离？"></a>数据库技术-查询请求增加时，如何做主从分离？</h4><blockquote>
<ul>
<li><p>数据库的主从复制</p>
<ul>
<li>MySQL 的主从复制是依赖于 binlog 的，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上二进制日志文件。主从复制就是将 binlog 中的数据从主库传输到从库上，<code>一般这个过程是异步</code>的，即主库上的操作不会等待 binlog 同步的完成。因为如果等待从库同步完返回，则写入性能会受影响，一般会优先考虑数据库性能而不是数据的强一致性；其实就是cap，保证的是a和p；</li>
<li>首先从库在连接到主节点时会创建一个 IO 线程，用以请求主库更新的 binlog，并且把接收到的 binlog 信息写入一个叫做 relay log 的日志文件中，而主库也会创建一个 log dump 线程来发送 binlog 给从库；同时，从库还会创建一个 SQL 线程读取 relay log 中的内容，并且在从库中做回放，最终实现主从的一致性。这是一种比较常见的主从复制方式。</li>
</ul>
<p><img src="/images/concurrentServer/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="mysql主从复制的过程"></p>
<ul>
<li>主库不是可以无限的挂载从库，因为每增加一个从库会消耗主库的dunp线程，同时受限于带宽的影响，所以需要一般挂载3-5个；</li>
</ul>
</li>
<li><p>主从复制实现读写分离是一种数据库横向扩展的方法；</p>
</li>
<li><p>主从同步延迟的问题解决</p>
<ul>
<li><p>使用消息中间件同步数据的时候，冗余发送全部数据而不是只发送id；</p>
</li>
<li><p><strong>使用缓存</strong></p>
</li>
<li><p><strong>查询主库</strong></p>
</li>
</ul>
</li>
<li><p>一般我们会把从库落后的时间作为一个重点的数据库指标做监控和报警，正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。 </p>
</li>
<li><p>实现主从分离的方案：</p>
<ul>
<li>第一种使用TDDL这种的jar包来处理，管理多个数据源；</li>
<li>第二种是单独部署代理层的方案，比如mycat、DBProxy(美团)，对外暴露的是一个数据库，其实内部管理多个数据源；</li>
</ul>
</li>
</ul>
</blockquote>
<h4 id="数据库优化方案（二）：写入数据量增加时，如何实现分库分表？"><a href="#数据库优化方案（二）：写入数据量增加时，如何实现分库分表？" class="headerlink" title="数据库优化方案（二）：写入数据量增加时，如何实现分库分表？"></a>数据库优化方案（二）：写入数据量增加时，如何实现分库分表？</h4><blockquote>
<ul>
<li><p>单数据库存在的问题：</p>
<ul>
<li>单表的数据量达到了千万甚至上亿，读写性能在下降；</li>
<li>数据量的增加占据了磁盘空间，数据库的备份和恢复时间太长；</li>
<li>不同模块的数据。比如用户数据和用户关系数据，全都存储在一个主库中，一旦主库发生故障，所有的模块儿都会受到影响</li>
</ul>
</li>
<li><p>分库分表在解决了数据<code>存储瓶颈</code>的同时也能有效的提升<code>数据查询的性能</code>，同时可以提高并发写数据的能力；</p>
</li>
<li><p><code>垂直拆分</code>是按照业务类型拆分，将业务耦合度搞的表拆分到单独的表中；</p>
</li>
<li><p><code>水平拆分</code>可以按照字段取模、按照时间字段的范围拆分；</p>
</li>
<li><p>分库分表存在的问题</p>
<ul>
<li><code>引入了分库分表键，也叫分区键</code>。就是对数据分库分表依据的字段；所以每次查询都要带上这个分区键。如果没有的话需要建立查询字段到数据库分区键的映射字段；</li>
<li><code>对于一些数据库的特性在实现的时候会很困难</code>，比如join的场景，好在这种场景不太高，如果需要的话可以查询出来在业务层处理。比如<code>count的情况</code> 我们可以单独的记录在一张表中或者记录在redis里。</li>
</ul>
</li>
</ul>
</blockquote>
<h4 id="如何保证分库分表后ID的全局唯一性？"><a href="#如何保证分库分表后ID的全局唯一性？" class="headerlink" title="如何保证分库分表后ID的全局唯一性？"></a>如何保证分库分表后ID的全局唯一性？</h4><blockquote>
<ul>
<li><p>变种的Snowflake 算法来生成业务需要的 ID </p>
<ul>
<li>时间戳（41位的时间错）、机器 ID（10位的机器id）、序列号（12位的序列号）、IDC（2位）；</li>
<li>每个节点每ms可以生成4096个id；</li>
<li>内置到代码中或者使用单独的服务来部署发号器（单实例单cpu 2万个/s）</li>
</ul>
</li>
<li><p>UUID（UUID无法实现有序）：需要排序、且有序的可以提高mysql的查询性能、32个16进制的数字耗费空间；</p>
</li>
<li><p>使用数据库的分片自增+步长的方式；</p>
</li>
</ul>
</blockquote>
<h4 id="在高并发场景下，数据库和NoSQL如何做到互补？"><a href="#在高并发场景下，数据库和NoSQL如何做到互补？" class="headerlink" title="在高并发场景下，数据库和NoSQL如何做到互补？"></a>在高并发场景下，数据库和NoSQL如何做到互补？</h4><blockquote>
<ul>
<li><p>nosql可以提高数据库的的读写能力，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写；例如mysql在存储数据的时候使用b+树，要找到指定的位置就要进行磁盘寻址，是一种随机IO。而Nosql（Hbase、Cassandra、LevelDB ）一般使用LSM数存储，他是将数据写到一种内存中的MemTable树中，然后写到磁盘上，；</p>
</li>
<li><p>在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持，使用ES的倒排索引来实现全文搜索；</p>
</li>
<li><p>提高数据库的扩展能力；NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。</p>
<blockquote>
<p>比如mongoDB的扩展性：</p>
<ul>
<li>一是 Replica，也叫做副本集，你可以理解为主从分离，也就是通过将数据拷贝成多份来保证当主挂掉后数据不会丢失。同时呢，Replica 还可以分担读请求。Replica 中有主节点来承担写请求，并且把对数据变动记录到 oplog 里（类似于 binlog）；从节点接收到 oplog 后就会修改自身的数据以保持和主节点的一致。一旦主节点挂掉，MongoDB 会从从节点中选取一个节点成为主节点，可以继续提供写数据服务。</li>
<li>二是 Shard，也叫做分片，你可以理解为分库分表，即将数据按照某种规则拆分成多份，存储在不同的机器上。MongoDB 的 Sharding 特性一般需要三个角色来支持，一个是 Shard Server，它是实际存储数据的节点，是一个独立的 Mongod 进程；二是 Config Server，也是一组 Mongod 进程，主要存储一些元信息，比如说哪些分片存储了哪些数据等；最后是 Route Server，它不实际存储数据，仅仅作为路由使用，它从 Config Server 中获取元信息后，将请求路由到正确的 Shard Server 中。</li>
<li>三是负载均衡，就是当 MongoDB 发现 Shard 之间数据分布不均匀，会启动 Balancer 进程对数据做重新的分配，最终让不同 Shard Server 的数据可以尽量的均衡。当我们的 Shard Server 存储空间不足需要扩容时，数据会自动被移动到新的 Shard Server 上，减少了数据迁移和验证的成本。</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="数据库成为瓶颈后，动态数据的查询要如何加速？"><a href="#数据库成为瓶颈后，动态数据的查询要如何加速？" class="headerlink" title="数据库成为瓶颈后，动态数据的查询要如何加速？"></a>数据库成为瓶颈后，动态数据的查询要如何加速？</h4><blockquote>
<ul>
<li><p>数据库磁盘IO成为系统的瓶颈后可以考虑使用缓存；内存的<code>寻址</code>100ns，磁盘的<code>查找</code>需要10ms</p>
</li>
<li><p><code>缓存</code> 不等于内存，凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存。</p>
<p><img src="/images/concurrentServer/%E7%BC%93%E5%AD%98%E7%9A%84%E9%80%9F%E5%BA%A6.png" alt="缓存的速度"></p>
</li>
<li><p><code>缓冲区</code>：<strong>缓冲区则是一块临时存储数据的区域，这些数据后面会被传输到其他设备上。</strong>缓冲区更像“消息队列篇”中即将提到的消息队列，用以弥补高速设备和低速设备通信时的速度差。比如，我们将数据写入磁盘时并不是直接刷盘，而是写到一块缓冲区里面，内核会标识这个缓冲区为脏。当经过一定时间或者脏缓冲区比例到达一定阈值时，由单独的线程把脏块刷新到硬盘上。这样避免了每次写数据都要刷盘带来的性能问题。</p>
</li>
<li><p>缓存的分类</p>
<blockquote>
<ul>
<li>静态缓存：静态数据，比如文档内容在生成的时候会渲染一个静态页面放在nginx服务器上</li>
<li>分布式缓存</li>
<li>热点数据本地缓存：热点数据的缓存放到进程中的hashMap中，多个进程中可能存在不同，但用户是可以接受的。如果没有从数据库中或分布式缓存中拉取，Guava 的 Loading Cache。这种通常缓存时间比较短，秒级别的或者分钟级别的，避免脏数据。</li>
</ul>
</blockquote>
</li>
<li><p>缓存的不足</p>
<blockquote>
<ul>
<li><strong>缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性</strong></li>
<li><strong>缓存会给整体系统带来复杂度，并且会有数据不一致的风险</strong></li>
<li><strong>之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的</strong>，所以需要做下数据存储量级的评估；</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="如何选择缓存的读写策略？"><a href="#如何选择缓存的读写策略？" class="headerlink" title="如何选择缓存的读写策略？"></a>如何选择缓存的读写策略？</h4><blockquote>
<ul>
<li><p>缓存的读取策略</p>
<ul>
<li>从缓存中读取数据；</li>
<li>如果缓存命中，则直接返回数据；</li>
<li>如果缓存不命中，则从数据库中查询数据；</li>
<li>查询到数据后，将数据写入到缓存中，并且返回给用户。</li>
</ul>
</li>
<li><p>缓存的修改策略 </p>
<ul>
<li>先更新数据库，</li>
<li>更新成功后删除缓存</li>
</ul>
</li>
<li><p><code>直接修改缓存也是不可以的，会造成库和缓存不一致的问题</code></p>
<p>这个过程中也会有并发的问题，比如说原有金额是 20，A 请求从缓存中读到数据，并且把金额加 1，变更成 21，在未写入缓存之前又有请求 B 也读到缓存的数据后把金额也加 1，也变更成 21，两个请求同时把金额写回缓存，这时缓存里面的金额是 21，但是我们实际上预期是金额数加 2，这也是一个比较大的问题。</p>
</li>
<li><p><code>更新缓存的时候 先删除缓存，后修改数据库</code></p>
<p>假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21，这就造成了缓存和数据库的不一致。</p>
</li>
</ul>
</blockquote>
<h4 id="缓存如何做到高可用？"><a href="#缓存如何做到高可用？" class="headerlink" title="缓存如何做到高可用？"></a>缓存如何做到高可用？</h4><blockquote>
<ul>
<li><p><strong>客户端方案</strong>：就是在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。有点是性能没有损耗，缺点是客户端逻辑复杂；多语言环境不能复用；</p>
<blockquote>
<p>单一的缓存节点受到机器内存、网卡带宽和单节点请求量的限制，不能承担比较高的并发，因此我们考虑将数据分片，依照分片算法将数据打散到多个不同的节点上，每个节点上存储部分数据；</p>
<p>考虑一致性hash算法，当某个节点不可用的时候就沿着环往下寻找第一个遇到的可用节点。增加和删除节点只会影响一个节点上的数据，不会影响所有数据；虚拟节点的问题；</p>
</blockquote>
</li>
<li><p><strong>中间代理层方案</strong>：是在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。</p>
<p>业界也有很多中间代理层方案，比如 Facebook 的<a href="https://github.com/facebook/mcrouter">Mcrouter</a>，Twitter 的<a href="https://github.com/twitter/twemproxy">Twemproxy</a>，豌豆荚的<a href="https://github.com/CodisLabs/codis">Codis</a>。</p>
<p>中间代理层是只是实现了高可用的路由功能；性能上有损耗</p>
</li>
<li><p><strong>服务端方案</strong>：是 Redis 2.4 版本后提出的 Redis Sentinel 方案。</p>
<p>Redis Sentinel 也是集群部署的，这样可以避免 Sentinel 节点挂掉造成无法自动故障恢复的问题，每一个 Sentinel 节点都是无状态的。在 Sentinel 中会配置 Master 的地址，Sentinel 会时刻监控 Master 的状态，当发现 Master 在配置的时间间隔内无响应，就认为 Master 已经挂了，Sentinel 会从从节点中选取一个提升为主节点，并且把所有其他的从节点作为新主的从节点。Sentinel 集群内部在仲裁的时候，会根据配置的值来决定当有几个 Sentinel 节点认为主挂掉可以做主从切换的操作，也就是集群内部需要对缓存节点的状态达成一致才行。</p>
</li>
</ul>
</blockquote>
<h4 id="缓存穿透了怎么办？"><a href="#缓存穿透了怎么办？" class="headerlink" title="缓存穿透了怎么办？"></a>缓存穿透了怎么办？</h4><blockquote>
<p>在低缓存命中率的系统中，大量查询商品信息的请求会穿透缓存到数据库，因为数据库对于并发的承受能力是比较脆弱的。一旦数据库承受不了用户大量刷新商品页面、定向搜索衣服信息，就会导致查询变慢，导致大量的请求阻塞在数据库查询上，造成应用服务器的连接和线程资源被占满，最终导致你的电商系统崩溃。</p>
<p><code>解决方案</code>：</p>
<ul>
<li><p>回种空值，但是要注意 全是当内存不够用的时候会存在全是空值的情况；</p>
</li>
<li><p>使用布隆过滤器：二进制数组和一个 Hash 算法组成</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">加入要判断用户是否存在缓存中</span><br><span class="line">1. 初始化一个20亿的数组； 20亿&#x2F;8&#x2F;1024&#x2F;2014 &#x3D; 238M</span><br><span class="line">2. 把所有的数据库的用户id进行取hash然后对20亿取余，计算出在布隆过滤器的位置，设置为1；新增的数据插入数据库中，同事布隆过滤对应的位置也设置为1；</span><br><span class="line">3. 然后获取数据前，先从布隆过滤器中判断是否存在；</span><br><span class="line"></span><br><span class="line">存在hash碰撞，所以会误判。不存在的却被布隆过滤器判断为存在；可以使用多个hash值解决</span><br><span class="line">不支持删除。不止使用0和1 也是用2，但会浪费空间</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<h4 id="CDN：静态资源如何加速？-content-deliver-network"><a href="#CDN：静态资源如何加速？-content-deliver-network" class="headerlink" title="CDN：静态资源如何加速？(content deliver network)"></a>CDN：静态资源如何加速？(content deliver network)</h4><blockquote>
<p>静态资源（js文件、css文件、html、图片、视频、流媒体信息）都放到nginx等web服务器上，他们的读请求量极大，对访问速度要求极高，占据和很高的带宽；</p>
<p>使用CDN技术在业务服务器的上一层，增加一层特殊的缓存，用来承担绝大多数的静态资源的访问，这一层遍布在全国各地，这用用户选择就近的节点访问。</p>
<p><code>CDN是如何实现加速用户对静态资源的请求的</code></p>
<ul>
<li>DNS解决域名映射问题：一种是返回域名对应的ip，叫A记录；一种是返回CName记录就是返回域名对应的另一个域名；</li>
</ul>
<p><img src="/images/concurrentServer/DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B.png" alt="DNS域名解析过程"></p>
<ul>
<li>使用GSLB（全局负载均衡）对于部署在各地的服务器之间做负载均衡，另一方面保证流量流经的服务器与流量源头在地缘上是比较近的；</li>
</ul>
</blockquote>
<h4 id="消息队列：秒杀时如何处理每秒上万次的下单请求？"><a href="#消息队列：秒杀时如何处理每秒上万次的下单请求？" class="headerlink" title="消息队列：秒杀时如何处理每秒上万次的下单请求？"></a>消息队列：秒杀时如何处理每秒上万次的下单请求？</h4><blockquote>
<ul>
<li><p>消息队列是暂时存储数据的容器，它是一个平衡低俗系统和告诉系统处理任务时间差的工具。</p>
</li>
<li><p>将用户请求放入到消息队列中，返回秒杀进行中；然后处理后续的下单、业务处理；之后处理结果返回给用户。</p>
</li>
<li><p>通过异步处理简化业务流程；重要的业务线处理，次要的业务异步处理；</p>
<p><code>异步处理、削峰填谷、解耦合</code></p>
</li>
<li><p>主要作用：提高写性能，实现系统的解耦合，提高高并发的写流量；</p>
</li>
</ul>
</blockquote>
<h4 id="消息投递：如何保证消息仅仅被消费一次？"><a href="#消息投递：如何保证消息仅仅被消费一次？" class="headerlink" title="消息投递：如何保证消息仅仅被消费一次？"></a>消息投递：如何保证消息仅仅被消费一次？</h4><blockquote>
<ul>
<li><p>生产消息中丢失消息</p>
<blockquote>
<ul>
<li>发送失败或者超时，则进行消息重传；</li>
</ul>
</blockquote>
</li>
<li><p>消息队列中消息的丢失</p>
<blockquote>
<ul>
<li>为了减少存储消息对磁盘的随机IO，会将消息先写入到操作系统的page Cache中，再找合适的时机输入到磁盘上。可以配置cache达到一定消息数量或者间隔一段时间后再刷盘，也就是异步刷盘；</li>
<li>部署集群的方法，集群部署中leader中的数据会同步给ISR中的follower，有个ACK机制，配置成所有的ISR同步完毕才代表发送成功；kafka集群还有集群的leader选举机制；</li>
</ul>
</blockquote>
</li>
<li><p>消费过程中消息的丢失</p>
<blockquote>
<ul>
<li><p>消费消息的三步：接收消息、处理消息、更新消费进度</p>
</li>
<li><p>服务端和消费端进行幂等处理：多次和一次执行的结果一样；</p>
</li>
<li><p><code>生产端，消息服务器队列会存储生产者id和最后一条消息的映射，消息服务端会将消息id和最后一条消息的id进行比对</code>；</p>
</li>
<li><p>生产的时候生成一个全局唯一id，消费后进行保存到缓存，消费的时候判断消息是否存在；而且你得用事务处理，消息处理和写入缓存必须保证原子性；</p>
</li>
<li><p>或者处理的时候增加一个版本号使用乐观锁的机制；</p>
</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="消息队列：如何降低消息队列系统中消息的延迟？"><a href="#消息队列：如何降低消息队列系统中消息的延迟？" class="headerlink" title="消息队列：如何降低消息队列系统中消息的延迟？"></a>消息队列：如何降低消息队列系统中消息的延迟？</h4><blockquote>
<ul>
<li><p>增加消费者组的消费者的数量，一个partition只能被一个消费者组中的一个消费者消费，所以需要新建topic并且创建多个消费者来处理；</p>
</li>
<li><p>增加线程池异步处理；</p>
</li>
<li><p>拉取不到消息则sleep一段时间；</p>
<p><code>数据从磁盘写入到缓冲区的过程</code>：</p>
<p><img src="/images/concurrentServer/%E6%95%B0%E6%8D%AE%E4%BB%8E%E7%A3%81%E7%9B%98%E5%86%99%E5%85%A5%E5%88%B0%E7%BD%91%E7%BB%9C%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="数据从磁盘写入到网络的过程"></p>
</li>
</ul>
</blockquote>
<h4 id="系统架构：每秒1万次请求的系统要做服务化拆分吗？"><a href="#系统架构：每秒1万次请求的系统要做服务化拆分吗？" class="headerlink" title="系统架构：每秒1万次请求的系统要做服务化拆分吗？"></a>系统架构：每秒1万次请求的系统要做服务化拆分吗？</h4><blockquote>
<p><code>一体化项目的优点</code></p>
<ul>
<li>开发简单直接，项目和代码集中式管理；</li>
<li>节省了运维系统的成本；</li>
<li>排查问题简单；</li>
</ul>
<p><code>一体化项目缺点</code></p>
<ul>
<li>系统的资源出现扩展性问题：数据库连接数成为系统的瓶颈。数据库最大连接数是8000，各个客户端的连接数是30，还有别的消息队列的服务需要连接数据库；</li>
<li>大家共同维护一套代码：增加了研发的成本，抑制了研发的效率。业务变大的时候需要拆分成各个小团队，各个小组维护一套代码在配合时会出现问题；一个小问题影响这个服务；</li>
<li>一体化架构对运维也有很大影响，代码比较多，比较复杂，任何小的修改都需要上线；</li>
</ul>
<p><code>微服务的拆分</code></p>
<ul>
<li>按照业务拆分：拆成内容服务、用户服务、互动服务，各个服务有各自的数据库；各个服务职能直接调用自己的库，调用其它库只能通过别的服务去调用，减少了数据库连接数；</li>
<li>按照公共逻辑拆分：减少重复代码；</li>
</ul>
<p><code> 系统演进的感悟</code></p>
<ul>
<li>前期考虑的是性能、可用性、可扩展性；</li>
<li>后期考虑成功：研发团队、开发成本、沟通成本、运维成本；要做一些小工具提高工程师的效率；</li>
</ul>
</blockquote>
<h4 id="微服务架构：微服务化后，系统架构要如何改造？"><a href="#微服务架构：微服务化后，系统架构要如何改造？" class="headerlink" title="微服务架构：微服务化后，系统架构要如何改造？"></a>微服务架构：微服务化后，系统架构要如何改造？</h4><blockquote>
<p>服务拆分的原则：</p>
<ul>
<li>单一服务内部功能高内聚、低耦合。每个服务只完成自己的职责的任务，对于不是自己职责的功能要交给其他模块完成；比如判断用户是否为认证用户的逻辑要放在用户服务中而不能放到内容服务中；</li>
<li>服务拆分的粒度，先粗略拆分、再逐渐细化；比如黑名单相关的服务要先拆到用户服务中，后期可以再细拆；</li>
<li>拆分的过程尽量避免日常功能的迭代<ul>
<li>优先剥离比较独立的边界服务，从非核心服务出发，减少对现有服务的影响。也给团队一个试错的机会；</li>
<li>两个服务有依赖关系的时候，需要先拆分被依赖的服务；</li>
</ul>
</li>
<li>服务接口的定义要具备可扩展性；比如一个微服务的接口有三个参数，一次需求开发中，组内的同学调整为4个参数，调用方没有修改，所以会报错；</li>
</ul>
<p>微服务化带来的问题和解决思路</p>
<ul>
<li><code>引入服务注册中心</code>：服务接口的调用是跨进程的网络调用，同时接口调用方需要知道服务部署在哪个机器上，哪个端口上；于是需要引入服务注册中心；</li>
<li><code>多个服务之间有复杂的依赖关系，需要服务治理体系</code>：单个服务会影响别的依赖该服务的其它服务，这时候需要熔断、限流、降级、超时控制；</li>
<li>需要快速定位调用链路的问题，这时候需要引入<code>分布式追踪工具</code>，以及服务端监控报表；</li>
</ul>
</blockquote>
<h4 id="RPC框架：10万QPS下如何实现毫秒级的服务调用"><a href="#RPC框架：10万QPS下如何实现毫秒级的服务调用" class="headerlink" title="RPC框架：10万QPS下如何实现毫秒级的服务调用"></a>RPC框架：10万QPS下如何实现毫秒级的服务调用</h4><blockquote>
<p>微服务拆分后存在问题</p>
<ul>
<li>跨网络通讯的问题；</li>
<li>服务治理问题；</li>
</ul>
<p>RPC框架的性能要求</p>
<ul>
<li>选择合适的网络模型，针对性的调整网络参数，优化网络传输性能；</li>
<li>选择合适的序列化方式，以提升封包和解包的性能；</li>
</ul>
<p><img src="/images/concurrentServer/RPC%E6%A1%86%E6%9E%B6%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9.png" alt="RPC框架的设计注意事项"></p>
</blockquote>
<h4 id="注册中心：分布式系统如何寻址？"><a href="#注册中心：分布式系统如何寻址？" class="headerlink" title="注册中心：分布式系统如何寻址？"></a>注册中心：分布式系统如何寻址？</h4><blockquote>
<p>注册中心组件：老派的zookeeper、k8s使用的etcd、springcloud使用的eureka，阿里使用nacos；</p>
<p>主要功能：</p>
<ol>
<li><p>提供了服务地址的存储，本地会做缓存；</p>
</li>
<li><p>当存储内容发生变化的时候，可以经变更的内容推送给客户端；（紧急扩容和服务节点故障需要变更节点）</p>
</li>
</ol>
<p>探测存活一般使用两种机制：</p>
<ol>
<li>主动请求探活机制：子服务提供一个端口，每隔一段时间注册中心向子服务探测是否可用。存在问题：①：端口固定，多了有可能被占用；②：服务多了注册中心的压力比较大；</li>
<li>使用心跳机制：子服务每次向注册中心提供心跳，注册中心接受到心跳包后会在注册中心更新服务的续约时间。然后注册中心会定期检测当前时间和节点，如果阈值超过一定时间，那么节点被标记为不可用；</li>
</ol>
<p>注意事项：</p>
<ul>
<li>注册中心存在过度摘除的问题，可以使用保护策略。如果存活节点少于40%，则停止摘除服务，同时服务报警；</li>
</ul>
</blockquote>
<h4 id="分布式Trace（链路追踪）：横跨几十个分布式组件的慢请求要如何排查？"><a href="#分布式Trace（链路追踪）：横跨几十个分布式组件的慢请求要如何排查？" class="headerlink" title="分布式Trace（链路追踪）：横跨几十个分布式组件的慢请求要如何排查？"></a>分布式Trace（链路追踪）：横跨几十个分布式组件的慢请求要如何排查？</h4><blockquote>
<p>主要作用</p>
<ul>
<li>跨进程的调用链展示，服务依赖分析，在性能优化和问题排查方面提供数据上的支持；</li>
<li>常用组件zipkin、jaeger</li>
</ul>
<p>一体化服务的问题排查过程：</p>
<ul>
<li>简单的可以添加每个方法的调用时间日志，逐步排查；</li>
<li>使用切面对每个方法添加打印调用时间的操作；</li>
</ul>
<p>动态代理和静态代理</p>
<ul>
<li>静态代理是在编译器插入代码，增加了编译的时间，运行期对性能没有影响；</li>
<li>动态代理不会修改class文件，在运行期生成一个代理对象，这个代理对象会对源对象做字节码增强，来完成切面需要做的工作。由于需要在运行期间生成代理对象，则动态代理性能要不静态代理的查；</li>
</ul>
<p>打印日志的小技巧：</p>
<ul>
<li>尽量使用ASPECTJ 做静态代理，减少了对代码的侵入性；</li>
<li>对性能要低损耗；</li>
<li>使用requstId标记调用流程；</li>
<li>对请求id做取模 requestId%10==0 采样打印，以减少日志量；</li>
<li>分布式存储，不能打印日志到服务器上，使用放入到mq中，发送日志到es中；</li>
</ul>
<p>微服务的服务问题排查过程</p>
<ul>
<li><p>使用traceId(requestId)记录服务内的调用，使用spanId记录每一次RPC调用；</p>
<p><img src="/images/concurrentServer/%E5%88%86%E5%B8%83%E5%BC%8FtraceId%E8%BF%BD%E8%B8%AA%E9%97%AE%E9%A2%98.png" alt="分布式traceId追踪问题"></p>
</li>
</ul>
</blockquote>
<h4 id="负载均衡：怎样提升系统的横向扩展能力？"><a href="#负载均衡：怎样提升系统的横向扩展能力？" class="headerlink" title="负载均衡：怎样提升系统的横向扩展能力？"></a>负载均衡：怎样提升系统的横向扩展能力？</h4><blockquote>
<p> 负载均衡服务分类：</p>
<ul>
<li><p>代理类负载均衡服务；</p>
<blockquote>
<p> LVS：它在osi的第四层（传输层）；</p>
<p>nginx：它在地七层（应用层）；</p>
<p>一般使用lvs–&gt;多个nginx。单节点的nginx可以承担10万以下的QPS，lvs可以承担更大的流量。</p>
</blockquote>
</li>
<li><p>客户端负载均衡服务</p>
<p>rpc服务一般使用的rpc协议，而不是http协议，不能使用nginx这种，所以需要使用客户端负载均衡，也就是负载均衡服务内嵌在rpc客户端内。它提供多种节点选取的策略。这种一般是配合注册中心来使用，注册中心负责提供服务节点列表，客户端负责选取后进行服务调用</p>
</li>
<li><p>常见的负载均衡策略</p>
<blockquote>
<ul>
<li><p>静态策略：在选择节点时不会根据后端的服务实际运行状态来选择；</p>
<p>轮训的策略、权重的策略、ipHash、url_hash</p>
</li>
<li><p>动态策略：在选择节点时会根据后端服务的状态来进行选择；</p>
<p>根据服务的存活情况，服务的连接数，服务的响应时间来动态的分配权重；</p>
<p>nginx的探活模块可以指定服务的接口探测是否可用</p>
<p><img src="/images/concurrentServer/nginx%E7%9A%84%E6%8E%A2%E6%B4%BB%E6%A8%A1%E5%9D%97.png" alt="nginx的探活模块"></p>
</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="API网关，系统的门面设计"><a href="#API网关，系统的门面设计" class="headerlink" title="API网关，系统的门面设计"></a>API网关，系统的门面设计</h4><blockquote>
<ul>
<li><p>概念</p>
<p>  api网关是一个架构模式，他可以将服务共有的功能整合在一起，独立部署为单独的一层，来解决一些服务治理问题。对出入系统的流量做统一的管控。分为入口和出口网关；</p>
</li>
<li><p>作用：入口网关通常部署在负载均衡服务器和应用服务器之间</p>
<ol>
<li>给客户端提供一个统一的接入地址，它可以根据用户的请求路由到不同的业务服务上。你部署的微服务对外暴露的协议可能不同，api网关可以屏蔽这些细节；</li>
<li>做服务治理，比如熔断、降级、流量控制和分流；</li>
<li>客户端的授权和认证；</li>
<li>针对设备id、用户id、用户ip维度做一些黑白名单策略；</li>
<li>做日志记录；</li>
</ol>
</li>
<li><p>实现的注意事项</p>
<ol>
<li>网关注重的是性能和扩展性，你可以采用多路IO复用模型和线程池并发处理，来提升网关性能；使用责任链模式来提升网关的扩展性；</li>
<li>API网关的线程池可以针对不同的接口或者服务做隔离保护，提升网关的可用性；</li>
<li>API网关可以代替原本系统中的web层，将web层中的协议转换，认证、限流等功能放入api网关中；</li>
</ol>
</li>
<li><p>API网关的开源实现</p>
<ol>
<li>kong是在nginx中运行的lua程序，得益于nginx的优势，kong对于api网关来说性能是最好的；</li>
<li>zuul是spring cloud全家桶中的一员，他是java开发的，zuul1使用的是同步阻塞模型，所以性能不是很高，zuul2使用异步nio的线程模型，但成熟度不高；</li>
<li>Tyk是go语言实现的轻量级API网关；</li>
</ol>
</li>
</ul>
</blockquote>
<h4 id="全链路压力测试"><a href="#全链路压力测试" class="headerlink" title="全链路压力测试"></a>全链路压力测试</h4><blockquote>
<p> 普通的压测存在的问题</p>
<ul>
<li>首先压测时需要使用线上数据和线上环境；</li>
<li>其次，压力测试不能模拟请求，而是要使用线上的流量，你可以使用拷贝流量的方式把线上的流量拷贝到压测测试环境；比如线上的缓存数据，不可能让你使用一条数据，你命中缓存后都走缓存；</li>
<li>不能从一台服务器发起，这样很容易达到这台服务器性能瓶颈，从而导致压力测试服务器的QPS上不去；</li>
</ul>
<p><code>全链路压测</code>和<code>性能监控平台</code></p>
<p>   不能针对某个模块来做压测，需要对后端服务、数据库、缓存、消息队列、中间件等所有的服务做压测。</p>
<p>全链路压测平台的关键点</p>
<ul>
<li><p>流量隔离</p>
<blockquote>
<p>要区分压力测试流量和正式流量；</p>
</blockquote>
</li>
<li><p>风险的控制</p>
<blockquote>
<p>需要避免压力测试对正常用户的影响；</p>
</blockquote>
<p>全链路压测要包括以下模块</p>
</li>
<li><p>流量构造和生产模块；</p>
<blockquote>
<ol>
<li>一般将http请求入口流量拷贝一份，然后经过清洗后放入到nosql存储数据库中；一般可以使用nginx日志，然后将日志进行解析（增加开发成本）；</li>
<li>另一种是使用开源的流量拷贝工具GoReplay，它可以劫持本机某一个端口的流量，将他们记录在文件中，在压测时进行流量回放；</li>
</ol>
</blockquote>
</li>
<li><p>压测数据隔离模块，流量染色；</p>
<blockquote>
<ol>
<li>一般，我们针对读取数据（下行流量）的请求，会针对不能压测的服务或者组件做mock处理，比如浏览数据的行为不能做统计；比如展示过的数据，被请求过就不在展示了，这种要做特殊处理；这些数据要搭建mock服务，最好部署在真实的机房；</li>
<li>对于写入的数据，我们会把数据写入到影子库中，和线上的数据完全隔离；对于mysql中的麽易新建一个mysql实例，把线上的schema和数据导入到进来，redis可以新增加一个前缀；es可以新建一个索引；</li>
</ol>
</blockquote>
</li>
<li><p>系统健康检查和压测流量干预模块；</p>
<blockquote>
<ol>
<li>先设置流量测试的压力目标比如 20万次/QPS</li>
<li>逐渐增加压力，观察一段时间；</li>
<li>做一些工具，来根据监控通知机制服务</li>
</ol>
</blockquote>
<p><img src="/images/concurrentServer/%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="全链路压测架构图"></p>
</li>
</ul>
<p>全链路压测的意义</p>
<ol>
<li>帮助我们发现系统中的性能瓶颈，方便我们做预案来应对；</li>
<li>为我们做容量评估，提供数据支撑；</li>
<li>在压测时候做预案演练；</li>
</ol>
</blockquote>
<h4 id="多机房部署：跨地域的分布式系统如何做？"><a href="#多机房部署：跨地域的分布式系统如何做？" class="headerlink" title="多机房部署：跨地域的分布式系统如何做？"></a>多机房部署：跨地域的分布式系统如何做？</h4><blockquote>
<p> IDC机房（互联网数据中心）部署多套服务，共享一份业务数据，共同承担来自客户的流量；</p>
<p>跨机房：</p>
<ul>
<li>北京同地双机房之间的专线延迟一般在1-3ms；</li>
<li>国内异地双机房之间的专线延迟在50ms内；根据距离有所不同；</li>
<li>国际化的服务延迟在100-200ms，所以需要做异步数据同步，无法做到同步调用；</li>
</ul>
<p>同城多机房允许有跨机房的写入的发生，但是数据的读取服务的调用尽量保证在一个机房；</p>
<p>异地多活方案则应该避免跨机房同步数据的读取和写入，采用异步的方式，将数据从一个机房同步到另一个机房；</p>
</blockquote>
<h4 id="Service-Mesh：如何屏蔽服务化系统的服务治理细节？"><a href="#Service-Mesh：如何屏蔽服务化系统的服务治理细节？" class="headerlink" title="Service Mesh：如何屏蔽服务化系统的服务治理细节？"></a>Service Mesh：如何屏蔽服务化系统的服务治理细节？</h4><blockquote>
<p>前面提到的服务治理方案：</p>
<ul>
<li>用RPC框架解决服务通信的问题；</li>
<li>用注册中心解决服务注册，和发现的问题；</li>
<li>使用分布式Trace中间件，排查跨服务调用慢请求；</li>
<li>使用负载均衡服务器，解决服务扩展性的问题</li>
<li>使用API网关植入服务熔断、降级、流控等服务治理的策略；</li>
</ul>
<p>跨语言的细节</p>
<p>比如序列化的协议、各种api网关的策略</p>
<p>使用istio来实现service mesh来解决各个服务模块的治理的细节；</p>
</blockquote>
<h4 id="给系统加上眼睛：服务端监控要怎么做？"><a href="#给系统加上眼睛：服务端监控要怎么做？" class="headerlink" title="给系统加上眼睛：服务端监控要怎么做？"></a>给系统加上眼睛：服务端监控要怎么做？</h4><blockquote>
<p>主要存在的问题</p>
<ul>
<li>使用数据库主从延迟变长，导致业务上出现问题；</li>
<li>接口响应时间变长；</li>
<li>系统中出现大量错误，影响了用户的使用；</li>
</ul>
<p>如何搭建监控服务</p>
<ul>
<li><p>指标：除了基础机器的基础指标还有以下业务指标；</p>
<blockquote>
<ul>
<li><p>延迟：比如接口的响应时间、访问数据库和缓存的延迟；</p>
</li>
<li><p>通信量：可以理解为吞吐量，也就是单位时间内请求量的大小。比如第三方服务的请求量、访问消息队列的请求量；</p>
</li>
<li><p>错误：当前系统的错误数量，比如错误码 4** 5**，也比如虽然返回200，但是业务上是异常的；</p>
</li>
<li><p>饱和度：服务或者资源达到上限的程度，比如cpu使用率、内存使用率、数据库连接池使用情况；</p>
</li>
</ul>
<p><img src="/images/concurrentServer/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87.png" alt="监控指标"></p>
</blockquote>
</li>
<li><p>采集指标的方法和途径：</p>
<blockquote>
<ul>
<li><p>使用<code>代理</code>主要监控的是服务端的情况，比如redis调用它的state命令获取它的统计数据，kafka的队列队堆积数或者GC信息都可以通过JMX来监控使用；</p>
</li>
<li><p>在代码中<code>埋点</code>，主要是在客户端使用的情况。使用之前说到的trace组件，监控服务的耗时，调用量，慢请求数，发送给监控服务器； 注意对数据的汇总，不要每个请求都发送数据；</p>
</li>
<li><p><code>日志</code>也可以作为指标来源。可以使用开源的日志采集工具，flume、fluentd、filebeat</p>
</li>
<li><p>Prometheus </p>
</li>
</ul>
</blockquote>
</li>
<li><p>指标采集后如何处理和展示：</p>
<blockquote>
<p>使用kafka接收消息，消费填谷；</p>
<p>然后使用一个消费来写入es，然后通过kibana来展示，这些主要用来做原始数据的查询；</p>
<p>另一种是做流式数据处理的中间件比如spark、storm来做数据处理</p>
<blockquote>
<ul>
<li>解析数据的请求量、响应时间、请求url等数据；</li>
<li>做一些聚合运算，比如tomcat的访问日志，对同一个url一段时间内的请求量、响应时间分隔位置、非200请求量的大小；</li>
<li>存入时序数据库中，比如influxDB。</li>
<li>最后使用grafana来连接时序数据库，将监控数据制作成报表，呈现出来；</li>
</ul>
</blockquote>
</blockquote>
<p><img src="/images/concurrentServer/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="监控系统架构图"></p>
<p><img src="/images/concurrentServer/%E7%9B%91%E6%8E%A7%E5%BD%A2%E6%88%90%E7%9A%84%E6%8A%A5%E8%A1%A8.png" alt="监控形成的报表"></p>
</li>
</ul>
</blockquote>
<h4 id="配置管理：成千上万的配置项要如何管理？"><a href="#配置管理：成千上万的配置项要如何管理？" class="headerlink" title="配置管理：成千上万的配置项要如何管理？"></a>配置管理：成千上万的配置项要如何管理？</h4><blockquote>
<p>配置中心的开源方案：</p>
<ol>
<li>携程的apollo：支持不同环境、不同集群的配置、有完善的管理功能。支持灰度发布，热发布；</li>
<li>springcloud config</li>
<li>阿里的nocas</li>
</ol>
<p>配置信息的存储</p>
<p> 一般使用mysql、etcd、redis、zookeeper都可以；</p>
<p>变更消息的推送</p>
<ul>
<li>轮训查询：应用程序向配置中心客户端注册一个监听器，配置中心的客户端定时查询配置是否有变化，如果有变化则通知触发监听器，让应用程序变更通知；为了防止查询量太大使用MD5值；</li>
<li>长连接推送，更实时；</li>
</ul>
<p>为了保证高可用，在配置中心的客户端添加两级缓存，一级是在内存中的缓存（降低和客户端的交互），另外一级是文件的缓存（灾备）；</p>
<p>动态需要调整的可以放到配置中心；</p>
</blockquote>
<h4 id="降级和熔断，屏蔽非核心系统故障的影响"><a href="#降级和熔断，屏蔽非核心系统故障的影响" class="headerlink" title="降级和熔断，屏蔽非核心系统故障的影响"></a>降级和熔断，屏蔽非核心系统故障的影响</h4><blockquote>
<ul>
<li><p>降级和熔断主要解决的问题：</p>
<ol>
<li>由于依赖的资源或者服务不可用，导致整体服务宕机。比如数据库访问缓慢；</li>
<li>超过系统承载能力的流量到来，系统不堪重负，出现拒绝服务的情况；</li>
</ol>
</li>
<li><p>雪崩是如何发生的？</p>
<ol>
<li>局部故障会导致全局故障就是雪崩。比如A服务调用B服务，b服务响应缓慢，导致A服务也运行缓慢，最终导致A服务不可用；</li>
<li>所以分布式最怕的不是某个服务或者组件宕机，而是响应缓慢，响应变慢会导致雪崩拖垮整个系统。</li>
</ol>
</li>
<li><p>熔断机制</p>
<ol>
<li>发起服务调用，如果服务返回错误或者超时次数超过一定的阈值，则后续请求不再向远程服务发起请求而是暂时返回错误；</li>
<li>状态机，关闭（调用远程服务）、半打开（尝试调用远程服务）、打开（返回错误）</li>
</ol>
</li>
<li><p>熔断机制的状态维护</p>
<ol>
<li>当调用失败的次数累计到一定的阈值时，熔断状态从关闭到打开状态。一般在实现时，如果成功调用一次，就会重置调用失败的次数；</li>
<li>当熔断处于打开状态时，我们会启动一个超时计时器，当计时器超时时，状态切换到半打开状态，你也可以设置一个定时器，定时的探测服务是否恢复；</li>
<li>在熔断处于半打开状态时，请求可以达到后端服务，如果累计一定次数后，状态切换到关闭状态；如果出现调用失败的情况则切换到打开状态；</li>
</ol>
</li>
<li><p>封装的redis客户端中实现的熔断机制：</p>
<ol>
<li><p>当处于熔断状态时，定期的检查redis组件是否可用</p>
<p><img src="/images/concurrentServer/%E7%86%94%E6%96%AD%E7%8A%B6%E6%80%81%E6%A3%80%E6%9F%A5redis%E7%BB%84%E4%BB%B6%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8.png" alt="熔断状态检查redis组件是否可用"></p>
</li>
<li><p>redis客户端需要加入熔断逻辑</p>
<p><img src="/images/concurrentServer/redis%E7%86%94%E6%96%AD%E6%A3%80%E6%9F%A5%E9%80%BB%E8%BE%91.png" alt="redis熔断检查逻辑"></p>
</li>
</ol>
</li>
<li><p>开关降级</p>
<p>开关降级是指在代码中预先设置一些开关，用来控制服务的返回值，比方说开关打开时，执行指定的降级策略，这些开关的值可以存储在配置中心中，当系统出现问题需要降级时，只需要修改配置中心中开关的值就可以了。</p>
</li>
<li><p>具体的降级策略</p>
<ol>
<li>针对读取数据的场景，我们一般采用的策略是<code>直接返回降级数据</code></li>
<li>对一些轮训获取数据的场景，比如每隔30秒获取一次未读数的，可以<code>降低读取数据的频率</code>；</li>
<li>对于写数据的场景，一般会考虑把同步写改成<code>异步</code>，这样可以牺牲一些数据的的一致性来保证系统的可用性；</li>
</ol>
</li>
</ul>
</blockquote>
<h4 id="流量控制：高并发系统中我们如何操纵流量？"><a href="#流量控制：高并发系统中我们如何操纵流量？" class="headerlink" title="流量控制：高并发系统中我们如何操纵流量？"></a>流量控制：高并发系统中我们如何操纵流量？</h4><blockquote>
<p> 核心服务流量太大的时候不能熔断，需要进行流量控制</p>
<p><img src="/images/concurrentServer/%E9%99%90%E6%B5%81%E7%AD%96%E7%95%A5.png" alt="限流策略"></p>
<p>限流算法</p>
<ul>
<li><p>固定窗口</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 每秒重置计数器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> AtomicInteger counter = <span class="keyword">new</span> AtomicInteger();</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">    ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();</span><br><span class="line">  </span><br><span class="line">    scheduledExecutorService.scheduleAtFixedRate(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            counter.set(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,<span class="number">0</span>,<span class="number">1</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>滑动窗口</p>
<blockquote>
<p>为了解决固定窗口流量集中的问题，将一秒钟的时间段拆分成5分，每次计算都要按当前时间往后计算1秒；</p>
</blockquote>
</li>
<li><p>漏桶算法，消息队列</p>
</li>
<li><p>桶令牌：消费后消费令牌，根据时间频率往令牌桶放令牌；（使用guava中的限流器；但是分布式环境的话需要在redis中存储，为了解决频繁请求的问题，则使用一次获取多个令牌的方案）</p>
</li>
</ul>
</blockquote>
<p>参考：极客时间 <a href="https://time.geekbang.org/column/intro/230">《高并发系统设计40问》</a></p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title>maven实战</title>
    <url>/2018-06-09/maven%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>构建: 清理 编译 测试生成报告 打包 部署 就是自动化构建的过程;</p>
<p>maven不仅是构建工具,还是一个依赖管理工具和项目信息管理工具(包括获取项目文档 测试报告 静态分析报告 源码版本日志报告等项目的信息).</p>
<h2 id="安装maven"><a href="#安装maven" class="headerlink" title="安装maven"></a>安装maven</h2><p>安装maven需要首先安装jdk环境,配置java环境变量.然后安装maven,这里不在赘述.</p>
<h2 id="m2"><a href="#m2" class="headerlink" title="/.m2"></a>/.m2</h2><p>mvn help:system 命令执行后会打印出所有的java系统属性和环境变量.</p>
<p>包括System Properties和Environment Variables两大部分</p>
<h2 id="设置http代理"><a href="#设置http代理" class="headerlink" title="设置http代理"></a>设置http代理</h2><p>确认是否可以访问公共的maven仓库, ping repol.maven.org.如果不通,则需要telnet需要设置的代理ip和port,连接正确,则输入ctrl+] 绕后q回车即可.</p>
<p>检查完毕之后,编辑~/.m2/settings.xml文件.添加代理配置 在maven的conf目录下是有proxies节点配置代理的,copy到.m2下的settings文件中.</p>
<h2 id="设置MAVEN-OPTS环境变量"><a href="#设置MAVEN-OPTS环境变量" class="headerlink" title="设置MAVEN_OPTS环境变量"></a>设置MAVEN_OPTS环境变量</h2><p>执行mvn命令实际上执行的时java命令,那么运行的时候需要执行虚拟机参数.默认的MAVEN_OPTS=”-Xms128m -Xmx512m”是不能满足需求的,可以自行修改,和设置maven_home时一样的设置方式.</p>
<p>export MAVEN_OPTS=”-Xms256m -Xmx512m”</p>
<h2 id="不要使用IDE内嵌的maven"><a href="#不要使用IDE内嵌的maven" class="headerlink" title="不要使用IDE内嵌的maven"></a>不要使用IDE内嵌的maven</h2><p>原因:</p>
<p>1.内嵌的maven通常会比较新,通常不稳定;</p>
<p>2.命令行的和内嵌的版本不一致,我们有时候需要使用命令行运行maven,这样会产生一些奇怪的问题.</p>
<h1 id="使用入门"><a href="#使用入门" class="headerlink" title="使用入门"></a>使用入门</h1><p>maven项目的核心是pom.xml文件(project object model,项目对象模型).</p>
<h2 id="编写pom文件"><a href="#编写pom文件" class="headerlink" title="编写pom文件"></a>编写pom文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot;</span><br><span class="line">         xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line"></span><br><span class="line">    &lt;groupId&gt;com.juvenxu.mvnbook&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hello-world&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;name&gt;Maven Hello World Project&lt;&#x2F;name&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;project&gt;         </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>pom文件的demo.SNAPSHOT意思是快照,说明该项目还在开发中,是不稳定的版本.</p>
<h2 id="编写主代码"><a href="#编写主代码" class="headerlink" title="编写主代码"></a>编写主代码</h2><p>1.主代码和测试代码不同,项目的主代码会被打包到最终的构建如jar包中,而测试代码只在运行测试时用到.</p>
<p>2.默认情况下,maven假设主代码位于src/main/java目录.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.juvenxu.mvnbook.helloworld;</span><br><span class="line"></span><br><span class="line">public class HelloWorld&#123;</span><br><span class="line"></span><br><span class="line">public String sayHello()&#123;</span><br><span class="line"></span><br><span class="line"> return &quot;hello maven&quot;;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">public static void main(String [] args)&#123;</span><br><span class="line"></span><br><span class="line">System.out.println(new HelloWorld().sayHello());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>java类中的包要基于项目的groupId和artifactId,这样逻辑清晰;</p>
<p>3.在项目的根目录下编译 mvn clean compile</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~&#x2F;IdeaProjects&#x2F;hello-world$ mvn clean compile</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ------------------&lt; com.juvenxu.mvnbook:hello-world &gt;-------------------</span><br><span class="line">[INFO] Building Maven Hello World Project 1.0-SNAPSHOT</span><br><span class="line">[INFO] --------------------------------[ jar ]---------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hello-world ---</span><br><span class="line">[INFO] Deleting &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hello-world ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] skip non existing resourceDirectory &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;src&#x2F;main&#x2F;resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hello-world ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!</span><br><span class="line">[INFO] Compiling 1 source file to &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;classes</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 1.869 s</span><br><span class="line">[INFO] Finished at: 2018-06-09T15:13:33+08:00</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">zhuningning@ubuntu:~&#x2F;IdeaProjects&#x2F;hello-world$ </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>clean告诉maven清理输出目录target/,compile告诉maven编译项目主代码.</p>
<p>从输出中看到maven首先执行了clean任务,删除target/目录,默认构建的所有输出都会在target目录下,紧接着执行resources任务,最后执行compile命令,将项目主代码编译到target/classes目录下.</p>
<h2 id="编写测试代码"><a href="#编写测试代码" class="headerlink" title="编写测试代码"></a>编写测试代码</h2><p>1.测试代码的默认目录是src/test/java/,而测试使用的是junit单元测试标准.</p>
<p><scope>test</scope> 的意思是,在import junit代码中引入是没有问题的,但是在主代码中引入就会编译错误.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.juvenxu.mvnbook.helloworld</span><br><span class="line"></span><br><span class="line">import static org.junit.Assert.assertEquals;</span><br><span class="line">import org.junit.Test;</span><br><span class="line"></span><br><span class="line">public class HelloWorldTest&#123;</span><br><span class="line"></span><br><span class="line">@Test</span><br><span class="line">public void testSayHello()&#123;</span><br><span class="line"></span><br><span class="line">  HelloWorld helloWorld &#x3D;new HelloWorld();</span><br><span class="line">  String result &#x3D; helloWorld.sayHello();</span><br><span class="line">  assertEquals(&quot;hello maven&quot;,result);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2.典型的单元测试分为三个步骤:准备测试类和数据;执行要测试的行为;检查结果;</p>
<p>3.执行mvn clean test命令.实际执行的命令包括:clean:clean / resources:resources /compiler:compile / resources:testResources /compiler:testCompile</p>
<p> 过程中出现surefire:test,它是maven中负责执行测试的插件,并输出测试报告.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~&#x2F;IdeaProjects&#x2F;hello-world$ mvn clean test</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ------------------&lt; com.juvenxu.mvnbook:hello-world &gt;-------------------</span><br><span class="line">[INFO] Building Maven Hello World Project 1.0-SNAPSHOT</span><br><span class="line">[INFO] --------------------------------[ jar ]---------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hello-world ---</span><br><span class="line">[INFO] Deleting &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hello-world ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] skip non existing resourceDirectory &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;src&#x2F;main&#x2F;resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hello-world ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!</span><br><span class="line">[INFO] Compiling 1 source file to &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;classes</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hello-world ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] skip non existing resourceDirectory &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;src&#x2F;test&#x2F;resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hello-world ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!</span><br><span class="line">[INFO] Compiling 1 source file to &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;test-classes</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ hello-world ---</span><br><span class="line">[INFO] Surefire report directory: &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;surefire-reports</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------</span><br><span class="line"> T E S T S</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">Running com.juvenxu.mvnbook.helloworld.HelloWorldTest</span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 sec</span><br><span class="line"></span><br><span class="line">Results :</span><br><span class="line"></span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0</span><br><span class="line"></span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 2.951 s</span><br><span class="line">[INFO] Finished at: 2018-06-09T15:37:21+08:00</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">zhuningning@ubuntu:~&#x2F;IdeaProjects&#x2F;hello-world$ </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="打包和运行"><a href="#打包和运行" class="headerlink" title="打包和运行"></a>打包和运行</h2><p>1.打包是下一个进行的步骤,由于pom中没有指定打包的类型,所以默认的打包类型时jar包.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~&#x2F;IdeaProjects&#x2F;hello-world$ mvn clean package </span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ------------------&lt; com.juvenxu.mvnbook:hello-world &gt;-------------------</span><br><span class="line">[INFO] Building Maven Hello World Project 1.0-SNAPSHOT</span><br><span class="line">[INFO] --------------------------------[ jar ]---------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hello-world ---</span><br><span class="line">[INFO] Deleting &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hello-world ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] skip non existing resourceDirectory &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;src&#x2F;main&#x2F;resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hello-world ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!</span><br><span class="line">[INFO] Compiling 1 source file to &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;classes</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hello-world ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] skip non existing resourceDirectory &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;src&#x2F;test&#x2F;resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hello-world ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!</span><br><span class="line">[INFO] Compiling 1 source file to &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;test-classes</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ hello-world ---</span><br><span class="line">[INFO] Surefire report directory: &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;surefire-reports</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------</span><br><span class="line"> T E S T S</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">Running com.juvenxu.mvnbook.helloworld.HelloWorldTest</span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.05 sec</span><br><span class="line"></span><br><span class="line">Results :</span><br><span class="line"></span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0</span><br><span class="line"></span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ hello-world ---</span><br><span class="line">[INFO] Building jar: &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;hello-world-1.0-SNAPSHOT.jar</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 3.030 s</span><br><span class="line">[INFO] Finished at: 2018-06-09T17:46:57+08:00</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.jar:jar 操作就是负责打包. 如何让其它的项目直接引用到这个jar包呢?</p>
<p>运行mvn clean install ,安装任务 install:install.将项目输出的jar安装到了maven本地仓库中.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~&#x2F;IdeaProjects&#x2F;hello-world$ mvn clean install</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ------------------&lt; com.juvenxu.mvnbook:hello-world &gt;-------------------</span><br><span class="line">[INFO] Building Maven Hello World Project 1.0-SNAPSHOT</span><br><span class="line">[INFO] --------------------------------[ jar ]---------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hello-world ---</span><br><span class="line">[INFO] Deleting &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hello-world ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] skip non existing resourceDirectory &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;src&#x2F;main&#x2F;resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hello-world ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!</span><br><span class="line">[INFO] Compiling 1 source file to &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;classes</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hello-world ---</span><br><span class="line">[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!</span><br><span class="line">[INFO] skip non existing resourceDirectory &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;src&#x2F;test&#x2F;resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hello-world ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!</span><br><span class="line">[INFO] Compiling 1 source file to &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;test-classes</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ hello-world ---</span><br><span class="line">[INFO] Surefire report directory: &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;surefire-reports</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------</span><br><span class="line"> T E S T S</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">Running com.juvenxu.mvnbook.helloworld.HelloWorldTest</span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.063 sec</span><br><span class="line"></span><br><span class="line">Results :</span><br><span class="line"></span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0</span><br><span class="line"></span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ hello-world ---</span><br><span class="line">[INFO] Building jar: &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;hello-world-1.0-SNAPSHOT.jar</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-install-plugin:2.4:install (default-install) @ hello-world ---</span><br><span class="line">[INFO] Installing &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target&#x2F;hello-world-1.0-SNAPSHOT.jar to &#x2F;home&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;com&#x2F;juvenxu&#x2F;mvnbook&#x2F;hello-world&#x2F;1.0-SNAPSHOT&#x2F;hello-world-1.0-SNAPSHOT.jar</span><br><span class="line">[INFO] Installing &#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world&#x2F;pom.xml to &#x2F;home&#x2F;zhuningning&#x2F;.m2&#x2F;repository&#x2F;com&#x2F;juvenxu&#x2F;mvnbook&#x2F;hello-world&#x2F;1.0-SNAPSHOT&#x2F;hello-world-1.0-SNAPSHOT.pom</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 2.913 s</span><br><span class="line">[INFO] Finished at: 2018-06-09T17:52:27+08:00</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>install命令执行完之后,本地仓库/.m2 中有项目的pom和jar</p>
<ol start="3">
<li>main方法的运行</li>
</ol>
<p>到目前为止还是没有运行Hello World项目的,但是helloWorld类是有main方法的.默认打包生成的jar包是不能够直接运行的.那是因为带有main方法的类信息是不会添加到mainfest中(打开jar文件中的META-INF/MANIFEST.MF文件,无法查看到Main-Class-mainifest),为了生成,需要借助maven-shade-plugin</p>
<p>配置插件如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">&lt;plugins&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">  &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;maven-shade-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.2.1&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;executions&gt;</span><br><span class="line">          &lt;execution&gt;</span><br><span class="line">            &lt;phase&gt;package&lt;&#x2F;phase&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">              &lt;goal&gt;shade&lt;&#x2F;goal&gt;</span><br><span class="line">            &lt;&#x2F;goals&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">              &lt;transformers&gt;</span><br><span class="line">                &lt;transformer implementation&#x3D;&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;</span><br><span class="line">                  &lt;mainClass&gt;com.juvenxu.mvnbook.helloworld.HelloWorld&lt;&#x2F;mainClass&gt;</span><br><span class="line">                &lt;&#x2F;transformer&gt;</span><br><span class="line">              &lt;&#x2F;transformers&gt;</span><br><span class="line">            &lt;&#x2F;configuration&gt;</span><br><span class="line">          &lt;&#x2F;execution&gt;</span><br><span class="line">        &lt;&#x2F;executions&gt;</span><br><span class="line">      &lt;&#x2F;plugin&gt;</span><br><span class="line">&lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;build&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>然后再次运行mvn clean install</p>
<p>在target目录下有jar包,然后执行 java -jar</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target$ java -jar hello-world-1.0-SNAPSHOT.jar </span><br><span class="line">hello maven</span><br><span class="line">zhuningning@ubuntu:~&#x2F;IdeaProjects&#x2F;hello-world&#x2F;target$ </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="使用Archetype生成项目骨架"><a href="#使用Archetype生成项目骨架" class="headerlink" title="使用Archetype生成项目骨架"></a>使用Archetype生成项目骨架</h2><p>项目的默认约定：在项目的根目录中防止pom.xml 在/src/main/java中放置项目的主代码，在/src/test/java中放置项目的测试代码。</p>
<p>执行以下命令后需要输入groupId、artifactId、version、packaging。创建默认结构的maven项目。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:~&#x2F;IdeaProjects&#x2F;test$ mvn archetype:generate</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ------------------&lt; org.apache.maven:standalone-pom &gt;-------------------</span><br><span class="line">[INFO] Building Maven Stub Project (No POM) 1</span><br><span class="line">[INFO] --------------------------------[ pom ]---------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] &gt;&gt;&gt; maven-archetype-plugin:3.0.1:generate (default-cli) &gt; generate-sources @ standalone-pom &gt;&gt;&gt;</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] &lt;&lt;&lt; maven-archetype-plugin:3.0.1:generate (default-cli) &lt; generate-sources @ standalone-pom &lt;&lt;&lt;</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-archetype-plugin:3.0.1:generate (default-cli) @ standalone-pom ---</span><br><span class="line">[INFO] Generating project in Interactive mode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h2 id="maven坐标"><a href="#maven坐标" class="headerlink" title="maven坐标"></a>maven坐标</h2><p>如下是引入spring的context包。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-context&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;4.3.5.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>groupId：定义当前maven项目隶属的实际项目，groupId不应该对应项目隶属的公司或者组织，因为一个公司有可能有多个项目。</p>
<p>artifactId： 该元素定义实际项目中的一个maven项目（模块），推荐的是使用实际项目名称作为artifactId的前缀。</p>
<p>version:项目的版本，</p>
<p>packaging：该元素定义的maven项目的打包方式。默认为jar</p>
<h1 id="依赖的配置"><a href="#依赖的配置" class="headerlink" title="依赖的配置"></a>依赖的配置</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-context&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;4.3.5.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;type&gt;jar&lt;&#x2F;type&gt;</span><br><span class="line">    &lt;scope&gt;runtime&lt;&#x2F;scope&gt;</span><br><span class="line">    &lt;optional&gt;false&lt;&#x2F;optional&gt;</span><br><span class="line">    &lt;exclusions&gt;</span><br><span class="line">        &lt;exclusion&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-core&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;&#x2F;exclusion&gt;</span><br><span class="line">    &lt;&#x2F;exclusions&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="依赖范围。"><a href="#依赖范围。" class="headerlink" title="依赖范围。"></a>依赖范围。</h2><p>依赖范围就是用来控制依赖与三种classpath（编译classpath、测试classpath、运行classpath）的关系</p>
<p>scope范围包括：</p>
<ol>
<li><p>compile 编译依赖范围，默认的。对于编译、测试、运行三种classpath都有用。</p>
</li>
<li><p>test 测试有效。在编译和运行主代码时无效。如 junit</p>
</li>
<li><p>provided 编译和测试的时候有效，运行的时候无效。如 servlet-api</p>
</li>
<li><p>runtime 对于测试和运行有效，对编译主代码无效。</p>
</li>
<li><p>system 系统依赖范围，和compile一致，但是必须通过systemPath元素显式的指定依赖文件的路径。</p>
</li>
<li><p>import dependencyManagement中才可以使用import，表示从其它的pom文件中导入依赖设置。</p>
</li>
</ol>
<h2 id="传递性依赖"><a href="#传递性依赖" class="headerlink" title="传递性依赖"></a>传递性依赖</h2><p>如A项目依赖 spring-core包，而spring-core包依赖一个common-logging包，common-logging包就是A项目的传递依赖。</p>
<p>假设A依赖于B，B依赖于C，我们说A对于B是第一直接依赖，B对于C是第二直接依赖，A对于C是传递性依赖。</p>
<h2 id="依赖调解"><a href="#依赖调解" class="headerlink" title="依赖调解"></a>依赖调解</h2><p>maven引入的传递性依赖机制。一方面大大简化和方便了依赖声明；另一方面，大部分情况我们只需要关心项目的直接依赖，而不用考虑直接依赖会引入什么传递性依赖。</p>
<p>例子： 项目A有这样的依赖关系：A-&gt;B-&gt;C-&gt;X(1.0),A-&gt;D-&gt;X(2.0),X是传递性依赖，但是有2个版本，要选择一个去依赖。<strong>调解的第一原则：路径最近者优先，会选择2.0；当路径相同的情况下，第二原则：第一声明者优先。</strong></p>
<h2 id="可选依赖"><a href="#可选依赖" class="headerlink" title="可选依赖"></a>可选依赖</h2><p>项目B实现了2个特性，其中一个特性依赖于X，另一个依赖于Y，而且这两个特性是互斥的。用户不可能同时使用两个特性。比如支持多种数据库，在构建的时候需要两种数据库的驱动程序，但在使用这个工具包的时候指挥依赖一种数据库。</p>
<p><optional> true </optional></p>
<h2 id="项目依赖实践技巧"><a href="#项目依赖实践技巧" class="headerlink" title="项目依赖实践技巧"></a>项目依赖实践技巧</h2><p>1.排除依赖</p>
<p>exclusions 排除依赖。声明exclusion的时候，只需要groupId和artifactId。不需要version</p>
<p>2.依赖归类</p>
<p><properties> 声明一个属性子元素，多个版本相同的项目的依赖使用同一个版本。</p>
<p>3.优化依赖</p>
<p>①查看当前项目的已解析依赖  mvn:dependency:list</p>
<p>②查看当前项目的依赖树  mvn:dependency:tree</p>
<p>③查看使用未声明的依赖和声明未使用的依赖： mvn dependency:analyze 。used undeclared dependencies 和Unused declared undeclared.由于该命令只会分析编译主代码和测试主代码需要的依赖，一些执行测试和运行时需要的依赖发现不了。所以不要随便根据此提示来删除一些声明未使用的依赖。</p>
<h1 id="仓库"><a href="#仓库" class="headerlink" title="仓库"></a>仓库</h1><h2 id="仓库分类"><a href="#仓库分类" class="headerlink" title="仓库分类"></a>仓库分类</h2><p>maven仓库是为共享依赖的jar包而创建的，分为本地仓库和远程仓库。</p>
<p>当maven寻找组件的时候，首先从本地仓库查找，如果本地没有或者需要更新的时候从远程仓库下载到本地仓库。</p>
<p>两个特殊的远程仓库 1.中央仓库：maven核心自带的仓库； 2.私服：特殊的局域网假设的仓库；</p>
<h2 id="本地仓库"><a href="#本地仓库" class="headerlink" title="本地仓库"></a>本地仓库</h2><p>.m2/repository/的仓库目录。可以在maven的settings配置中设置本地仓库的位置。</p>
<p>一个构件只有在本地仓库中之后，才能由其它maven项目使用，那么构件如何进入本地仓库呢？最常见的是从远程下载到本地，还有一种是将本地的项目的构件安装到maven仓库中。</p>
<p>mvn clean install命令就是，执行install插件的install的目标项目的构建输出文件安装到本地仓库。</p>
<h2 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h2><h2 id="中央仓库"><a href="#中央仓库" class="headerlink" title="中央仓库"></a>中央仓库</h2><p>默认的maven仓库是中央仓库，在maven的lib/maven-model-builder-3.0.jar，然后访问路径org/apache/maven/model/pom-4.0.0.xml可以看到</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&lt;repositories&gt;     </span><br><span class="line">  &lt;repository&gt;     </span><br><span class="line">    &lt;id&gt; central&lt;&#x2F;id&gt;     </span><br><span class="line">    &lt;name&gt; Maven Repository Switchboard&lt;&#x2F;name&gt;     </span><br><span class="line">    &lt;layout&gt; default&lt;&#x2F;layout&gt;     </span><br><span class="line">    &lt;url&gt; http:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&lt;&#x2F;url&gt;     </span><br><span class="line">    &lt;snapshots&gt;     </span><br><span class="line">      &lt;enabled&gt; false&lt;&#x2F;enabled&gt;     </span><br><span class="line">    &lt;&#x2F;snapshots&gt;     </span><br><span class="line">  &lt;&#x2F;repository&gt;     </span><br><span class="line">&lt;&#x2F;repositories&gt;    </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这是所有maven项目都会继承的超级pom。</p>
<h2 id="私服"><a href="#私服" class="headerlink" title="私服"></a>私服</h2><p>私服是一种特殊的远程仓库，它时架设在局域网内的仓库服务。当maven需要下载构件的时候，先从私服请求，如果私服上不存在该构件，则从外部的远程仓库下载，缓存在私服上之后，再为maven的下载请求提供服务。</p>
<p>优点：</p>
<ol>
<li>节省自己的外网带宽；</li>
<li>加速maven构建；</li>
<li>部署第三方构件；</li>
<li>提高稳定性，增强控制；</li>
<li>降低中央仓库的负荷；</li>
</ol>
<h2 id="远程仓库的配置"><a href="#远程仓库的配置" class="headerlink" title="远程仓库的配置"></a>远程仓库的配置</h2><h3 id="在pom中配置远程仓库"><a href="#在pom中配置远程仓库" class="headerlink" title="在pom中配置远程仓库"></a>在pom中配置远程仓库</h3><p>在pom中添加repositories/repository 两个节点，可以配置多个远程仓库。其中id是唯一的，中央仓库的id时central。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;repositories&gt;  </span><br><span class="line">   &lt;repository&gt;  </span><br><span class="line">     &lt;id&gt;jboss&lt;&#x2F;id&gt;  </span><br><span class="line">     &lt;name&gt;JBoss Repository&lt;&#x2F;name&gt;  </span><br><span class="line">     &lt;url&gt;http:&#x2F;&#x2F;repository.jboss.com&#x2F;maven2&#x2F;&lt;&#x2F;url&gt;  </span><br><span class="line">     &lt;releases&gt;  </span><br><span class="line">       &lt;enabled&gt;true&lt;&#x2F;enabled&gt;  </span><br><span class="line">     &lt;&#x2F;releases&gt;  </span><br><span class="line">   &lt;&#x2F;repository&gt;  </span><br><span class="line">   &lt;snapshots&gt;  </span><br><span class="line">     &lt;enabled&gt;false&lt;&#x2F;enabled&gt;  </span><br><span class="line">   &lt;&#x2F;snapshots&gt;  </span><br><span class="line">   &lt;layout&gt;default&lt;&#x2F;layout&gt;  </span><br><span class="line"> &lt;&#x2F;repositories&gt;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中关键的两个节点releases 表示发布版本的下载为true，snapshots表示快照版本的下载为false。</p>
<p>snapshots比较重要的节点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;snapshots&gt;  </span><br><span class="line">  &lt;enabled&gt;true&lt;&#x2F;enabled&gt;  </span><br><span class="line">  &lt;updatePolicy&gt;daily&lt;&#x2F;updatePolicy&gt;  </span><br><span class="line">  &lt;checksumPolicy&gt;ignore&lt;&#x2F;checksumPolicy&gt;  </span><br><span class="line">&lt;&#x2F;snapshots&gt;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>updatePolicy daily，表示Maven每天检查一次。其他可用的值包括：never—从不检查更新；always—每次构建都检查更新；interval:X—每隔X分钟检查一次更新(X为任意整数)</p>
<p>checksumPolicy节点表示检查更新的频率和下载失败时的处理策略。</p>
<p>值为默认的warn时，Maven会在执行构建时输出警告信息，其他可用的值包括：fail—Maven遇到校验和错误就让构建失败；ignore—使用Maven完全忽略校验和错误。</p>
<h3 id="在setting-xml中配置远程仓库"><a href="#在setting-xml中配置远程仓库" class="headerlink" title="在setting.xml中配置远程仓库"></a>在setting.xml中配置远程仓库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.需要在profiles标签中添加远程仓库配置</span><br><span class="line"></span><br><span class="line">&lt;profile&gt;  </span><br><span class="line">        &lt;id&gt;myProfiel&lt;&#x2F;id&gt;    </span><br><span class="line">    &lt;repositories&gt;    </span><br><span class="line">        &lt;repository&gt;    </span><br><span class="line">            &lt;id&gt;me&lt;&#x2F;id&gt;    </span><br><span class="line">            &lt;name&gt;me Repository&lt;&#x2F;name&gt;    </span><br><span class="line">            &lt;url&gt;http:&#x2F;&#x2F;192.168.106.58:57770&#x2F;nexus&#x2F;&lt;&#x2F;url&gt;    </span><br><span class="line">            &lt;releases&gt;    </span><br><span class="line">                &lt;updatePolicy&gt;daily&lt;&#x2F;updatePolicy&gt;never,always,interval n    </span><br><span class="line">                &lt;enabled&gt;true&lt;&#x2F;enabled&gt;    </span><br><span class="line">                &lt;checksumPolicy&gt;warn&lt;&#x2F;checksumPolicy&gt;fail,ignore    </span><br><span class="line">            &lt;&#x2F;releases&gt;    </span><br><span class="line">            &lt;snapshots&gt;    </span><br><span class="line">                &lt;enabled&gt;false&lt;&#x2F;enabled&gt;    </span><br><span class="line">            &lt;&#x2F;snapshots&gt;    </span><br><span class="line">            &lt;layout&gt;default&lt;&#x2F;layout&gt;    </span><br><span class="line">        &lt;&#x2F;repository&gt;    </span><br><span class="line">    &lt;&#x2F;repositories&gt;    </span><br><span class="line">&lt;&#x2F;profile&gt;  </span><br><span class="line"></span><br><span class="line">2.在settings标签中添加activeProfiles标签，用于激活配置的profile标签</span><br><span class="line"></span><br><span class="line">&lt;activeProfiles&gt;       </span><br><span class="line">    &lt;activeProfile&gt;myProfiel&lt;&#x2F;activeProfile&gt;       </span><br><span class="line">&lt;&#x2F;activeProfiles&gt; </span><br><span class="line"> </span><br></pre></td></tr></table></figure>



<h3 id="远程仓库的认证"><a href="#远程仓库的认证" class="headerlink" title="远程仓库的认证"></a>远程仓库的认证</h3><p>大部分仓库时无需认证的，但是有的时需要的。这个是必须在settings.xml中配置。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;settings&gt;  </span><br><span class="line">  ...  </span><br><span class="line">  &lt;servers&gt;  </span><br><span class="line">    &lt;server&gt;  </span><br><span class="line">      &lt;id&gt;my-proj&lt;&#x2F;id&gt;  </span><br><span class="line">      &lt;username&gt;repo-user&lt;&#x2F;username&gt;  </span><br><span class="line">      &lt;password&gt;repo-pwd&lt;&#x2F;password&gt;  </span><br><span class="line">    &lt;&#x2F;server&gt;  </span><br><span class="line">  &lt;&#x2F;servers&gt;  </span><br><span class="line">  ...  </span><br><span class="line">&lt;&#x2F;settings&gt;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="部署至远程仓库"><a href="#部署至远程仓库" class="headerlink" title="部署至远程仓库"></a>部署至远程仓库</h3><p>私服的一大作用是部署第三方构件，包括组织内部生成的构件以及一些无法从外部仓库直接获取的构件。无论是日常开发中生成的构件，还是正式版本发布的构件，都需要部署到仓库中，供其他团队成员使用。</p>
<p>Maven除了能对项目进行编译、测试、打包之外，还能将项目生成的构建部署到仓库中。首先，需要编辑项目的pom.xml文件。配置distributionManagement元素</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;project&gt;  </span><br><span class="line">  ...  </span><br><span class="line">  &lt;destributionManagement&gt;  </span><br><span class="line">    &lt;repository&gt;  </span><br><span class="line">      &lt;id&gt;proj-releases&lt;&#x2F;id&gt;  </span><br><span class="line">      &lt;name&gt;Proj Release Repository&lt;&#x2F;name&gt;  </span><br><span class="line">      &lt;url&gt;http:&#x2F;&#x2F;192.168.1.100&#x2F;content&#x2F;repositories&#x2F;proj-releases&lt;&#x2F;url&gt;  </span><br><span class="line">    &lt;&#x2F;repository&gt;  </span><br><span class="line">    &lt;snapshotRepository&gt;  </span><br><span class="line">      &lt;id&gt;proj-snapshots&lt;&#x2F;id&gt;  </span><br><span class="line">      &lt;name&gt;Proj Snapshot Repository&lt;&#x2F;name&gt;  </span><br><span class="line">      &lt;url&gt;http:&#x2F;&#x2F;192.168.1.100&#x2F;content&#x2F;repositories&#x2F;proj-snapshots&lt;&#x2F;url&gt;  </span><br><span class="line">    &lt;&#x2F;snapshotRepository&gt;  </span><br><span class="line">  &lt;&#x2F;destributionManagement&gt;  </span><br><span class="line">  ...  </span><br><span class="line">&lt;&#x2F;project&gt; </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>distributionManagement包含repository和snapshotRepository子元素，前者表示发布版本构件的仓库，后者表示快照版本的仓库。这两个元素下都需要配置id、name和url，id为该远程仓库的唯一标识，name是为了方便人阅读，关键的url表示该仓库的地址。</p>
<p>一般都需要认证。配置正确后，在命令行运行mvn clean deploy，Maven就会将项目构建输出的构件部署到配置对应的远程仓库。</p>
<h2 id="快照版本"><a href="#快照版本" class="headerlink" title="快照版本"></a>快照版本</h2><p>快照版本时为了解决A依赖B模块，B模块一直在不停的更新的情况。</p>
<p>在开发过程中只需将B模块改为2.1-SNAPSHOT，然后发布到私服中，在发布的过程中，maven会自动为构件打时间戳，比如2.1-2009-1214.221414-13表示这个时间点的第13次构建。有了时间戳maven就能随时找到仓库中该构件的最新的文件，这个更新策略是在之前的私服配置中已经介绍，或者使用mvn clean install-U。如果已经稳定，则将2.1-SNAPSHOT改为2.1 .</p>
<p>组织内部的模块或者项目的依赖,由于具有完全的理解和控制权可以使用快照版本，外部依赖如果使用快照版本则会存在潜在的危险。</p>
<h2 id="仓库解析依赖的机制"><a href="#仓库解析依赖的机制" class="headerlink" title="仓库解析依赖的机制"></a>仓库解析依赖的机制</h2><p>当本地仓库没有依赖构件的时候，maven会自动从远程仓库下载；当依赖版本为快照版本的时候maven会自动找到最新的快照。这背后的依赖解析机制可以概括如下:</p>
<p>1.当依赖的范围是system的时候maven直接从本地文件系统解析构件。</p>
<p>2.根据依赖坐标计算仓库路径后，尝试直接从本地仓库寻找构件，如果发现相应构件则解析成功。</p>
<p>3.在本地仓库不存在相应构件的情况下，如果依赖的版本显示的发布版本构件，如1.2,2.1-beta-1等，则遍历所有的远程仓库，发现后下载并解析使用。</p>
<p>4.如果依赖的版本是RELEASE或者LATEST，则基于更新策略读取所有远程仓库的元数据groupId/artifactId/maven-metadata.xml,将其与本地仓库对应元数据合并后计算出RELEASE或者LATEST真实的值，然后基于这个真实的值检查本地和远程仓库如步骤2和3。</p>
<p>5.如果依赖的版本是SNAPSHOT，则基于更新策略读取所有远程仓库的元数据groupId/artifactId/version/maven-metadata.xml，将其与本地仓库对应元数据合并后得到最新快照版本的值，然后基于该值检查本地仓库或者从远程仓库下载。</p>
<p>6.如果最后解析得到的构件版本时间是时间戳格式的快照，如1.4.1-20091104.121450-121，则复制其时间戳格式的文件至非时间戳格式，如SNAPSHOT，并使用该非时间戳格式的构件。</p>
<h2 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h2><p>如果仓库X可以提供仓库Y存储的所有内容，那么就可以认为X是Y的一个镜像</p>
<p>settings.xml 中配置镜像，以下是中央仓库在中国的一个镜像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;settings&gt;  </span><br><span class="line">  ...  </span><br><span class="line">  &lt;mirrors&gt;  </span><br><span class="line">    &lt;mirror&gt;  </span><br><span class="line">      &lt;id&gt;maven.net.cn&lt;&#x2F;id&gt;  </span><br><span class="line">      &lt;name&gt;one of the central mirrors in china&lt;&#x2F;name&gt;  </span><br><span class="line">      &lt;url&gt;http:&#x2F;&#x2F;maven.net.cn&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt;  </span><br><span class="line">      &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;  </span><br><span class="line">    &lt;&#x2F;mirror&gt;  </span><br><span class="line">  &lt;&#x2F;mirrors&gt;  </span><br><span class="line">  ...  </span><br><span class="line">&lt;&#x2F;settings&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中一般私服和镜像一起使用。</p>
<h2 id="仓库搜索服务"><a href="#仓库搜索服务" class="headerlink" title="仓库搜索服务"></a>仓库搜索服务</h2><p>一般使用仓库搜索服务来根据关键字得到maven坐标。</p>
<p>主流的仓库搜索服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. sonatype</span><br><span class="line">https:&#x2F;&#x2F;repository.sonatype.org</span><br><span class="line"></span><br><span class="line">2. MVN Browser</span><br><span class="line">http:&#x2F;&#x2F;www.mvnbrowser.com</span><br><span class="line"></span><br><span class="line">3. MVNrepository</span><br><span class="line">http:&#x2F;&#x2F;mvnrepository.com&#x2F;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="生命周期和插件"><a href="#生命周期和插件" class="headerlink" title="生命周期和插件"></a>生命周期和插件</h1><p>maven的生命周期是抽象的，其实际行为都是由插件来完成，如package阶段的任务就会由maven-jar-plugin完成。生命周期和插件两者协同工作，密不可分。</p>
<h2 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h2><p>maven的生命周期就是为了对所有的构建进行抽象和统一。总结了一套包含项目<strong>清理、初始化、编译、测试、打包、集成测试、验证、部署和站点生成等</strong>几乎所有的构建步骤。</p>
<p>maven的生命周期时抽象的，生命周期本身不做工作，主要由插件来完成。类似于设计模式中的模板方法。</p>
<p>maven在生命周期的各个阶段绑定了一个或者多个插件，而且maven为生命周期绑定了默认的插件。</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>maven定义生命周期和插件机制一方面保证了所有maven项目有一致的构建标准，另一方面又通过默认插件简化和稳定了实际项目的构建。</p>
<h2 id="生命周期详解"><a href="#生命周期详解" class="headerlink" title="生命周期详解"></a>生命周期详解</h2><p>maven有三套相互独立的生命周期，他们分别为clean default site。clean生命周期主要是清理项目，default生命周期主要是构建项目，site生命周期主要时建立项目站点。</p>
<h3 id="clean生命周期：清理项目，包含三个phase。"><a href="#clean生命周期：清理项目，包含三个phase。" class="headerlink" title="clean生命周期：清理项目，包含三个phase。"></a>clean生命周期：清理项目，包含三个phase。</h3><p>1）pre-clean：执行清理前需要完成的工作</p>
<p>2）clean：清理上一次构建生成的文件</p>
<p>3）post-clean：执行清理后需要完成的工作</p>
<h3 id="default生命周期：构建项目，重要的phase如下。"><a href="#default生命周期：构建项目，重要的phase如下。" class="headerlink" title="default生命周期：构建项目，重要的phase如下。"></a>default生命周期：构建项目，重要的phase如下。</h3><p>1）validate：验证工程是否正确，所有需要的资源是否可用。</p>
<p>2）initialize 初始化操作</p>
<p>2）compile：编译项目的源代码。  </p>
<p>3）test：使用合适的单元测试框架来测试已编译的源代码。这些测试不需要已打包和布署。</p>
<p>4）Package：把已编译的代码打包成可发布的格式，比如jar。</p>
<p>5）integration-test：如有需要，将包处理和发布到一个能够进行集成测试的环境。</p>
<p>6）verify：运行所有检查，验证包是否有效且达到质量标准。</p>
<p>7）install：把包安装到maven本地仓库，可以被其他工程作为依赖来使用。</p>
<p>8）Deploy：在集成或者发布环境下执行，将最终版本的包拷贝到远程的repository，使得其他的开发者或者工程可以共享。</p>
<h3 id="site生命周期：建立和发布项目站点，phase如下"><a href="#site生命周期：建立和发布项目站点，phase如下" class="headerlink" title="site生命周期：建立和发布项目站点，phase如下"></a>site生命周期：建立和发布项目站点，phase如下</h3><p>1）pre-site：生成项目站点之前需要完成的工作</p>
<p>2）site：生成项目站点文档</p>
<p>3）post-site：生成项目站点之后需要完成的工作</p>
<p>4）site-deploy：将项目站点发布到服务器</p>
<h3 id="命令行与生命周期"><a href="#命令行与生命周期" class="headerlink" title="命令行与生命周期"></a>命令行与生命周期</h3><p>1.mvn clean 执行clean生命周期的clean阶段，包括pre-clean、clean</p>
<p>2.mvn test 执行default生命周期之前的所有阶段，包括validate initialize compile test</p>
<p>3.mvn clean install 执行包括clean和default生命周期从validate到install的所有阶段</p>
<p>4.mvn clean deploy site-deploy ,执行包括clean 和default所有阶段以及site周期的所有阶段</p>
<h2 id="插件目标"><a href="#插件目标" class="headerlink" title="插件目标"></a>插件目标</h2><p>一个maven插件maven-dependency-plugin可以做很多事情，包括分析项目依赖，列出依赖树，列出所有已经解析的依赖等等。这些功能聚集在一个插件里，每个功能就是一个目标。</p>
<p>maven-dependency-plugin有10多个插件目标如：dependency：analyze；dependency：tree；dependency：list等。冒号前是插件前缀，冒号后面是插件的目标。</p>
<h2 id="插件绑定"><a href="#插件绑定" class="headerlink" title="插件绑定"></a>插件绑定</h2><p>生命周期的阶段与插件的目标项目绑定，以完成某个具体的构建任务。如项目编译这一任务，它对应了default生命周期的compile这一阶段，而maven-compile-plugin这一插件的compile目标能够完成。</p>
<h3 id="内置绑定"><a href="#内置绑定" class="headerlink" title="内置绑定"></a>内置绑定</h3><p><img src="/images/maven/default%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%9A%84%E5%86%85%E7%BD%AE%E6%8F%92%E4%BB%B6%E7%BB%91%E5%AE%9A%E5%85%B3%E7%B3%BB%E5%92%8C%E5%85%B7%E4%BD%93%E4%BB%BB%E5%8A%A1.png" alt="default生命周期的内置插件绑定关系和具体任务"></p>
<h3 id="自定义绑定"><a href="#自定义绑定" class="headerlink" title="自定义绑定"></a>自定义绑定</h3><p>除了内置绑定以外，用户还能够自己选择将某个插件目标绑定到生命周期的某个阶段。自定义绑定允许我们自己掌控插件目标与生命周期的结合</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-source-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;2.1.1&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;executions&gt;</span><br><span class="line">                &lt;execution&gt;</span><br><span class="line">                    &lt;id&gt;attach-sources&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;phase&gt;verify&lt;&#x2F;phase&gt;</span><br><span class="line">                    &lt;goals&gt;</span><br><span class="line">                        &lt;goal&gt;jar-no-fork&lt;&#x2F;goal&gt;</span><br><span class="line">                    &lt;&#x2F;goals&gt;</span><br><span class="line">                &lt;&#x2F;execution&gt;</span><br><span class="line">            &lt;&#x2F;executions&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">    &lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;build&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上述配置有插件的坐标声明、还有excutions下面每个excution子元素配置的执行的一个个任务、通过phase指定与生命周期的那个阶段绑定、在通过goals指定执行绑定插件的哪些目标。</p>
<p>输出对应插件的详细信息：</p>
<h3 id="使用maven-help-plugin获取插件描述"><a href="#使用maven-help-plugin获取插件描述" class="headerlink" title="使用maven-help-plugin获取插件描述"></a>使用maven-help-plugin获取插件描述</h3><p>以下为显示目标插件的描述命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn help:describe -Dplugin&#x3D;org.apache.maven.plugins:maven-source-plugin -Dgoal&#x3D;jar-no-fork -Ddetail&#x3D;true</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以使用插件目标前缀来替换坐标:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn help:describe -Dplugin &#x3D; compiler</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>如果仅仅是需要描述某个插件的目标信息，则需要加上goal目标 更详细的信息添加-Ddeta</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn help:describe -Dplugin &#x3D; compiler -Dgoal &#x3D; compile</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="插件配置"><a href="#插件配置" class="headerlink" title="插件配置"></a>插件配置</h3><h4 id="从命令行调用插件"><a href="#从命令行调用插件" class="headerlink" title="从命令行调用插件"></a>从命令行调用插件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@ubuntu:&#x2F;home&#x2F;zhuningning&#x2F;IdeaProjects&#x2F;hello-world# mvn -h</span><br><span class="line">usage: mvn [options] [&lt;goal(s)&gt;] [&lt;phase(s)&gt;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我们可以从命令行激活生命周期阶段如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn clean</span><br></pre></td></tr></table></figure>

<p>还可以支持从命令行调用插件目标如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn dependency:tree(插件前缀：插件目标)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="Maven变量及常见插件配置详解"><a href="#Maven变量及常见插件配置详解" class="headerlink" title="Maven变量及常见插件配置详解"></a>Maven变量及常见插件配置详解</h3><p>1.自定义变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;properties&gt;  </span><br><span class="line">    &lt;project.build.name&gt;tools&lt;&#x2F;project.build.name&gt;  </span><br><span class="line">    &lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt;  </span><br><span class="line">&lt;&#x2F;properties&gt;  </span><br></pre></td></tr></table></figure>
<p>2.内置变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$&#123;basedir&#125; 项目根目录</span><br><span class="line">$&#123;project.build.directory&#125; 构建目录，缺省为target</span><br><span class="line">$&#123;project.build.outputDirectory&#125; 构建过程输出目录，缺省为target&#x2F;classes</span><br><span class="line">$&#123;project.build.finalName&#125; 产出物名称，缺省为$&#123;project.artifactId&#125;-$&#123;project.version&#125;</span><br><span class="line">$&#123;project.packaging&#125; 打包类型，缺省为jar</span><br><span class="line">$&#123;project.xxx&#125; 当前pom文件的任意节点的内容</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>3.编译插件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;plugin&gt;  </span><br><span class="line">   &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;  </span><br><span class="line">   &lt;artifactId&gt;maven-compiler-plugin&lt;&#x2F;artifactId&gt;  </span><br><span class="line">   &lt;configuration&gt;  </span><br><span class="line">       &lt;source&gt;1.6&lt;&#x2F;source&gt;  </span><br><span class="line">       &lt;target&gt;1.6&lt;&#x2F;target&gt;  </span><br><span class="line">       &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;&#x2F;encoding&gt;  </span><br><span class="line">   &lt;&#x2F;configuration&gt;  </span><br><span class="line">&lt;&#x2F;plugin&gt;</span><br><span class="line"></span><br><span class="line">   source： 源代码编译版本；  </span><br><span class="line">   target： 目标平台编译版本；  </span><br><span class="line">   encoding： 字符集编码</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>4.设置资源文件的编码方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&lt;plugin&gt;  </span><br><span class="line">  &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;  </span><br><span class="line">  &lt;artifactId&gt;maven-resources-plugin&lt;&#x2F;artifactId&gt;  </span><br><span class="line">  &lt;version&gt;2.4.3&lt;&#x2F;version&gt;  </span><br><span class="line">  &lt;executions&gt;  </span><br><span class="line">      &lt;execution&gt;  </span><br><span class="line">          &lt;phase&gt;compile&lt;&#x2F;phase&gt;  </span><br><span class="line">      &lt;&#x2F;execution&gt;  </span><br><span class="line">  &lt;&#x2F;executions&gt;  </span><br><span class="line">  &lt;configuration&gt;  </span><br><span class="line">      &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;&#x2F;encoding&gt;  </span><br><span class="line">  &lt;&#x2F;configuration&gt;  </span><br><span class="line">&lt;&#x2F;plugin&gt; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>5.自动拷贝jar包到target目录 <a href="http://liugang594.iteye.com/blog/2093082">参考</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&lt;plugin&gt;  </span><br><span class="line">  &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;  </span><br><span class="line">  &lt;artifactId&gt;maven-dependency-plugin&lt;&#x2F;artifactId&gt;  </span><br><span class="line">  &lt;version&gt;2.6&lt;&#x2F;version&gt;  </span><br><span class="line">  &lt;executions&gt;  </span><br><span class="line">      &lt;execution&gt;  </span><br><span class="line">          &lt;id&gt;copy-dependencies&lt;&#x2F;id&gt;  </span><br><span class="line">          &lt;phase&gt;compile&lt;&#x2F;phase&gt;  </span><br><span class="line">          &lt;goals&gt;  </span><br><span class="line">              &lt;goal&gt;copy-dependencies&lt;&#x2F;goal&gt;  </span><br><span class="line">          &lt;&#x2F;goals&gt;  </span><br><span class="line">          &lt;configuration&gt;  </span><br><span class="line">              &lt;!-- $&#123;project.build.directory&#125;为Maven内置变量，缺省为target --&gt;  </span><br><span class="line">              &lt;outputDirectory&gt;$&#123;project.build.directory&#125;&#x2F;lib&lt;&#x2F;outputDirectory&gt;  </span><br><span class="line">              &lt;!-- 表示是否不包含间接依赖的包 --&gt;  </span><br><span class="line">              &lt;excludeTransitive&gt;false&lt;&#x2F;excludeTransitive&gt;  </span><br><span class="line">              &lt;!-- 表示复制的jar文件去掉版本信息 --&gt;  </span><br><span class="line">              &lt;stripVersion&gt;true&lt;&#x2F;stripVersion&gt;  </span><br><span class="line">          &lt;&#x2F;configuration&gt;  </span><br><span class="line">      &lt;&#x2F;execution&gt;  </span><br><span class="line">  &lt;&#x2F;executions&gt;  </span><br><span class="line">&lt;&#x2F;plugin&gt;  </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>6.生成源代码jar包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&lt;plugin&gt;  </span><br><span class="line">  &lt;artifactId&gt;maven-source-plugin&lt;&#x2F;artifactId&gt;  </span><br><span class="line">  &lt;version&gt;2.1&lt;&#x2F;version&gt;  </span><br><span class="line">  &lt;configuration&gt;  </span><br><span class="line">      &lt;!-- &lt;finalName&gt;$&#123;project.build.name&#125;&lt;&#x2F;finalName&gt; --&gt;  </span><br><span class="line">      &lt;attach&gt;true&lt;&#x2F;attach&gt;  </span><br><span class="line">      &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;&#x2F;encoding&gt;  </span><br><span class="line">  &lt;&#x2F;configuration&gt;  </span><br><span class="line">  &lt;executions&gt;  </span><br><span class="line">      &lt;execution&gt;  </span><br><span class="line">          &lt;phase&gt;compile&lt;&#x2F;phase&gt;  </span><br><span class="line">          &lt;goals&gt;  </span><br><span class="line">              &lt;goal&gt;jar&lt;&#x2F;goal&gt;  </span><br><span class="line">          &lt;&#x2F;goals&gt;  </span><br><span class="line">      &lt;&#x2F;execution&gt;  </span><br><span class="line">  &lt;&#x2F;executions&gt;  </span><br><span class="line">&lt;&#x2F;plugin&gt;</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>将项目打成jar包</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&lt;plugin&gt;  </span><br><span class="line">  &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;  </span><br><span class="line">  &lt;artifactId&gt;maven-jar-plugin&lt;&#x2F;artifactId&gt;  </span><br><span class="line">  &lt;version&gt;2.4&lt;&#x2F;version&gt;  </span><br><span class="line">  &lt;configuration&gt;  </span><br><span class="line">      &lt;archive&gt;  </span><br><span class="line">          &lt;manifest&gt;  </span><br><span class="line">              &lt;!-- 告知 maven-jar-plugin添加一个 Class-Path元素到 MANIFEST.MF文件，以及在Class-Path元素中包括所有依赖项 --&gt;  </span><br><span class="line">              &lt;addClasspath&gt;true&lt;&#x2F;addClasspath&gt;  </span><br><span class="line">              &lt;!-- 所有的依赖项应该位于 lib文件夹 --&gt;  </span><br><span class="line">              &lt;classpathPrefix&gt;lib&#x2F;&lt;&#x2F;classpathPrefix&gt;  </span><br><span class="line">              &lt;!-- 当用户使用 lib命令执行JAR文件时，使用该元素定义将要执行的类名 --&gt;  </span><br><span class="line">              &lt;mainClass&gt;com.zhengtian.tools.service.phone.MobilePhoneTool&lt;&#x2F;mainClass&gt;  </span><br><span class="line">          &lt;&#x2F;manifest&gt;  </span><br><span class="line">      &lt;&#x2F;archive&gt;  </span><br><span class="line">  &lt;&#x2F;configuration&gt;  </span><br><span class="line">&lt;&#x2F;plugin&gt;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="maven的模块聚合-多模块"><a href="#maven的模块聚合-多模块" class="headerlink" title="maven的模块聚合(多模块)"></a>maven的模块聚合(多模块)</h3><p>为了将2个模块聚合到一个模块下，必须新建一个聚合模块，它有自己的pom文件，packaging为pom。modules下配置多个模块</p>
<p>聚合项目可以使用父子结构和平行结构，一般建议使用父子结构。</p>
<p>构建各个模块的顺序是采用反应堆构建顺序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;project</span><br><span class="line">xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">        xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0</span><br><span class="line">        http:&#x2F;&#x2F;maven.apache.org&#x2F;maven-v4_0_0.xsd&gt;</span><br><span class="line">        &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line">        &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifact&gt;account-aggregator&lt;&#x2F;artifact&gt;</span><br><span class="line">        &lt;version&gt;1.0.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;packaging&gt;pom&lt;&#x2F;packaging&gt;</span><br><span class="line">        &lt;name&gt;Account Aggregator&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;modules&gt;</span><br><span class="line">            &lt;module&gt;account-email&lt;&#x2F;module&gt;</span><br><span class="line">            &lt;module&gt;account-persist&lt;&#x2F;module&gt;</span><br><span class="line">        &lt;&#x2F;modules&gt;</span><br><span class="line">&lt;&#x2F;project&gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="maven的模块继承"><a href="#maven的模块继承" class="headerlink" title="maven的模块继承"></a>maven的模块继承</h3><p>父模块的packaging为pom，这一点与聚合模块一样。父模块是为了消除配置的重复。</p>
<p>父模块：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;project</span><br><span class="line">xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">xsi:shemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0</span><br><span class="line">http:&#x2F;&#x2F;maven.apache.org&#x2F;maven-v4_0_0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line">    &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;account-parent&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;packaging&gt;pom&lt;&#x2F;packaging&gt;</span><br><span class="line">    &lt;name&gt;Account Parent&lt;&#x2F;name&gt;</span><br><span class="line">&lt;&#x2F;project&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>继承父模块的子模块</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;project</span><br><span class="line">xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">xsi:shemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0</span><br><span class="line">http:&#x2F;&#x2F;maven.apache.org&#x2F;maven-v4_0_0.xsd&quot;&gt;</span><br><span class="line">    &lt;parent&gt;</span><br><span class="line">        &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;account-parent&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.0.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;relativePath&gt;..&#x2F;account-parent&#x2F;pom.xml&lt;&#x2F;relativePath&gt;</span><br><span class="line">    &lt;&#x2F;parent</span><br><span class="line">    </span><br><span class="line">    &lt;artifactId&gt;account-email&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;name&gt;Account Email&lt;&#x2F;name&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        ....</span><br><span class="line">    &lt;&#x2F;dependencies&gt;</span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            ....</span><br><span class="line">        &lt;&#x2F;plugins&gt;</span><br><span class="line">    &lt;&#x2F;build&gt;</span><br><span class="line">&lt;&#x2F;project&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>父模块加入到聚合模块</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;project</span><br><span class="line">xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">        xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0</span><br><span class="line">        http:&#x2F;&#x2F;maven.apache.org&#x2F;maven-v4_0_0.xsd&gt;</span><br><span class="line">        &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line">        &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifact&gt;account-aggregator&lt;&#x2F;artifact&gt;</span><br><span class="line">        &lt;version&gt;1.0.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;packaging&gt;pom&lt;&#x2F;packaging&gt;</span><br><span class="line">        &lt;name&gt;Account Aggregator&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;modules&gt;</span><br><span class="line">            &lt;module&gt;account-email&lt;&#x2F;module&gt;</span><br><span class="line">            &lt;module&gt;account-persist&lt;&#x2F;module&gt;</span><br><span class="line">            &lt;module&gt;account-parent&lt;&#x2F;module&gt;</span><br><span class="line">        &lt;&#x2F;modules&gt;</span><br><span class="line">&lt;&#x2F;project&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以继承的pom元素</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">groupId:项目组ID,项目坐标的核心元素</span><br><span class="line">version:项目版本,项目坐标的核心元素</span><br><span class="line">description:项目的描述信息</span><br><span class="line">organnization:项目的组织信息</span><br><span class="line">inceptionYear:项目的创始年份</span><br><span class="line">url:项目的URL地址</span><br><span class="line">developers:项目的开发者信息</span><br><span class="line">contributors:项目的贡献者信息</span><br><span class="line">distributionManagement:项目的部署配置</span><br><span class="line">issueManagement:项目的缺陷跟踪系统信息</span><br><span class="line">ciManagement:项目的集成信息</span><br><span class="line">scm:项目的版本控制系统信息</span><br><span class="line">mailingLists:项目的邮件列表信息</span><br><span class="line">properties:自定义的Maven属性</span><br><span class="line">dependencies:项目的依赖配置</span><br><span class="line">dependencyManagement:项目的依赖管理配置</span><br><span class="line">repositories:项目的仓库配置</span><br><span class="line">build:包括项目的源码目录配置、输出目录配置、插件配置、插件管理配置等</span><br><span class="line">reporting:包括项目的报告输出目录配置，报告插件配置等。</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="模块的依赖管理"><a href="#模块的依赖管理" class="headerlink" title="模块的依赖管理"></a>模块的依赖管理</h3><p>Maven提供的dependentcyManagement元素既能让子模块继承到父模块的依赖配置，又能保证子模块依赖使用的灵活度。在dependentcyManagement元素下的依赖声明不会引入实际的依赖，不过他能够约束denpendencies下的依赖使用</p>
<p>整理后的父模块的pom</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;project</span><br><span class="line">xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">xsi:shemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0</span><br><span class="line">http:&#x2F;&#x2F;maven.apache.org&#x2F;maven-v4_0_0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line">    &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;account-parent&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;packaging&gt;pom&lt;&#x2F;packaging&gt;</span><br><span class="line">    &lt;name&gt;Account Parent&lt;&#x2F;name</span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;springframework.version&gt;2.5.6&lt;&#x2F;springframework.version&gt;</span><br><span class="line">        &lt;junit.version&gt;4.7&lt;&#x2F;junit.version&gt;</span><br><span class="line">    &lt;&#x2F;properties&gt;</span><br><span class="line">    &lt;dependencyManagement&gt;</span><br><span class="line">        &lt;dependencies&gt;</span><br><span class="line">            &lt;dependency&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-core&lt;&#x2F;artifactId&gt;</span><br><span class="line">                &lt;version&gt;$&#123;springframework.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;&#x2F;dependency&gt;</span><br><span class="line">            &lt;dependency&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-beans&lt;&#x2F;artifactId&gt;</span><br><span class="line">                &lt;version&gt;$&#123;springframework.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;&#x2F;dependency&gt;</span><br><span class="line">            &lt;dependency&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-context&lt;&#x2F;artifactId&gt;</span><br><span class="line">                &lt;version&gt;$&#123;springframework.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;&#x2F;dependency&gt;</span><br><span class="line">            &lt;dependency&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-context-support&lt;&#x2F;artifactId&gt;</span><br><span class="line">                &lt;version&gt;$&#123;springframework.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;&#x2F;dependency&gt;</span><br><span class="line">            &lt;dependency&gt;</span><br><span class="line">                &lt;groupId&gt;junit&lt;&#x2F;groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt;</span><br><span class="line">                &lt;version&gt;$&#123;springframework.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">                &lt;scope&gt;test&lt;&#x2F;scope&gt;</span><br><span class="line">            &lt;&#x2F;dependency&gt;</span><br><span class="line">        &lt;&#x2F;dependencies&gt;</span><br><span class="line">    &lt;&#x2F;dependencyManagement&gt;</span><br><span class="line">&lt;&#x2F;project&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>整理后的继承父模块的子模块</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;javax.mail.version&gt;1.4.1&lt;&#x2F;javax.mail.version&gt;</span><br><span class="line">    &lt;greenmail.version&gt;1.3.1b&lt;&#x2F;greenmail.version&gt;</span><br><span class="line">&lt;&#x2F;properties&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-core&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;&#x2F;dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-beans&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;&#x2F;dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-context&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;&#x2F;dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-context-support&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;&#x2F;dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;junit&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;&#x2F;dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;javax.mail&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;mail&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;javax.mail.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;&#x2F;dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;javax.icegreen&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;greenmail&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;greenmail.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;&#x2F;scope&gt;</span><br><span class="line">        &lt;&#x2F;dependency&gt;</span><br><span class="line">    &lt;&#x2F;dependencies&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>子模块只需要配置简单的groupId和artifactId就能获得对应的依赖信息，从而引入正确的依赖。</p>
<p>如果在子模块不声明依赖的使用，即使该依赖已经在父POM的dependencyManagement中声明了，也不会产生任何实际的效果。</p>
<p>依赖范围有个import范围，import依赖范围只有在dependencyManagement下才有效果，使用该范围的依赖通常指向一个POM，作用是将目标中的dependencyManagement配置导入到当前POM的dependencyManagement中配置，除了复制配置或者继承这两种方式之外，还可以使用import范围依赖将这一配置导入。</p>
<h3 id="插件管理"><a href="#插件管理" class="headerlink" title="插件管理"></a>插件管理</h3><p>Maven提供了dependencyManagement元素帮忙管理依赖，类似地，Maven也提供了pluginManagement元素帮忙管理插件。该元素中配置的依赖不会造成实际的插件调用行为，当POM中配置了真正的plugin元素，并且其groupId和artifactId与pluginManagement中配置的插件匹配时，pluginManagement的配置才会影响实际的插件行为。</p>
<h3 id="聚合和继承的关系"><a href="#聚合和继承的关系" class="headerlink" title="聚合和继承的关系"></a>聚合和继承的关系</h3><p>多模块中的聚合与继承其实是两个概念，其目的是完全不同的，前者主要是为了方便快速构建项目，后者主要是为了消除重复配置。</p>
<p>在现有的实际项目中，往往会发现一个POM即是聚合POM，又是父POM，这么做主要是为了方便。</p>
<h3 id="约定优于配置"><a href="#约定优于配置" class="headerlink" title="约定优于配置"></a>约定优于配置</h3><p>Maven默认的源码目录是：src/main/java但是用户也可以自己指定源码目录，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;project&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line">    &lt;groupId&gt;com.juvenxu.mvnbook&lt;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;my-project&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;sourceDirectory&gt;src&#x2F;java&lt;&#x2F;sourceDirectory&gt;</span><br><span class="line">    &lt;&#x2F;build&gt;</span><br><span class="line">&lt;&#x2F;project&gt;</span><br></pre></td></tr></table></figure>

<p>maven会默认隐身的继承于超级pom，超级pom内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;repositories&gt;</span><br><span class="line">    &lt;repository&gt;</span><br><span class="line">        &lt;id&gt;central&lt;&#x2F;id&gt;</span><br><span class="line">        &lt;name&gt;Maven Repository Switchboard&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;url&gt;http:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&lt;&#x2F;url&gt;</span><br><span class="line">        &lt;layout&gt;default&lt;&#x2F;layout&gt;</span><br><span class="line">        &lt;snapshots&gt;</span><br><span class="line">            &lt;enabled&gt;false&lt;&#x2F;enabled&gt;</span><br><span class="line">        &lt;&#x2F;snapshots&gt;</span><br><span class="line">    &lt;&#x2F;repository&gt;</span><br><span class="line">&lt;&#x2F;repositories&gt;</span><br><span class="line">&lt;pluginRepositories&gt;</span><br><span class="line">    &lt;pluginRepository&gt;</span><br><span class="line">        &lt;id&gt;central&lt;&#x2F;id&gt;</span><br><span class="line">        &lt;name&gt;Maven Plugin Repository&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;url&gt;http:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&lt;&#x2F;url&gt;</span><br><span class="line">        &lt;layout&gt;default&lt;&#x2F;layout&gt;</span><br><span class="line">        &lt;snapshots&gt;</span><br><span class="line">            &lt;enabled&gt;false&lt;&#x2F;enabled&gt;</span><br><span class="line">        &lt;&#x2F;snapshots&gt;</span><br><span class="line">        &lt;releases&gt;</span><br><span class="line">            &lt;updatePolicy&gt;never&lt;&#x2F;updatePolicy&gt;</span><br><span class="line">        &lt;&#x2F;releases&gt;</span><br><span class="line">    &lt;&#x2F;pluginRepository&gt;</span><br><span class="line">&lt;&#x2F;pluginRepositories&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>超级POM中关于项目结构的定义：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">    &lt;directory&gt;$&#123;project.basedir&#125;&#x2F;target&lt;directory&gt;</span><br><span class="line">    &lt;outputDirectory&gt;$&#123;project.build.directory&#125;&#x2F;classes&lt;&#x2F;outputDirectory&gt;</span><br><span class="line">    &lt;finalName&gt;$&#123;project.artifactId&#125;-$&#123;project.version&#125;&lt;&#x2F;finalName&gt;</span><br><span class="line">    &lt;testOutputDirectory&gt;$&#123;project.build.directory&#125;&#x2F;test-classes&lt;&#x2F;testOutputDirectory&gt;</span><br><span class="line">    &lt;sourceDirectory&gt;$&#123;project.basedir&#125;&#x2F;src&#x2F;main&#x2F;java&lt;&#x2F;sourceDirectory&gt;</span><br><span class="line">    &lt;scriptSourceDirectory&gt;src&#x2F;main&#x2F;script&lt;&#x2F;scriptSourceDirectory&gt;</span><br><span class="line">    &lt;testSourceDirectory&gt;$&#123;project.basedir&#125;&#x2F;src&#x2F;test&#x2F;java&lt;&#x2F;testSourceDirectory&gt;</span><br><span class="line">    &lt;resources&gt;</span><br><span class="line">        &lt;resource&gt;</span><br><span class="line">            &lt;directory&gt;$&#123;project.basedir&#125;&#x2F;src&#x2F;main&#x2F;resources&lt;&#x2F;directory&gt;</span><br><span class="line">        &lt;&#x2F;resource&gt;</span><br><span class="line">    &lt;&#x2F;resources&gt;</span><br><span class="line">    &lt;testResources&gt;</span><br><span class="line">        &lt;testResource&gt;</span><br><span class="line">            &lt;directory&gt;$&#123;project.basedir&#125;&#x2F;src&#x2F;test&#x2F;resources&lt;&#x2F;directory&gt;</span><br><span class="line">        &lt;&#x2F;testResource&gt;</span><br><span class="line">    &lt;&#x2F;testResources&gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以下是超级pom关于插件版本的设定</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;pluginManagement&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-antrun-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.3&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line"></span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-assembly-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;2.2-bete-4&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">        </span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-clean-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;2.3&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">        </span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-compiler-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;2.0.2&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">        ........</span><br><span class="line">    &lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;pluginManagement&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;build&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>超级pom的位置</p>
<p>对于Maven3,超级POM在文件$MAVEN_HOME/lib/maven-model-builder-x.x.x.jar中的org/apache/maven/model/pom-4.0.0.xml路径下。</p>
<p>对于Maven2,超级POM在文件$MAVEN_HOME/lib/maven-x.x.x-uber.jar中的org/apache/maven/project/pom-4.0.0.xml目录下。</p>
<h3 id="反应堆"><a href="#反应堆" class="headerlink" title="反应堆"></a>反应堆</h3><p>对于一个多模块的项目，反应堆就是所有模块构成的一个构建结构。反应堆就包含了各模块之间继承与依赖的关系，从而能够自动计算出合理的模块构建顺序。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;modules&gt;</span><br><span class="line">    &lt;module&gt;account-email&lt;&#x2F;module&gt;</span><br><span class="line">    &lt;module&gt;account-persist&lt;&#x2F;module&gt;</span><br><span class="line">    &lt;module&gt;account-parent&lt;&#x2F;module&gt;</span><br><span class="line">&lt;&#x2F;modules&gt;</span><br></pre></td></tr></table></figure>

<p>实际项目时这样的，maven按照顺序读取pom，如果pom没有依赖模块，那么就构建该模块。否则就构建其它依赖模块。如果其它依赖模块还依赖别的其它模块，则先构建别的模块。</p>
<p>以上，构建顺序不一定是顺序去读取POM的顺序，当一个模块依赖于另外一个模块，Maven会先去构建被依赖模块，<br>并且Maven中不允许出现循环依赖的情况，就是，当出现模块A依赖于B,而B又依赖于A的情况时，Maven就会报错。</p>
<h3 id="裁剪反应堆"><a href="#裁剪反应堆" class="headerlink" title="裁剪反应堆"></a>裁剪反应堆</h3><p>一般来说，用户会选择构建整个项目或者选择构建单个的模块，但有些时候，用户会想要仅仅构建完整反应堆中的某些个模块。换句话说，用户需要实时地剪裁反应堆。</p>
<p>Maven提供很多命令行选项支持裁剪反应堆，输入mvn -h可以看到这些选项：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-am, --also-make：同时构建所列模块的依赖模块</span><br><span class="line">-amd -also-make-dependents:同时构建依赖于所列模块的模块</span><br><span class="line">-p,--project 构建指定的模块，模块之间使用逗号分割</span><br><span class="line">-rf -resume-from 从指定的模块回复反应堆</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>例子：</p>
<p>默认情况从account-aggregator执行mvn clean install会得到如下完整的反应堆：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[INFO]-----------------------------------------------------</span><br><span class="line">[INFO]Reactor Build Order:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]Account Aggregator</span><br><span class="line">[INFO]Account Parent</span><br><span class="line">[INFO]Account Email</span><br><span class="line">[INFO]Account Persist</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]-----------------------------------------------------</span><br></pre></td></tr></table></figure>

<p>可以使用-pl选项指定构建某几个模块，如运行如下命令：</p>
<p>$ mvn clean install -p account-email,account-persist<br>得到的反应堆为:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[INFO]-----------------------------------------------------</span><br><span class="line">[INFO]Reactor Build Order:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]Account Email</span><br><span class="line">[INFO]Account Persist</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]-----------------------------------------------------</span><br></pre></td></tr></table></figure>

<p>使用-am选项可以同时构建所列模块的依赖模块，例如：</p>
<p>$ mvn clean install -pl account-parent -am<br>由于account-email和account-persist都依赖于account-parent，因此会得到如下反应堆：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[INFO]-----------------------------------------------------</span><br><span class="line">[INFO]Reactor Build Order:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]Account Parent</span><br><span class="line">[INFO]Account Email</span><br><span class="line">[INFO]Account Persist</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]-----------------------------------------------------</span><br></pre></td></tr></table></figure>

<p>使用-rf选项可以在完整的反应堆构建顺序基础上指定从哪个模块开始构建。例如：</p>
<p>$mvn clean install -rf account-email<br>完整的反应堆构建顺序中，account-email位于第三，它之后只有account-persist因此会得到如下的剪裁反应堆：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[INFO]-----------------------------------------------------</span><br><span class="line">[INFO]Reactor Build Order:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]Account Email</span><br><span class="line">[INFO]Account Persist</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]-----------------------------------------------------</span><br></pre></td></tr></table></figure>
<p>最后在-pl -am或者-pl -amd的基础上，还能应用-rf参数，以对裁剪后的反应堆再次剪裁,例如：</p>
<p>$ mvn clean install -pl account-parent -amd -rf account-email<br>该命令中的-pl和-amd参数会裁剪出一个account-parent、account-email和account-persist的反应堆，在此基础上，-rf参数指定从account-email参数构建。因此会得到如下的反应堆：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[INFO]-----------------------------------------------------</span><br><span class="line">[INFO]Reactor Build Order:</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]Account Email</span><br><span class="line">[INFO]Account Persist</span><br><span class="line">[INFO]</span><br><span class="line">[INFO]-----------------------------------------------------</span><br></pre></td></tr></table></figure>

<p>在开发过程中，灵活应用上述四个参数，可以帮助我们跳过无须构建的模块，从而加速构建。在项目庞大、规模特别多的时候，这种效果就会异常明显。</p>
<h2 id="私服-1"><a href="#私服-1" class="headerlink" title="私服"></a>私服</h2><h3 id="私服的优点"><a href="#私服的优点" class="headerlink" title="私服的优点"></a>私服的优点</h3><p>1.节省外网宽带<br>2.加速Maven构建<br>3.部署第三方构件<br>4.提高稳定性、增强控制：原因是外网不稳定<br>5.降低中央仓库的负荷：原因是中央仓库访问量太大</p>
<h3 id="镜像库"><a href="#镜像库" class="headerlink" title="镜像库"></a>镜像库</h3><p>mirror相当于一个拦截器，它会拦截maven对remote repository的相关请求，把请求里的remote repository地址，重定向到mirror里配置的地址。</p>
<h3 id="nexus私服的安装方式"><a href="#nexus私服的安装方式" class="headerlink" title="nexus私服的安装方式"></a>nexus私服的安装方式</h3><p>Nexus提供了两种安装方式，一种是内嵌Jetty的bundle，只要你有JRE就能直接运行。第二种方式是WAR，你只须简单的将其发布到web容器中即可使用。</p>
<p>我们采用第一种：</p>
<p>1.下载解压后的文件 <a href="http://download.sonatype.com/nexus/oss/nexus-2.10.0-02-bundle.tar.gz">bundle文件下载</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;nexus-2.10.0-02$ ls</span><br><span class="line">bin  conf  lib  LICENSE.txt  logs  nexus  NOTICE.txt  tmp</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2.在bin目录下启动文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;nexus-2.10.0-02&#x2F;bin$ sudo .&#x2F;nexus start</span><br><span class="line">****************************************</span><br><span class="line">WARNING - NOT RECOMMENDED TO RUN AS ROOT</span><br><span class="line">****************************************</span><br><span class="line">If you insist running as root, then set the environment variable RUN_AS_USER&#x3D;root before running this script.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>/nexus-2.12.0-01/bin/nexus 在该文件中增加一行配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">RUN_AS_USER&#x3D;root</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>3.修改nexus.properties配置文件(可选) 在config目录下</p>
<p>4.启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;nexus-2.10.0-02&#x2F;bin$ sudo .&#x2F;nexus start</span><br><span class="line">****************************************</span><br><span class="line">WARNING - NOT RECOMMENDED TO RUN AS ROOT</span><br><span class="line">****************************************</span><br><span class="line">Starting Nexus OSS...</span><br><span class="line">Started Nexus OSS.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>5.报错 nexus启动报错(Unable to start JVM: No such file or directory (2))</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">通过 service nexus start 启动报错，查看 &#x2F;usr&#x2F;local&#x2F;nexus&#x2F;nexus-2.10.0-02&#x2F;logs 下的日志得出是找不到jdk路径</span><br><span class="line"></span><br><span class="line">解决:</span><br><span class="line">修改[NEXUS_HOME]&#x2F;bin&#x2F;jsw&#x2F;conf&#x2F;wrapper.conf（&#x2F;usr&#x2F;local&#x2F;nexus&#x2F;nexus-2.10.0-02&#x2F;bin&#x2F;jsw&#x2F;conf） 文件中的 wrapper.java.command&#x3D;java目录  就可以了，将它改成java的安装位置。</span><br><span class="line">    wrapper.java.command&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_151&#x2F;bin&#x2F;java</span><br></pre></td></tr></table></figure>

<p>6.重新启动 成功</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jvm 1    | 2018-09-17 00:25:10,375+0800 INFO  [jetty-main-1] *SYSTEM org.eclipse.jetty.server.AbstractConnector - Started InstrumentedSelectChannelConnector@0.0.0.0:8081</span><br><span class="line"></span><br><span class="line">表示启动成功</span><br></pre></td></tr></table></figure>

<p>7.访问 <a href="http://localhost:8081/nexus/#welcome">http://localhost:8081/nexus/#welcome</a> 使用默认密码登录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">默认管理员</span><br><span class="line"></span><br><span class="line">账号：admin</span><br><span class="line"></span><br><span class="line">密码：admin123</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">默认发布者</span><br><span class="line"></span><br><span class="line">账号：deployment</span><br><span class="line"></span><br><span class="line">密码：deployment123</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>8.登录后如图所示：</p>
<p><img src="/images/maven/nexus%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2.png" alt="nexus登录界面"></p>
<h3 id="nexus仓库与仓库组"><a href="#nexus仓库与仓库组" class="headerlink" title="nexus仓库与仓库组"></a>nexus仓库与仓库组</h3><p>有四种类型:group(仓库组),hosted(宿主),proxy(代理),virtual(虚拟)。仓库还有一个属性为Pilicy(策略),表示该仓库为发布(Release)版本还是快照(Snapshot)版本库。最后两列为仓库的状态和路径</p>
<p>下面解释一下各个仓库的用途，maven1格式的仓库不会介绍。此外由于虚拟类型仓库的作用实际上是动态地将仓库内容格式转换，换言之也是为了服务maven1格式，因此也被省略。</p>
<ul>
<li><p>Central:该仓库代理maven中央仓库，其策略为Release，因此只会下载和缓存中央仓库中的发布版本构件。</p>
</li>
<li><p>Releases:这是一个策略为Release的宿主类型仓库，用来部署组织内部的发布版本构件。</p>
</li>
<li><p>Snapshots:这是一个策略为Snapshots的宿主类型仓库，用来部署组织内部的快照版本构件。</p>
</li>
<li><p>3rd party:这是一个策略为Release的宿主类型仓库，用来部署无法从公共仓库获得的第三方发布版本构件。</p>
</li>
<li><p>Apache Snapshots:这是一个策略为Snapshot的代理仓库，用来代理Apache Maven仓库的快照版本构件。</p>
</li>
<li><p>Codehaus Snapshots:这是一个策略为Snapshot的代理仓库，用来代理Codehaus Maven仓库的快照版本构件。</p>
</li>
<li><p>Public Repositories:该仓库组将上述所有策略为Release的仓库聚合并通过一致的地址提供服务。</p>
</li>
</ul>
<h3 id="nexus仓库分类的概念"><a href="#nexus仓库分类的概念" class="headerlink" title="nexus仓库分类的概念"></a>nexus仓库分类的概念</h3><p><img src="/images/maven/%E5%90%84%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84nexus%E4%BB%93%E5%BA%93.png" alt="各种类型的nexus仓库"></p>
<p>maven可以直接从宿主仓库下载构建，也可以直接从代理仓库下载构建，而代理仓库会直接从远程仓库下载并缓存构建。最后为了方便可以从仓库组下载构建。</p>
<h3 id="从nexus私服下载jar包"><a href="#从nexus私服下载jar包" class="headerlink" title="从nexus私服下载jar包"></a>从nexus私服下载jar包</h3><p>在maven的settings的文件中配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;profile&gt;    </span><br><span class="line">    &lt;!--profile 的 id--&gt; </span><br><span class="line">   &lt;id&gt;dev&lt;&#x2F;id&gt;    </span><br><span class="line">    &lt;repositories&gt;    </span><br><span class="line">      &lt;repository&gt;   </span><br><span class="line">        &lt;!--仓库 id，repositories 可以配置多个仓库，保证 id 不重复--&gt; </span><br><span class="line">        &lt;id&gt;nexus&lt;&#x2F;id&gt;    </span><br><span class="line">        &lt;!--仓库地址，即 nexus 仓库组的地址--&gt; </span><br><span class="line">        &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt;    </span><br><span class="line">        &lt;!--是否下载 releases 构件--&gt; </span><br><span class="line">        &lt;releases&gt;    </span><br><span class="line">          &lt;enabled&gt;true&lt;&#x2F;enabled&gt;    </span><br><span class="line">        &lt;&#x2F;releases&gt;    </span><br><span class="line">        &lt;!--是否下载 snapshots 构件--&gt; </span><br><span class="line">        &lt;snapshots&gt;    </span><br><span class="line">          &lt;enabled&gt;true&lt;&#x2F;enabled&gt;    </span><br><span class="line">        &lt;&#x2F;snapshots&gt;    </span><br><span class="line">      &lt;&#x2F;repository&gt;    </span><br><span class="line">    &lt;&#x2F;repositories&gt;   </span><br><span class="line">     &lt;pluginRepositories&gt;   </span><br><span class="line">     &lt;!-- 插件仓库，maven 的运行依赖插件，也需要从私服下载插件 --&gt; </span><br><span class="line">        &lt;pluginRepository&gt;   </span><br><span class="line">         &lt;!-- 插件仓库的 id 不允许重复，如果重复后边配置会覆盖前边 --&gt; </span><br><span class="line">            &lt;id&gt;public&lt;&#x2F;id&gt;   </span><br><span class="line">            &lt;name&gt;Public Repositories&lt;&#x2F;name&gt;   </span><br><span class="line">            &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt;   </span><br><span class="line">        &lt;&#x2F;pluginRepository&gt;   </span><br><span class="line">    &lt;&#x2F;pluginRepositories&gt;   </span><br><span class="line">  &lt;&#x2F;profile&gt;   </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用 profile 定义仓库需要激活才可生效。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;activeProfiles&gt; </span><br><span class="line">  &lt;activeProfile&gt;dev&lt;&#x2F;activeProfile&gt; </span><br><span class="line">&lt;&#x2F;activeProfiles&gt; </span><br></pre></td></tr></table></figure>


<h4 id="比较常用的maven镜像"><a href="#比较常用的maven镜像" class="headerlink" title="比较常用的maven镜像"></a>比较常用的maven镜像</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;mirror&gt;</span><br><span class="line">    &lt;id&gt;alimaven&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;name&gt;aliyun maven&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">    &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">&lt;&#x2F;mirror&gt;</span><br><span class="line">&lt;mirror&gt;</span><br><span class="line">    &lt;id&gt;ui&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">    &lt;name&gt;Human Readable Name for this Mirror.&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;url&gt;http:&#x2F;&#x2F;uk.maven.org&#x2F;maven2&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">&lt;&#x2F;mirror&gt;</span><br><span class="line">&lt;mirror&gt;</span><br><span class="line">    &lt;id&gt;jboss-public-repository-group&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">    &lt;name&gt;JBoss Public Repository Group&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;url&gt;http:&#x2F;&#x2F;repository.jboss.org&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&lt;&#x2F;url&gt;</span><br><span class="line">&lt;&#x2F;mirror&gt;</span><br><span class="line">&lt;mirror&gt;</span><br><span class="line">    &lt;id&gt;repo2&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">    &lt;name&gt;Human Readable Name for this Mirror.&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;url&gt;http:&#x2F;&#x2F;repo2.maven.org&#x2F;maven2&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">&lt;&#x2F;mirror&gt;</span><br><span class="line">&lt;mirror&gt;</span><br><span class="line">    &lt;id&gt;OSChina&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;name&gt;OSChina Central&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;url&gt;http:&#x2F;&#x2F;maven.oschina.net&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">    &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">&lt;&#x2F;mirror&gt;</span><br><span class="line">&lt;mirror&gt;</span><br><span class="line">    &lt;id&gt;nexus-osc-thirdparty&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;mirrorOf&gt;thirdparty&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">    &lt;name&gt;Nexus osc thirdparty&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;url&gt;http:&#x2F;&#x2F;maven.oschina.net&#x2F;content&#x2F;repositories&#x2F;thirdparty&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">&lt;&#x2F;mirror&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="maven镜像的使用"><a href="#maven镜像的使用" class="headerlink" title="maven镜像的使用"></a>maven镜像的使用</h3><p>编辑settings.xml配置中央仓库镜像：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;settings&gt;</span><br><span class="line">  ...</span><br><span class="line">  &lt;mirrors&gt;</span><br><span class="line">    &lt;mirror&gt;</span><br><span class="line">      &lt;id&gt;maven.net.cn&lt;&#x2F;id&gt;</span><br><span class="line">      &lt;name&gt;one of the central mirrors in china&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;url&gt;http:&#x2F;&#x2F;maven.net.cn&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">      &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">    &lt;&#x2F;mirror&gt;</span><br><span class="line">  &lt;&#x2F;mirrors&gt;</span><br><span class="line">  ...</span><br><span class="line">&lt;&#x2F;settings&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>该例中，<mirrorOf>的值为central，表示该配置为中央仓库的镜像，任何对于中央仓库的请求都会转至该镜像，用户也可以使用同样的方法配置其他仓库的镜像。另外三个元素id,name,url与一般仓库配置无异，表示该镜像仓库的唯一标识符、名称以及地址。类似地，如果该镜像需认证，也可以基于该id配置仓库认证。<br>任何需要的构件都可以从私服获得，私服就是所有仓库的镜像。这时，可以配置这样的一个镜像，如例： </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;settings&gt;</span><br><span class="line">  ...</span><br><span class="line">  &lt;mirrors&gt;</span><br><span class="line">    &lt;mirror&gt;</span><br><span class="line">      &lt;id&gt;internal-repository&lt;&#x2F;id&gt;</span><br><span class="line">      &lt;name&gt;Internal Repository Manager&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;url&gt;http:&#x2F;&#x2F;192.168.1.100&#x2F;maven2&lt;&#x2F;url&gt;</span><br><span class="line">      &lt;mirrorOf&gt;*&lt;&#x2F;mirrorOf&gt;</span><br><span class="line">    &lt;&#x2F;mirror&gt;</span><br><span class="line">  &lt;&#x2F;mirrors&gt;</span><br><span class="line">  ...</span><br><span class="line">&lt;&#x2F;settings&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>该例中<mirrorOf>的值为星号，表示该配置是所有Maven仓库的镜像，任何对于远程仓库的请求都会被转至<a href="http://192.168.1.100/maven2/%E3%80%82%E5%A6%82%E6%9E%9C%E8%AF%A5%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E9%9C%80%E8%A6%81%E8%AE%A4%E8%AF%81%EF%BC%8C%E5%88%99%E9%85%8D%E7%BD%AE%E4%B8%80%E4%B8%AAId%E4%B8%BAinternal-repository%E7%9A%84">http://192.168.1.100/maven2/。如果该镜像仓库需要认证，则配置一个Id为internal-repository的</a><server>即可。为了满足一些复杂的需求，Maven还支持更高级的镜像配置：</p>
<p>1.<mirrorOf>*</mirrorOf></p>
<p>匹配所有远程仓库。</p>
<p>2.<mirrorOf>external:*</mirrorOf></p>
<p>匹配所有远程仓库，使用localhost的除外，使用file://协议的除外。也就是说，匹配所有不在本机上的远程仓库。</p>
<p>3.<mirrorOf>repo1,repo2</mirrorOf></p>
<p>匹配仓库repo1和repo2，使用逗号分隔多个远程仓库。</p>
<p>4.<mirrorOf>*,!repo1</miiroOf></p>
<p>匹配所有远程仓库，repo1除外，使用感叹号将仓库从匹配中排除。</p>
<h3 id="部署构件到nexus"><a href="#部署构件到nexus" class="headerlink" title="部署构件到nexus"></a>部署构件到nexus</h3><p>如果只为代理外部公共仓库，那么nexus的代理仓库就已经完全能够满足需求了。对于宿主仓库来说，主要作用是存储组织内部的或者一些无法从公共仓库中获得的第三方构件。</p>
<p>使用maven部署构件至nexus，具体配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;distributionManagement&gt;</span><br><span class="line">  &lt;repository&gt;</span><br><span class="line">    &lt;id&gt;nexus-releases&lt;&#x2F;id&gt;</span><br><span class="line">      &lt;name&gt;Nexus Release Repository&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;url&gt;http:&#x2F;&#x2F;42.121.113.40:8981&#x2F;nexus&#x2F;content&#x2F;repositories&#x2F;releases&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">  &lt;&#x2F;repository&gt;</span><br><span class="line">  &lt;snapshotRepository&gt;</span><br><span class="line">    &lt;id&gt;nexus-snapshots&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;name&gt;Nexus Snapshot Repository&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;url&gt;http:&#x2F;&#x2F;42.121.113.40:8981&#x2F;nexus&#x2F;content&#x2F;repositories&#x2F;snapshots&#x2F;&lt;&#x2F;url&gt;</span><br><span class="line">  &lt;&#x2F;snapshotRepository&gt;</span><br><span class="line">&lt;&#x2F;distributionManagement&gt;</span><br><span class="line">    </span><br><span class="line"> 所有的release构件部署到Nexus的Releases仓库中。由于部署需要登陆，因为我们在settings.xml中配置对应Repository id的用户名和密码。</span><br><span class="line"></span><br><span class="line">&lt;servers&gt;  </span><br><span class="line">      &lt;server&gt;  </span><br><span class="line">        &lt;id&gt;nexus-releases&lt;&#x2F;id&gt;  </span><br><span class="line">        &lt;username&gt;admin&lt;&#x2F;username&gt;  </span><br><span class="line">        &lt;password&gt;admin123&lt;&#x2F;password&gt;  </span><br><span class="line">      &lt;&#x2F;server&gt;  </span><br><span class="line">      &lt;server&gt;  </span><br><span class="line">        &lt;id&gt;nexus-snapshots&lt;&#x2F;id&gt;  </span><br><span class="line">        &lt;username&gt;admin&lt;&#x2F;username&gt;  </span><br><span class="line">       &lt;password&gt;admin123&lt;&#x2F;password&gt;  </span><br><span class="line">      &lt;&#x2F;server&gt;     </span><br><span class="line"> &lt;&#x2F;servers&gt;  </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven实战</tag>
      </tags>
  </entry>
  <entry>
    <title>redis集群-cluster</title>
    <url>/2018-02-05/redis%E9%9B%86%E7%BE%A4-cluster/</url>
    <content><![CDATA[<p>最近学习了redis设计与实现这本书.这本书中主要讲述是理论知识,所以最近首先整理一下关于redis的集群的知识.然后学习redis实战这本书,实战一下.</p>
<h1 id="关于redis-cluster"><a href="#关于redis-cluster" class="headerlink" title="关于redis cluster"></a>关于redis cluster</h1><p>redis cluster在设计的时候，就考虑到了去中心化，去中间件，也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。</p>
<p>Redis 集群<strong>没有使用传统的一致性哈希</strong>来分配数据，而是采用另外一种叫做<strong>哈希槽</strong> (hash slot)的方式来分配的。redis cluster 默认分配了 16384 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384。</p>
<h1 id="Redis-Cluster主从模式"><a href="#Redis-Cluster主从模式" class="headerlink" title="Redis Cluster主从模式"></a>Redis Cluster主从模式</h1><p>redis cluster 为了保证数据的高可用性，加入了主从模式，一个主节点对应一个或多个从节点，主节点提供数据存取，从节点则是从主节点拉取数据备份，当这个主节点挂掉后，就会有这个从节点选取一个来充当主节点，从而保证集群不会挂掉。</p>
<ul>
<li>例子</li>
</ul>
<p>集群有ABC三个主节点, 如果这3个节点都没有加入从节点，如果B挂掉了，我们就无法访问整个集群了。A和C的slot也无法访问。所以我们在集群建立的时候，一定要为每个主节点都添加了从节点,比如像这样, 集群包含主节点A、B、C, 以及从节点A1、B1、C1, 那么即使B挂掉系统也可以继续正确工作。B1节点替代了B节点，所以Redis集群将会选择B1节点作为新的主节点，集群将会继续正确地提供服务。当B重新开启后，它就会变成B1的从节点。不过需要注意，如果节点B和B1同时挂了，Redis集群就无法继续正确地提供服务了。</p>
<p>更多关于redisCluster的知识访问我的博文 <a href="http://chenwj.cn/2018-01-28/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0-cluster/">redisCluster</a></p>
<h1 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h1><p>按照<a href="http://redis.io/topics/cluster-tutorial">官方cluster文档</a>进行实战 </p>
<h2 id="创建并使用集群"><a href="#创建并使用集群" class="headerlink" title="创建并使用集群"></a>创建并使用集群</h2><p>Redis 集群由多个运行在集群模式（cluster mode）下的 Redis 实例组成， 实例的集群模式需要通过配置来开启， 开启集群模式的实例将可以使用集群特有的功能和命令。</p>
<p>以下是一个包含了最少选项的集群配置文件示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">port 7000    &#x2F;&#x2F;端口号</span><br><span class="line">cluster-enabled yes   &#x2F;&#x2F;开启集群模式</span><br><span class="line">cluster-config-file nodes.conf   &#x2F;&#x2F;集群的配置文件</span><br><span class="line">cluster-node-timeout 5000   &#x2F;&#x2F;认定节点下线的时间</span><br><span class="line">appendonly yes   &#x2F;&#x2F;开启aof持久化</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>官方建议三主三从来搭建集群(本集群采用3.2.11版本)</p>
<p>首先下载redis的源码 地址<a href="http://download.redis.io/releases/redis-3.2.11.tar.gz">redis-3.2.11</a></p>
<ul>
<li>下载源码 修改文件权限<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-3.2.11.tar.gz</span><br><span class="line">sudo chmod  753 redis-3.2.11.tar.gz </span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>创建集群文件夹  解压redis源码 进入redis集群文件夹下的redis-3.2.11</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo mkdir &#x2F;usr&#x2F;local&#x2F;redisCluster</span><br><span class="line">sudo tar -zxvf redis-3.2.11.tar.gz -C &#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;</span><br><span class="line">cd &#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;redis-3.2.11&#x2F;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>安装(该操作需要linux系统有c环境,如果报错请自行查阅资料安装) 以上操作后在src文件夹下会生成可执行文件 redis-server和redis-cli等,如果出现编译问题,请切换到root用户下操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo make&amp;&amp;make install</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后修改配置文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim redis.conf</span><br><span class="line"></span><br><span class="line">如下</span><br><span class="line"></span><br><span class="line">port 7000    &#x2F;&#x2F;端口号</span><br><span class="line">cluster-enabled yes   &#x2F;&#x2F;开启集群模式</span><br><span class="line">cluster-config-file nodes.conf   &#x2F;&#x2F;集群的配置文件</span><br><span class="line">cluster-node-timeout 5000   &#x2F;&#x2F;认定节点下线的时间</span><br><span class="line">appendonly yes   &#x2F;&#x2F;开启aof持久化</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>让我们进入一个新目录， 并创建六个以端口号为名字的子目录， 稍后我们在将每个目录中运行一个 Redis 实例</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ..</span><br><span class="line">sudo mkdir 7000 7001 7002 7003 7004 7005 </span><br><span class="line"></span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;redisCluster$ sudo cp -r redis-3.2.11&#x2F;*  7000&#x2F;</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;redisCluster$ sudo cp -r redis-3.2.11&#x2F;*  7001&#x2F;</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;redisCluster$ sudo cp -r redis-3.2.11&#x2F;*  7002&#x2F;</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;redisCluster$ sudo cp -r redis-3.2.11&#x2F;*  7003&#x2F;</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;redisCluster$ sudo cp -r redis-3.2.11&#x2F;*  7004&#x2F;</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;redisCluster$ sudo cp -r redis-3.2.11&#x2F;*  7005&#x2F;</span><br><span class="line"></span><br><span class="line">现在只需修改每个配置文件下的port参数就行    </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>然后进入每个端口号命名的文件夹下运行以下命令</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo .&#x2F;src&#x2F;redis-server redis.conf &amp;</span><br><span class="line"></span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ ps -ef|grep redis</span><br><span class="line">root      4700  3041  0 00:56 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4701  4700  0 00:56 pts&#x2F;4    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:7003 [cluster]</span><br><span class="line">root      4721  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4722  4721  0 00:57 pts&#x2F;4    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:7000 [cluster]</span><br><span class="line">root      4740  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4741  4740  0 00:57 pts&#x2F;4    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:7001 [cluster]</span><br><span class="line">root      4755  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4756  4755  0 00:57 pts&#x2F;4    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:7002 [cluster]</span><br><span class="line">root      4771  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4772  4771  0 00:57 pts&#x2F;4    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:7004 [cluster]</span><br><span class="line">root      4789  3041  0 00:58 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4790  4789  0 00:58 pts&#x2F;4    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:7005 [cluster]</span><br><span class="line">zhuning+  4794  3041  0 00:58 pts&#x2F;4    00:00:00 grep --color&#x3D;auto redis</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>使用 Redis 集群命令行工具 redis-trib ， 编写节点配置文件的工作可以非常容易地完成</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ sudo .&#x2F;src&#x2F;redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 </span><br><span class="line">&gt;&gt;&gt; Creating cluster</span><br><span class="line">&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...</span><br><span class="line">Using 3 masters:</span><br><span class="line">127.0.0.1:7000</span><br><span class="line">127.0.0.1:7001</span><br><span class="line">127.0.0.1:7002</span><br><span class="line">Adding replica 127.0.0.1:7003 to 127.0.0.1:7000</span><br><span class="line">Adding replica 127.0.0.1:7004 to 127.0.0.1:7001</span><br><span class="line">Adding replica 127.0.0.1:7005 to 127.0.0.1:7002</span><br><span class="line">M: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">S: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   replicates a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">Can I set the above configuration? (type &#39;yes&#39; to accept): </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中–replicas 1表示每个主节点创建一个从节点,该命令自动为各个主节点分配槽位.m表示主节点,s表示从节点;</p>
<p>yes确认</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Can I set the above configuration? (type &#39;yes&#39; to accept): yes</span><br><span class="line">&gt;&gt;&gt; Nodes configuration updated</span><br><span class="line">&gt;&gt;&gt; Assign a different config epoch to each node</span><br><span class="line">4722:M 06 Feb 01:04:46.722 # configEpoch set to 1 via CLUSTER SET-CONFIG-EPOCH</span><br><span class="line">4741:M 06 Feb 01:04:46.722 # configEpoch set to 2 via CLUSTER SET-CONFIG-EPOCH</span><br><span class="line">4756:M 06 Feb 01:04:46.723 # configEpoch set to 3 via CLUSTER SET-CONFIG-EPOCH</span><br><span class="line">4701:M 06 Feb 01:04:46.723 # configEpoch set to 4 via CLUSTER SET-CONFIG-EPOCH</span><br><span class="line">4772:M 06 Feb 01:04:46.724 # configEpoch set to 5 via CLUSTER SET-CONFIG-EPOCH</span><br><span class="line">4790:M 06 Feb 01:04:46.724 # configEpoch set to 6 via CLUSTER SET-CONFIG-EPOCH</span><br><span class="line">&gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster</span><br><span class="line">4722:M 06 Feb 01:04:46.747 # IP address for this node updated to 127.0.0.1</span><br><span class="line">4741:M 06 Feb 01:04:46.801 # IP address for this node updated to 127.0.0.1</span><br><span class="line">4790:M 06 Feb 01:04:46.801 # IP address for this node updated to 127.0.0.1</span><br><span class="line">4701:M 06 Feb 01:04:46.801 # IP address for this node updated to 127.0.0.1</span><br><span class="line">4756:M 06 Feb 01:04:46.802 # IP address for this node updated to 127.0.0.1</span><br><span class="line">4772:M 06 Feb 01:04:46.802 # IP address for this node updated to 127.0.0.1</span><br><span class="line">Waiting for the cluster to join...</span><br><span class="line">4701:S 06 Feb 01:04:50.766 # Cluster state changed: ok</span><br><span class="line">4772:S 06 Feb 01:04:50.768 # Cluster state changed: ok</span><br><span class="line">4790:S 06 Feb 01:04:50.769 # Cluster state changed: ok</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">M: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">S: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ 4701:S 06 Feb 01:04:51.318 * Connecting to MASTER 127.0.0.1:7000</span><br><span class="line">4701:S 06 Feb 01:04:51.318 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4701:S 06 Feb 01:04:51.318 * Non blocking connect for SYNC fired the event.</span><br><span class="line">4701:S 06 Feb 01:04:51.318 * Master replied to PING, replication can continue...</span><br><span class="line">4701:S 06 Feb 01:04:51.319 * Partial resynchronization not possible (no cached master)</span><br><span class="line">4722:M 06 Feb 01:04:51.319 * Slave 127.0.0.1:7003 asks for synchronization</span><br><span class="line">4722:M 06 Feb 01:04:51.319 * Full resync requested by slave 127.0.0.1:7003</span><br><span class="line">4722:M 06 Feb 01:04:51.319 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">4722:M 06 Feb 01:04:51.320 * Background saving started by pid 5685</span><br><span class="line">4701:S 06 Feb 01:04:51.321 * Full resync from master: 4e9540a7b3c5c6caeb88fd51d09a1ecfc067fd5b:1</span><br><span class="line">5685:C 06 Feb 01:04:51.348 * DB saved on disk</span><br><span class="line">5685:C 06 Feb 01:04:51.350 * RDB: 6 MB of memory used by copy-on-write</span><br><span class="line">4722:M 06 Feb 01:04:51.426 * Background saving terminated with success</span><br><span class="line">4722:M 06 Feb 01:04:51.426 * Synchronization with slave 127.0.0.1:7003 succeeded</span><br><span class="line">4701:S 06 Feb 01:04:51.426 * MASTER &lt;-&gt; SLAVE sync: receiving 77 bytes from master</span><br><span class="line">4701:S 06 Feb 01:04:51.427 * MASTER &lt;-&gt; SLAVE sync: Flushing old data</span><br><span class="line">4701:S 06 Feb 01:04:51.427 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory</span><br><span class="line">4701:S 06 Feb 01:04:51.427 * MASTER &lt;-&gt; SLAVE sync: Finished with success</span><br><span class="line">4701:S 06 Feb 01:04:51.428 * Background append only file rewriting started by pid 5686</span><br><span class="line">4701:S 06 Feb 01:04:51.462 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">5686:C 06 Feb 01:04:51.462 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">5686:C 06 Feb 01:04:51.462 * Concatenating 0.00 MB of AOF diff received from parent.</span><br><span class="line">5686:C 06 Feb 01:04:51.463 * SYNC append only file rewrite performed</span><br><span class="line">5686:C 06 Feb 01:04:51.463 * AOF rewrite: 6 MB of memory used by copy-on-write</span><br><span class="line">4701:S 06 Feb 01:04:51.519 * Background AOF rewrite terminated with success</span><br><span class="line">4701:S 06 Feb 01:04:51.520 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">4701:S 06 Feb 01:04:51.520 * Background AOF rewrite finished successfully</span><br><span class="line">4772:S 06 Feb 01:04:51.527 * Connecting to MASTER 127.0.0.1:7001</span><br><span class="line">4772:S 06 Feb 01:04:51.527 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4772:S 06 Feb 01:04:51.527 * Non blocking connect for SYNC fired the event.</span><br><span class="line">4772:S 06 Feb 01:04:51.528 * Master replied to PING, replication can continue...</span><br><span class="line">4772:S 06 Feb 01:04:51.529 * Partial resynchronization not possible (no cached master)</span><br><span class="line">4741:M 06 Feb 01:04:51.529 * Slave 127.0.0.1:7004 asks for synchronization</span><br><span class="line">4741:M 06 Feb 01:04:51.529 * Full resync requested by slave 127.0.0.1:7004</span><br><span class="line">4741:M 06 Feb 01:04:51.529 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">4741:M 06 Feb 01:04:51.532 * Background saving started by pid 5687</span><br><span class="line">4772:S 06 Feb 01:04:51.535 * Full resync from master: be30d158d2de1e2edf37e74dc2c3cee348d02410:1</span><br><span class="line">5687:C 06 Feb 01:04:51.565 * DB saved on disk</span><br><span class="line">5687:C 06 Feb 01:04:51.566 * RDB: 6 MB of memory used by copy-on-write</span><br><span class="line">4790:S 06 Feb 01:04:51.584 * Connecting to MASTER 127.0.0.1:7002</span><br><span class="line">4790:S 06 Feb 01:04:51.584 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4790:S 06 Feb 01:04:51.584 * Non blocking connect for SYNC fired the event.</span><br><span class="line">4790:S 06 Feb 01:04:51.585 * Master replied to PING, replication can continue...</span><br><span class="line">4790:S 06 Feb 01:04:51.585 * Partial resynchronization not possible (no cached master)</span><br><span class="line">4756:M 06 Feb 01:04:51.585 * Slave 127.0.0.1:7005 asks for synchronization</span><br><span class="line">4756:M 06 Feb 01:04:51.585 * Full resync requested by slave 127.0.0.1:7005</span><br><span class="line">4756:M 06 Feb 01:04:51.585 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">4756:M 06 Feb 01:04:51.586 * Background saving started by pid 5688</span><br><span class="line">4790:S 06 Feb 01:04:51.587 * Full resync from master: 11082aa273a96447d9bdad8a6a004ea85878ad65:1</span><br><span class="line">4741:M 06 Feb 01:04:51.599 * Background saving terminated with success</span><br><span class="line">4772:S 06 Feb 01:04:51.600 * MASTER &lt;-&gt; SLAVE sync: receiving 77 bytes from master</span><br><span class="line">4741:M 06 Feb 01:04:51.600 * Synchronization with slave 127.0.0.1:7004 succeeded</span><br><span class="line">4772:S 06 Feb 01:04:51.600 * MASTER &lt;-&gt; SLAVE sync: Flushing old data</span><br><span class="line">4772:S 06 Feb 01:04:51.600 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory</span><br><span class="line">4772:S 06 Feb 01:04:51.600 * MASTER &lt;-&gt; SLAVE sync: Finished with success</span><br><span class="line">5688:C 06 Feb 01:04:51.624 * DB saved on disk</span><br><span class="line">4772:S 06 Feb 01:04:51.625 * Background append only file rewriting started by pid 5689</span><br><span class="line">5688:C 06 Feb 01:04:51.625 * RDB: 6 MB of memory used by copy-on-write</span><br><span class="line">4722:M 06 Feb 01:04:51.627 # Cluster state changed: ok</span><br><span class="line">4772:S 06 Feb 01:04:51.663 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">5689:C 06 Feb 01:04:51.663 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">5689:C 06 Feb 01:04:51.663 * Concatenating 0.00 MB of AOF diff received from parent.</span><br><span class="line">5689:C 06 Feb 01:04:51.663 * SYNC append only file rewrite performed</span><br><span class="line">5689:C 06 Feb 01:04:51.664 * AOF rewrite: 6 MB of memory used by copy-on-write</span><br><span class="line">4756:M 06 Feb 01:04:51.665 * Background saving terminated with success</span><br><span class="line">4756:M 06 Feb 01:04:51.665 # Cluster state changed: ok</span><br><span class="line">4790:S 06 Feb 01:04:51.665 * MASTER &lt;-&gt; SLAVE sync: receiving 77 bytes from master</span><br><span class="line">4756:M 06 Feb 01:04:51.665 * Synchronization with slave 127.0.0.1:7005 succeeded</span><br><span class="line">4790:S 06 Feb 01:04:51.665 * MASTER &lt;-&gt; SLAVE sync: Flushing old data</span><br><span class="line">4790:S 06 Feb 01:04:51.665 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory</span><br><span class="line">4790:S 06 Feb 01:04:51.665 * MASTER &lt;-&gt; SLAVE sync: Finished with success</span><br><span class="line">4790:S 06 Feb 01:04:51.666 * Background append only file rewriting started by pid 5690</span><br><span class="line">4741:M 06 Feb 01:04:51.699 # Cluster state changed: ok</span><br><span class="line">4790:S 06 Feb 01:04:51.705 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">5690:C 06 Feb 01:04:51.705 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">5690:C 06 Feb 01:04:51.706 * Concatenating 0.00 MB of AOF diff received from parent.</span><br><span class="line">5690:C 06 Feb 01:04:51.706 * SYNC append only file rewrite performed</span><br><span class="line">5690:C 06 Feb 01:04:51.707 * AOF rewrite: 4 MB of memory used by copy-on-write</span><br><span class="line">4772:S 06 Feb 01:04:51.727 * Background AOF rewrite terminated with success</span><br><span class="line">4772:S 06 Feb 01:04:51.727 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">4772:S 06 Feb 01:04:51.727 * Background AOF rewrite finished successfully</span><br><span class="line">4790:S 06 Feb 01:04:51.785 * Background AOF rewrite terminated with success</span><br><span class="line">4790:S 06 Feb 01:04:51.785 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">4790:S 06 Feb 01:04:51.785 * Background AOF rewrite finished successfully</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以上为创建集群成功后的整个打印信息.</p>
<p>以下信息表示集群创建成功.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure>

<p>连接上集群,查看集群信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ .&#x2F;src&#x2F;redis-cli -h 127.0.0.1 -p 7005</span><br><span class="line">127.0.0.1:7005&gt; cluster info</span><br><span class="line">cluster_state:ok</span><br><span class="line">cluster_slots_assigned:16384</span><br><span class="line">cluster_slots_ok:16384</span><br><span class="line">cluster_slots_pfail:0</span><br><span class="line">cluster_slots_fail:0</span><br><span class="line">cluster_known_nodes:6</span><br><span class="line">cluster_size:3</span><br><span class="line">cluster_current_epoch:6</span><br><span class="line">cluster_my_epoch:3</span><br><span class="line">cluster_stats_messages_sent:1559</span><br><span class="line">cluster_stats_messages_received:1559</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="检查集群"><a href="#检查集群" class="headerlink" title="检查集群"></a>检查集群</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ .&#x2F;src&#x2F;redis-cli -c -p 7005</span><br><span class="line">127.0.0.1:7005&gt; get foo</span><br><span class="line">-&gt; Redirected to slot [12182] located at 127.0.0.1:7002</span><br><span class="line">&quot;bar&quot;</span><br><span class="line">127.0.0.1:7002&gt; set test test</span><br><span class="line">-&gt; Redirected to slot [6918] located at 127.0.0.1:7001</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7001&gt; get test</span><br><span class="line">&quot;test&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上面参数 -c表示集群客户端</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:7001&gt; get foo</span><br><span class="line">-&gt; Redirected to slot [12182] located at 127.0.0.1:7002</span><br><span class="line">&quot;bar&quot;</span><br><span class="line">127.0.0.1:7002&gt; get foo</span><br><span class="line">&quot;bar&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意以上语句 7002节点上存在foo/bar和cluster/test键值对,我们查看它对应的从节点7005的aof中存在的数据.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ cat -n appendonly.aof </span><br><span class="line">     1    *2</span><br><span class="line">     2    $6</span><br><span class="line">     3    SELECT</span><br><span class="line">     4    $1</span><br><span class="line">     5    0</span><br><span class="line">     6    *3</span><br><span class="line">     7    $3</span><br><span class="line">     8    set</span><br><span class="line">     9    $3</span><br><span class="line">    10    foo</span><br><span class="line">    11    $3</span><br><span class="line">    12    bar</span><br><span class="line">    13    *3</span><br><span class="line">    14    $3</span><br><span class="line">    15    set</span><br><span class="line">    16    $7</span><br><span class="line">    17    cluster</span><br><span class="line">    18    $4</span><br><span class="line">    19    test</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>aof中显示,7005节点存在两组键值对,表示主节点的数据同步到从节点上.</p>
<h2 id="集群故障"><a href="#集群故障" class="headerlink" title="集群故障"></a>集群故障</h2><p>查看集群的情况</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:7005&gt; cluster nodes</span><br><span class="line">442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005 myself,slave bb31a89640b381e8de18f15a845512f08ab9f16f 0 0 6 connected</span><br><span class="line">df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003 slave a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 0 1517851933524 4 connected</span><br><span class="line">0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001 master - 0 1517851932019 2 connected 5461-10922</span><br><span class="line">bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002 master - 0 1517851933023 3 connected 10923-16383</span><br><span class="line">37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004 slave 0ca3673dfd352052b651b3898ba3f807ff9c7f55 0 1517851932019 5 connected</span><br><span class="line">a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000 master - 0 1517851933023 1 connected 0-5460</span><br></pre></td></tr></table></figure>
<p>此时kill掉7000</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ ps -ef|grep redis</span><br><span class="line">root      4700  3041  0 00:56 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4701  4700  0 00:56 pts&#x2F;4    00:00:04 .&#x2F;src&#x2F;redis-server 127.0.0.1:7003 [cluster]</span><br><span class="line">root      4721  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4722  4721  0 00:57 pts&#x2F;4    00:00:04 .&#x2F;src&#x2F;redis-server 127.0.0.1:7000 [cluster]</span><br><span class="line">root      4740  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4741  4740  0 00:57 pts&#x2F;4    00:00:04 .&#x2F;src&#x2F;redis-server 127.0.0.1:7001 [cluster]</span><br><span class="line">root      4755  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4756  4755  0 00:57 pts&#x2F;4    00:00:04 .&#x2F;src&#x2F;redis-server 127.0.0.1:7002 [cluster]</span><br><span class="line">root      4771  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4772  4771  0 00:57 pts&#x2F;4    00:00:04 .&#x2F;src&#x2F;redis-server 127.0.0.1:7004 [cluster]</span><br><span class="line">root      4789  3041  0 00:58 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4790  4789  0 00:58 pts&#x2F;4    00:00:04 .&#x2F;src&#x2F;redis-server 127.0.0.1:7005 [cluster]</span><br><span class="line">zhuning+ 10601  3041  0 01:33 pts&#x2F;4    00:00:00 grep --color&#x3D;auto redis</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ sudo kill -9 4722</span><br><span class="line">[sudo] password for zhuningning: </span><br><span class="line">4701:S 06 Feb 01:34:11.707 # Connection with master lost.</span><br><span class="line">4701:S 06 Feb 01:34:11.707 * Caching the disconnected master state.</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7005$ 4701:S 06 Feb 01:34:12.163 * Connecting to MASTER 127.0.0.1:7000</span><br><span class="line">4701:S 06 Feb 01:34:12.163 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4701:S 06 Feb 01:34:12.163 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">4701:S 06 Feb 01:34:13.168 * Connecting to MASTER 127.0.0.1:7000</span><br><span class="line">4701:S 06 Feb 01:34:13.169 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4701:S 06 Feb 01:34:13.169 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">4701:S 06 Feb 01:34:14.174 * Connecting to MASTER 127.0.0.1:7000</span><br><span class="line">4701:S 06 Feb 01:34:14.175 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4701:S 06 Feb 01:34:14.175 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">4701:S 06 Feb 01:34:15.180 * Connecting to MASTER 127.0.0.1:7000</span><br><span class="line">4701:S 06 Feb 01:34:15.181 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4701:S 06 Feb 01:34:15.181 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">4701:S 06 Feb 01:34:16.186 * Connecting to MASTER 127.0.0.1:7000</span><br><span class="line">4701:S 06 Feb 01:34:16.186 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4701:S 06 Feb 01:34:16.186 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">4701:S 06 Feb 01:34:17.190 * Connecting to MASTER 127.0.0.1:7000</span><br><span class="line">4701:S 06 Feb 01:34:17.190 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4701:S 06 Feb 01:34:17.190 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">4790:S 06 Feb 01:34:17.769 * Marking node a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 as failing (quorum reached).</span><br><span class="line">4790:S 06 Feb 01:34:17.769 # Cluster state changed: fail</span><br><span class="line">4756:M 06 Feb 01:34:18.088 * Marking node a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 as failing (quorum reached).</span><br><span class="line">4756:M 06 Feb 01:34:18.088 # Cluster state changed: fail</span><br><span class="line">4741:M 06 Feb 01:34:18.089 * FAIL message received from bb31a89640b381e8de18f15a845512f08ab9f16f about a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4</span><br><span class="line">4701:S 06 Feb 01:34:18.089 * FAIL message received from bb31a89640b381e8de18f15a845512f08ab9f16f about a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4</span><br><span class="line">4772:S 06 Feb 01:34:18.089 * FAIL message received from bb31a89640b381e8de18f15a845512f08ab9f16f about a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4</span><br><span class="line">4701:S 06 Feb 01:34:18.089 # Cluster state changed: fail</span><br><span class="line">4741:M 06 Feb 01:34:18.089 # Cluster state changed: fail</span><br><span class="line">4772:S 06 Feb 01:34:18.089 # Cluster state changed: fail</span><br><span class="line">4701:S 06 Feb 01:34:18.094 # Start of election delayed for 515 milliseconds (rank #0, offset 2465).</span><br><span class="line">4701:S 06 Feb 01:34:18.194 * Connecting to MASTER 127.0.0.1:7000</span><br><span class="line">4701:S 06 Feb 01:34:18.194 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">4701:S 06 Feb 01:34:18.194 # Error condition on socket for SYNC: Connection refused</span><br><span class="line">4701:S 06 Feb 01:34:18.697 # Starting a failover election for epoch 7.</span><br><span class="line">4756:M 06 Feb 01:34:18.740 # Failover auth granted to df9ac983886f0f09b0c62feef9288a9296a1a08c for epoch 7</span><br><span class="line">4741:M 06 Feb 01:34:18.740 # Failover auth granted to df9ac983886f0f09b0c62feef9288a9296a1a08c for epoch 7</span><br><span class="line">4701:S 06 Feb 01:34:18.740 # Failover election won: I&#39;m the new master.</span><br><span class="line">4701:S 06 Feb 01:34:18.740 # configEpoch set to 7 after successful failover</span><br><span class="line">4701:M 06 Feb 01:34:18.740 * Discarding previously cached master state.</span><br><span class="line">4701:M 06 Feb 01:34:18.740 # Cluster state changed: ok</span><br><span class="line">4756:M 06 Feb 01:34:18.782 # Cluster state changed: ok</span><br><span class="line">4772:S 06 Feb 01:34:18.782 # Cluster state changed: ok</span><br><span class="line">4741:M 06 Feb 01:34:18.782 # Cluster state changed: ok</span><br><span class="line">4790:S 06 Feb 01:34:18.782 # Cluster state changed: ok</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以上信息表示,在五秒的尝试连接7000节点,发现其连接不上.某个节点首先将其标识为fail状态,然后通过节点间通讯,各个节点都将7000节点对应的状态置为fail状态,然后各个节点将集群状态标识为fail状态.然后各个节点为7000节点的从节点投票选举出7003(在这7000只有一个从节点)为主节点,代替元7000的工作(管理其对应的槽位),然后集群状态恢复.</p>
<p>此时集群状态如下: 7000 节点此时为fail状态,集群中正常的节点有5个.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:7005&gt; cluster nodes</span><br><span class="line">442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005 myself,slave bb31a89640b381e8de18f15a845512f08ab9f16f 0 0 6 connected</span><br><span class="line">df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003 master - 0 1517852576553 7 connected 0-5460</span><br><span class="line">0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001 master - 0 1517852576054 2 connected 5461-10922</span><br><span class="line">bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002 master - 0 1517852575048 3 connected 10923-16383</span><br><span class="line">37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004 slave 0ca3673dfd352052b651b3898ba3f807ff9c7f55 0 1517852575552 5 connected</span><br><span class="line">a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000 master,fail - 1517852051773 1517852049869 1 disconnected</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="故障节点恢复"><a href="#故障节点恢复" class="headerlink" title="故障节点恢复"></a>故障节点恢复</h2><p>恢复节点7000</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7000$ sudo .&#x2F;src&#x2F;redis-server redis.conf &amp;</span><br><span class="line"></span><br><span class="line">13569:M 06 Feb 01:45:53.163 # Server started, Redis version 3.2.11</span><br><span class="line">13569:M 06 Feb 01:45:53.163 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &#39;vm.overcommit_memory &#x3D; 1&#39; to &#x2F;etc&#x2F;sysctl.conf and then reboot or run the command &#39;sysctl vm.overcommit_memory&#x3D;1&#39; for this to take effect.</span><br><span class="line">13569:M 06 Feb 01:45:53.163 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &#39;echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled&#39; as root, and add it to your &#x2F;etc&#x2F;rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.</span><br><span class="line">13569:M 06 Feb 01:45:53.164 * The server is now ready to accept connections on port 7000</span><br><span class="line">13569:M 06 Feb 01:45:53.165 # Configuration change detected. Reconfiguring myself as a replica of df9ac983886f0f09b0c62feef9288a9296a1a08c</span><br><span class="line">13569:S 06 Feb 01:45:53.166 # Cluster state changed: ok</span><br><span class="line">4756:M 06 Feb 01:45:53.247 * Clear FAIL state for node a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4: master without slots is reachable again.</span><br><span class="line">4790:S 06 Feb 01:45:53.247 * Clear FAIL state for node a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4: master without slots is reachable again.</span><br><span class="line">4772:S 06 Feb 01:45:53.254 * Clear FAIL state for node a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4: master without slots is reachable again.</span><br><span class="line">4701:M 06 Feb 01:45:53.259 * Clear FAIL state for node a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4: master without slots is reachable again.</span><br><span class="line">4741:M 06 Feb 01:45:53.261 * Clear FAIL state for node a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4: master without slots is reachable again.</span><br><span class="line">13569:S 06 Feb 01:45:54.168 * Connecting to MASTER 127.0.0.1:7003</span><br><span class="line">13569:S 06 Feb 01:45:54.168 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">13569:S 06 Feb 01:45:54.168 * Non blocking connect for SYNC fired the event.</span><br><span class="line">13569:S 06 Feb 01:45:54.168 * Master replied to PING, replication can continue...</span><br><span class="line">13569:S 06 Feb 01:45:54.169 * Partial resynchronization not possible (no cached master)</span><br><span class="line">4701:M 06 Feb 01:45:54.169 * Slave 127.0.0.1:7000 asks for synchronization</span><br><span class="line">4701:M 06 Feb 01:45:54.169 * Full resync requested by slave 127.0.0.1:7000</span><br><span class="line">4701:M 06 Feb 01:45:54.169 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">4701:M 06 Feb 01:45:54.170 * Background saving started by pid 13572</span><br><span class="line">13569:S 06 Feb 01:45:54.171 * Full resync from master: cecbe45078fac08152e9ca95d7741ae086b4ea68:1</span><br><span class="line">13572:C 06 Feb 01:45:54.218 * DB saved on disk</span><br><span class="line">13572:C 06 Feb 01:45:54.219 * RDB: 6 MB of memory used by copy-on-write</span><br><span class="line">4701:M 06 Feb 01:45:54.261 * Background saving terminated with success</span><br><span class="line">13569:S 06 Feb 01:45:54.261 * MASTER &lt;-&gt; SLAVE sync: receiving 77 bytes from master</span><br><span class="line">4701:M 06 Feb 01:45:54.261 * Synchronization with slave 127.0.0.1:7000 succeeded</span><br><span class="line">13569:S 06 Feb 01:45:54.262 * MASTER &lt;-&gt; SLAVE sync: Flushing old data</span><br><span class="line">13569:S 06 Feb 01:45:54.262 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory</span><br><span class="line">13569:S 06 Feb 01:45:54.262 * MASTER &lt;-&gt; SLAVE sync: Finished with success</span><br><span class="line">13569:S 06 Feb 01:45:54.281 * Background append only file rewriting started by pid 13573</span><br><span class="line">13569:S 06 Feb 01:45:54.333 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">13573:C 06 Feb 01:45:54.333 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">13573:C 06 Feb 01:45:54.333 * Concatenating 0.00 MB of AOF diff received from parent.</span><br><span class="line">13573:C 06 Feb 01:45:54.334 * SYNC append only file rewrite performed</span><br><span class="line">13573:C 06 Feb 01:45:54.334 * AOF rewrite: 4 MB of memory used by copy-on-write</span><br><span class="line">13569:S 06 Feb 01:45:54.382 * Background AOF rewrite terminated with success</span><br><span class="line">13569:S 06 Feb 01:45:54.382 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">13569:S 06 Feb 01:45:54.382 * Background AOF rewrite finished successfully</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以下两种方式检查集群的状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7000$ .&#x2F;src&#x2F;redis-cli -c -p 7000</span><br><span class="line">127.0.0.1:7000&gt; cluster nodes</span><br><span class="line">37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004 slave 0ca3673dfd352052b651b3898ba3f807ff9c7f55 0 1517852872929 5 connected</span><br><span class="line">df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003 master - 0 1517852872427 7 connected 0-5460</span><br><span class="line">442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005 slave bb31a89640b381e8de18f15a845512f08ab9f16f 0 1517852873431 6 connected</span><br><span class="line">bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002 master - 0 1517852873431 3 connected 10923-16383</span><br><span class="line">0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001 master - 0 1517852871424 2 connected 5461-10922</span><br><span class="line">a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000 myself,slave df9ac983886f0f09b0c62feef9288a9296a1a08c 0 0 1 connected</span><br><span class="line">127.0.0.1:7000&gt; quit</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7000$ .&#x2F;src&#x2F;redis-trib.rb check 127.0.0.1:7001</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7001)</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates df9ac983886f0f09b0c62feef9288a9296a1a08c</span><br><span class="line">M: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>此时7000节点变为7003节点的从节点</p>
<h2 id="集群中新加入删除节点"><a href="#集群中新加入删除节点" class="headerlink" title="集群中新加入删除节点"></a>集群中新加入删除节点</h2><h3 id="作为主节点加入"><a href="#作为主节点加入" class="headerlink" title="作为主节点加入"></a>作为主节点加入</h3><p>新复制一个节点7006,修改其端口号配置,然后启动.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster$ sudo mkdir 7006 </span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster$ sudo cp redis-3.2.11&#x2F;* -r 7006&#x2F;</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster$ cd 7006</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7006$ sudo .&#x2F;src&#x2F;redis-server redis.conf &amp;</span><br><span class="line">[8] 15048</span><br><span class="line"></span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7006$ ps -ef|grep redis</span><br><span class="line">root      4700  3041  0 00:56 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4701  4700  0 00:56 pts&#x2F;4    00:00:09 .&#x2F;src&#x2F;redis-server 127.0.0.1:7003 [cluster]</span><br><span class="line">root      4740  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4741  4740  0 00:57 pts&#x2F;4    00:00:09 .&#x2F;src&#x2F;redis-server 127.0.0.1:7001 [cluster]</span><br><span class="line">root      4755  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4756  4755  0 00:57 pts&#x2F;4    00:00:09 .&#x2F;src&#x2F;redis-server 127.0.0.1:7002 [cluster]</span><br><span class="line">root      4771  3041  0 00:57 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4772  4771  0 00:57 pts&#x2F;4    00:00:08 .&#x2F;src&#x2F;redis-server 127.0.0.1:7004 [cluster]</span><br><span class="line">root      4789  3041  0 00:58 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root      4790  4789  0 00:58 pts&#x2F;4    00:00:09 .&#x2F;src&#x2F;redis-server 127.0.0.1:7005 [cluster]</span><br><span class="line">root     13568  3041  0 01:45 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root     13569 13568  0 01:45 pts&#x2F;4    00:00:01 .&#x2F;src&#x2F;redis-server 127.0.0.1:7000 [cluster]</span><br><span class="line">root     15048  3041  0 01:55 pts&#x2F;4    00:00:00 sudo .&#x2F;src&#x2F;redis-server redis.conf</span><br><span class="line">root     15049 15048  0 01:55 pts&#x2F;4    00:00:00 .&#x2F;src&#x2F;redis-server 127.0.0.1:7006 [cluster]</span><br><span class="line">zhuning+ 15139  3041  0 01:55 pts&#x2F;4    00:00:00 grep --color&#x3D;auto redis</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>加入新节点7006</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7006$ .&#x2F;src&#x2F;redis-trib.rb add-node 127.0.0.1:7006 127.0.0.1:7000</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; Adding node 127.0.0.1:7006 to cluster 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">S: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates df9ac983886f0f09b0c62feef9288a9296a1a08c</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">M: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">&gt;&gt;&gt; Send CLUSTER MEET to node 127.0.0.1:7006 to make it join the cluster.</span><br><span class="line">[OK] New node added correctly.</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7006$ 15049:M 06 Feb 01:57:40.626 # IP address for this node updated to 127.0.0.1</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7006$ 15049:M 06 Feb 01:57:45.733 # Cluster state changed: ok</span><br></pre></td></tr></table></figure>

<p>add-node是加入指令，127.0.0.1:7006 表示新加入的节点，127.0.0.1:7000 表示加入的集群的一个节点，用来辨识是哪个集群，理论上哪个都可以。</p>
<p>检查集群状态,此时7006为master节点,处于无槽位状态.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7006$ .&#x2F;src&#x2F;redis-trib.rb check 127.0.0.1:7006</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7006)</span><br><span class="line">M: 54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">   0 additional replica(s)</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">M: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates df9ac983886f0f09b0c62feef9288a9296a1a08c</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>看来，redis cluster 不是在新加节点的时候帮我们做好了迁移工作，需要我们手动对集群进行重新分片迁移，也是这个命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7006$ .&#x2F;src&#x2F;redis-trib.rb reshard 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">S: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates df9ac983886f0f09b0c62feef9288a9296a1a08c</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">M: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">   0 additional replica(s)</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">How many slots do you want to move (from 1 to 16384)? 4096</span><br><span class="line">What is the receiving node ID? efc3131fbdc6cf929720e0e0f7136cae85657481</span><br><span class="line">*** The specified node is not known or not a master, please retry.</span><br><span class="line">What is the receiving node ID? 54fe323634d8830f2ef93feaaedb2b70e19d0765</span><br><span class="line">Please enter all the source node IDs.</span><br><span class="line">  Type &#39;all&#39; to use all the nodes as source nodes for the hash slots.</span><br><span class="line">  Type &#39;done&#39; once you entered all the source nodes IDs.</span><br><span class="line">Source node #1:all</span><br><span class="line"></span><br><span class="line">Ready to move 4096 slots.</span><br><span class="line">  Source nodes:</span><br><span class="line">    M: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">    M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">    M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">  Destination node:</span><br><span class="line">    M: 54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">   0 additional replica(s)</span><br><span class="line">  Resharding plan:</span><br><span class="line">    Moving slot 5461 from 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>第一个问句 how many slots do you want to move 平均的4096个</p>
<p>第二个问句,接收节点的id :7006对应的节点id:efc3131fbdc6cf929720e0e0f7136cae85657481</p>
<p>第三个问句,从哪获取这些槽位,  如果我们不打算从特定的节点上取出指定数量的哈希槽， 那么可以向 redis-trib 输入 all ， 这样的话， 集群中的所有主节点都会成为源节点.</p>
<p>它会提示是否迁移,输入yes即可,但是最后出现如下的error,查阅资料说时cluster的 <a href="https://github.com/antirez/redis/issues/4272">bug</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ERR] Calling MIGRATE: ERR Syntax error, try CLIENT (LIST | KILL | GETNAME | SETNAME | PAUSE | REPLY)</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7006$ .&#x2F;src&#x2F;redis-trib.rb reshard 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">S: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates df9ac983886f0f09b0c62feef9288a9296a1a08c</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">M: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   slots:1365-5460 (4096 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006</span><br><span class="line">   slots:0-1364,5461-6826,10923-12181 (3990 slots) master</span><br><span class="line">   0 additional replica(s)</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:12182-16383 (4202 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:6827-10922 (4096 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">[WARNING] Node 127.0.0.1:7006 has slots in importing state (12182).</span><br><span class="line">[WARNING] Node 127.0.0.1:7002 has slots in migrating state (12182).</span><br><span class="line">[WARNING] The following slots are open: 12182</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">*** Please fix your cluster problems before resharding</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>12182这个数字看着比较熟悉,原来是之前的该槽位中有数据.暂时还么有解决.(???????????)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7006$ .&#x2F;src&#x2F;redis-cli -c -p 7006</span><br><span class="line">127.0.0.1:7006&gt; cluster nodes</span><br><span class="line">37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004 slave 0ca3673dfd352052b651b3898ba3f807ff9c7f55 0 1517854904123 2 connected</span><br><span class="line">df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003 master - 0 1517854903119 7 connected 1365-5460</span><br><span class="line">442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005 slave bb31a89640b381e8de18f15a845512f08ab9f16f 0 1517854903119 3 connected</span><br><span class="line">bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002 master - 0 1517854903621 3 connected 12182-16383</span><br><span class="line">54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006 myself,master - 0 0 8 connected 0-1364 5461-6826 10923-12181 [12182-&lt;-bb31a89640b381e8de18f15a845512f08ab9f16f]</span><br><span class="line">0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001 master - 0 1517854903621 2 connected 6827-10922</span><br><span class="line">a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000 slave df9ac983886f0f09b0c62feef9288a9296a1a08c 0 1517854902617 7 connected</span><br><span class="line">127.0.0.1:7006&gt; cluster info</span><br><span class="line">cluster_state:ok</span><br><span class="line">cluster_slots_assigned:16384</span><br><span class="line">cluster_slots_ok:16384</span><br><span class="line">cluster_slots_pfail:0</span><br><span class="line">cluster_slots_fail:0</span><br><span class="line">cluster_known_nodes:7</span><br><span class="line">cluster_size:4</span><br><span class="line">cluster_current_epoch:8</span><br><span class="line">cluster_my_epoch:8</span><br><span class="line">cluster_stats_messages_sent:7375</span><br><span class="line">cluster_stats_messages_received:7362</span><br><span class="line"></span><br><span class="line">127.0.0.1:7001&gt; set age 100</span><br><span class="line">-&gt; Redirected to slot [741] located at 127.0.0.1:7006</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7006&gt; get age</span><br><span class="line">&quot;100&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>暂时集群时可以用的,不知道以上的error有啥影响.</p>
<h3 id="新建一个7007从节点"><a href="#新建一个7007从节点" class="headerlink" title="新建一个7007从节点"></a>新建一个7007从节点</h3><p>新建一个节点,启动和之前类似,不做描述.</p>
<p>加入一个新节点,7007 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7007$ .&#x2F;src&#x2F;redis-trib.rb add-node --slave 127.0.0.1:7007 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Adding node 127.0.0.1:7007 to cluster 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">S: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates df9ac983886f0f09b0c62feef9288a9296a1a08c</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">M: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   slots:1365-5460 (4096 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006</span><br><span class="line">   slots:0-1364,5461-6826,10923-12181 (3990 slots) master</span><br><span class="line">   0 additional replica(s)</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:12182-16383 (4202 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:6827-10922 (4096 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">[WARNING] Node 127.0.0.1:7006 has slots in importing state (12182).</span><br><span class="line">[WARNING] Node 127.0.0.1:7002 has slots in migrating state (12182).</span><br><span class="line">[WARNING] The following slots are open: 12182</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">Automatically selected master 127.0.0.1:7006</span><br><span class="line">&gt;&gt;&gt; Send CLUSTER MEET to node 127.0.0.1:7007 to make it join the cluster.</span><br><span class="line">Waiting for the cluster to join.20427:M 06 Feb 02:30:11.160 # IP address for this node updated to 127.0.0.1</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; Configure node as replica of 127.0.0.1:7006.</span><br><span class="line">20427:S 06 Feb 02:30:12.032 # Cluster state changed: ok</span><br><span class="line">[OK] New node added correctly.</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7007$ 20427:S 06 Feb 02:30:12.136 * Connecting to MASTER 127.0.0.1:7006</span><br><span class="line">20427:S 06 Feb 02:30:12.136 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">20427:S 06 Feb 02:30:12.136 * Non blocking connect for SYNC fired the event.</span><br><span class="line">20427:S 06 Feb 02:30:12.136 * Master replied to PING, replication can continue...</span><br><span class="line">20427:S 06 Feb 02:30:12.137 * Partial resynchronization not possible (no cached master)</span><br><span class="line">15049:M 06 Feb 02:30:12.137 * Slave 127.0.0.1:7007 asks for synchronization</span><br><span class="line">15049:M 06 Feb 02:30:12.137 * Full resync requested by slave 127.0.0.1:7007</span><br><span class="line">15049:M 06 Feb 02:30:12.137 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">15049:M 06 Feb 02:30:12.138 * Background saving started by pid 20906</span><br><span class="line">20427:S 06 Feb 02:30:12.139 * Full resync from master: defd3e21a2f15f27e3319035074c5002d4ff4b1b:1</span><br><span class="line">20906:C 06 Feb 02:30:12.500 * DB saved on disk</span><br><span class="line">20906:C 06 Feb 02:30:12.501 * RDB: 6 MB of memory used by copy-on-write</span><br><span class="line">15049:M 06 Feb 02:30:12.509 * Background saving terminated with success</span><br><span class="line">20427:S 06 Feb 02:30:12.510 * MASTER &lt;-&gt; SLAVE sync: receiving 89 bytes from master</span><br><span class="line">15049:M 06 Feb 02:30:12.510 * Synchronization with slave 127.0.0.1:7007 succeeded</span><br><span class="line">20427:S 06 Feb 02:30:12.510 * MASTER &lt;-&gt; SLAVE sync: Flushing old data</span><br><span class="line">20427:S 06 Feb 02:30:12.510 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory</span><br><span class="line">20427:S 06 Feb 02:30:12.510 * MASTER &lt;-&gt; SLAVE sync: Finished with success</span><br><span class="line">20427:S 06 Feb 02:30:12.512 * Background append only file rewriting started by pid 20907</span><br><span class="line">20427:S 06 Feb 02:30:12.581 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">20907:C 06 Feb 02:30:12.582 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">20907:C 06 Feb 02:30:12.582 * Concatenating 0.00 MB of AOF diff received from parent.</span><br><span class="line">20907:C 06 Feb 02:30:12.582 * SYNC append only file rewrite performed</span><br><span class="line">20907:C 06 Feb 02:30:12.583 * AOF rewrite: 6 MB of memory used by copy-on-write</span><br><span class="line">20427:S 06 Feb 02:30:12.639 * Background AOF rewrite terminated with success</span><br><span class="line">20427:S 06 Feb 02:30:12.639 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">20427:S 06 Feb 02:30:12.639 * Background AOF rewrite finished successfully</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>add-node的时候加上–slave表示是加入到从节点中，但是这样加，是随机的。这里的命令行完全像我们在添加一个新主服务器时使用的一样，所以我们没有指定要给哪个主服 务器添加副本。这种情况下，redis-trib 会将7007作为一个具有较少副本的随机的主服务器的副本。</p>
<ul>
<li>加入从节点,为该从节点指定一个主节点 </li>
</ul>
<p>新建7008节点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7008$ .&#x2F;src&#x2F;redis-trib.rb add-node --slave --master-id df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7008 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Adding node 127.0.0.1:7008 to cluster 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">S: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates df9ac983886f0f09b0c62feef9288a9296a1a08c</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">M: df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003</span><br><span class="line">   slots:1365-5460 (4096 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: db439109563a804d8d63ffdb6937baf88adde5cc 127.0.0.1:7007</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 54fe323634d8830f2ef93feaaedb2b70e19d0765</span><br><span class="line">M: 54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006</span><br><span class="line">   slots:0-1364,5461-6826,10923-12181 (3990 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:12182-16383 (4202 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:6827-10922 (4096 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">[WARNING] Node 127.0.0.1:7006 has slots in importing state (12182).</span><br><span class="line">[WARNING] Node 127.0.0.1:7002 has slots in migrating state (12182).</span><br><span class="line">[WARNING] The following slots are open: 12182</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">&gt;&gt;&gt; Send CLUSTER MEET to node 127.0.0.1:7008 to make it join the cluster.</span><br><span class="line">Waiting for the cluster to join.21391:M 06 Feb 02:36:05.351 # IP address for this node updated to 127.0.0.1</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; Configure node as replica of 127.0.0.1:7003.</span><br><span class="line">21391:S 06 Feb 02:36:06.188 # Cluster state changed: ok</span><br><span class="line">[OK] New node added correctly.</span><br><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7008$ 21391:S 06 Feb 02:36:06.612 * Connecting to MASTER 127.0.0.1:7003</span><br><span class="line">21391:S 06 Feb 02:36:06.612 * MASTER &lt;-&gt; SLAVE sync started</span><br><span class="line">21391:S 06 Feb 02:36:06.612 * Non blocking connect for SYNC fired the event.</span><br><span class="line">21391:S 06 Feb 02:36:06.613 * Master replied to PING, replication can continue...</span><br><span class="line">21391:S 06 Feb 02:36:06.613 * Partial resynchronization not possible (no cached master)</span><br><span class="line">4701:M 06 Feb 02:36:06.613 * Slave 127.0.0.1:7008 asks for synchronization</span><br><span class="line">4701:M 06 Feb 02:36:06.614 * Full resync requested by slave 127.0.0.1:7008</span><br><span class="line">4701:M 06 Feb 02:36:06.614 * Starting BGSAVE for SYNC with target: disk</span><br><span class="line">4701:M 06 Feb 02:36:06.616 * Background saving started by pid 21659</span><br><span class="line">21391:S 06 Feb 02:36:06.617 * Full resync from master: cecbe45078fac08152e9ca95d7741ae086b4ea68:4201</span><br><span class="line">21659:C 06 Feb 02:36:06.659 * DB saved on disk</span><br><span class="line">21659:C 06 Feb 02:36:06.660 * RDB: 8 MB of memory used by copy-on-write</span><br><span class="line">4701:M 06 Feb 02:36:06.753 * Background saving terminated with success</span><br><span class="line">4701:M 06 Feb 02:36:06.753 * Synchronization with slave 127.0.0.1:7008 succeeded</span><br><span class="line">21391:S 06 Feb 02:36:06.753 * MASTER &lt;-&gt; SLAVE sync: receiving 77 bytes from master</span><br><span class="line">21391:S 06 Feb 02:36:06.754 * MASTER &lt;-&gt; SLAVE sync: Flushing old data</span><br><span class="line">21391:S 06 Feb 02:36:06.754 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory</span><br><span class="line">21391:S 06 Feb 02:36:06.754 * MASTER &lt;-&gt; SLAVE sync: Finished with success</span><br><span class="line">21391:S 06 Feb 02:36:06.755 * Background append only file rewriting started by pid 21660</span><br><span class="line">21391:S 06 Feb 02:36:06.790 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">21660:C 06 Feb 02:36:06.790 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">21660:C 06 Feb 02:36:06.791 * Concatenating 0.00 MB of AOF diff received from parent.</span><br><span class="line">21660:C 06 Feb 02:36:06.791 * SYNC append only file rewrite performed</span><br><span class="line">21660:C 06 Feb 02:36:06.792 * AOF rewrite: 6 MB of memory used by copy-on-write</span><br><span class="line">21391:S 06 Feb 02:36:06.814 * Background AOF rewrite terminated with success</span><br><span class="line">21391:S 06 Feb 02:36:06.814 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">21391:S 06 Feb 02:36:06.814 * Background AOF rewrite finished successfully</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>–master-id 指定7003节点成为7008节点的主节点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7008$ .&#x2F;src&#x2F;redis-cli -c -p 7008 </span><br><span class="line">127.0.0.1:7008&gt; cluster nodes</span><br><span class="line">db439109563a804d8d63ffdb6937baf88adde5cc 127.0.0.1:7007 slave 54fe323634d8830f2ef93feaaedb2b70e19d0765 0 1517855860750 8 connected</span><br><span class="line">bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002 master - 0 1517855861752 3 connected 12182-16383</span><br><span class="line">54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006 master - 0 1517855861751 8 connected 0-1364 5461-6826 10923-12181</span><br><span class="line">df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003 master - 0 1517855859747 7 connected 1365-5460</span><br><span class="line">0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001 master - 0 1517855860248 2 connected 6827-10922</span><br><span class="line">37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004 slave 0ca3673dfd352052b651b3898ba3f807ff9c7f55 0 1517855861251 2 connected</span><br><span class="line">442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005 slave bb31a89640b381e8de18f15a845512f08ab9f16f 0 1517855860750 3 connected</span><br><span class="line">c29ea305fc8283a9987629b10dbc2ccae97c0c38 127.0.0.1:7008 myself,slave df9ac983886f0f09b0c62feef9288a9296a1a08c 0 0 0 connected</span><br><span class="line">a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000 slave df9ac983886f0f09b0c62feef9288a9296a1a08c 0 1517855860248 7 connected</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>7003是7008和7000的主节点,kill掉70003,7000成为主节点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:7008&gt; cluster nodes</span><br><span class="line">db439109563a804d8d63ffdb6937baf88adde5cc 127.0.0.1:7007 slave 54fe323634d8830f2ef93feaaedb2b70e19d0765 0 1517856011263 8 connected</span><br><span class="line">bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002 master - 0 1517856010761 3 connected 12182-16383</span><br><span class="line">54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006 master - 0 1517856010862 8 connected 0-1364 5461-6826 10923-12181</span><br><span class="line">df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003 master,fail - 1517855992209 1517855990103 7 disconnected</span><br><span class="line">0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001 master - 0 1517856009257 2 connected 6827-10922</span><br><span class="line">37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004 slave 0ca3673dfd352052b651b3898ba3f807ff9c7f55 0 1517856010761 2 connected</span><br><span class="line">442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005 slave bb31a89640b381e8de18f15a845512f08ab9f16f 0 1517856009757 3 connected</span><br><span class="line">c29ea305fc8283a9987629b10dbc2ccae97c0c38 127.0.0.1:7008 myself,slave a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 0 0 0 connected</span><br><span class="line">a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000 master - 0 1517856010258 9 connected 1365-5460</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="移除一个主节点"><a href="#移除一个主节点" class="headerlink" title="移除一个主节点"></a>移除一个主节点</h3><p>和新加节点有点不同的是，移除需要节点的node-id。那我们尝试将7002这个主节点移除：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7008$ .&#x2F;src&#x2F;redis-trib.rb del-node 127.0.0.1:7000 bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">&gt;&gt;&gt; Removing node bb31a89640b381e8de18f15a845512f08ab9f16f from cluster 127.0.0.1:7000</span><br><span class="line">[ERR] Node 127.0.0.1:7002 is not empty! Reshard data away and try again.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>提示节点非空,需要重新分片</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7008$ .&#x2F;src&#x2F;redis-trib.rb reshard 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)</span><br><span class="line">M: a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000</span><br><span class="line">   slots:1365-5460 (4096 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: db439109563a804d8d63ffdb6937baf88adde5cc 127.0.0.1:7007</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 54fe323634d8830f2ef93feaaedb2b70e19d0765</span><br><span class="line">M: 54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006</span><br><span class="line">   slots:0-1364,5461-6826,10923-12181 (3990 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001</span><br><span class="line">   slots:6827-10922 (4096 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: c29ea305fc8283a9987629b10dbc2ccae97c0c38 127.0.0.1:7008</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4</span><br><span class="line">S: 37b5d56cbce25be2e3ad25b52ce39e3e4885654e 127.0.0.1:7004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 0ca3673dfd352052b651b3898ba3f807ff9c7f55</span><br><span class="line">S: 442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates bb31a89640b381e8de18f15a845512f08ab9f16f</span><br><span class="line">M: bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002</span><br><span class="line">   slots:12182-16383 (4202 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">[WARNING] Node 127.0.0.1:7006 has slots in importing state (12182).</span><br><span class="line">[WARNING] Node 127.0.0.1:7002 has slots in migrating state (12182).</span><br><span class="line">[WARNING] The following slots are open: 12182</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line">*** Please fix your cluster problems before resharding</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>由于上面的error,现在不能重新分片,所以暂时没办法演示删除主节点.如果你的可以重新分片,则将7002中的槽位移动到其它某个master节点(不知道slave节点是否可以,读者可以自行实验).</p>
<p>然后重新执行删除操作即可.</p>
<h3 id="移除一个从节点"><a href="#移除一个从节点" class="headerlink" title="移除一个从节点"></a>移除一个从节点</h3><p>由于不考虑数据迁移,则直接删除即可,在此删除从节点7004</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zhuningning@ubuntu:&#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7008$ .&#x2F;src&#x2F;redis-trib.rb del-node 127.0.0.1:7000 37b5d56cbce25be2e3ad25b52ce39e3e4885654e</span><br><span class="line">&gt;&gt;&gt; Removing node 37b5d56cbce25be2e3ad25b52ce39e3e4885654e from cluster 127.0.0.1:7000</span><br><span class="line">&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...</span><br><span class="line">&gt;&gt;&gt; SHUTDOWN the node.</span><br><span class="line">4772:S 06 Feb 02:52:42.770 # User requested shutdown...</span><br><span class="line">4772:S 06 Feb 02:52:42.770 * Calling fsync() on the AOF file.</span><br><span class="line">4772:S 06 Feb 02:52:42.770 * Saving the final RDB snapshot before exiting.</span><br><span class="line">4772:S 06 Feb 02:52:42.860 * DB saved on disk</span><br><span class="line">4772:S 06 Feb 02:52:42.860 * Removing the pid file.</span><br><span class="line">4772:S 06 Feb 02:52:42.860 # Redis is now ready to exit, bye bye...</span><br><span class="line">4741:M 06 Feb 02:52:42.861 # Connection with slave 127.0.0.1:7004 lost.</span><br><span class="line">[5]   Done                    sudo .&#x2F;src&#x2F;redis-server redis.conf  (wd: &#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7004)</span><br><span class="line">(wd now: &#x2F;usr&#x2F;local&#x2F;redisCluster&#x2F;7008)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>查询集群状态,被删除的和fail状态的不同.fail仍然数据该集群,恢复后仍然可以加入集群,删除则不存在集群了,需要手动操作去加入集群.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">127.0.0.1:7008&gt; cluster nodes</span><br><span class="line">db439109563a804d8d63ffdb6937baf88adde5cc 127.0.0.1:7007 slave 54fe323634d8830f2ef93feaaedb2b70e19d0765 0 1517856814381 8 connected</span><br><span class="line">bb31a89640b381e8de18f15a845512f08ab9f16f 127.0.0.1:7002 master - 0 1517856814884 3 connected 12182-16383</span><br><span class="line">54fe323634d8830f2ef93feaaedb2b70e19d0765 127.0.0.1:7006 master - 0 1517856814884 8 connected 0-1364 5461-6826 10923-12181</span><br><span class="line">df9ac983886f0f09b0c62feef9288a9296a1a08c 127.0.0.1:7003 master,fail - 1517855992209 1517855990103 7 disconnected</span><br><span class="line">0ca3673dfd352052b651b3898ba3f807ff9c7f55 127.0.0.1:7001 master - 0 1517856815383 2 connected 6827-10922</span><br><span class="line">442c6654dfda38fe6544c96627fcafaac833a7be 127.0.0.1:7005 slave bb31a89640b381e8de18f15a845512f08ab9f16f 0 1517856814381 3 connected</span><br><span class="line">c29ea305fc8283a9987629b10dbc2ccae97c0c38 127.0.0.1:7008 myself,slave a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 0 0 0 connected</span><br><span class="line">a05c8dcbd5e7861000b3b5bf7e28d6843c85efe4 127.0.0.1:7000 master - 0 1517856813375 9 connected 1365-5460</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://www.zybuluo.com/phper/note/195558">redis集群研究和实践</a></p>
<p><a href="http://blog.51cto.com/hsbxxl/1978491">在线迁移redis cluster</a></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis cluster</tag>
      </tags>
  </entry>
</search>
